{
  "data": [
    {
      "id": "474_1755822760.900",
      "type": "feed",
      "offset": 474,
      "verb": "TOPIC_ACKNOWLEDGED_ANSWER",
      "created_time": 1755822760,
      "updated_time": 1755822760,
      "target": {
        "id": "1939488957365753521",
        "type": "answer",
        "url": "https://api.zhihu.com/answers/1939488957365753521",
        "author": {
          "id": "3470c6b2145d36d40121e8f87ed70f06",
          "url": "https://api.zhihu.com/people/3470c6b2145d36d40121e8f87ed70f06",
          "user_type": "people",
          "url_token": "41-52-98-72",
          "name": "白蘭渡",
          "headline": "八卦是人类的阶梯，吐槽可以解答世间万物。",
          "avatar_url": "https://pica.zhimg.com/50/v2-c1f231619113f2f7cb48b20fc613c31b_l.jpg?source=b6762063",
          "is_org": false,
          "gender": -1,
          "followers_count": 29,
          "is_following": false,
          "is_followed": false
        },
        "created_time": 1755190201,
        "updated_time": 1755190201,
        "voteup_count": 4,
        "thanks_count": 0,
        "comment_count": 0,
        "is_copyable": true,
        "question": {
          "id": "525116078",
          "type": "question",
          "url": "https://api.zhihu.com/questions/525116078",
          "author": {
            "id": "b9840c983f4f7e7aedb10e6b0ad126fc",
            "url": "https://api.zhihu.com/people/b9840c983f4f7e7aedb10e6b0ad126fc",
            "user_type": "people",
            "url_token": "qiu-sheng-23-64",
            "name": "秋生",
            "headline": "秋天见。",
            "avatar_url": "https://picx.zhimg.com/50/v2-30fd59dc505e7275f2d955c2169a6195_l.jpg?source=b6762063",
            "is_org": false,
            "gender": 0,
            "followers_count": 277,
            "is_following": false,
            "is_followed": false
          },
          "title": "电影《教父》中有哪些关乎家庭、江湖、宿命的东方哲学？",
          "created": 1648658292,
          "answer_count": 0,
          "follower_count": 0,
          "comment_count": 0,
          "bound_topic_ids": [
            68,
            1497,
            4328,
            39714
          ],
          "is_following": false,
          "excerpt": "",
          "relationship": {
            "is_author": false
          },
          "detail": "",
          "question_type": "normal"
        },
        "thumbnail": "https://pica.zhimg.com/50/v2-8ded69631e42da0fb80a57bce9cb231d_720w.jpg?source=b6762063",
        "excerpt": "世界上所有的亿万富翁，哪一个不是保守的？！ 而大部分创业者，都是作死的。 因为，真正的强者是勇敢地面对命运，用耐心和睿智赢得命运的眷顾。 像雷军说，他到40岁越明白这个道理。 在《教父2》的回忆片段里，我们看到了第一代教父维多·柯里昂的童年——他出生在西西里岛的一个普通农民家庭，父亲和哥哥因为冒犯了黑帮首领被杀。 母亲为保全他，与黑帮谈判未果，当场被枪杀。 那一年，他才九岁。 孤身一人，他被亲友偷运上船…",
        "excerpt_new": "世界上所有的亿万富翁，哪一个不是保守的？！ 而大部分创业者，都是作死的。 因为，真正的强者是勇敢地面对命运，用耐心和睿智赢得命运的眷顾。 像雷军说，他到40岁越明白这个道理。 在《教父2》的回忆片段里，我们看到了第一代教父维多·柯里昂的童年——他出生在西西里岛的一个普通农民家庭，父亲和哥哥因为冒犯了黑帮首领被杀。 母亲为保全他，与黑帮谈判未果，当场被枪杀。 那一年，他才九岁。 孤身一人，他被亲友偷运上船…",
        "preview_type": "default",
        "preview_text": "",
        "reshipment_settings": "allowed",
        "content": "<p></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-86584a85730a70cc8b6f4c6e492bc233_1440w.jpg\" data-rawwidth=\"1080\" data-rawheight=\"720\" data-size=\"normal\" data-original-token=\"v2-8ded69631e42da0fb80a57bce9cb231d\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-86584a85730a70cc8b6f4c6e492bc233_r.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-8db39de1aacb21f5713973e7c1bd6753_1440w.jpg\" data-rawwidth=\"1080\" data-rawheight=\"130\" data-size=\"normal\" data-original-token=\"v2-8db39de1aacb21f5713973e7c1bd6753\" data-default-watermark-src=\"https://pic2.zhimg.com/v2-8db39de1aacb21f5713973e7c1bd6753_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-8db39de1aacb21f5713973e7c1bd6753_r.jpg\"/></figure><p data-pid=\"iFFvsrMt\">世界上所有的亿万富翁，哪一个不是保守的？！</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"DAGOzfxE\">而大部分创业者，都是作死的。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"2nedKYtW\">因为，真正的强者是勇敢地面对命运，用耐心和睿智赢得命运的眷顾。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"8hvuAf0d\">像雷军说，他到40岁越明白这个道理。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"iyUr108t\">在《教父2》的回忆片段里，我们看到了第一代教父维多·柯里昂的童年——他出生在西西里岛的一个普通农民家庭，父亲和哥哥因为冒犯了黑帮首领被杀。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"VGPARvtS\">母亲为保全他，与黑帮谈判未果，当场被枪杀。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"ha7pG3JR\">那一年，他才九岁。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"6po0_cAg\">孤身一人，他被亲友偷运上船，漂洋过海来到美国。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"j6zL_6YN\">连名字都不是自己取的——移民官误以为他的姓是「柯里昂」（他的家乡名），于是一个新的身份就这样被「命运」盖了章。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"DWQlFIp5\">维多没有反抗，也无从反抗。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"Upirs7Am\">他默默接受，带着命运塞给他的名字和身份，开始了在新大陆的生活。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"lf6xrZQ-\">在那之后，他遇到的每一个人，都像是命运派来的角色：</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"tr11T2F5\">教他生存技巧的朋友，给他机会的雇主，甚至那些想要剥削他、欺压他的人——最终都成了促成他伟大的助力。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"hOnf4coJ\">有人给他机会，有人逼他成长，有人让他看清人性。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"2iMgJzLT\">维多的每一步，并不是主动「出击」，而是像一条盘踞的龙，静静等待，直到时机成熟，一击必中。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"Ti8R4hSb\">维多一生最可贵的地方，是他深知一个生存原则——在你没有足够的力量之前，不要展示锋芒。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"C7fzt2B9\">他不像普通年轻人那样急于证明自己，也不被赌性驱使去冒险。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"-G07BtRB\">他懂得耐着性子玩游戏，哪怕暂时忍辱负重，也不急于反击。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"6mtp1xtv\">他明白，命运的游戏从来不是拼一时的输赢，而是拼你是否能活到最后。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"SY6np7Fs\">当年他在商店被老板解雇，也只是默默接受，回家陪家人吃饭。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"IOtYISWL\">直到他发现街区的黑帮老大法努奇趁机勒索他的朋友，他才冷静出手。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"8msFRDvx\">那一击既精准又致命——不仅除掉了威胁，还让自己取而代之，建立起属于自己的秩序。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"QnCXXs0w\">这就是维多的智慧：</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"_jf0dhAh\">他不是反抗命运，而是勇敢地面对命运，用耐心和睿智赢得命运的眷顾。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"B2g-BTri\">对他而言，命运并非敌人，而是一盘漫长的棋局。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"iYXQlCJs\">你不必在每一步都赢，但必须在最后一步笑到最后。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"5bXXWs2m\">是龙，就得盘着。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"2Sl3M_3U\">盘着，并不是消极，而是一种高度的自控与谋略。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"MDPiJfuu\">它要求你收敛锋芒，不急功近利，不被情绪和赌性左右，而是让对手低估你，让局势自然成熟，让命运自己把机会推到你面前。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"-hIqhqpB\">强者与弱者最大的区别在于：</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"hBEp3SkI\">弱者急于证明自己，急于出手，急于在当下赢一局；</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"UHkjalZm\">强者愿意耐得住寂寞，忍得住不公，等得起时机。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"bzAjsa4h\">他们深知，命运会给那些沉得住气的人最好的牌。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"jJF5Tl_r\">维多·柯里昂的一生，是命运安排下的长跑——他没有选择出生，也没有选择名字，但他选择了面对的姿态：安静、专注、耐心、智慧。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"Tt9VGa31\">最终，他赢得的不仅是权力和财富，更是命运本身的尊重。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"zZTUSAhz\">我们每个人的人生里，都有无法选择的「被安排」：家庭、出身、时代，甚至偶然进入你生命中的人。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"KZkEB7kt\">但真正的强者，不是反抗这些安排，而是用自己的方式接住它们，把每一个看似无关的节点，都变成让自己变强的契机。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"ZssEBzHr\">记住一句话——你不是要打败命运，而是要赢得命运的青睐。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"up2FQaJv\">而赢得它的第一步，就是学会像龙一样，盘着。</p><p></p>",
        "relationship": {
          "is_thanked": false,
          "is_nothelp": false,
          "voting": 0
        },
        "is_labeled": false,
        "visited_count": 276,
        "thumbnails": [
          "https://picx.zhimg.com/50/v2-8ded69631e42da0fb80a57bce9cb231d_720w.jpg?source=b6762063"
        ],
        "favorite_count": 11,
        "answer_type": "normal",
        "is_navigator": false,
        "navigator_vote": false,
        "vote_next_step": "vote"
      },
      "brief": "{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1939488957365753521}",
      "attached_info": "CucGCMfLgIfe7o38rQEQBBoJNzQyMjQxMTIyILmn+MQGKAQwAEDaA0pCCi1UU19TT1VSQ0VfVFdPVE9XRVJfTVVMVElfU0NFTkVfVjFfUkVDQUxMX1RFWFQSATAYACAAOgp7InJhdyI6IiJ9Wgg3ODk3MzkxN2IgZjA3NWJiMDBjMjlmNGMzMzYyNWE1OWJiMzUxYWUwYTdyEzE5Mzk0ODg5NTczNjU3NTM1MjGKAQk1MjUxMTYwNziqAQlyZWNvbW1lbmTCASAzNDcwYzZiMjE0NWQzNmQ0MDEyMWU4Zjg3ZWQ3MGYwNvIBCggMEgZOb3JtYWzyASgIChIkMmY3MWQ5MjItZWI2ZS00YjkyLWJjMWMtNGM2YWNlNGUyNGM58gEGCAsSAjgwggIAiALNwsT5jDOSAiAzNDcwYzZiMjE0NWQzNmQ0MDEyMWU4Zjg3ZWQ3MGYwNpoCAMoCFlNob3JJbnRlcmVzdFdlaWdodFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXKAhRDb250ZW50QWdlV2VpZ2h0UnVsZcoCFVF1ZXN0aW9uSXNvbGF0aW9uUnVsZdoCLVRTX1NPVVJDRV9UV09UT1dFUl9NVUxUSV9TQ0VORV9WMV9SRUNBTExfVEVYVOgCA/oCC05PUk1BTF9GTE9XigMgOWNjNzk1MjExMmUzNGFmZDljNTVlYjA0YmQ0MDhkMziaAw0KAnYyEAAaBW90aGVyqAOUAtgDAOoDH3RleHRGZWVkVHdvVG93ZXJXYXJtdXBTdWNjZXNzVjH6A30SDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFOi0IAxC4CBjQBSIjdjItOGRlZDY5NjMxZTQyZGEwZmI4MGE1N2JjZTljYjIzMWQ6LQgCELgIGIIBIiN2Mi04ZGIzOWRlMWFhY2IyMWY1NzEzOTczZTdjMWJkNjc1M4AEAIgEAJIEBk5vcm1hbJoEATOgBACoBACwBAC6BAJhacIEAzQwMMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAAMQcoj+BBQAAAAAAAAAAiQW82/uZplTZP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AVQkAYAoAbeA6gGAZICLgoJNzQyMjQxMTIyEhMxOTM5NDg4OTU3MzY1NzUzNTIxGAQiCklNQUdFX1RFWFQ=",
      "action_card": false
    },
    {
      "id": "475_1755822760.973",
      "type": "feed",
      "offset": 475,
      "verb": "TOPIC_ACKNOWLEDGED_ANSWER",
      "created_time": 1755822760,
      "updated_time": 1755822760,
      "target": {
        "id": "1893597420761362572",
        "type": "answer",
        "url": "https://api.zhihu.com/answers/1893597420761362572",
        "author": {
          "id": "aef5e5b7c559b50b8b0fabfd3965582b",
          "url": "https://api.zhihu.com/people/aef5e5b7c559b50b8b0fabfd3965582b",
          "user_type": "people",
          "url_token": "mao-lao-shi-72-70",
          "name": "猫老师100418",
          "headline": "摄影、绘画、游戏、计算机爱好者",
          "avatar_url": "https://picx.zhimg.com/50/5c07145732210fa7c595cd1a1f3670aa_l.jpg?source=b6762063",
          "is_org": false,
          "gender": 1,
          "followers_count": 3590,
          "is_following": false,
          "is_followed": false
        },
        "created_time": 1744248806,
        "updated_time": 1744339630,
        "voteup_count": 6346,
        "thanks_count": 259,
        "comment_count": 499,
        "is_copyable": false,
        "question": {
          "id": "1891907489873768723",
          "type": "question",
          "url": "https://api.zhihu.com/questions/1891907489873768723",
          "author": {
            "id": "dffcd5dd60458b2d77670d9f994e1fd5",
            "url": "https://api.zhihu.com/people/dffcd5dd60458b2d77670d9f994e1fd5",
            "user_type": "people",
            "url_token": "hsksks",
            "name": "hsksks",
            "headline": "学生",
            "avatar_url": "https://pica.zhimg.com/50/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=b6762063",
            "is_org": false,
            "gender": -1,
            "followers_count": 7,
            "is_following": false,
            "is_followed": false
          },
          "title": "为什么台湾网军会以知乎为主要阵地，而不是国内其他平台？",
          "created": 1743845895,
          "answer_count": 0,
          "follower_count": 0,
          "comment_count": 68,
          "bound_topic_ids": [
            180777
          ],
          "is_following": false,
          "excerpt": "",
          "relationship": {
            "is_author": false
          },
          "detail": "",
          "question_type": "normal"
        },
        "excerpt": "微博饭圈化了，蛙蛙很难挤进去的。 贴吧太抽象了，蛙蛙很难溶进去的。 B站的用户容易被带节奏，其实是蛙蛙的好去处，但是……B站的架构是弹幕为主，和知乎不同，知乎有点像邮件往来，你写一段，我回一段，整整齐齐方便看过程，B站那就像QQ群，七嘴八舌，你说的话要么被淹没了，要么被无视了，要么被抓着吵几百条…… 这就很不利于蛙蛙搞输出，因为输出得有效率啊，在知乎你把通稿放AI里跑一下，再润个色配几张图，半小时不到就能…",
        "excerpt_new": "微博饭圈化了，蛙蛙很难挤进去的。 贴吧太抽象了，蛙蛙很难溶进去的。 B站的用户容易被带节奏，其实是蛙蛙的好去处，但是……B站的架构是弹幕为主，和知乎不同，知乎有点像邮件往来，你写一段，我回一段，整整齐齐方便看过程，B站那就像QQ群，七嘴八舌，你说的话要么被淹没了，要么被无视了，要么被抓着吵几百条…… 这就很不利于蛙蛙搞输出，因为输出得有效率啊，在知乎你把通稿放AI里跑一下，再润个色配几张图，半小时不到就能…",
        "preview_type": "default",
        "preview_text": "",
        "reshipment_settings": "disallowed",
        "content": "<p data-pid=\"rE4k0UnX\">微博饭圈化了，蛙蛙很难挤进去的。</p><p data-pid=\"ydq-bbTX\">贴吧太抽象了，蛙蛙很难溶进去的。</p><p data-pid=\"l2Td6tB-\">B站的用户容易被带节奏，其实是蛙蛙的好去处，但是……B站的架构是弹幕为主，和知乎不同，知乎有点像邮件往来，你写一段，我回一段，整整齐齐方便看过程，B站那就像QQ群，七嘴八舌，你说的话要么被淹没了，要么被无视了，要么被抓着吵几百条……</p><p data-pid=\"991Oc09Q\">这就很不利于蛙蛙搞输出，因为输出得有效率啊，在知乎你把通稿放AI里跑一下，再润个色配几张图，半小时不到就能出一篇，叫同行点个赞，马上就有几十几百个人来评论区吵架。</p><p data-pid=\"qHbQfL5n\">不说你剪个视频肯定比发文字更花时间，你上B站用弹幕吵架？发几十条都不一定有这效果，被抓住槽点了你是火了，但你也暴露了……</p><p data-pid=\"XomnM7r4\">抖Y，快S之类的则是短视频信息密度太低了，输出的东西塞不进去，只能带节奏，但节奏这玩意来的快去的也快，指望短视频平台的主流用户深入思考是不可能的，意义也有限。</p><p data-pid=\"WlH9dAsC\">所以，知乎可能不是最好的阵地，但综合性价比、产出收益比、成本、广度、深度、投送速度等方面来说，更适合蛙蛙们。</p>",
        "relationship": {
          "is_thanked": false,
          "is_nothelp": false,
          "voting": 0
        },
        "is_labeled": false,
        "visited_count": 314256,
        "favorite_count": 515,
        "answer_type": "normal",
        "is_navigator": false,
        "navigator_vote": false,
        "vote_next_step": "vote"
      },
      "brief": "{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1893597420761362572}",
      "attached_info": "CscGCMfLgIfe7o38rQEQBBoJNzIyMTQ5Mzc0IOa/3L8GKMoxMPMDQNsDSkMKF1RTX1NPVVJDRV9USEVNRV9XQUtFX1VQEiJ0aGVtZTpkZXRlY3Q6Y29udGVudDp0aGVtZTppZDo0MjI1GAAgADoAWgkxMTQzNDQ0NDdiIGYwNzViYjAwYzI5ZjRjMzM2MjVhNTliYjM1MWFlMGE3chMxODkzNTk3NDIwNzYxMzYyNTcyigETMTg5MTkwNzQ4OTg3Mzc2ODcyM6oBCXJlY29tbWVuZMIBIGFlZjVlNWI3YzU1OWI1MGI4YjBmYWJmZDM5NjU1ODJi8gEKCAwSBk5vcm1hbPIBKAgKEiQyYjdlMWE0YS04MjVmLTRhMzktYjhmOS1iYjdhZGU2Y2QxYzPyAQYICxICODCCAgCIAs3CxPmMM5ICIGFlZjVlNWI3YzU1OWI1MGI4YjBmYWJmZDM5NjU1ODJimgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCFkFjdGlvblNob3JJbnRlcmVzdFJ1bGXKAhtJbnRlcmFjdGlvblNob3JJbnRlcmVzdFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXKAhRDb250ZW50QWdlV2VpZ2h0UnVsZcoCE1RoZW1lV2FrZVVwUmV3ZWlnaHTKAhVRdWVzdGlvbklzb2xhdGlvblJ1bGXaAhdUU19TT1VSQ0VfVEhFTUVfV0FLRV9VUOgCAvoCC05PUk1BTF9GTE9XigMgOWNjNzk1MjExMmUzNGFmZDljNTVlYjA0YmQ0MDhkMziaAw0KAnYyEAAaBW90aGVyqAOQlxPYAwDqAxNUaGVtZVdha2VVcFJlY2FsbGVy+gMfEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERYAEAIgEAJIEBk5vcm1hbJoEATKgBACoBACwBAC6BAZtYW51YWzCBAMxNjDIBADSBA/mjqjojZDlt7Lmm7TmlrDYBADwBAD5BAAAACB0Qbo/gQUAAAAAAAAAAIkFvNv7maZU2T+SBQCaBQNkZnSiBQNkZnSyBQExuQUAAAAAAAAAANAFAOAFAOgFAPAFUJAGAKAG3wOoBgOSAi4KCTcyMjE0OTM3NBITMTg5MzU5NzQyMDc2MTM2MjU3MhgEIgpJTUFHRV9URVhU",
      "action_card": false
    },
    {
      "id": "476_1755822760.846",
      "type": "feed",
      "offset": 476,
      "verb": "TOPIC_ACKNOWLEDGED_ARTICLE",
      "created_time": 1755822760,
      "updated_time": 1755822760,
      "target": {
        "id": "1927420378491389862",
        "type": "article",
        "url": "https://api.zhihu.com/articles/1927420378491389862",
        "author": {
          "id": "a002dfc783992b0cd802ee5c25d501d2",
          "url": "https://api.zhihu.com/people/a002dfc783992b0cd802ee5c25d501d2",
          "user_type": "people",
          "url_token": "zhang-zong-13-88",
          "name": "Machine Learning",
          "headline": "公众号：机器AI学习",
          "avatar_url": "https://pica.zhimg.com/50/v2-2c153dfec5b450ebf5f7931e3a0d43ba_l.jpg?source=b6762063",
          "is_org": false,
          "gender": -1,
          "followers_count": 404,
          "is_following": false,
          "is_followed": false
        },
        "title": "万字长文——生成式推荐有几种写法",
        "image_url": "https://picx.zhimg.com/v2-d53268dcfaeb945795a38be340098c8c.jpg?source=7e7ef6e2&needBackground=1",
        "comment_permission": "all",
        "created": 1753606348,
        "updated": 1755424587,
        "voteup_count": 142,
        "voting": 0,
        "comment_count": 3,
        "linkbox": {
          "category": "",
          "pic": "",
          "title": "",
          "url": ""
        },
        "excerpt": "Motivation随着大语言模型的迅速发展，生成式推荐作为一种有前景的新范式备受关注。生成式推荐简单来说就是将大模型的训练范式与推荐技术结合，在推荐算法红利逐渐见顶的今天，各家也在如火如荼的开展对于生成式推荐的探索。目前主流的深度学习推荐模型（DLRMs）依赖大量手工设计的特征（如用户 ID、物品类别、点击次数等），但随着数据规模爆炸式增长，这些模型面临 计算效率低下的问题 —— 比如处理数十亿用户行为时，计算成…",
        "excerpt_new": "Motivation随着大语言模型的迅速发展，生成式推荐作为一种有前景的新范式备受关注。生成式推荐简单来说就是将大模型的训练范式与推荐技术结合，在推荐算法红利逐渐见顶的今天，各家也在如火如荼的开展对于生成式推荐的探索。目前主流的深度学习推荐模型（DLRMs）依赖大量手工设计的特征（如用户 ID、物品类别、点击次数等），但随着数据规模爆炸式增长，这些模型面临 计算效率低下的问题 —— 比如处理数十亿用户行为时，计算成…",
        "preview_type": "default",
        "preview_text": "",
        "column": {
          "id": "c_1631735029817663488",
          "type": "column",
          "url": "https://api.zhihu.com/columns/c_1631735029817663488",
          "author": {
            "id": "",
            "url": "",
            "user_type": "people",
            "url_token": "",
            "name": "匿名用户",
            "headline": "",
            "avatar_url": "https://picx.zhimg.com/v2-d41c2ceaed8f51999522f903672a521f_l.jpg?source=b6762063",
            "is_org": false,
            "gender": -1,
            "followers_count": 0,
            "is_following": false,
            "is_followed": false
          },
          "title": "机器AI学习",
          "imageUrl": "https://pic1.zhimg.com/v2-f111d7ee1c41944859e975a712c0883b_720w.jpg?source=d16d100b",
          "comment_permission": "private",
          "intro": "",
          "updated": 1681815947,
          "is_following": false
        },
        "content": "<h2>Motivation</h2><p data-pid=\"mU5PEvru\">随着大语言模型的迅速发展，生成式推荐作为一种有前景的新范式备受关注。生成式推荐简单来说就是将大模型的训练范式与推荐技术结合，在推荐算法红利逐渐见顶的今天，各家也在如火如荼的开展对于生成式推荐的探索。目前主流的深度学习推荐模型（DLRMs）依赖大量手工设计的特征（如用户 ID、物品类别、点击次数等），但随着数据规模爆炸式增长，这些模型面临<b>计算效率低下</b>的问题 —— 比如处理数十亿用户行为时，计算成本会呈指数级上升，难以扩展。而生成式推荐不再依赖手工设计的复杂特征，而是将所有特征（包括用户 ID、物品类别、点击频率等）编码成统一的时间序列，将所有特征都看做LLM中的token，<b>模型的目标是根据历史交互序列生成未来的交互行为</b>。传统的DLRMs范式提升明显遇到了瓶颈，且模型迭代的边际收益持续走低，在这种背景下，各大厂也尝试将大模型成功的训练范式迁移到推荐系统中去，以实现在推荐系统中的scaling law，从而为推荐算法的迭代走出一条新的方向。本文整理了这段时间各大厂提出的主流生成式推荐模型，并逐一分析它们的技术特点，供读者参考。</p><h2>精排</h2><h3>GRs</h3><p data-pid=\"HkWn0biR\">首先来介绍一下meta在2024年发表的GRs（Generative Recommendations），作者还起了一个响亮的名字：行动胜过语言。从论文名就可以看出，模型通过建模海量用户的行为序列，来预测用户下一次动作。总的来说，这篇工作的亮点还是很多的，第一次在核心产品线替换掉了分层海量特征的模型范式，第一次在推荐模态观测到了语言模态的scaling law；<b>同时实现了召回和精排的建模</b>，召回精排累计收益达到了惊人的18.6%，是工业级推荐系统大规模scaling的<b>开创性工作。</b></p><ul><li data-pid=\"Uo8WHlCk\">特征处理</li></ul><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-3f23d6c846a5afe559c4ab72fbb99cb9_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1126\" data-rawheight=\"680\" data-original-token=\"v2-ff1d33b20fe9293d642ad7c84af0b819\" class=\"origin_image zh-lightbox-thumb\" width=\"1126\" data-original=\"https://picx.zhimg.com/v2-3f23d6c846a5afe559c4ab72fbb99cb9_r.jpg\"/><figcaption>GRs与DLRMs对比</figcaption></figure><p data-pid=\"e6cCZjS_\">我们先从特征的角度看一下与传统的DLRMs相比，GRs在建模范式上究竟有什么不同，又为什么说它是颠覆式的创新？如上图左侧是DLRMs的特征结构，通常可分为id类和dense类，其中id类经过embedding层后转化为稠密向量，输入给模型后结合label计算loss；而右侧的GRs结构则完全不同，它首先将时间跨度最长的序列设置为主序列（通常是历史曝光序列），将item按时间先后逐一放置。再将辅助时间序列特征（如用户profile特征、关注作者、加入话题等）也按时序插入到主序列中，<b>且同一时间片内插入最早发生的那个特征</b>，这样就实现了将所有特征序列化。值得注意的是，作者筛选的这些都是相对稳定、缓慢变化的id类特征，而像<b>统计类特征这种变化频繁的不会加入进去</b>。主要是因为user和item在实时进行交互，期间会产生大量变化的统计特征，从计算和存储的角度来看，将这些特征<b>完全序列化是不可行的。</b>其次，用户序列特征中也隐含了统计类信息，那么通过特征交叉模型是可以捕获到统计特征的，且随着序列长度的拉大，特征的挖掘也就越丰富、越置信。</p><ul><li data-pid=\"7XRdF0Ro\">重塑召排</li></ul><p data-pid=\"gPd89zCh\">上文提到过GRs的一大特点就是一套框架，同时支持召回和精排，这得益于它的直推式学习（transductive learning）方式。与传统的归纳式学习（instructive Learning）不同，直推式学习更强调从历史数据中学习规律，发现隐含的模式和结构。GRs在召回和排序建模方式如下表所示：</p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-04908fa96dd321a13890c7a0c3eb2a96_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1230\" data-rawheight=\"306\" data-original-token=\"v2-fefee99d6c98a03e0166026a2ae98607\" class=\"origin_image zh-lightbox-thumb\" width=\"1230\" data-original=\"https://pic3.zhimg.com/v2-04908fa96dd321a13890c7a0c3eb2a96_r.jpg\"/></figure><p data-pid=\"cDXvVeEp\">排序：排序是做下一个action的预估。 <img src=\"https://www.zhihu.com/equation?tex=x_is\" alt=\"x_is\" eeimg=\"1\"/> 表示模型输入，其中φ表示item，a表示action（如曝光、点击、点赞等）。如果暂时抛开其他id类特征，我们可以看到整个输入序列是item和对应action的交替序列，其中所有输入特征都要转成id embedding。<img src=\"https://www.zhihu.com/equation?tex=y_is\" alt=\"y_is\" eeimg=\"1\"/> 表示模型输出，当输入是item时，输出是对应item的预估action；而当输入是非item时（action、其他特征），输出则会做一个mask。这样设计的好处是让整个模型实现了自回归结构，<b>即第t个位置的输入预估的是t+1的输出</b>，只不过让action预估item本身无意义，所以做了一个mask。序列总长度大约是item长度的两倍。线上直接将用户的序列按时间拼接，并对target item进行action预估。</p><p data-pid=\"s9Dxdn1H\">召回：召回是做下一个item的预估。输入特征和排序完全一致，只是在模型输出时有所区别。由于召回更关心的是下一个item的选择，因此当输入是item时，不需要对action预估；当输入是action时，且下一个item是正样本，我们就预估下一个item，否则也进行mask，因为我们没必要预估用户不喜欢的item。训练方式应该还是正样本+负采样，预测时将最后一个位置的输出作为user embedding，并在线上进行ANN检索，这个过程和双塔模型基本一致。</p><ul><li data-pid=\"HBxmoiX8\">HSTU</li></ul><p data-pid=\"pgTET9Yn\">相较于传统的自回归attention，GRs提出了HSTU（Hierarchical Sequential Transduction Unit）来作为特征提取器，其模型结构与DLRMs对比如下图所示：</p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-ebe2b9470003a4c4196dfc871c39bebc_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"732\" data-rawheight=\"814\" data-original-token=\"v2-0a3b17016e5041fbd4f06ae1d840def0\" class=\"origin_image zh-lightbox-thumb\" width=\"732\" data-original=\"https://pic1.zhimg.com/v2-ebe2b9470003a4c4196dfc871c39bebc_r.jpg\"/><figcaption>DLRMs vs HSTU</figcaption></figure><p data-pid=\"Ftd4iCKO\">让我们回顾一下传统的DLRMs，其通常由特征提取层、特征交互层、表征层组成。id特征经过embedding lookup后转化为稠密向量，再和各种模型层做非线性变换、特征交叉、多任务等，最终到输出层进行loss计算，这是一个典型的DLRMs建模范式。而GRs将整个特征体系序列化后，通过多层HSTU提取特征间的交互信息，与Transformer Decoder相比，主要有以下几个优化：</p><ol><li data-pid=\"rC-aA1YA\">sigmoid取代softmax：这个Motivation和DIN类似，使用sigmoid可以保留数值本身的强度，避免被softmax拉扯。rab(P,T)在原文中是引入了一个attention网络，<b>用来计算position信息和time_diff信息的attention偏置。</b></li><li data-pid=\"PSspZvRa\">QKV-&gt;QKVU：QKVU是Embedding的最后一维split而来，U代表着原始的向量表征，最终会和attention后的表征相乘，同时保留了深度交互后和原始的特征表征，有点类似于resnet的操作。因为深度交互压缩后的特征可能会丢失一些原始信息，这样可以增强模型的泛化能力。</li><li data-pid=\"XTb5xEfi\">激活函数：MLP中使用silu(silu=x*sigmoid(x))作为激活函数，同时保留了线性和非线性激活函数，结合了relu和sigmoid的信息，且不会产生神经元死亡的现象，提升了模型的表现和稳定性。</li></ol><p data-pid=\"GujrDXDY\">最后看一下GRs的scaling表现，以召回为例，随着模型的参数增多、复杂度和算力增加，可以看到GRs在hitrate@100上的效果基本上程线性趋势发展，而DLRM的scaling基本没啥变化，说明基于生成式推荐架构可以带来模型的scaling。对于HSTU来说，scaling主要包括调整HSTU的超参数，包括残差层数、序列长度、embedding dim, attention heads数量。对召回而言，还额外调整了负样本的个数。不过这里作者也指出，<b>scaling中最work的还是序列长度，</b>更长的序列能够捕捉更多的上下文和依赖关系，从而表现更好。因此在可能的情况下，扩大序列长度是很重要的。</p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-6705851ea4f09e08adfce613196055ba_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"942\" data-rawheight=\"534\" data-original-token=\"v2-3331fccaeb3d5d224b9c125c0fb75a4b\" class=\"origin_image zh-lightbox-thumb\" width=\"942\" data-original=\"https://pica.zhimg.com/v2-6705851ea4f09e08adfce613196055ba_r.jpg\"/><figcaption>scaling law对比</figcaption></figure><ul><li data-pid=\"SFnqbszw\">总结</li></ul><p data-pid=\"WzfIr9EY\">以上就是GRs这个工作的核心结构，除此之外，论文还分享了很多训练推理中的性能优化技巧，这里就不一一展开了。综上所述，GRs推翻了DLRM的id embedding训练范式，开创了生成式推荐的新篇章，作者首次展示了从LLMs中得出的Scaling Law同样适用于大规模推荐系统，并能成功落地。对后续生成式推荐的优化起到了很强的借鉴意义。</p><h3>MTGR</h3><p data-pid=\"dX1Znte1\">下面来介绍美团的工作——MTGR，从名字中就可以看出，是参考GR做的工作，主要应用于精排。相比于meta的HSTU，MTGR的模型结构更加简化，减少了序列长度，优化了样本组织形式和模型结构。对于想尝试生成式推荐的团队来说，美团提供了一个更适合落地的轻量化解法。在美团外卖场景下，对比基准模型，单样本前向推理FLOPs提升65倍，离线CTCVR GAUC + 2.88pp，外卖首页列表订单量+1.22%，PV_CTR + 1.31%。MTGR相比于HSTU有以下几个优化点：</p><ol><li data-pid=\"xvRuzqkP\">基于用户的历史序列预测target的action，造成user和item token之间的割裂，然而user和item的交叉特征十分重要，MTGR中加入了这一特征。尽量保证特征体系和base对齐。</li><li data-pid=\"j5JuuIBi\">组层归一化(GLN)对异质token分别归一化，实现多类信息的并行高效建模；</li><li data-pid=\"2jehp56b\">动态掩码策略，通过全注意力、自回归及自可见三种模式的灵活切换确保性能并防止信息泄露。</li><li data-pid=\"14JNsvaq\">去掉历史序列中的action token，以缩短序列长度</li></ol><ul><li data-pid=\"h1CfuebQ\">样本组织</li></ul><p data-pid=\"tjRrf4TE\">首先看一下MTGR对于样本组织方式的优化，与HSTU按session粒度生成样本不同，MTGR采用了按用户粒度压缩训练数据集的办法，即将当天同一用户的candidate都拼接成了一行样本。这样做的好处在于降低了重复的用户特征存储，解决了同一个用户的N行样本存在大量重复编码的问题，提升了计算效率。额外的，为了避免训练穿越，对于用户行为序列以及target item，在数据中保存了其发生的原始时间戳，以用于生产掩码保证正确的因果性，具体的掩码细节将在下一节展开介绍。</p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-7d1e30cf2d47b8fb622d2cb60b2d9164_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1646\" data-rawheight=\"568\" data-original-token=\"v2-cfc0110478cfd621a4c293464c0c0fad\" class=\"origin_image zh-lightbox-thumb\" width=\"1646\" data-original=\"https://pic1.zhimg.com/v2-7d1e30cf2d47b8fb622d2cb60b2d9164_r.jpg\"/></figure><ul><li data-pid=\"Od3rJ9w6\">特征工程&amp;模型结构</li></ul><p data-pid=\"3y3qnHqG\">MTGR的特征主要包括五大类型，分别是用户profile特征，长期序列，实时序列，用户&amp;target交叉特征，以及target item特征。一行样本具体表示如下：</p><p data-pid=\"2Py56sNR\"><img src=\"https://www.zhihu.com/equation?tex=D_i%3D%5BU_i%2C%5Cvec%7BS_i%7D%2C%5Cvec%7BR_i%7D%2C%5BC%2CI%5D_1%2C%5BC%2CI%5D_2%2C...%2C%5BC%2CI%5D_N%5D%5C%5C\" alt=\"D_i=[U_i,\\vec{S_i},\\vec{R_i},[C,I]_1,[C,I]_2,...,[C,I]_N]\\\\\" eeimg=\"1\"/></p><ul><li data-pid=\"PCXC7iW5\">Ui：用户profile特征，包括用户年龄、性别等，统一放到序列的最前面，作为静态特征使用</li><li data-pid=\"S81gACDz\">Si：用户长期序列，序列中包含多个item，每个item包含物品ID，标签，品牌等特征</li><li data-pid=\"le5i8dAI\">Ri：用户实时序列，最近几个小时或者最近一天交互的物品序列，表示用户实时兴趣和偏好，结构和<img src=\"https://www.zhihu.com/equation?tex=%5Cvec%7BS%7D\" alt=\"\\vec{S}\" eeimg=\"1\"/>特征类似；</li><li data-pid=\"xauuI8nv\">C：用户&amp;target交叉特征，如用户在物品标签上的统计特征，用户id和物品id交叉特征；</li><li data-pid=\"UPuHBGTs\">I：表示候选集的特征，比如物品ID，标签，品牌。</li></ul><p data-pid=\"j7pepeFd\">这里将C和I打包，共同作为target特征，弥补了HSTU无法使用交叉特征的缺陷。相比于DLRM一行样本只有一个target，MTGR一行样本有N个。实际使用时，对于包含item的特征，将item携带的sideinfo、统计特征一起concat，使用一个MLP做非线性变化，实现embedding size和profile特征对齐。在丰富了item特征的同时，没有引入新的token。论文中没有明说，但从模型特结构图可以看到，历史序列是没有进行梯度回传的，只有在target侧有。这一点与HSTU还是有很大区别，个人猜测可能是为了防止样本的重复训练而引起过拟合。</p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-e5616568cf86dfca61a875b774906bc3_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1766\" data-rawheight=\"904\" data-original-token=\"v2-d20c84464970e8735481788b8150f15a\" class=\"origin_image zh-lightbox-thumb\" width=\"1766\" data-original=\"https://picx.zhimg.com/v2-e5616568cf86dfca61a875b774906bc3_r.jpg\"/></figure><p data-pid=\"GSzJBk_p\">除此之外，MTGR使用了GLN来替换传统的LN，即对于不同类型的token，学习不同的LN参数。从而使得异构特征能自适应归一化，防止被不同类型的token干扰。</p><ul><li data-pid=\"PtI40-Dz\">掩码机制</li></ul><p data-pid=\"5oWz4L5F\">下面来回答上文遗留的掩码问题，与HSTU纯自回归不同，MTGR设计了三种不同的掩码方式。整体类似一个T5结构，包含encoder-decoder，掩码机制如下图所示，其中每一行代表当前token能看到哪些token，每一列代表当前token能被哪些token看到。</p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-85a6c4e72e14e2cd5c0dbe644adbd434_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"4675\" data-rawheight=\"5137\" data-original-token=\"v2-aeee7fc0c17e545add2323d71a804926\" class=\"origin_image zh-lightbox-thumb\" width=\"4675\" data-original=\"https://pic3.zhimg.com/v2-85a6c4e72e14e2cd5c0dbe644adbd434_r.jpg\"/></figure><ul><li data-pid=\"e1FOPJrF\">用户profile和长期序列特征：使用full visible的attention机制，对所有特征可见。因为这类特征属于静态特征，包含的信息比较稳定，不会产生信息泄露。</li><li data-pid=\"LJ4nRvqc\">实时序列：因为实时序列都是近期发生的，使用自回归防止未来的信息泄露，每个token只能被它之后的token看见（包括target），这与HSTU逻辑一致。</li><li data-pid=\"C0lE-8-r\">target item：使用对角验码，只对自己可见，防止target item之间出现信息交互干扰训练。这与HSTU在推理效率上的优化类似</li></ul><p data-pid=\"Ka3Q2zjA\">总结</p><p data-pid=\"G4PbLjcJ\">总的来说，MTGR大部分还是沿袭了HSTU的做法，其中很多优化工作还是可圈可点的。虽说是生成式推荐，其中也能看到不少传统推荐算法的优化逻辑，如增加交叉特征、GLN等。以及在减少复杂度做出的优化，如按用户粒度构建样本、去掉action token缩短序列，省去了rab这种复杂的attention bias逻辑（应该是有对应的替换，文中没明说）。整体模型应该还是一个天级更新的模型，团队的初步构想应该也是奔着能快速上线，基于GR做出的最小改动吧。不过由于只在candidate处做了梯度回传，因此整个结构看上去不太像一个预训练的LLM，反倒更类似于一个拉长了序列的、复杂的异构attention的DLRM，从这个角度来说改进不明显。当然HSTU在精排中也是一个判别式模型，所以对于实现真正的生成式可能还需要很长的路要走。</p><h2>召回</h2><p data-pid=\"YFSlM0xg\">相比于精排，生成式推荐在召回上可能更好落地一点。因为精排本质上是在给定候选集的情况下，对candidate的action进行预估；而召回的目的就是生成候选集，因此天然就多了一层「生成」的Motivation。</p><h3>Tiger</h3><p data-pid=\"Iza5MmsG\">首先介绍Google的Tiger模型，这篇论文是在2023年发表的。我们都知道2023年是大模型元年，因此这个工作的江湖地位就不用多说了，也是召回方向的一篇开山之作。它的主要贡献在于提出了id的语义化，即通过RQ-VAE将id embedding转化为多个语义embedding，以至于RQ-VAE这一量化技术几乎成为了生成式推荐的标配（我们在后续模型讲解中也能看到它的身影）。传统的双塔模型，以及上文提到的HSTU在处理召回任务时，都是通过生成user和item的embedding后做ANN检索；而Tiger摈弃了这一模式，真正实现了「生成」下一个item作为召回结果，也就是LLM中的NTP（Next Token Prediction）任务。</p><p data-pid=\"Gpn_lMuT\">Tiger的训练框架包括两阶段，分别是<b>基于内容特征的语义 ID 生成，</b>以及<b>基于语义 ID 的生成式推荐系统训练。</b>Tiger的整体训练框架如下图所示，下面让我们分别看一下两阶段的训练逻辑。</p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-e80681e901ace1e82d9f53faf8db9d18_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1650\" data-rawheight=\"696\" data-original-token=\"v2-949f0b24fafd74aeb9b4daf050ef45c0\" class=\"origin_image zh-lightbox-thumb\" width=\"1650\" data-original=\"https://pic1.zhimg.com/v2-e80681e901ace1e82d9f53faf8db9d18_r.jpg\"/></figure><ul><li data-pid=\"HmcH9hbs\">语义id生成</li></ul><p data-pid=\"Be0qL6L3\">如上图(a)所示，我们会将用户的语义信息，以及sideinfo等特征信息（如类别、品牌等），通过一个预训练的文本编码器（如 Sentence-T5 和 BERT）转换物品的文本特征以获得<b>语义嵌入，</b>再通过量化技术转为语义ID<b>。</b>从图(b)中可以看出，我们需要将语义 ID 定义为长度为3的codewords元组，元组中的每个codeword来自不同的codebook，一个codebook包含一组codeword。因此，语义 ID 能够唯一表示的物品数量等于各codebook大小的乘积。在Tiger中，一个codebook中有256个codeword，这样能表示的物料个数大概有千万级（256^3）。</p><p data-pid=\"4ZXAgdtD\">尽管生成语义 ID 的不同技术会导致 ID 具有不同的语义属性，希望它们至少具备以下特性：<b>相似物品（内容特征相似或语义嵌入接近的物品）的语义 ID 应有重叠。</b>例如，语义 ID 为 (10, 21, 35) 的物品应与 ID 为 (10, 21, 40) 的物品更为相似，而非与 ID 为 (10, 23, 32) 的物品相似。引入语义<b>能够实现两种能力：一是提高冷启动推荐效果，二是生成多样化的推荐。</b>提高冷启好理解，由于输入都是语义信息，对冷启item来说更友好；其次在预估时，我们可以通过控制softmax的temperature，便于在准确性和多样性之间寻找tradeoff。关于RQ-VAE的实现逻辑我们将在下文详细讲解。</p><ul><li data-pid=\"vcw7P1uw\">模型训练</li></ul><p data-pid=\"q-LLz33i\">整体类似于一个T5的架构。在训练完RQ-VAE后，我们将物料全部转化为语义ID元组，并做一个语义ID元组-&gt;物料ID的映射便于查找。接着将语义ID embedding序列拼接到用户embedding后面，使用双向Transformer encoder实现特征间的充分交叉，这在一定程度上也缓解了双塔长期诟病的ui特征交叉太晚的问题。在生成物料时，使用了Transformer decoder结构，让语义ID逐一生成。最后将生成的语义ID元组放到事先存好的映射表中查找，就知道生成的物料ID是个啥了。由于codebook大大缩短了候选Token的个数（从千万级到256），这样在softmax时就不至于太慢，也就不用像传统召回那样做负采样+ANN检索了，<b>从而真正实现生成式检索</b>。</p><p data-pid=\"OPUuTOig\">ID碰撞：在生成语义id时可能出现多个物料产生的id元组完全一致的情况，为消除碰撞，在有序语义编码的末尾附加一个额外 token 以确保其唯一性（如果没有碰撞末尾也会有个0）。例如，若两个物品共享语义 ID（12, 24, 52），通过附加 token 将其区分为（12, 24, 52, 0）和（12, 24, 52, 1）。需要注意的是，碰撞检测和修复仅在 RQ-VAE 模型训练完成后执行一次。如果在预测时恰好生成了碰撞id，该选择哪个作为结果呢？文中没有明说，一个简单的做法就是都选上，反正是召回不怕多，碰撞了反而说明语义近似。总之末尾补一个Token让物料之间能区分就行了。</p><p data-pid=\"Zg9EQxrl\">无效结果：由于Tiger具有生成性，解码器生成的语义 ID 可能与推荐语料库中的物品不匹配。然而，论文也做了大量的数据测试，此类事件发生的概率较低。</p><ul><li data-pid=\"-wfbsngv\">RQ-VAE</li></ul><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-a52c6338d2e38895cf0321af1e4628bc_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1632\" data-rawheight=\"652\" data-original-token=\"v2-44ed9961996f0f9d7f1599b343c5b891\" class=\"origin_image zh-lightbox-thumb\" width=\"1632\" data-original=\"https://pic1.zhimg.com/v2-a52c6338d2e38895cf0321af1e4628bc_r.jpg\"/><figcaption>RQ-VAE</figcaption></figure><p data-pid=\"y49GBMfQ\">RQ-VAE的全称是「残差量化」VAE，顾名思义其中用到了残差的思想。以上图为例，我们初始化了三个codebook，每个codebook有8个codeword，每个codeword对应一个embedding。训练时我们会初始化codebook，在encoder得到语义嵌入后，我们会和codebook1中的所有embedding计算距离，选择距离最接近的作为d0位置的codeword（图中选择的是7）；接下来将输入减去d0 codeword，得到残差表征（vector 1），再去和codebook2中的所有embedding计算距离，得到d1位置的codeword。不断重复这个过程，我们最终会得到每一层的codeword组成语义code元组（7,1,4）。最后将语义code相加后得到量化表征，经过一个Decoder后得到输出表征 <img src=\"https://www.zhihu.com/equation?tex=%5Chat%7Bx%7D\" alt=\"\\hat{x}\" eeimg=\"1\"/> 。使用残差的好处在于范数会随着层级增加而递减，因此<b>允许不同层级具有不同的粒度</b>，即每一层语义含义粒度由粗到细。</p><p data-pid=\"FEhlImwV\">RQ-VAE 的损失函数定义为<img src=\"https://www.zhihu.com/equation?tex=%5C%28L%28x%29+%3A%3D+L_%7B%5Ctext%7Brecon%7D%7D+%2B+L_%7B%5Ctext%7Brqvae%7D%7D%5C%29\" alt=\"\\(L(x) := L_{\\text{recon}} + L_{\\text{rqvae}}\\)\" eeimg=\"1\"/>。其中 <img src=\"https://www.zhihu.com/equation?tex=%5C%28L_%7B%5Ctext%7Brecon%7D%7D+%3A%3D+%5C%7Cx+-+%5Chat%7Bx%7D%5C%7C%5E2%5C%29\" alt=\"\\(L_{\\text{recon}} := \\|x - \\hat{x}\\|^2\\)\" eeimg=\"1\"/> ， <img src=\"https://www.zhihu.com/equation?tex=%5C%28L_%7B%5Ctext%7Brqvae%7D%7D+%3A%3D+%5Csum_%7Bd%3D0%7D%5E%7Bm-1%7D+%5C%7C+%5Ctext%7Bsg%7D%5Br_i%5D+-+e_%7Bc_i%7D+%5C%7C%5E2+%2B+%5Cbeta+%5C%7C+r_i+-+%5Ctext%7Bsg%7D%5Be_%7Bc_i%7D%5D+%5C%7C%5E2%5C%29\" alt=\"\\(L_{\\text{rqvae}} := \\sum_{d=0}^{m-1} \\| \\text{sg}[r_i] - e_{c_i} \\|^2 + \\beta \\| r_i - \\text{sg}[e_{c_i}] \\|^2\\)\" eeimg=\"1\"/> 。这里 <img src=\"https://www.zhihu.com/equation?tex=%5C%28%5Chat%7Bx%7D%5C%29\" alt=\"\\(\\hat{x}\\)\" eeimg=\"1\"/> 是解码器的输出， <img src=\"https://www.zhihu.com/equation?tex=%5C%28%5Ctext%7Bsg%7D%5C%29\" alt=\"\\(\\text{sg}\\)\" eeimg=\"1\"/> 表示停止梯度操作。该损失函数用于联合训练编码器、解码器和 codebook。</p><p data-pid=\"zpdaqmMg\">值得注意的是，为防止 RQ-VAE 出现 codebook 崩溃（即大多数输入仅映射到少数 codebook 向量），采用基于 k-means 聚类的 codebook 初始化方法。论文中没具体说，这里讲一个我的思路。比如将encoder输出的语义embedding聚类成256个类，并将这256个类作为第一层的codebook初始参数；接着将语义embedding减去各自的簇心，再次聚成256个类，作为第二层的codebook初始参数，以此类推。</p><ul><li data-pid=\"LfdDChy7\">总结</li></ul><p data-pid=\"-pW3RWGa\">作为生成式召回的代表作之一，Tiger给我们的惊喜还是很多的。它最大贡献在于引入了残差量化技术，减小了Token词表大小，让生成式召回成为可能。然而语义id引入的更多是文本信息，对于统计类特征没有覆盖，过分关注语义信息可能造成行为信息的缺失，这一点未来应该是有优化空间的。</p><h3>COBRA</h3><p data-pid=\"AdNHJgJo\">百度在Tiger的基础上做了些优化，提出了COBRA的生成式召回框架。百度的同学们认为，基于语义id的检索过程粒度还是太粗，<b>依靠稀疏 ID只能捕捉物品的类别本质，缺乏细粒度信息。</b>而 COBRA 生成的稠密向量能捕获物品的详细属性信息，比如物品的具体特征、独特卖点等。在向量空间中，语义相近的物品其稠密向量的距离更接近，<b>这有助于模型理解物品间的细微差别和联系</b>。因此，COBRA最大的优化点就是在生成式基础上引入了稠密检索能力，从而进一步提升生成式推荐的性能和效率。</p><ul><li data-pid=\"xE3cc3kH\">模型结构</li></ul><p data-pid=\"z3-VwHfN\">COBRA基本上复用了Tiger语义id的模型结构，并在此基础上增加了稠密向量，整体结构如下图所示：</p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-ec1a88a76cd64e5a09babbcbd3d8bb21_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1528\" data-rawheight=\"1086\" data-original-token=\"v2-a885382681c0a146043ad4c3148aa710\" class=\"origin_image zh-lightbox-thumb\" width=\"1528\" data-original=\"https://pic4.zhimg.com/v2-ec1a88a76cd64e5a09babbcbd3d8bb21_r.jpg\"/><figcaption>COBRA</figcaption></figure><p data-pid=\"nAeknGaa\">稀疏id：这里复用了Tiger的RQ-VAE的语义生成方式，生成了长度为3的语义id元组（图中出于简便，用ID代表元组），且codebook是预训练好的。</p><p data-pid=\"SnJgdVOz\">稠密向量：将类别、标题、品牌等文本信息输入到一个Transformer encoder结构中去，输入侧增加文本类别、位置编码等信息，提升模型区分不同标记及其位置的能力。在文本开头增加[CLS]标记，输出作为整个文本的稠密表征。值得注意的是，稠密向量提取器<b>Transformer encoder也是端到端训练的</b>，能更好地捕捉用户 - 物品交互中的复杂信息，动态优化对物品的表示。</p><p data-pid=\"lWogfvmw\">级联训练：生成式召回的模型结构采用了Transformer Decoder结构，特征输入按照语义ID、稠密向量交错的顺序放置。COBRA 把目标物品概率分布建模拆成两个阶段，分别预测稀疏 ID <img src=\"https://www.zhihu.com/equation?tex=ID_%7Bt%2B1%7D\" alt=\"ID_{t+1}\" eeimg=\"1\"/> 和稠密向量 <img src=\"https://www.zhihu.com/equation?tex=v_%7Bt%2B1%7D\" alt=\"v_{t+1}\" eeimg=\"1\"/>，<img src=\"https://www.zhihu.com/equation?tex=P%5Cleft%28ID_%7Bt%2B1%7D%2C+v_%7Bt%2B1%7D+%7C+S_%7B1%3At%7D%5Cright%29%3DP%5Cleft%28ID_%7Bt%2B1%7D+%7C+S_%7B1%3At%7D%5Cright%29+P%5Cleft%28v_%7Bt%2B1%7D+%7C+ID_%7Bt%2B1%7D%2C+S_%7B1%3At%7D%5Cright%29%5C\" alt=\"P\\left(ID_{t+1}, v_{t+1} | S_{1:t}\\right)=P\\left(ID_{t+1} | S_{1:t}\\right) P\\left(v_{t+1} | ID_{t+1}, S_{1:t}\\right)\\\" eeimg=\"1\"/> 。其中， <img src=\"https://www.zhihu.com/equation?tex=%5C%28P%28ID_%7Bt%2B1%7D+%7C+S_%7B1%3At%7D%29%5C%29\" alt=\"\\(P(ID_{t+1} | S_{1:t})\\)\" eeimg=\"1\"/> 根据<b>历史序列</b>生成<b>稀疏 ID</b>，捕捉物品类别本质；<img src=\"https://www.zhihu.com/equation?tex=%5C%28P%28v_%7Bt%2B1%7D+%7C+ID_%7Bt%2B1%7D%2C+S_%7B1%3At%7D%29%5C%29\" alt=\"\\(P(v_{t+1} | ID_{t+1}, S_{1:t})\\)\" eeimg=\"1\"/> 依据<b>稀疏 ID</b> 和<b>历史序列</b>生成<b>稠密向量</b>，捕捉物品细粒度细节。最后看一下loss部分， <img src=\"https://www.zhihu.com/equation?tex=L_%7Bsparse%7D\" alt=\"L_{sparse}\" eeimg=\"1\"/> 指的就是NTP的loss，预测下一个语义id； <img src=\"https://www.zhihu.com/equation?tex=L_%7Bdense%7D\" alt=\"L_{dense}\" eeimg=\"1\"/> 是一个in-batch的负采样loss，其中正样本对是预估稠密向量 <img src=\"https://www.zhihu.com/equation?tex=%5Chat%7Bv_%7Bt%2B1%7D%7D\" alt=\"\\hat{v_{t+1}}\" eeimg=\"1\"/> 和ground truth对应的稠密向量<img src=\"https://www.zhihu.com/equation?tex=v_%7Bt%2B1%7D\" alt=\"v_{t+1}\" eeimg=\"1\"/>。与Tiger不同的是，<b>历史序列也需要进行梯度回传</b>。</p><ul><li data-pid=\"vj4Mclbe\">预测阶段</li></ul><p data-pid=\"xrCbh9I1\">预测时先通过beam search生成M个候选稀疏ID，并将这M个ID append到输入序列，再生成M个稠密向量。最后用这M个稠密向量做ANN检索，得到的召回结果融合beam score和NN score，生成一个fusion score再截断返回给下游。增加beam search的好处是可以增加召回结果的多样性。</p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-6b35ff86d1983139acefd9ef970efb7e_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"724\" data-rawheight=\"260\" data-original-token=\"v2-c5eb1c5096fb3270cf879b0e889bc7ea\" class=\"origin_image zh-lightbox-thumb\" width=\"724\" data-original=\"https://pica.zhimg.com/v2-6b35ff86d1983139acefd9ef970efb7e_r.jpg\"/></figure><p data-pid=\"nK13xiMN\">这里有一个优化点是，当dense vector <img src=\"https://www.zhihu.com/equation?tex=%5Chat%7Bv_%7Bt%2B1%7D%7D%5Ek\" alt=\"\\hat{v_{t+1}}^k\" eeimg=\"1\"/>进行检索时，只会和对应sparse id <img src=\"https://www.zhihu.com/equation?tex=%5Chat%7BID_%7Bt%2B1%7D%7D%5Ek\" alt=\"\\hat{ID_{t+1}}^k\" eeimg=\"1\"/> <b>相关联的候选集计算ANN</b>。对于相关联的定义论文没讲，猜测可能是初筛语义相近的item作为候选集（如ID元组的第一位都相同）。这样初筛过的候选集大概率和dense vector更近似，从而降低检索开销。</p><p data-pid=\"faK1szFN\">第k个beam的fusion score计算公式如下：<img src=\"https://www.zhihu.com/equation?tex=+%5CPhi%5E%7B%28%5Chat%7Bv%7D_%7BT%2B1%7D%5E%7Bk%7D%2C+ID_%7BT%2B1%7D%5E%7Bk%7D%2C+a%29%7D%3DSoftmax%28%5Ctau+%5Cphi_%7BID_%7BT%2B1%7D%5E%7Bk%7D%7D%29+%C3%97+Softmax%28%5Cpsi+cos+%28%5Chat%7Bv%7D_%7BT%2B1%7D%5E%7Bk%7D%2C+a%29%29\" alt=\" \\Phi^{(\\hat{v}_{T+1}^{k}, ID_{T+1}^{k}, a)}=Softmax(\\tau \\phi_{ID_{T+1}^{k}}) × Softmax(\\psi cos (\\hat{v}_{T+1}^{k}, a))\" eeimg=\"1\"/> 。其中 <img src=\"https://www.zhihu.com/equation?tex=a+\" alt=\"a \" eeimg=\"1\"/> 代表候选物品， <img src=\"https://www.zhihu.com/equation?tex=%5C%28%5Ctau%5C%29\" alt=\"\\(\\tau\\)\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=%5C%28%5Cpsi%5C%29\" alt=\"\\(\\psi\\)\" eeimg=\"1\"/> 是系数， <img src=\"https://www.zhihu.com/equation?tex=%5C%28%5Cphi_%7BID_%7BT%7D%5E%7Bk%7D%7D%5C%29\" alt=\"\\(\\phi_{ID_{T}^{k}}\\)\" eeimg=\"1\"/> 表示束搜索过程中获得的束得分。最终返回topk个fusion score即可。</p><ul><li data-pid=\"6zh9Smx0\">总结</li></ul><p data-pid=\"Z6dOT-sv\">COBRA的核心优化点在于增加了稠密向量的级联训练，让生成模型和稠密检索方法相互补充，<b>生成模型为稠密检索提供了高质量的物品表示和预测信息，稠密检索则利用生成的向量表示快速筛选和排序候选物品</b>，从而提升了推荐系统的性能和效率。说白了COBRA认为直接通过生成式召回不太靠谱，因此在生成式后面又打了一个NN检索的补丁，相当于又走了向量召回的老路，而并非是一个彻底的生成式召回方案。</p><h2>端到端</h2><p data-pid=\"09HQU9kE\">最后介绍LLM在推荐领域中端到端的方案，传统推荐系统一般包含了召回-&gt;粗排-&gt;精排-&gt;重排这样的级联链路，端到端的意思就是通过一个推荐模型，直接生成用户的推荐结果，彻底解决了级联任务中存在的目标不一致的问题。而模型结构也是类似于LLM不断生成下一个item，生成的数量达到一个session后直接返回给用户，相较于GR类的模型来说，是一种更彻底的生成式推荐方案。</p><h3>oneRec</h3><p data-pid=\"DGYMO7Y9\">端到端生成式推荐在业界最成功、最有影响力的应该就属快手的这篇onerec了，onerec的论文在今年的二月发表，当时看了就觉得思路清晰，结构严谨，和charGPT系列模型的训练流程（pretrain-&gt;sft-&gt;RHLF）高度一致。随后在7月的technical report中披露了更多技术细节，一度引来了众多推荐从业者的追捧。看的出来快手对于这个工作还是很自信的，整体来说工作本身也是非常solid，让我们看到了快手团队在生成式推荐中领先业界的能力，以及在推动LLM结合推荐的技术的发展中做出的贡献。本节将结合最新的技术报告，来解析onerec的模型结构。</p><ul><li data-pid=\"KgUcTJGD\">motivation</li></ul><p data-pid=\"LJb_pH_b\">传统的级联架构主要存在几个问题：1）各链路目标不一致，任务之间都是各自为战，无法实现整体目标对齐；2）级联的层数越多，越可能产生样本选择偏差（SSB）的问题；3）推荐系统的整体开销更多的用在了存储和通信上，真实的计算上的开销实际很小，不利于模型的scaling。基于以上几个问题，onerec的出现可以统一整体目标，推荐好坏全由这一个模型决定，从而避免了各任务目标不一致的问题；将存储和通信节省下来的资源用来提升onerec的模型复杂度，提升模型训练和预测的算力，从而实现scaling上的更大提升。</p><p data-pid=\"lnFpy_YZ\">模型整体结构分为Tokenizer-&gt;pretrain-&gt;post-train三个阶段，和Tiger相比多了一步post-train，整体做法还是比较完整的follow了大模型的训练过程，下面我们就来着重看下这几个过程。</p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-31e2c2763be6359962eb26d61feb0d16_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2268\" data-rawheight=\"1320\" data-original-token=\"v2-fd3335203fbd4529e878b9e6eb3277da\" class=\"origin_image zh-lightbox-thumb\" width=\"2268\" data-original=\"https://pica.zhimg.com/v2-31e2c2763be6359962eb26d61feb0d16_r.jpg\"/><figcaption>onerec整体结构</figcaption></figure><ul><li data-pid=\"jSHh4gqP\">Tokenizer</li></ul><p data-pid=\"aRHMzCOC\">Tokenizer的目的也是生成语义id，和Tiger只使用了语义embeddding不同，onerec的做法同时引入了语义信息和协同信息，这样可以更好的捕捉到item之间的行为相关性，更有利于高热item的相似度计算。与RQ-VAE不同，onerec这里使用的是RQ-kmeans，与RQ-VAE相比可以显著提升Token质量、codebook的利用率和平衡性。</p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-a70350613b4f931ba3261d46431c7056_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2208\" data-rawheight=\"900\" data-original-token=\"v2-f242b329fc49eb02d56abb8c07745b04\" class=\"origin_image zh-lightbox-thumb\" width=\"2208\" data-original=\"https://pic1.zhimg.com/v2-a70350613b4f931ba3261d46431c7056_r.jpg\"/><figcaption>多模态embedding&amp;RQ-kmeans</figcaption></figure><p data-pid=\"jo2JVL9c\"><b>Token生成：</b>如上图左侧所示，RQ-VAE使用的是纯文本的语义embedding，onerec首先在输入模态上做了优化，引入了更多多模态的信息，包括图片、标题&amp;tag、音频（ASR）、OCR等。通过一个编码器将输入信息压缩为一个二维矩阵 <img src=\"https://www.zhihu.com/equation?tex=M%5Cin+R%5E%7BN_M%2Ad_t%7D\" alt=\"M\\in R^{N_M*d_t}\" eeimg=\"1\"/> ，再通过一个多层的QFormer将矩阵M压缩为<img src=\"https://www.zhihu.com/equation?tex=%5Ctilde%7BM%7D%3DQ%5E%7BN_c%2B1%7D%5Cin+R%5E%7BN_%5Ctilde%7BM%7D%2Ad_t%7D%E3%80%82\" alt=\"\\tilde{M}=Q^{N_c+1}\\in R^{N_\\tilde{M}*d_t}。\" eeimg=\"1\"/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-703bf7a685e3687ac8656367f44bb861_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1270\" data-rawheight=\"254\" data-original-token=\"v2-0747de6d865fb9cf8fc312b25f9ee74f\" class=\"origin_image zh-lightbox-thumb\" width=\"1270\" data-original=\"https://pic2.zhimg.com/v2-703bf7a685e3687ac8656367f44bb861_r.jpg\"/></figure><p data-pid=\"hWTt-u-w\">其中 <img src=\"https://www.zhihu.com/equation?tex=Q%5E%7B%28i%29%7D%5Cin+R%5E%7BN_%5Ctilde%7BM%7D%2Ad_t%7D\" alt=\"Q^{(i)}\\in R^{N_\\tilde{M}*d_t}\" eeimg=\"1\"/>是可学习的二维矩阵，且 <img src=\"https://www.zhihu.com/equation?tex=N_%5Ctilde%7BM%7D%3C%3CN_M\" alt=\"N_\\tilde{M}&lt;&lt;N_M\" eeimg=\"1\"/> ，Nc表示QFormer的层数。crossAttn可以理解为一个target attention，且KV都是矩阵M。在得到压缩后的矩阵后 <img src=\"https://www.zhihu.com/equation?tex=%5Ctilde%7BM%7D\" alt=\"\\tilde{M}\" eeimg=\"1\"/> 后，我们需要基于这个矩阵设计两个loss，第一个是i2i的loss，其本质是一个对比学习loss，正样本对包含两种情况：</p><ul><li data-pid=\"kz6hGOQm\"><b>基于U2I召回模型:</b> 对于每个用户正向点击的目标Item，从最近的50个点击Item中选择与目标Item在ID表征空间中最相似的Item作为触发Item。</li><li data-pid=\"Oa7w726H\"><b>基于I2I召回模型:</b> 利用现有模型学习到的具有高相似度的稳定Item Pair对作为数据源，比如Swing召回。</li></ul><p data-pid=\"cO7HcWt0\">第二个loss是标题生成的NTP loss，其本意在于将<img src=\"https://www.zhihu.com/equation?tex=%5Ctilde%7BM%7D\" alt=\"\\tilde{M}\" eeimg=\"1\"/>作为LLM的输入（如LLaMA3），生成item对应的标题，可以帮助多模态表征学到更多内容理解上的能力，防止多模态表征学偏。</p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-0049d49fb7f50dbc078973f2447488a6_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1320\" data-rawheight=\"424\" data-original-token=\"v2-3aaa77255f8821c1599407860cc04aee\" class=\"origin_image zh-lightbox-thumb\" width=\"1320\" data-original=\"https://pic1.zhimg.com/v2-0049d49fb7f50dbc078973f2447488a6_r.jpg\"/></figure><p data-pid=\"5hk6b0hU\"><b>RQ-kmeans：</b>如上图右侧所示，与RQ-VAE最大区别是RQ-kmeans是<b>不需要训练的，</b>其codebook的生成过程就是聚类过程。假设每层有4个codeword，首先会将全部item的原始embedding<img src=\"https://www.zhihu.com/equation?tex=%5Ctilde%7BM%7D\" alt=\"\\tilde{M}\" eeimg=\"1\"/>聚成4个类，得到codebook1的4个codeword embedding。接着根据最近相似度计算每个item所属簇心，将item和簇心相减计算残差，得到的第二层残差embedding继续聚类，就可以得到codebook2的4个codeword embedding，以此类推就可以得到全部codebook的表征。值得注意的是，onerec对k-means也做了优化，使用了一种balance的k-means，简单说来就是确保每个簇心下的item个数尽量相等，防止计算语义id时出现表征坍塌的现象，感兴趣的同学可以阅读一下原论文。之后预测语义id的流程就和RQ-VAE完全一致了，对于输出层的m个item，我们都会将其转化为语义id的表征 <img src=\"https://www.zhihu.com/equation?tex=%5C%7Bs_m%5E1%2Cs_m%5E2%2C...%2Cs_m%5EL%5C%7D\" alt=\"\\{s_m^1,s_m^2,...,s_m^L\\}\" eeimg=\"1\"/> 。其中L是codebook的个数，onerec里用的是3，每一层codebook中codeword个数是8196。</p><ul><li data-pid=\"gPQRgg7O\">encoder</li></ul><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-425ec1feb0918ad06efbd228374f2ba0_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2204\" data-rawheight=\"888\" data-original-token=\"v2-8830d09fe94373ffed94a208cd0cdd16\" class=\"origin_image zh-lightbox-thumb\" width=\"2204\" data-original=\"https://pic3.zhimg.com/v2-425ec1feb0918ad06efbd228374f2ba0_r.jpg\"/><figcaption>encoder&amp;decoder</figcaption></figure><p data-pid=\"QEnJ8F5A\">模型结构和原论文中的结构基本一致，和Tiger一样也是一个类似T5的结构，技术报告中披露了更多细节，先来看下encoder的。主要是特征层面，引入了用户静态特征、短期序列（Ls=20）、长期序列（Lp=256）和终身序列（Ll=10万）四种特征。这个特征设计其实和MTGR十分类似，onerec这多了一个终身序列，用来建模用户终身兴趣。但由于终身序列的长度太长，onerec采用了层次聚类的方式，直接聚类成2000个类，<b>并选择距离簇心最近的item</b>作为终身序列。对于离散特征，直接使用挑选出来的最近item embedding表征；对于连续特征，使用簇内item的连续特征平均值。接着采用Token生成中使用的QFormer方法，使用两层QFormer将序列长度进一步缩短为128。所有特征都会经过concat+非线性变换，让所有embedding的最后一维都保持一致（dmodel），以便于后续attention的计算。以短期序列为例：</p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-ebb2a8b842ad42524395290522843280_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1018\" data-rawheight=\"180\" data-original-token=\"v2-3cbcde3db57955552b6997324ea2b4a6\" class=\"origin_image zh-lightbox-thumb\" width=\"1018\" data-original=\"https://pic3.zhimg.com/v2-ebb2a8b842ad42524395290522843280_r.jpg\"/></figure><p data-pid=\"EOWSlHRn\">最终短期序列的表征hs维度会统一到Ls*dmodel，其中Ls表示短期序列长度。值得注意的是，论文在item embedding的选择上做了实验，对比了语义id和原始sparse embedding的效果，发现encoder阶段使用语义id要优于或等于sparse embedding。encoder的结构和Tiger一致这里就不赘述了，最终concat上述四种特征，并加上可学习的位置编码，作为encoder的输入。</p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-47e3106853b47e2e51bd10175f79c258_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"626\" data-rawheight=\"104\" data-original-token=\"v2-47e3106853b47e2e51bd10175f79c258\" class=\"origin_image zh-lightbox-thumb\" width=\"626\" data-original=\"https://pic1.zhimg.com/v2-47e3106853b47e2e51bd10175f79c258_r.jpg\"/></figure><ul><li data-pid=\"L4ll740O\">decoder</li></ul><p data-pid=\"zfg92eUl\">decoder的结构也比较常规，最底层用了一个因果attention+cross attention，相信熟悉Transformer的读者应该对这个结构不会陌生。输出层用了一个MoE结构取代传统的Feed Forward，MoE在LLM领域中也算是比较常用的结构了，通过一个Gate筛选专家中的topK个输出（oneRec中K=2），再做一个加权和送给下游做NTP。MoE的好处在于相同的计算资源下，训练速度更快，训练的模型更大；且多个expert增加模型的泛化性，可以防止过拟合。<b>decoder的输入输出必须是语义id</b>。</p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-ef73c54c2e21dbe2976300cf6702f306_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"954\" data-rawheight=\"396\" data-original-token=\"v2-47a9dbd9e37ccaf34e61a9644ebbe55b\" class=\"origin_image zh-lightbox-thumb\" width=\"954\" data-original=\"https://pic3.zhimg.com/v2-ef73c54c2e21dbe2976300cf6702f306_r.jpg\"/></figure><p data-pid=\"2-azm5PX\">值得注意的是，这里decoder的训练是pointwise的，即一条样本只预测一个item的语义id，而不是论文中提到的session wise的样本组织方式。同时会使用DeepSeek-V3提到的Loss-free的负载均衡策略来提高专家的能力。不过个人认为长序列的target样本组织方式，既能减少样本存储开销，也能降低模型训练的计算开销，如果做不到user-wise至少也应该是session-wise的呀，这一点在MTGR和HSTU都有所体现，但onerec却反其道采用了pointwise组织，report里没解释这里暂且先打一个问号吧。</p><ul><li data-pid=\"oadN9CC7\">reward model &amp; RL</li></ul><p data-pid=\"ZEn_KRhI\">刚才提到的都是预训练阶段，要和LLM对齐，还需要增加RLHF的post-traing阶段。预训练通过NTP只能拟合item的曝光分布，然而曝光分布是由基础模型带来的，只通过预训练很难突破原有模型的天花板。在论文中，onerec的做法是session-wise+DPO，而报告中使用的是pointwise+强化学习（RL）。这里我们以最新的报告做法来解读，具体说来总共设计了三种reward，使用on-pollicy的RL来对预训练模型进行偏好对齐。其中用户偏好对齐可以捕获用户更细粒度的兴趣信息，格式对齐确保模型产出的语义id都是合法的，工业场景对齐使模型更适应工业界的场景需求。实际使用时，onerec应该是将三种reward model都作用在了RL策略中，以保证模型在各维度上的对齐。</p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-1293c3318e7568a8bd08ba889aa7731e_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2188\" data-rawheight=\"1022\" data-original-token=\"v2-59b7de5fa5070a3e4ac559bb1941cce3\" class=\"origin_image zh-lightbox-thumb\" width=\"2188\" data-original=\"https://pic3.zhimg.com/v2-1293c3318e7568a8bd08ba889aa7731e_r.jpg\"/><figcaption>reward mode &amp; RL</figcaption></figure><p data-pid=\"CNq_nt-1\"><b>用户偏好对齐</b>：想要定义一个”好的推荐系统“是很难的，传统方案是做多任务融合，但手搓参数融合的方式不能保证精度，且存在目标冲突的问题。如上图右上角所示，onerec先设计了一个SIM+MLT的精排模型，最上层做一个BCE loss作为辅助loss；再提取各task的中间层参数，和user/item特征concat后输入到一个MLP中，再最上层输出一个P-Score，并通过BCE同时拟合多个label，label包括各种xtr类的二分类任务。作者表示使用这种方案训练模型，可以避免用户偏好被其他用户所干扰，整体是更容易实现帕累托最优的。</p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-952ef1771693a71699cc0f02ba77353a_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1016\" data-rawheight=\"364\" data-original-token=\"v2-adefc8cdab22e4c2c499a4d3e914521e\" class=\"origin_image zh-lightbox-thumb\" width=\"1016\" data-original=\"https://pica.zhimg.com/v2-952ef1771693a71699cc0f02ba77353a_r.jpg\"/></figure><p data-pid=\"lRoW3LoR\">这个过程其实对齐的是用户的精排结果，由于对齐的是&lt;u,i&gt;粒度，这里也可以解释为什么模型的输出是point-wise的粒度了。除此之外，onerec在GRPO的基础上对loss进行了优化，提出了ECPO。主要解决的是当优势A&lt;0时GRPO的policy率<img src=\"https://www.zhihu.com/equation?tex=%EF%BC%88%5Cpi_%7B%5Ctheta%7D%2F%5Cpi_%7B%5Ctheta_%7Bodd%7D%7D%EF%BC%89\" alt=\"（\\pi_{\\theta}/\\pi_{\\theta_{odd}}）\" eeimg=\"1\"/>过大导致的梯度爆炸问题，其实就是在policy率过大时提前做了一次截断（Early Clipping），保证训练的稳定性。并且增加了一个超参δ，允许policy率可以略大于1+ 。除此之外，ECPO去掉了KL散度，原因在于SFT（在post-training中详细解释）和RL是联合训练的，SFT loss可以保证模型训练的稳定性，确保actor model不会偏离reference model太远。</p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-93f1029cb7417dd2bb849bccb2c14026_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1770\" data-rawheight=\"672\" data-original-token=\"v2-de6f79aedaf2dff0505425aa079b8787\" class=\"origin_image zh-lightbox-thumb\" width=\"1770\" data-original=\"https://pica.zhimg.com/v2-93f1029cb7417dd2bb849bccb2c14026_r.jpg\"/></figure><p data-pid=\"LjrTFl34\"><b>生成格式对齐</b>：如reward model的右下角所示，和Tiger的做法类似，我们在生成语义id后，会将item与语义id建立一个映射关系，以此确认生成的item是否合法。然而在RL的过程中会出现”压缩效应“，如下图的概率分布图所示：可以看到当A&lt;0时，模型为将大部分概率质量压缩至当前认定的最优输出周围O*，导致原本合法的Token概率分布被压缩至了非法Token的层次上，使得模型难以区分token是否合法。这个问题的解决办法也十分容易，只要将生成的合法Token对应A设为1，非法的A设为0即可，让RL强化记忆那些合法id组合，忽略非法id的更新。</p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-695b91c45267e0ddafc87586bee76906_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2216\" data-rawheight=\"568\" data-original-token=\"v2-1fd1e2cd3abc7b7b3d9aa32eb9a8c970\" class=\"origin_image zh-lightbox-thumb\" width=\"2216\" data-original=\"https://pica.zhimg.com/v2-695b91c45267e0ddafc87586bee76906_r.jpg\"/></figure><p data-pid=\"s_3VrO1M\"><b>工业场景对齐</b>：传统推荐系统在推荐链路的每个部分通过算法或策略解决商业、社区、冷启、长尾推荐等等工业问题，在onerec中，只需要将这些工业场景的目标通过奖励系统应用到模型中，并通过强化学习进行优化即可。</p><ul><li data-pid=\"7PLjNtzC\">post-training</li></ul><p data-pid=\"KKSISUi5\">整个后训练采用流式数据处理，同时使用了拒绝采样微调（RSFT）和强化学习（RL）</p><p data-pid=\"HrUV4lkT\">RSFT：RSFT就是在ECPO中提到的SFT，拒绝采样的意思是过滤播放时长在bottom 50%的样本，使用过滤后的数据对模型实时SFT，这个loss也是NTP，其实本质上还是在做预训练的那些事。此外，还通过降低学习率来实现模拟退火，来找到一个近似的全局最优解。</p><p data-pid=\"pXrJpHC1\">RL：onerec在后训练阶段会将RSFT中随机抽取1%的用户进行RL，为了最大化利用计算资源，我们使用了一个额外的infer服务来生成RL样本，与线上服务解耦开。这1%的用户会去请求这个额外服务，并生成512个item。reward model会对这512个结果进行打分，并返回给inference Service做RL计算，训练任务每1000步会对这个额外的inference Service上报参数并更新，因此整个过程是实时on-policy的。文中没说，我理解参数应该也会定时同步到线上服务，以实现更好的线上时效性。</p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-4af72c9b9f9f6a3458a92e1705cad202_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2080\" data-rawheight=\"778\" data-original-token=\"v2-f4ea339f75319ae6905fcdbf66b4c6d1\" class=\"origin_image zh-lightbox-thumb\" width=\"2080\" data-original=\"https://pic1.zhimg.com/v2-4af72c9b9f9f6a3458a92e1705cad202_r.jpg\"/><figcaption>post-training</figcaption></figure><ul><li data-pid=\"vldEeg9l\">总结</li></ul><p data-pid=\"O4WdxZdI\">onerec这个工作分析到现在其实也只解读了一半，由于本文旨在介绍不同生成式推荐的模型结构，篇幅有限，后面还有大量关于scaling、消融实验、超参对比等结论没有和大家一一分享。在看onerec时，第一反应就是信息量巨大（一篇paper+一篇report），技术点全面工作量扎实，从传统搜推到LLM和RL，每个细节都值得深刻探究。不得不说这篇文章还是非常有研究价值的，即使在自家场景无法复现整个工作，对于推荐系统中的一些传统做法也是可以借鉴的（如multi-modal对比学习、QFormer降维、P-score迁移学习模型等）。多follow这样的工作不论是对业务发展还是个人成长都是很有帮助的，期待后续的onerecV2给我们带来更多的惊喜吧！~</p><h2>参考文献</h2><ul><li data-pid=\"9TK6M7dK\"><a href=\"https://www.zhihu.com/question/1916207872066430537/answer/1917137204104377875\" class=\"internal\" target=\"_blank\">生成式推荐会成为下一代推荐系统的范式吗？</a></li><li data-pid=\"6aC_QaOA\"><a href=\"https://zhuanlan.zhihu.com/p/687478684\" class=\"internal\" target=\"_blank\">行动胜过言语: Meta落地工业界首个万亿级别参数的生成式推荐系统模型</a></li><li data-pid=\"-uqjacUe\"><a href=\"https://zhuanlan.zhihu.com/p/1906722156563394693\" class=\"internal\" target=\"_blank\">MTGR：美团外卖生成式推荐Scaling Law落地实践</a></li><li data-pid=\"Muccx3uw\"><a href=\"https://zhuanlan.zhihu.com/p/1897030256965177585\" class=\"internal\" target=\"_blank\">【谷歌2023】TIGER：基于生成式召回的推荐系统</a></li><li data-pid=\"a_x3K9R6\"><a href=\"https://zhuanlan.zhihu.com/p/1912038985280234052\" class=\"internal\" target=\"_blank\">美团 | 生成式推荐MTGR</a></li><li data-pid=\"Dor5UsBl\"><a href=\"https://zhuanlan.zhihu.com/p/1895875955798560958\" class=\"internal\" target=\"_blank\">【百度2025】COBRA：级联稀疏与稠密表示的统一生成式召回</a></li><li data-pid=\"tTrEOYZw\"><a href=\"https://zhuanlan.zhihu.com/p/1927385267645424584\" class=\"internal\" target=\"_blank\">快手OneRec:无召回&#34;一步到位&#34;的生成式推荐方案</a></li><li data-pid=\"R-YMJyrZ\"><a href=\"https://zhuanlan.zhihu.com/p/1927386141486735715\" class=\"internal\" target=\"_blank\">细读快手推荐模型OneRec技术报告</a></li><li data-pid=\"Cqsjsj_2\"><a href=\"https://zhuanlan.zhihu.com/p/1920600051480258200\" class=\"internal\" target=\"_blank\">快手端到端推荐大模型 onerec 技术报告阅读笔记</a></li><li data-pid=\"uYqgX9Qm\">GRs：<a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2402.17152\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">arxiv.org/pdf/2402.1715</span><span class=\"invisible\">2</span><span class=\"ellipsis\"></span></a></li><li data-pid=\"NHMClxp3\">MTGR：<a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2505.18654\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">arxiv.org/pdf/2505.1865</span><span class=\"invisible\">4</span><span class=\"ellipsis\"></span></a></li><li data-pid=\"1wnt2bkG\">Tiger：<a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2305.05065\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">arxiv.org/pdf/2305.0506</span><span class=\"invisible\">5</span><span class=\"ellipsis\"></span></a></li><li data-pid=\"xkUlO3pw\">COBRA：<a href=\"https://link.zhihu.com/?target=https%3A//www.arxiv.org/pdf/2503.02453\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://www.</span><span class=\"visible\">arxiv.org/pdf/2503.0245</span><span class=\"invisible\">3</span><span class=\"ellipsis\"></span></a></li><li data-pid=\"m9JMXSbk\">onerec：<a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2502.18965\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">arxiv.org/pdf/2502.1896</span><span class=\"invisible\">5</span><span class=\"ellipsis\"></span></a></li><li data-pid=\"mf_1P556\">onerec technical report：<a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2506.13695\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">arxiv.org/pdf/2506.1369</span><span class=\"invisible\">5</span><span class=\"ellipsis\"></span></a></li></ul><p></p>",
        "is_labeled": false,
        "visited_count": 3557,
        "thumbnails": [
          "https://picx.zhimg.com/v2-d53268dcfaeb945795a38be340098c8c.jpg?source=7e7ef6e2&needBackground=1",
          "https://pic1.zhimg.com/50/v2-f9f98f421fcab97232f7186d5f3d98a6_720w.jpg?source=b6762063",
          "https://pica.zhimg.com/50/v2-750f58b77d025b2b42ceec5fd4dda654_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-636ff187b4fe716a55897aafb4a74853_720w.jpg?source=b6762063",
          "https://pica.zhimg.com/50/v2-563b46f3671de32e23b3bfec846aaa00_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-acffe19f66ceac590bfac8e56fb2bcf0_720w.jpg?source=b6762063",
          "https://pic1.zhimg.com/50/v2-d322b49e82c0bb17176c961fdf5c6580_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-67cbab955f62981d24d0c0c5afa22f9f_720w.jpg?source=b6762063",
          "https://pica.zhimg.com/50/v2-2e1ed4ad08673ba830d8c4e2b61cdac0_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-c31d9d309ed2459f7db9b130bd574ae1_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-02e7d23929e19a29eb7adc97919ff5c3_720w.jpg?source=b6762063",
          "https://pic1.zhimg.com/50/v2-51943104c9927c8f677257a4616cdea8_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-4aaa6d664d896380957170cad13aa372_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-01e1fee243c2e179ea51bf43c1e180e3_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-5a21fc134fd3147d9dad7a865f6806d1_720w.jpg?source=b6762063"
        ],
        "favorite_count": 314,
        "article_type": "normal",
        "is_navigator": false,
        "navigator_vote": false,
        "vote_next_step": "vote"
      },
      "brief": "{\"source\": \"TS\", \"type\": \"article\", \"id\": 1927420378491389862}",
      "attached_info": "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",
      "action_card": false
    },
    {
      "id": "477_1755822760.191",
      "type": "feed",
      "offset": 477,
      "verb": "TOPIC_ACKNOWLEDGED_ANSWER",
      "created_time": 1755822760,
      "updated_time": 1755822760,
      "target": {
        "id": "1939340234664944033",
        "type": "answer",
        "url": "https://api.zhihu.com/answers/1939340234664944033",
        "author": {
          "id": "0e47db1369fdec9d524ff60409455c49",
          "url": "https://api.zhihu.com/people/0e47db1369fdec9d524ff60409455c49",
          "user_type": "people",
          "url_token": "87-84-98-95-24",
          "name": "花花世界",
          "headline": "",
          "avatar_url": "https://pica.zhimg.com/50/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=b6762063",
          "is_org": false,
          "gender": 0,
          "followers_count": 19,
          "is_following": false,
          "is_followed": false
        },
        "created_time": 1755154743,
        "updated_time": 1755154743,
        "voteup_count": 16,
        "thanks_count": 0,
        "comment_count": 0,
        "is_copyable": true,
        "question": {
          "id": "512050469",
          "type": "question",
          "url": "https://api.zhihu.com/questions/512050469",
          "author": {
            "id": "e1b8ac7aad21d25f5b7320ef31a1f3d4",
            "url": "https://api.zhihu.com/people/e1b8ac7aad21d25f5b7320ef31a1f3d4",
            "user_type": "people",
            "url_token": "huan-shi-xia-yu-27",
            "name": "卡拉鸡嗖",
            "headline": "",
            "avatar_url": "https://picx.zhimg.com/50/v2-f011ad7427c75ee472300ef887070ca9_l.jpg?source=b6762063",
            "is_org": false,
            "gender": -1,
            "followers_count": 1,
            "is_following": false,
            "is_followed": false
          },
          "title": "怎么用百度网盘搜索资源呢？",
          "created": 1642427951,
          "answer_count": 0,
          "follower_count": 0,
          "comment_count": 0,
          "bound_topic_ids": [
            3705,
            10040,
            43981
          ],
          "is_following": false,
          "excerpt": "",
          "relationship": {
            "is_author": false
          },
          "detail": "",
          "question_type": "normal"
        },
        "excerpt": "「夫Q延时」 链接： pan.quark.cn/s/cce938a9f7df 「跟大佬学说话：央视主持人陈伟鸿的24堂沟通必修课，做一个会说话的人（完结）」 链接： pan.quark.cn/s/e53b84cbb914 「基础英语资料」 链接： pan.quark.cn/s/97f59afedc11 「高途中考数学 几何模型决胜88招全解版+全练版」 链接： pan.quark.cn/s/f2fa9d7e69c9 「培培爸《小学数学思维课》」 链接： pan.quark.cn/s/2e8b43ea827a 「拼音资源合集」 链接： pan.quark.cn/s/60bbf62…",
        "excerpt_new": "「夫Q延时」 链接： pan.quark.cn/s/cce938a9f7df 「跟大佬学说话：央视主持人陈伟鸿的24堂沟通必修课，做一个会说话的人（完结）」 链接： pan.quark.cn/s/e53b84cbb914 「基础英语资料」 链接： pan.quark.cn/s/97f59afedc11 「高途中考数学 几何模型决胜88招全解版+全练版」 链接： pan.quark.cn/s/f2fa9d7e69c9 「培培爸《小学数学思维课》」 链接： pan.quark.cn/s/2e8b43ea827a 「拼音资源合集」 链接： pan.quark.cn/s/60bbf62…",
        "preview_type": "default",
        "preview_text": "",
        "reshipment_settings": "allowed",
        "content": "<p data-pid=\"7CLNrehq\">「夫Q延时」</p><p data-pid=\"wkze4PnC\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/cce938a9f7df\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/cce938a9f7df</a></p><p data-pid=\"zA5d2_rh\">「跟大佬学说话：央视主持人陈伟鸿的24堂沟通必修课，做一个会说话的人（完结）」</p><p data-pid=\"yOinprnx\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/e53b84cbb914\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/e53b84cbb914</a></p><p data-pid=\"4W6U_iP3\">「基础英语资料」</p><p data-pid=\"B7wkJY97\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/97f59afedc11\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/97f59afedc11</a></p><p data-pid=\"MTiyNE51\">「高途中考数学 几何模型决胜88招全解版+全练版」</p><p data-pid=\"W6TRQnIk\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/f2fa9d7e69c9\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/f2fa9d7e69c9</a></p><p data-pid=\"P5bIsAke\">「培培爸《小学数学思维课》」</p><p data-pid=\"XdTUZYPH\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/2e8b43ea827a\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/2e8b43ea827a</a></p><p data-pid=\"Ho5iGmq1\">「拼音资源合集」</p><p data-pid=\"Qpz2cWgT\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/60bbf62db8bd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/60bbf62db8bd</a></p><p data-pid=\"wk15sgM-\">「如何成为一个年赚100W的副业高手」</p><p data-pid=\"o07UQ-qK\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/6948d69081e9\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/6948d69081e9</a></p><p data-pid=\"YXqBeIa3\">「认知觉醒：开启自我改变的原动力丨清醒成长进步，何惧焦虑迷茫」</p><p data-pid=\"pqcUgFD1\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/895b3a4a9fc9\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/895b3a4a9fc9</a></p><p data-pid=\"scH6BhZH\">「少儿护眼必修课」</p><p data-pid=\"tXVSEI2t\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/38336f3f21e7\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/38336f3f21e7</a></p><p data-pid=\"gBjDLWeF\"> 「天涯贴」</p><p data-pid=\"XFM6XfSC\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/2bd44f7c8f53\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/2bd44f7c8f53</a></p><p data-pid=\"r9k9qP39\">「53科学备考《初中各科模拟试卷·2025春》」</p><p data-pid=\"G-aS-mf5\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/7e7e2f0d1103\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/7e7e2f0d1103</a></p><p data-pid=\"sxQlmBjr\">「2025一级建造师」</p><p data-pid=\"40uhh2F8\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/406ae972bf7e\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/406ae972bf7e</a></p><p data-pid=\"YD2hT6ZV\">「曾国藩-冰鉴」</p><p data-pid=\"9RJYcgxV\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/88d047c1e59f\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/88d047c1e59f</a></p><p data-pid=\"LsPvLaPv\">「电动车维修改装系统教程」</p><p data-pid=\"XhSOxmrY\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/5d263f6d1ab1\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/5d263f6d1ab1</a></p><p data-pid=\"nbE1QXIu\">「【喜马拉雅】全球富豪传记精读：商业思维进阶课」</p><p data-pid=\"eH-FMSdv\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/5f4bd8599622\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/5f4bd8599622</a></p><p data-pid=\"3e_zIctI\">「《张作霖全传》有声类 乱世枭雄 军阀东北王」</p><p data-pid=\"f_U3A-TA\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/e19318e1a35f\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/e19318e1a35f</a></p><p data-pid=\"hYKxjbyE\">「《倪海厦作品及相关文集》倪海厦」</p><p data-pid=\"5h1ONTMV\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/a85ee74318ed\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/a85ee74318ed</a></p><p data-pid=\"HRjG3Bw8\">「《DIdi’s Day 幼儿英语启蒙动画全30集》跟着视频学英语[mp4]」</p><p data-pid=\"3BV7XECH\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/38fb2200551d\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/38fb2200551d</a></p><p data-pid=\"aSJCwJzX\">「张嵩拍案《大案要案侦破纪实》」</p><p data-pid=\"87sl3lgY\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/8e0f59f4eae6\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/8e0f59f4eae6</a></p><p data-pid=\"QgMaWbng\">「60课时学完高中英语」</p><p data-pid=\"0iAh3x40\">链接：<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/74abc10bc1ea\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">pan.quark.cn/s/74abc10bc1ea</a></p>",
        "relationship": {
          "is_thanked": false,
          "is_nothelp": false,
          "voting": 0
        },
        "is_labeled": false,
        "visited_count": 992,
        "favorite_count": 65,
        "answer_type": "normal",
        "is_navigator": false,
        "navigator_vote": false,
        "vote_next_step": "vote"
      },
      "brief": "{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1939340234664944033}",
      "attached_info": "CvYFCMfLgIfe7o38rQEQBBoJNzQyMTU5NTA2ILeS9sQGKBAwAEDdA0pCCi1UU19TT1VSQ0VfVFdPVE9XRVJfTVVMVElfU0NFTkVfVjFfUkVDQUxMX1RFWFQSATAYACAAOgp7InJhdyI6IiJ9Wgg3NjA3MDUzMGIgZjA3NWJiMDBjMjlmNGMzMzYyNWE1OWJiMzUxYWUwYTdyEzE5MzkzNDAyMzQ2NjQ5NDQwMzOKAQk1MTIwNTA0NjmqAQlyZWNvbW1lbmTCASAwZTQ3ZGIxMzY5ZmRlYzlkNTI0ZmY2MDQwOTQ1NWM0OfIBCggMEgZOb3JtYWzyASgIChIkMTgwZjkwOTAtOTJlMC00MzY5LTliN2YtOTU2ZWYyNjRhY2Vk8gEGCAsSAjgwggIAiALNwsT5jDOSAiAwZTQ3ZGIxMzY5ZmRlYzlkNTI0ZmY2MDQwOTQ1NWM0OZoCAMoCFlNob3JJbnRlcmVzdFdlaWdodFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXKAhVRdWVzdGlvbklzb2xhdGlvblJ1bGXaAi1UU19TT1VSQ0VfVFdPVE9XRVJfTVVMVElfU0NFTkVfVjFfUkVDQUxMX1RFWFToAgL6AgtOT1JNQUxfRkxPV4oDIDljYzc5NTIxMTJlMzRhZmQ5YzU1ZWIwNGJkNDA4ZDM4mgMNCgJ2MhAAGgVvdGhlcqgD4AfYAwDqAx90ZXh0RmVlZFR3b1Rvd2VyV2FybXVwU3VjY2Vzc1Yx+gMfEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERYAEAIgEAJIEBk5vcm1hbJoEATKgBACoBACwBAC6BAZtYW51YWzCBAMxNTnIBADSBA/mjqjojZDlt7Lmm7TmlrDYBADwBAD5BAAAAABifpk/gQUAAAAAAAAAAIkFvNv7maZU2T+SBQCaBQNkZnSiBQNkZnSyBQExuQUAAAAAAAAAANAFAOAFAOgFAPAFUJAGAKAG4QOoBgCSAi4KCTc0MjE1OTUwNhITMTkzOTM0MDIzNDY2NDk0NDAzMxgEIgpJTUFHRV9URVhU",
      "action_card": false
    },
    {
      "id": "478_1755822760.483",
      "type": "feed",
      "offset": 478,
      "verb": "TOPIC_ACKNOWLEDGED_ANSWER",
      "created_time": 1755822760,
      "updated_time": 1755822760,
      "target": {
        "id": "1941820840560821424",
        "type": "answer",
        "url": "https://api.zhihu.com/answers/1941820840560821424",
        "author": {
          "id": "5c96e1b10813e1453388e1d4d3bf5a24",
          "url": "https://api.zhihu.com/people/5c96e1b10813e1453388e1d4d3bf5a24",
          "user_type": "organization",
          "url_token": "mai-liang-xiao-fei-ji-94",
          "name": "买量小飞机",
          "headline": "广告投放提效工具，Click-ID技术服务，随心推营销工具",
          "avatar_url": "https://picx.zhimg.com/50/v2-41e8f7dbd71e418df8d3b323a4393eed_l.jpg?source=b6762063",
          "is_org": true,
          "gender": -1,
          "followers_count": 1927,
          "is_following": false,
          "is_followed": false
        },
        "created_time": 1755746165,
        "updated_time": 1755746165,
        "voteup_count": 0,
        "thanks_count": 0,
        "comment_count": 0,
        "is_copyable": true,
        "question": {
          "id": "599710197",
          "type": "question",
          "url": "https://api.zhihu.com/questions/599710197",
          "author": {
            "id": "0445ea3b1413fb5e5f097a9f7c2567c9",
            "url": "https://api.zhihu.com/people/0445ea3b1413fb5e5f097a9f7c2567c9",
            "user_type": "people",
            "url_token": "15915888420",
            "name": "抖音官方广告商",
            "headline": "抖音、千川、快手、磁力金牛官方广告代理商，开户&amp;代运营",
            "avatar_url": "https://picx.zhimg.com/50/v2-cb662a5c53bc7d9307cf9b4b22ac0140_l.jpg?source=b6762063",
            "is_org": false,
            "gender": 1,
            "followers_count": 8,
            "is_following": false,
            "is_followed": false
          },
          "title": "电商是不是应该要付费获取流量？",
          "created": 1683516774,
          "answer_count": 0,
          "follower_count": 0,
          "comment_count": 0,
          "bound_topic_ids": [
            186,
            969,
            1240,
            3521,
            466317
          ],
          "is_following": false,
          "excerpt": "",
          "relationship": {
            "is_author": false
          },
          "detail": "",
          "question_type": "normal"
        },
        "excerpt": "付费投流买流量，是最直接的引流方式。 有商家可能会说，花钱买量也不一定靠谱，有时候买回来的都是不精准的流量，光消耗不成交，我不是白花钱了吗？ 是的，所以这年头个个都在讲ROI。特别是这几年兴起的引流电商Click-ID，更是帮助商家从固有电商平台的有限流量跳脱出来，到外部媒体平台去截取无限流量，相信做电商的朋友们都听说过CID，它可以算是是目前商家买量上策。 说回ROI，书面解释是投资回报率，通俗来讲就是你投入100…",
        "excerpt_new": "付费投流买流量，是最直接的引流方式。 有商家可能会说，花钱买量也不一定靠谱，有时候买回来的都是不精准的流量，光消耗不成交，我不是白花钱了吗？ 是的，所以这年头个个都在讲ROI。特别是这几年兴起的引流电商Click-ID，更是帮助商家从固有电商平台的有限流量跳脱出来，到外部媒体平台去截取无限流量，相信做电商的朋友们都听说过CID，它可以算是是目前商家买量上策。 说回ROI，书面解释是投资回报率，通俗来讲就是你投入100…",
        "preview_type": "default",
        "preview_text": "",
        "reshipment_settings": "allowed",
        "content": "<p data-pid=\"CFb8RwIJ\">付费投流买流量，是最直接的引流方式。<br/><br/><br/>有商家可能会说，花钱买量也不一定靠谱，有时候买回来的都是不精准的流量，光消耗不成交，我不是白花钱了吗？<br/><br/><br/>是的，所以这年头个个都在讲ROI。特别是这几年兴起的引流电商Click-ID，更是帮助商家从固有电商平台的有限流量跳脱出来，到外部媒体平台去截取无限流量，相信做电商的朋友们都听说过CID，它可以算是是目前商家买量上策。<br/><br/><br/>说回ROI，书面解释是投资回报率，通俗来讲就是你投入100块钱能收回多少钱，收回150，ROI就是150/100=1.5，这就是ROI（亦可简称为投产），ROI越高越好。<br/><br/><br/>投放CID链路，拉正和提升ROI很重要，目前我们买量小飞机CID可以做到ROI提升80%。<br/><br/><br/>那么投CID链路如何提升ROI？有三点关键：<br/>1、精准人群<br/>先明确自己的产品主要目标人群是谁，投放时先设置初步的定向范围，搭建广告计划测试人群定向的准确度。买量小飞机CID技术链路可回传真实成交数据，实现点击ID和订单ID的1:1精准归因。同时媒体平台收到回传数据，也会帮商家定位精准人群。<br/><br/><br/>2、提升点击率<br/>跑CID要提升点击率，就是素材一定要做好，你的素材是在外部媒体平台上跑量的，我建议不要按照主观审美去做素材，在哪个平台上跑就照着哪个平台的爆量素材参考，颗粒级地去借鉴爆量素材的标题、文案、画面元素、BGM、营销手段等即可。<br/><br/><br/>3、提升转化率<br/>转化率这点无论是站内站外都要把主图详情评论做好，跑CID二跳的还要加上二跳落地页的页面设计，露出优惠信息、权威信息等，同时你合适用一跳还是二跳也不要人云亦云，最好经过测试验证，哪个效果好用哪个。具体操作可咨询买量小飞机CID的专业技术人员。<br/><br/><br/>人人都在提ROI，你怎样才能从众多竞争对手中脱颖而出？这就涉及到投放效率问题，就像赛跑，起步就比别人快，一开始就赢在起跑线上。<br/><br/><br/>但广告投放之痛，相信投放过的人都有所体会：<br/>1、投放平台多计划量大，操作繁琐<br/>特别是当你需要投放多个平台时，每天光是登上后台，搭建计划，然后每条计划都需要具有一定的差异。常规搭建任务再碰上变量测试时，优化师经常一天要搭几百条计划，手动搭完，一天都要过去了，严重内耗还挤压了复盘思考的时间，这是非常低效的。<br/><br/><br/>2、数据多，统计和复盘都很麻烦<br/>投放任务一多，数据的复盘就容易被忽略，即使你还记得复盘的事情，数据复盘本身也需要耗费大量时间，除了需要挨个平台下载数据，还很容易忽略关键指标像定向、标题等细致的数据维度。<br/><br/><br/>3、空耗计划无法及时调整<br/>优化师经常遇到这种情况，本来看计划都跑得好好的，吃个饭的时间就空耗了，人不在电脑前没及时调整计划，造成不小的损失。人的精力非常有限，一直靠人力盯盘始终无法很及时去处理突发情况。<br/><br/><br/>然而许多商家早就用上了智能工具来规避这些问题！<br/>买量小飞机智能投放工具，实现以程序化随机组合的方式，批量搭建广告计划，10分钟就可以搭上千条广告计划。<br/><br/><br/>所有平台全部广告计划产生的投放数据，细致到定向、标题、文案等数据报表都能一键下载。投放中，优化师离开电脑前可以设置条件让系统自动调整计划，即使人不在也不会耽误投放时机。<br/><br/><br/>因为高效，所以许多大品牌商家可以抢占商机，也是这个道理，人家都进入到工业化社会批量操作、智能管理了，你还在原始社会手动插秧，那必然是没得比的。</p><a href=\"https://link.zhihu.com/?target=https%3A//shunfei.feishu.cn/share/base/form/shrcnYSFoWB7sY8GmPEvm81i4zf%3Fchunked%3Dfalse\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">免费申请买量小飞机</a><p></p>",
        "relationship": {
          "is_thanked": false,
          "is_nothelp": false,
          "voting": 0
        },
        "is_labeled": false,
        "visited_count": 21,
        "favorite_count": 1,
        "answer_type": "normal",
        "is_navigator": false,
        "navigator_vote": false,
        "vote_next_step": "vote"
      },
      "brief": "{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1941820840560821424}",
      "attached_info": "CoMGCMfLgIfe7o38rQEQBBoJNzQzMjMzMzU4IPWemsUGKAAwAEDeA0okChlUU19TT1VSQ0VfV0FSTV9VUF9OT1JNQUwyEgEwGAAgADoASi8KJFRTX1NPVVJDRV9XQVJNVVBfVFdPVE9XRVJfRVhQVjJfVEVYVBIBMBgAIAA6AFoIOTU1NDk1MjViIGYwNzViYjAwYzI5ZjRjMzM2MjVhNTliYjM1MWFlMGE3chMxOTQxODIwODQwNTYwODIxNDI0igEJNTk5NzEwMTk3qgEJcmVjb21tZW5kwgEgNWM5NmUxYjEwODEzZTE0NTMzODhlMWQ0ZDNiZjVhMjTyAQoIDBIGTm9ybWFs8gEoCAoSJDEzNGFiNGQzLWZkNTUtNDBlYy05Y2Y3LTZiOTFiMTQ3YWVjOPIBBggLEgI4MIICAIgCzcLE+YwzkgIgNWM5NmUxYjEwODEzZTE0NTMzODhlMWQ0ZDNiZjVhMjSaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygIYQ29udGVudFdhcm1VcEJyZWFrSW5SdWxl2gIZVFNfU09VUkNFX1dBUk1fVVBfTk9STUFMMugCAvoCC05PUk1BTF9GTE9XigMgOWNjNzk1MjExMmUzNGFmZDljNTVlYjA0YmQ0MDhkMziaAw0KAnYyEAAaBW90aGVyqAMV2AMA6gMvY29udGVudFdhcm11cFR3b1Rvd2VyVHZwVGV4dE5vcm1hbEV4cFYyUmVjYWxsZXL6Ax8SDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFgAQAiAQAkgQGTm9ybWFsmgQBMqAEAKgEALAEALoEAmFpwgQDNDAwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAACANmyCP4EFAAAAAAAAAACJBbzb+5mmVNk/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBVCQBgCgBuIDqAYBkgIuCgk3NDMyMzMzNTgSEzE5NDE4MjA4NDA1NjA4MjE0MjQYBCIKSU1BR0VfVEVYVA==",
      "action_card": false
    },
    {
      "id": "479_1755822760.244",
      "type": "feed",
      "offset": 479,
      "verb": "TOPIC_ACKNOWLEDGED_ANSWER",
      "created_time": 1755822760,
      "updated_time": 1755822760,
      "target": {
        "id": "1941920602194679026",
        "type": "answer",
        "url": "https://api.zhihu.com/answers/1941920602194679026",
        "author": {
          "id": "db2ecfd304c94e443981788d7ec654d0",
          "url": "https://api.zhihu.com/people/db2ecfd304c94e443981788d7ec654d0",
          "user_type": "people",
          "url_token": "xiao-song-zi-16-44",
          "name": "贰拾肆",
          "headline": "教你怎么学习！ 偶尔分享短句～",
          "avatar_url": "https://picx.zhimg.com/50/v2-91234b41e6642af35c05aa2afd2479b7_l.jpg?source=b6762063",
          "is_org": false,
          "gender": 0,
          "followers_count": 14,
          "is_following": false,
          "is_followed": false
        },
        "created_time": 1755769950,
        "updated_time": 1755769950,
        "voteup_count": 10,
        "thanks_count": 0,
        "comment_count": 0,
        "is_copyable": true,
        "question": {
          "id": "343009345",
          "type": "question",
          "url": "https://api.zhihu.com/questions/343009345",
          "author": {
            "id": "051ed4f60a8f7ac114f642a264becea2",
            "url": "https://api.zhihu.com/people/051ed4f60a8f7ac114f642a264becea2",
            "user_type": "people",
            "url_token": "cheng-zi-39-11",
            "name": "青山撞入怀",
            "headline": "知乎是学习工具，不是拿来玩的",
            "avatar_url": "https://picx.zhimg.com/50/v2-88223c9bead24077ec361a46526c2a5d_l.jpg?source=b6762063",
            "is_org": false,
            "gender": 1,
            "followers_count": 1076,
            "is_following": false,
            "is_followed": false
          },
          "title": "下一个风口最可能是什么？",
          "created": 1566895240,
          "answer_count": 0,
          "follower_count": 0,
          "comment_count": 33,
          "bound_topic_ids": [
            99,
            307,
            922,
            2143,
            167007
          ],
          "is_following": false,
          "excerpt": "",
          "relationship": {
            "is_author": false
          },
          "detail": "",
          "question_type": "normal"
        },
        "thumbnail": "https://pic1.zhimg.com/50/v2-d7a8ba72b80cd86fd9a19216cc130e45_720w.jpg?source=b6762063",
        "excerpt": "2026年风口已经很明显了！！！   01.上瘾类行业 现代人生活压力大,失业率高,这一类的人会成为赌场、游戏、彩票、网络小说、短视频之类的消费大军其实,上瘾类产品还有酒、烟、咖啡、香辣甜的食物。 02.占卜玄学类 我是听朋友说起才接触这个行业的,这个行业绝对算得上闷声赚大钱的行业了。因为自古以来,上至君王下至老百姓都有想让别人算一算的心理。 03.知识付费类 有人提到这个就觉得割韭菜,但不可否认它是有增量市场的。只要你有…",
        "excerpt_new": "2026年风口已经很明显了！！！   01.上瘾类行业 现代人生活压力大,失业率高,这一类的人会成为赌场、游戏、彩票、网络小说、短视频之类的消费大军其实,上瘾类产品还有酒、烟、咖啡、香辣甜的食物。 02.占卜玄学类 我是听朋友说起才接触这个行业的,这个行业绝对算得上闷声赚大钱的行业了。因为自古以来,上至君王下至老百姓都有想让别人算一算的心理。 03.知识付费类 有人提到这个就觉得割韭菜,但不可否认它是有增量市场的。只要你有…",
        "preview_type": "default",
        "preview_text": "",
        "reshipment_settings": "allowed",
        "content": "<p data-pid=\"im66oKxV\">2026年风口已经很明显了！！！</p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-b82efa2dbe3126dc9a3a5b0f6c99e76d_1440w.jpg\" data-rawwidth=\"690\" data-rawheight=\"690\" data-size=\"normal\" data-original-token=\"v2-d7a8ba72b80cd86fd9a19216cc130e45\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic2.zhimg.com/v2-b82efa2dbe3126dc9a3a5b0f6c99e76d_r.jpg\"/></figure><p data-pid=\"dE4xnfQr\">01.上瘾类行业</p><p data-pid=\"uQEUceMh\">现代人生活压力大,失业率高,这一类的人会成为赌场、游戏、彩票、网络小说、短视频之类的消费大军其实,上瘾类产品还有酒、烟、咖啡、香辣甜的食物。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"2sgmltU4\">02.占卜玄学类</p><p data-pid=\"cKMhdF81\">我是听朋友说起才接触这个行业的,这个行业绝对算得上闷声赚大钱的行业了。因为自古以来,上至君王下至老百姓都有想让别人算一算的心理。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"Jih25Trm\">03.知识付费类</p><p data-pid=\"ErXRiVL0\">有人提到这个就觉得割韭菜,但不可否认它是有增量市场的。只要你有核心优势或特殊技能,刚好又是别人需要的,那你就可以变成现金。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"0q8vmgIw\">04.大健康类</p><p data-pid=\"WEnO12je\">这个行业几乎没有周期性,不管有钱没钱,生病了都要吃药和健康服务。现在的人健康意识越来越强多留意一下市场有哪些便携、有趣、好玩的养生产品。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"4XSgIkpX\">05.懒人偏好类​</p><p data-pid=\"izsr5ygr\">不是所有人都能坚持运动和严格控制饮食，很多人想减肥又怕麻烦。针对这类人群，推出减脂训练营。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"pKq-_NuQ\">06.疗愈类行业</p><p data-pid=\"ql_OigRR\">随着生活压力的增加、工作生活的快节奏和竞争的加剧，人们对于寻求心灵慰藉和身心平衡的需求也越来越强烈。单单看线上知识付费做这类产品的就很多，还不包括那些线下的门店和工作室,这也算是一个非常大的行业了。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"Eca6_a0K\">07.娱乐类</p><p data-pid=\"1DIOR7Bt\">任何人都有喜欢的放松方式。这个行业涵盖娱乐主播、唱片、旅游、酒吧、电影、演唱会有点名气的明星,他们的票都很难抢到。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"CyGQ3Ucx\">08.高科技行业</p><p data-pid=\"OP0pdNDs\">高科技行业是未来的趋势,天生具有高回报性，同时也受到国家政策的支持。引得各大风投资金蜂拥而至。芯片、航天航空、A1、半导体、新材料等行业是风投的必争之地。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"QZp2LAbi\">09.日常必需类</p><p data-pid=\"F8mMcP2o\">这个就不用多说了。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"GzO0N_mF\">10. 小众兴趣类</p><p data-pid=\"F6N_11CF\">年轻人越来越追求个性化，各种小众爱好开始冒出来，比如露营、手账、汉服、脱口秀。围绕这些兴趣做产品、搞活动，只要能抓住精准人群，就能赚到钱。</p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-fd2757932c62b7219213561f24f303fa_1440w.jpg\" data-rawwidth=\"1620\" data-rawheight=\"1080\" data-size=\"normal\" data-original-token=\"v2-4cdf2891e59a4b631df668510482ddd7\" class=\"origin_image zh-lightbox-thumb\" width=\"1620\" data-original=\"https://pica.zhimg.com/v2-fd2757932c62b7219213561f24f303fa_r.jpg\"/></figure><p data-pid=\"6yEjMbXw\">11. 智能家居类</p><p data-pid=\"ije67qeC\">大家生活水平提高了，都想让家里更智能、更方便。智能门锁、扫地机器人、智能灯光这些，慢慢成了很多家庭的标配，这个行业会越来越红火。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"3y0_DWJX\">12. 心理健康类</p><p data-pid=\"696E8c9d\">现在生活节奏快，压力大，很多人都有心理困扰。心理咨询、情绪疏导、冥想课程这些需求在增加，而且大家对心理健康的重视程度也在提高，这行潜力很大。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"QDYCa6q6\">13. 群体刚需类​</p><p data-pid=\"gvs1CIPB\">现在不管是上班族还是宝妈，熬夜、压力大、劳累成了常态，很多人都有气血不足的问题，动不动就头晕乏力、脸色差。针对这类群体的市场前景很好。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"-PhnNh08\">14. 跨境电商类</p><p data-pid=\"v79LkHsN\">现在国内外的商品交流越来越频繁，很多国外的好东西想进来，国内的好产品也想出去。做跨境电商，把好货卖到全球，市场很大，只要摸透规则就能赚钱。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"vJb1GrWn\">15. 临期食品折扣类</p><p data-pid=\"KRT7ceja\">现在年轻人过日子越来越精打细算，临期食品价格便宜还不影响食用，很受欢迎。开个线下折扣店或者做线上社群团购，成本低利润不低，这行能做起来。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"DylrvSYF\">16. 儿童素质教育类</p><p data-pid=\"6ktQttny\">“双减”之后，家长更看重孩子的综合能力，像编程、书法、口才、运动这些素质类课程需求猛增。只要课程有特色、老师有水平，不愁招不到学生。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"QOehUQpI\">17. 需求明确类​</p><p data-pid=\"-MojUvjs\">现在人越来越注重护肤，尤其是洗面奶，天天都得用。美妆护肤类赛道很有关注的必要。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"4h2rYrAB\">18. 二手物品交易类</p><p data-pid=\"SVNXfK_R\">年轻人越来越接受二手物品，从衣服包包到家具家电，二手交易市场越来越大。做个二手物品回收、翻新或交易平台，既能环保又能赚钱。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"Kgui6XeJ\">19. 在线医疗咨询类</p><p data-pid=\"oy0RLIyv\">小病小痛不想跑医院，在线问诊、购药越来越方便。只要有正规资质，提供专业的医疗建议和药品配送服务，用户会越来越多，市场潜力大。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"L5X-Iy46\">20. 家庭园艺种植类</p><p data-pid=\"4MwJV0E6\">疫情后很多人爱上了在家养花种菜，花盆、花土、种子、园艺工具这些需求大增。开个线上园艺店，再教点种植技巧，生意肯定错不了。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"HXma0yCP\">21. 差异化优势类</p><p data-pid=\"K8xg346B\">有人瞅准年轻女孩的需求，把一款小众却效果佳的美白产品纽斯特vcve葡萄籽从国内带到海外，包装成私藏好物，开视频坚持打卡三个月，那脸是越用越白，越用越亮，老神奇了，我自己也买来宠幸了小半年，那小脸白嫩的跟抛光似的，肤感还好，光靠回头客每月稳定出几十瓶。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"bzbElh7l\">22. 智能健身设备类</p><p data-pid=\"vAxCsEzm\">没时间去健身房的人越来越多，家用智能健身镜、动感单车这些设备能跟着在线课程锻炼，方便又高效，会成为很多家庭的新选择。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"ZXy_jWpR\">23. 特色餐饮外卖类</p><p data-pid=\"Zp8RUz0Z\">现在外卖竞争激烈，但有特色的小餐饮反而容易突围，比如地方小吃、健康轻食、创意甜品。只要味道好、包装有特色，回头客会很多。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"qAqM2_p9\">24. 虚拟偶像运营类</p><p data-pid=\"5PtGy4-z\">年轻人追虚拟偶像的越来越多，虚拟主播、虚拟歌手能带货、开演唱会，商业价值不断提升。打造或运营有特色的虚拟偶像，变现路子广。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"BAiWv1Cv\">25.痛点驱动类​</p><p data-pid=\"UoEqBkJb\">现在人社交频繁，不管是职场沟通还是朋友聚会，多关注身边人的痛点，这不仅仅是单一现象，找到共同点，创新发展模式。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"SIfYrIxJ\">26.金融中介</p><p data-pid=\"iDCyJP7j\">有人说,现在平台放贷已经很方便了,应该不需要中介了。但债务优化还是不良资产的处置,还是需要中介处理的。现在经济下行期间,很多人做生意都需要钱,需求量是大幅增长的。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"g8MTvk5w\">27.二奢与贵金属回收类</p><p data-pid=\"_juoWy8V\">这个行业闷发大财的人太多了。有朋友的亲戚就是靠这行业赚到第一桶金。这个行业跟黄金回收一样很多人出现资金周转不开的问题。这时候他们就会把高价买的奢侈品低价卖或押给店里。中间的差价就是你的利润。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"v629AVoU\">28.低成本高回报类</p><p data-pid=\"2j3m32jd\">一个开美容院的姐妹分享的，美容院所谓的“小气泡”项目，成本不到10块钱，收你几百块。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"tFaYEcu4\">29.社区团购服务类</p><p data-pid=\"z6EQzssb\">大家习惯在手机上买菜买日用品，社区团购团长负责组织订单、收发货物，不用囤货风险小，每月赚点零花钱很轻松，做得好收入还能超过主业。</p><p class=\"ztext-empty-paragraph\"><br/></p><p data-pid=\"Q2mIrtDk\">30.银发美妆服饰类</p><p data-pid=\"PE9MWpA4\">别以为老年人不爱打扮，现在很多阿姨大爷也讲究穿搭和形象，适合他们的美妆、舒适的服饰很有市场。款式选对了，销量会很可观。</p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-55e7826cf6bf47487a3e68a26fd20b47_1440w.jpg\" data-rawwidth=\"690\" data-rawheight=\"690\" data-size=\"normal\" data-original-token=\"v2-152e60b3c6f05084f45a1cb0f738698e\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic4.zhimg.com/v2-55e7826cf6bf47487a3e68a26fd20b47_r.jpg\"/></figure><p></p>",
        "relationship": {
          "is_thanked": false,
          "is_nothelp": false,
          "voting": 0
        },
        "is_labeled": false,
        "visited_count": 1057,
        "thumbnails": [
          "https://picx.zhimg.com/50/v2-d7a8ba72b80cd86fd9a19216cc130e45_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-9a236ccd3b0c88426ef0948c7c0e2a04_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-152e60b3c6f05084f45a1cb0f738698e_720w.jpg?source=b6762063"
        ],
        "favorite_count": 33,
        "answer_type": "normal",
        "is_navigator": false,
        "navigator_vote": false,
        "vote_next_step": "vote"
      },
      "brief": "{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1941920602194679026}",
      "attached_info": "CvwGCMfLgIfe7o38rQEQBBoJNzQzMjk5NzkzIN7Ym8UGKAowAEDfA0ouChlUU19TT1VSQ0VfRkVFRFJFX01TX0hRX1YyEgEwGAAgADoKeyJyYXciOiIifUorChZUU19TT1VSQ0VfRkVFRFJFX01TX1YyEgEwGAAgADoKeyJyYXciOiIifVoIMzg1MDExOTRiIGYwNzViYjAwYzI5ZjRjMzM2MjVhNTliYjM1MWFlMGE3chMxOTQxOTIwNjAyMTk0Njc5MDI2igEJMzQzMDA5MzQ1qgEJcmVjb21tZW5kwgEgZGIyZWNmZDMwNGM5NGU0NDM5ODE3ODhkN2VjNjU0ZDDyAQoIDBIGTm9ybWFs8gEoCAoSJGI5M2M2NDhiLTdkMjktNDkxNy1hODBlLTAyNTFmZjc2YzM2NvIBBggLEgI4MIICAIgCzcLE+YwzkgIgZGIyZWNmZDMwNGM5NGU0NDM5ODE3ODhkN2VjNjU0ZDCaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygIVUXVlc3Rpb25Jc29sYXRpb25SdWxl2gIZVFNfU09VUkNFX0ZFRURSRV9NU19IUV9WMugCAvoCC05PUk1BTF9GTE9XigMgOWNjNzk1MjExMmUzNGFmZDljNTVlYjA0YmQ0MDhkMziaAw0KAnYyEAAaBW90aGVyqAOhCNgDAOoDFmZlZWRyZV9tc19nYXRlX29ubHlfaHH6A6wBEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERTotCAQQsgUYsgUiI3YyLWQ3YThiYTcyYjgwY2Q4NmZkOWExOTIxNmNjMTMwZTQ1Oi0IBBDUDBi4CCIjdjItNGNkZjI4OTFlNTlhNGI2MzFkZjY2ODUxMDQ4MmRkZDc6LQgEELIFGLIFIiN2Mi0xNTJlNjBiM2M2ZjA1MDg0ZjQ1YTFjYjBmNzM4Njk4ZYAEAIgEAJIEBk5vcm1hbJoEATKgBACoBACwBAC6BAJhacIEAzQwMMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAYErmsT+BBQAAAAAAAAAAiQW82/uZplTZP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AVQkAYAoAbjA6gGAJICLgoJNzQzMjk5NzkzEhMxOTQxOTIwNjAyMTk0Njc5MDI2GAQiCklNQUdFX1RFWFQ=",
      "action_card": false
    }
  ],
  "paging": {
    "is_end": false,
    "is_start": false,
    "next": "https://www.zhihu.com/api/v3/feed/topstory/recommend?action=down&ad_interval=-10&after_id=479&desktop=true&end_offset=483&page_number=81&session_token=f075bb00c29f4c33625a59bb351ae0a7",
    "previous": "https://www.zhihu.com/api/v3/feed/topstory/recommend?action=pull&ad_interval=-10&before_id=479&desktop=true&end_offset=483&page_number=81&session_token=f075bb00c29f4c33625a59bb351ae0a7",
    "totals": 0
  },
  "fresh_text": "推荐已更新"
}