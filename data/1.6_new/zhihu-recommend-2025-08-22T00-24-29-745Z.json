{
  "data": [
    {
      "id": "96_1755822316.434",
      "type": "feed",
      "offset": 96,
      "verb": "TOPIC_ACKNOWLEDGED_ARTICLE",
      "created_time": 1755822316,
      "updated_time": 1755822316,
      "target": {
        "id": "1941259859090707007",
        "type": "article",
        "url": "https://api.zhihu.com/articles/1941259859090707007",
        "author": {
          "id": "c79de8f5bf4db25afe3ec854e283eb10",
          "url": "https://api.zhihu.com/people/c79de8f5bf4db25afe3ec854e283eb10",
          "user_type": "people",
          "url_token": "123-10-43-44-42",
          "name": "西西123",
          "headline": "",
          "avatar_url": "https://pica.zhimg.com/50/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=b6762063",
          "is_org": false,
          "gender": 0,
          "followers_count": 39,
          "is_following": false,
          "is_followed": false
        },
        "title": "你绝对搞不到的稀缺资源都在我这里",
        "comment_permission": "all",
        "created": 1755614105,
        "updated": 1755614105,
        "voteup_count": 23,
        "voting": 0,
        "comment_count": 0,
        "linkbox": {
          "category": "",
          "pic": "",
          "title": "",
          "url": ""
        },
        "excerpt": "电视剧 https://pan.quark.cn/s/724b95ef0027 电影https://pan.quark.cn/s/e980c6121805 纪录片https://pan.quark.cn/s/dbd1d175aaae DeepSeek使用秘笈｜100个技巧从入门到精通（大模型操作指南+AI开发实战）https://pan.quark.cn/s/33801f38473c AI工具60种用法｜从文件优化到法律咨询（Kimi+ChatGLM全场景实战）https://pan.quark.cn/s/46ec10cee725 电商设计摄影课｜主图 详情页设计+转化率提升（2025年大流量运营秘籍）https://pan.quark.cn/s/4fb95ea12510 钢琴弹唱100天速成课｜零基础入门+流行歌曲伴奏（系统化教学+视…",
        "excerpt_new": "电视剧 https://pan.quark.cn/s/724b95ef0027 电影https://pan.quark.cn/s/e980c6121805 纪录片https://pan.quark.cn/s/dbd1d175aaae DeepSeek使用秘笈｜100个技巧从入门到精通（大模型操作指南+AI开发实战）https://pan.quark.cn/s/33801f38473c AI工具60种用法｜从文件优化到法律咨询（Kimi+ChatGLM全场景实战）https://pan.quark.cn/s/46ec10cee725 电商设计摄影课｜主图 详情页设计+转化率提升（2025年大流量运营秘籍）https://pan.quark.cn/s/4fb95ea12510 钢琴弹唱100天速成课｜零基础入门+流行歌曲伴奏（系统化教学+视…",
        "preview_type": "default",
        "preview_text": "",
        "content": "<p data-pid=\"FQyQrQIE\">电视剧<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/724b95ef0027\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/724b95ef</span><span class=\"invisible\">0027</span><span class=\"ellipsis\"></span></a><br/>电影<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/e980c6121805\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/e980c612</span><span class=\"invisible\">1805</span><span class=\"ellipsis\"></span></a><br/>纪录片<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/dbd1d175aaae\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/dbd1d175</span><span class=\"invisible\">aaae</span><span class=\"ellipsis\"></span></a><br/>DeepSeek使用秘笈｜100个技巧从入门到精通（大模型操作指南+AI开发实战）<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/33801f38473c\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/33801f38</span><span class=\"invisible\">473c</span><span class=\"ellipsis\"></span></a><br/>AI工具60种用法｜从文件优化到法律咨询（Kimi+ChatGLM全场景实战）<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/46ec10cee725\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/46ec10ce</span><span class=\"invisible\">e725</span><span class=\"ellipsis\"></span></a><br/>电商设计摄影课｜主图 详情页设计+转化率提升（2025年大流量运营秘籍）<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/4fb95ea12510\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/4fb95ea1</span><span class=\"invisible\">2510</span><span class=\"ellipsis\"></span></a><br/>钢琴弹唱100天速成课｜零基础入门+流行歌曲伴奏（系统化教学+视频跟练）<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/d8e045843e53\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/d8e04584</span><span class=\"invisible\">3e53</span><span class=\"ellipsis\"></span></a><br/>会计实操特训营｜零基础到初级会计（Excel财务+税务申报+就业指导）<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/1e1de0229355\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/1e1de022</span><span class=\"invisible\">9355</span><span class=\"ellipsis\"></span></a><br/>Linux基础命令实战课｜零基础入门+企业级实操（命令行操作+脚本编写）<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/c4ba51383891\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/c4ba5138</span><span class=\"invisible\">3891</span><span class=\"ellipsis\"></span></a><br/>SPSS论文数据分析实战<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/e5ab86ca2018\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/e5ab86ca</span><span class=\"invisible\">2018</span><span class=\"ellipsis\"></span></a><br/>Office工具集｜批量文档转换+水印管理（去水印 加水印 解密PDF Word）<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/df07c6737049\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/df07c673</span><span class=\"invisible\">7049</span><span class=\"ellipsis\"></span></a><br/>最全家电维修大全视频教程<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/648cf9102dde\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/648cf910</span><span class=\"invisible\">2dde</span><span class=\"ellipsis\"></span></a><br/>深入浅出Java并发多线程：核心基础+内存模型＋死锁——从用法到原理，面试必考<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/bab61b16cc28\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/bab61b16</span><span class=\"invisible\">cc28</span><span class=\"ellipsis\"></span></a><br/>夜猫编程-Python爬虫课｜零基础到高薪就业（JS逆向+企业实战）<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/6e009f80eaad\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/6e009f80</span><span class=\"invisible\">eaad</span><span class=\"ellipsis\"></span></a><br/>100部名著精读笔记<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/9da7e3c22644\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/9da7e3c2</span><span class=\"invisible\">2644</span><span class=\"ellipsis\"></span></a><br/>北京大学出版社十五讲经典套装—历史文化系列（14册） - 朱良志 等<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/7258b0b25cbe\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/7258b0b2</span><span class=\"invisible\">5cbe</span><span class=\"ellipsis\"></span></a><br/>成真《偷听女人心45期》<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/b2495c5284fe\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/b2495c52</span><span class=\"invisible\">84fe</span><span class=\"ellipsis\"></span></a><br/>8岁女孩关键期育儿指南｜成长心理+养育技巧（PDF电子书+免费下载+家长必读）<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/e1f504560994\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/e1f50456</span><span class=\"invisible\">0994</span><span class=\"ellipsis\"></span></a><a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/e1f504560994\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/e1f50456</span><span class=\"invisible\">0994</span><span class=\"ellipsis\"></span></a>创意写作书系经典系列（套装共36册） - 杰克·赫弗 等<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/6311980032af\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/63119800</span><span class=\"invisible\">32af</span><span class=\"ellipsis\"></span></a><br/>付费小说合集【上百本】<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/f55245b541a9\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/f55245b5</span><span class=\"invisible\">41a9</span><span class=\"ellipsis\"></span></a><br/>非常珍贵稀缺的古籍古史<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/76e120317b71\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">h</a><a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/86e640301f2c\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/86e64030</span><span class=\"invisible\">1f2c</span><span class=\"ellipsis\"></span></a><br/>儿童注意力训练<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/4810ff7601b3\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/4810ff76</span><span class=\"invisible\">01b3</span><span class=\"ellipsis\"></span></a><a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/4810ff7601b3\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">二十四史精华：文白对</a>照版（套装全十册) - 司马迁<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/592cff7ad679\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/592cff7a</span><span class=\"invisible\">d679</span><span class=\"ellipsis\"></span></a><br/>读一页就上瘾的唐朝史（全4册）<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/2016396708b9\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/20163967</span><span class=\"invisible\">08b9</span><span class=\"ellipsis\"></span></a><br/>官场小说225部<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/f2bd8909416d\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/f2bd8909</span><span class=\"invisible\">416d</span><span class=\"ellipsis\"></span></a><br/>分享经济时代（套装6册）<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/e53f012e2616\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/e53f012e</span><span class=\"invisible\">2616</span><span class=\"ellipsis\"></span></a><br/>国宴大师教做菜（120道菜合集）<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/9d4e5f654a4e\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/9d4e5f65</span><span class=\"invisible\">4a4e</span><span class=\"ellipsis\"></span></a><a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/592cff7ad679\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/592cff7a</span><span class=\"invisible\">d679</span><span class=\"ellipsis\"></span></a>高质量历史书<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/cdb8192e986c\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/cdb8192e</span><span class=\"invisible\">986c</span><span class=\"ellipsis\"></span></a><br/>好好接话：会说话是优势 会接话才是本事<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/cdb8192e986c\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/cdb8192e</span><span class=\"invisible\">986c</span><span class=\"ellipsis\"></span></a><br/>明清古籍583册合集<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/8ab9c891ee7e\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/8ab9c891</span><span class=\"invisible\">ee7e</span><span class=\"ellipsis\"></span></a><br/>墨菲定律：避开人生倒霉的20个坑 <a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/d1c4f7915254\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/d1c4f791</span><span class=\"invisible\">5254</span><span class=\"ellipsis\"></span></a><br/>历代名家词集精华录<a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/406b0db03047\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/406b0db0</span><span class=\"invisible\">3047</span><span class=\"ellipsis\"></span></a><a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/406b0db03047\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/406b0db0</span><span class=\"invisible\">3047</span><span class=\"ellipsis\"></span></a>酒桌秘籍-交际宝典-营销人酒桌 <a href=\"https://link.zhihu.com/?target=https%3A//pan.quark.cn/s/1be6d9f9dd88\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pan.quark.cn/s/1be6d9f9</span><span class=\"invisible\">dd88</span><span class=\"ellipsis\"></span></a></p>",
        "is_labeled": false,
        "visited_count": 2826,
        "favorite_count": 245,
        "article_type": "normal",
        "is_navigator": false,
        "navigator_vote": false,
        "vote_next_step": "vote"
      },
      "brief": "{\"source\": \"TS\", \"type\": \"article\", \"id\": 1941259859090707007}",
      "attached_info": "CvsFCNyT/PDV2JSqnQEQBxoJMjYxOTU3MTk5IJmXksUGKBcwAEBgSisKFlRTX1NPVVJDRV9GRUVEUkVfTVNfVjISATAYACAAOgp7InJhdyI6IiJ9SkQKIFRTX1NPVVJDRV9TT0NJQUxfRk9MTE9XX05FQVJMSU5FEhpuZWFybGluZUNvbnRlbnRWMjo1NzA1MzgyNBgAIAA6AEowChtUU19TT1VSQ0VfQkFTSUNfSU5GT19SRUNBTEwSATAYACAAOgp7InJhdyI6IiJ9YiBmMDc1YmIwMGMyOWY0YzMzNjI1YTU5YmIzNTFhZTBhN3ITMTk0MTI1OTg1OTA5MDcwNzAwN6oBCXJlY29tbWVuZMIBIGM3OWRlOGY1YmY0ZGIyNWFmZTNlYzg1NGUyODNlYjEw8gEKCAwSBk5vcm1hbPIBKAgKEiRkOThmYmRkNC0wYTMyLTQyNjctYTQ1NS0xNzdlYjYyY2RhNWHyAQYICxICMTeCAgCIApyzqfmMM5ICIGM3OWRlOGY1YmY0ZGIyNWFmZTNlYzg1NGUyODNlYjEwmgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZdoCFlRTX1NPVVJDRV9GRUVEUkVfTVNfVjLoAgL6AgtOT1JNQUxfRkxPV4oDIDkyNjUzMjE0OWY2NTRjNDdiZTJmNzM3Mjk4ODg1YWZmmgMNCgJ2MhAAGgVvdGhlcqgDihbYAwDqAw5mZWVkcmVfbXNfZ2F0ZfoDHxIMVU5LTk9XTl9NT0RFIAAqDU5PX0lNQUdFX01PREWABACIBACSBAZOb3JtYWyaBAEyoAQAqAQAsAQAugQCYWnCBAM0MDDIBADSBA/mjqjojZDlt7Lmm7TmlrDYBADwBAD5BAAAAGBfJqw/gQUAAAAAAAAAAIkFXkKMMwhU2T+SBQCaBQNkZnSiBQNkZnSyBQExuQUAAAAAAAAAANAFAOAFAOgFAPAFEZAGAKAGYqgGAZICLgoJMjYxOTU3MTk5EhMxOTQxMjU5ODU5MDkwNzA3MDA3GAciCklNQUdFX1RFWFQ=",
      "action_card": false
    },
    {
      "id": "97_1755822316.895",
      "type": "feed",
      "offset": 97,
      "verb": "TOPIC_ACKNOWLEDGED_ANSWER",
      "created_time": 1755822316,
      "updated_time": 1755822316,
      "target": {
        "id": "1941544129201939904",
        "type": "answer",
        "url": "https://api.zhihu.com/answers/1941544129201939904",
        "author": {
          "id": "dfd18f312d5211bc280bddc5188a8ff2",
          "url": "https://api.zhihu.com/people/dfd18f312d5211bc280bddc5188a8ff2",
          "user_type": "people",
          "url_token": "weihaisheng",
          "name": "韦海生",
          "headline": "公众号「韦海生」，一个比较正经的读书号。",
          "avatar_url": "https://picx.zhimg.com/50/v2-cc25c65d30efc8cad9823e870ad35fda_l.jpg?source=b6762063",
          "is_org": false,
          "gender": 1,
          "followers_count": 11697,
          "is_following": false,
          "is_followed": false
        },
        "created_time": 1755680192,
        "updated_time": 1755680192,
        "voteup_count": 3,
        "thanks_count": 0,
        "comment_count": 0,
        "is_copyable": false,
        "question": {
          "id": "20011144",
          "type": "question",
          "url": "https://api.zhihu.com/questions/20011144",
          "author": {
            "id": "",
            "url": "",
            "user_type": "people",
            "url_token": "",
            "name": "匿名用户",
            "headline": "",
            "avatar_url": "https://pica.zhimg.com/v2-d41c2ceaed8f51999522f903672a521f_l.jpg?source=b6762063",
            "is_org": false,
            "gender": -1,
            "followers_count": 0,
            "is_following": false,
            "is_followed": false
          },
          "title": "关于骗局方面的书籍有哪些推荐？",
          "created": 1326006307,
          "answer_count": 0,
          "follower_count": 0,
          "comment_count": 1,
          "bound_topic_ids": [
            53,
            9793,
            11973,
            35436
          ],
          "is_following": false,
          "excerpt": "",
          "relationship": {
            "is_author": false
          },
          "detail": "",
          "question_type": "normal"
        },
        "excerpt": "这几天，我在修订奚恺元的《别做正常的傻瓜》的精读文章时，就不自觉地想起了自己以前被人骗了几次的经历，有些是投资上的坑，有些是生活中的小套路，现在回过头去想，觉得当时我怎么那么傻。 于是我就主动去读相关的书。那段时间，我除了读奚恺元的书，还把理查德·塞勒的《「错误」的行为》拿出来看了一遍，还有几本讲心理学和决策的书。 如果你被人骗过，不想再被骗，就多读这方面的书，我给你找出了三本，除了《别做正常的傻…",
        "excerpt_new": "这几天，我在修订奚恺元的《别做正常的傻瓜》的精读文章时，就不自觉地想起了自己以前被人骗了几次的经历，有些是投资上的坑，有些是生活中的小套路，现在回过头去想，觉得当时我怎么那么傻。 于是我就主动去读相关的书。那段时间，我除了读奚恺元的书，还把理查德·塞勒的《「错误」的行为》拿出来看了一遍，还有几本讲心理学和决策的书。 如果你被人骗过，不想再被骗，就多读这方面的书，我给你找出了三本，除了《别做正常的傻…",
        "preview_type": "default",
        "preview_text": "",
        "reshipment_settings": "disallowed",
        "content": "<p data-pid=\"W6XV057d\">这几天，我在修订奚恺元的《别做正常的傻瓜》的精读文章时，就不自觉地想起了自己以前被人骗了几次的经历，有些是投资上的坑，有些是生活中的小套路，现在回过头去想，觉得当时我怎么那么傻。</p><p data-pid=\"XaEk7miq\">于是我就主动去读相关的书。那段时间，我除了读奚恺元的书，还把理查德·塞勒的《「错误」的行为》拿出来看了一遍，还有几本讲心理学和决策的书。</p><p data-pid=\"DLv4_hpX\">如果你被人骗过，不想再被骗，就多读这方面的书，我给你找出了三本，除了《别做正常的傻瓜》，还有另外两本叫《怪诞行为学》和《我们为什么会受骗》。</p><h3><b><u>第一本：《别做正常的傻瓜》</u></b></h3><p data-pid=\"9ZDUQt2j\">这本书讲的是，人为什么会在一些本该想得明白的问题上犯迷糊，做出不理性的选择。作者奚恺元把经常犯低级错的人叫做「正常的傻瓜」，意思是这些错误太普遍了，每个人都可能犯。</p><p data-pid=\"P4tNeMLZ\">这本书里有一个概念叫<b>「心理账户」</b>，它说的是你把实际上一样多的钱，在心里却分成了不同的类别。</p><p data-pid=\"zSzOvCSM\">比如你买了一张音乐会门票，结果弄丢了，你可能就不再愿意花钱买票了。可是你出门时丢了一张同样价值的电话卡，你可能还是会高高兴兴地去买音乐会门票。</p><p data-pid=\"_MwbuJw3\">你看，同样是损失了一千块钱，但因为它们在你的心里被分到了不同的「账户」——一个是「娱乐账户」的损失，一个是「通信账户」的损失，你的决定就完全不一样了。</p><p data-pid=\"OWoI0o9x\">从经济学的角度来看，钱就是钱，没有区别，一千块就是一千块。可是人不是机器，你心里给钱打上不同的标签，这就直接影响了你对花钱、赚钱的看法，让你对不同的收入和支出有不同的态度。比如有人就倾向于把大笔的钱存起来，而把小钱花在日常消费上。</p><p data-pid=\"oO7VutTz\">我再讲一个概念叫<b>「沉没成本」</b>，它的意思是你已经投入的钱或者时间，就算收不回来了，你也会因为舍不得这些投入，继续在一件明知道会亏本的事情上加大投入。</p><p data-pid=\"WCwFil1l\">就像英国和法国造「协和飞机」，明知道造价和运营成本很高，还可能亏本，但是因为之前已经投了那么多钱，不愿意放弃，结果亏得更多。</p><p data-pid=\"Oiw_bvNR\">还有父母给孩子买了电子琴，孩子不敢兴趣，但是因为琴已经买了，就觉得不能浪费，又花钱请家教，结果浪费了更多的钱。这些都是被过去无法挽回的成本牵着鼻子走，做出了不理智的决定。</p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-c298e3f1459b33fa8b95615a0d10b749_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"713\" data-rawheight=\"293\" data-original-token=\"v2-7181e6a55cac39426f004cdfd5f29fd4\" data-default-watermark-src=\"https://pica.zhimg.com/v2-6061f7d098ce658612fd901ba93aa542_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"713\" data-original=\"https://pic2.zhimg.com/v2-c298e3f1459b33fa8b95615a0d10b749_r.jpg\"/></figure><p data-pid=\"v7_rfrAI\"><b>推荐理由：</b>这本书能让你看清自己决策中，有哪些是「傻瓜」的行为。我过去就经常在消费上犯类似的毛病，看到打折的书就两眼放光，买了一堆根本不读的书回来。可是读完这本书，我明白了原来是心里的「心理账户」和「交易效用」在作怪。</p><p data-pid=\"ovanZ1JC\">幸亏读了这本书，我才注意到每个人身上都有不少偏见，<b>这些偏见不分学历高低，也不分你财富多少，每个人都有可能中招</b>。</p><p data-pid=\"3GKtjFMf\">当你明白了这些偏见的来龙去脉，下次再遇到类似的情况，你心里就有数了，也意识到自己可能要犯错了，这样你就能提前给自己提个醒，避免上当受骗。</p><h3><b><u>第二本：《怪诞行为学》</u></b></h3><p data-pid=\"VOWXsQQi\">丹·艾瑞里的这本书讲的是，一个人其实并不像传统经济学里说的那么理性，他做决定的时候就经常犯一些可预测的错误。这些错误不是偶然，而是有规律的，就是因为它们有规律，别人才能利用这些规律来影响你。</p><p data-pid=\"H-Ugiu6_\">书中提到了一个概念叫<b>「相对论的真相」</b>，意思是你很难不比较着看东西。你买一样东西，不是看它本身值多少钱，而是看它和其他同类东西比起来怎么样。</p><p data-pid=\"uU95ia7o\">比如订阅一本杂志，有电子版59美元，印刷版125美元，印刷加电子版也是125美元。你就觉得印刷版和电子版捆绑的那个最划算，因为电子版好像是白送的。</p><p data-pid=\"zlMK0N2S\">这就是因为有了那个「诱饵」——单订印刷版125美元，让你觉得印刷加电子版的服务赚到了。当你心里没有一个标准来衡量东西的真实价值，就只能通过比较来判断。</p><p data-pid=\"hPPOBzdH\">我再讲另外一个有用的概念叫<b>「锚定效应」和「任意的一致」</b>。它说的是你第一次接触到的某个价格，就像一个「锚」一样，牢牢地定在心里，影响你后面一系列的决定。</p><p data-pid=\"qXtX-7X_\">即使这个「锚」是随便定的，你也会不自觉地被它影响。比如你让几个人写下自己保号的后两位数，然后让他们给一样东西出价，结果社保号后两位数大的人，出价更高。</p><p data-pid=\"vD19GKF5\">这就说明，你一开始做的那个决定，不管是不是随意的，都会影响你后面怎么看、怎么做。你看星巴克的成功，就有一部分原因，是它一开始就提供了一个和普通咖啡店不一样的「锚」，让你愿意为它的咖啡支付更高的价格。</p><p data-pid=\"W7mQNnfZ\"><b>推荐理由：</b>当你读了这本《怪诞行为学》，就知道人不是一台精准的机器，你自己的不理性是有迹可循的，也是可以预测的。</p><p data-pid=\"yvyDST4z\">我之前就老是陷入选择的困境，把自己搞得筋疲力尽。读了这本书我才看清，很多时候那些所谓的选择，只是消耗我的精力和时间而已。</p><p data-pid=\"Kjj3MLac\">这本书不只告诉你人有哪些缺点，还让你看清这些「陷阱」是怎么运作的。当你明白了这些，就能在面对诱惑和复杂的选择时，不那么容易上当受骗了。</p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-d27521b0216d564dc9f46512e479cb73_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"326\" data-original-token=\"v2-98fdef6d031a7a4c7fb40e96f140928f\" data-default-watermark-src=\"https://pic1.zhimg.com/v2-1473af24b608a5117b89d173a6c7e420_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"700\" data-original=\"https://pic4.zhimg.com/v2-d27521b0216d564dc9f46512e479cb73_r.jpg\"/></figure><h3><b><u>第三本：《我们为什么会受骗》</u></b></h3><p data-pid=\"CN1Vbsds\">这本书讲的是，骗子是怎样一步步取得你的信任，让你心甘情愿地落入他们圈套的。作者玛丽亚·康妮科娃就把骗子的手法分成了几个阶段，我就带你从头到尾了解一遍。</p><p data-pid=\"1F0gNjkO\"><b>骗局的第一步是「料敌机先」</b>。这时骗子都是想办法了解你，知道你想要什么，有什么弱点，然后利用你的欲望来达成他的目的。</p><p data-pid=\"_ip0B7Eu\"><b>第二步是「动之以情」</b>。骗子了解你之后，就想办法和你培养感情，让你对他产生好感。比如他会利用你的孤独、焦虑、悲痛，或者让你先感到恐惧，再给你带来放松，让你在不假思索的状态下答应他的请求。</p><p data-pid=\"G3ZGQoGZ\"><b>第三步是「请君入瓮」和「取信于人」</b>。到了这一步，骗子就会编一个故事，这个故事听起来好得不像真的，但又刚好符合你的期望，或者你觉得应该得到的东西。</p><p data-pid=\"DBEQro-K\">接着他再拿出一些「证据」来证明这个故事是真的，就算这些证据模糊不清或者自相矛盾，你也会因为太想相信，而选择了忽视。</p><p data-pid=\"uxRTQKuh\"><b>第四步是「欲擒故纵」和「得寸进尺」</b>。这时你投入了不少的金钱、时间，已经很难退出了。因为你发现自己已经付出很多，如果放弃的话，之前的投入就白费了。</p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-d73a7edc3ae9d76b633f316212734e1b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"721\" data-rawheight=\"327\" data-original-token=\"v2-3ef961a9c5c09178d91ba54146e594f1\" data-default-watermark-src=\"https://picx.zhimg.com/v2-4d272d4f463db2ada7f91b1055b20435_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"721\" data-original=\"https://pic4.zhimg.com/v2-d73a7edc3ae9d76b633f316212734e1b_r.jpg\"/></figure><p data-pid=\"iguA936S\"><b>第五步是「逃之夭夭」和「斩草除根」</b>。骗子之所以能轻易脱身，很大一部分原因是你被骗之后，不愿意承认自己被骗了。因为你承认自己被骗，就意味着名誉受损，还会被别人看成傻瓜。这种羞耻感让你选择沉默，不愿声张。</p><p data-pid=\"uLhDKjUh\"><b>推荐理由：</b>这本书让你知道了骗局不是平白无故产生的，而是有一套完整的人心操控流程。我以前觉得那些上当受骗的人，是因为他们不够聪明。</p><p data-pid=\"apnWSQ4M\">但是读完这本书，我才知道骗子都是心理学高手，他不是靠蛮力，而是靠摸透了人性的弱点，再编造一个让你愿意相信的故事。</p><p data-pid=\"gSLKd-TT\">在这本书中，就带你了解骗子是怎么一步步下套的，从开始的搭讪，到最后让你自愿把钱送出去，你还在被骗之后，因为不想承认自己傻而选择沉默，帮助骗子逃脱。</p><p data-pid=\"PH9UgcVF\">当你看清了骗子的这些步骤，再遇到类似的情况时，你就能分辨真假，避免让自己陷进去，这样一来你就不容易上当受骗了。</p><p data-pid=\"ppvDHW2n\">最后我想说的是，你之所以轻易被人骗，很大原因是你容易被自己的情绪、习惯，或者别人设下的圈套给影响了。<b>其实你不是笨，而是对自己和骗局的了解，还不够全面</b>。</p><p data-pid=\"wLsWu3tp\">这三本书，就告诉了你有哪些心理陷阱，让你看清了这些陷阱是怎么来的，又是怎么影响你的。当你在面对各种复杂的情况时，能把这几本书中的道理融入到自己的生活中，慢慢地你就能少犯错，不再容易被骗了。</p>",
        "relationship": {
          "is_thanked": false,
          "is_nothelp": false,
          "voting": 0
        },
        "is_labeled": false,
        "visited_count": 138,
        "favorite_count": 14,
        "answer_type": "normal",
        "is_navigator": false,
        "navigator_vote": false,
        "vote_next_step": "vote"
      },
      "brief": "{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1941544129201939904}",
      "attached_info": "CqcHCNyT/PDV2JSqnQEQBBoJNzQzMTI1MzQ4IMCblsUGKAMwAEBhSkIKLVRTX1NPVVJDRV9UV09UT1dFUl9NVUxUSV9TQ0VORV9WMV9SRUNBTExfVEVYVBIBMBgAIAA6CnsicmF3IjoiIn1KQgotVFNfU09VUkNFX1RXT1RPV0VSX01VTFRJX1NDRU5FX1YxX1JFQ0FMTF9URVhUEgEwGAAgADoKeyJyYXciOiIifVoGMTg0NDM1YiBmMDc1YmIwMGMyOWY0YzMzNjI1YTU5YmIzNTFhZTBhN3ITMTk0MTU0NDEyOTIwMTkzOTkwNIoBCDIwMDExMTQ0qgEJcmVjb21tZW5kwgEgZGZkMThmMzEyZDUyMTFiYzI4MGJkZGM1MTg4YThmZjLyAQoIDBIGTm9ybWFs8gEoCAoSJDhhYWI5OTE3LWM1M2EtNGI0My04MTQxLWU2YWUwOWVkMzVjM/IBBggLEgIxN4ICAIgCnLOp+YwzkgIgZGZkMThmMzEyZDUyMTFiYzI4MGJkZGM1MTg4YThmZjKaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxl2gItVFNfU09VUkNFX1RXT1RPV0VSX01VTFRJX1NDRU5FX1YxX1JFQ0FMTF9URVhU6AIE+gILTk9STUFMX0ZMT1eKAyA5MjY1MzIxNDlmNjU0YzQ3YmUyZjczNzI5ODg4NWFmZpoDDQoCdjIQABoFb3RoZXKoA4oB2AMA6gMfdGV4dEZlZWRUd29Ub3dlcldhcm11cFN1Y2Nlc3NWMfoDrAESDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFOi0IAhDJBRilAiIjdjItNzE4MWU2YTU1Y2FjMzk0MjZmMDA0Y2RmZDVmMjlmZDQ6LQgCELwFGMYCIiN2Mi05OGZkZWY2ZDAzMWE3YTRjN2ZiNDBlOTZmMTQwOTI4ZjotCAIQ0QUYxwIiI3YyLTNlZjk2MWE5YzVjMDkxNzhkOTFiYTU0MTQ2ZTU5NGYxgAQAiAQAkgQGTm9ybWFsmgQBNKAEAKgEALAEALoEAmFpwgQDNDAwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAACgqQqWP4EFAAAAAAAAAACJBV5CjDMIVNk/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBRGQBgCgBmOoBgOSAi4KCTc0MzEyNTM0OBITMTk0MTU0NDEyOTIwMTkzOTkwNBgEIgpJTUFHRV9URVhU",
      "action_card": false
    },
    {
      "id": "98_1755822316.950",
      "type": "feed",
      "offset": 98,
      "verb": "TOPIC_ACKNOWLEDGED_ANSWER",
      "created_time": 1755822316,
      "updated_time": 1755822316,
      "target": {
        "id": "3531143372",
        "type": "answer",
        "url": "https://api.zhihu.com/answers/3531143372",
        "author": {
          "id": "ca34745a6d671abb6d561ffaa6e94221",
          "url": "https://api.zhihu.com/people/ca34745a6d671abb6d561ffaa6e94221",
          "user_type": "people",
          "url_token": "officech",
          "name": "小怪兽",
          "headline": "早出晚归搬砖ing",
          "avatar_url": "https://pic1.zhimg.com/50/v2-16420d1da22297854a94676de4e0505d_l.jpg?source=b6762063",
          "is_org": false,
          "gender": 0,
          "badge": [
            {
              "type": "identity_people",
              "description": "软件开发行业 从业人员"
            }
          ],
          "followers_count": 2173,
          "is_following": false,
          "is_followed": false
        },
        "created_time": 1718421349,
        "updated_time": 1727256100,
        "voteup_count": 171,
        "thanks_count": 37,
        "comment_count": 5,
        "is_copyable": false,
        "question": {
          "id": "650962560",
          "type": "question",
          "url": "https://api.zhihu.com/questions/650962560",
          "author": {
            "id": "aa05cb0616cdc151a3ce5f483d03e43a",
            "url": "https://api.zhihu.com/people/aa05cb0616cdc151a3ce5f483d03e43a",
            "user_type": "people",
            "url_token": "84-73-54-42-59",
            "name": "淡晴曦和",
            "headline": "",
            "avatar_url": "https://picx.zhimg.com/50/v2-6448c061212caf1815728ecba62ead53_l.jpg?source=b6762063",
            "is_org": false,
            "gender": 0,
            "followers_count": 54,
            "is_following": false,
            "is_followed": false
          },
          "title": "把Excel函数用到极致是怎样一种体验?",
          "created": 1711837899,
          "answer_count": 0,
          "follower_count": 0,
          "comment_count": 0,
          "bound_topic_ids": [
            22278,
            23068,
            161967
          ],
          "is_following": false,
          "excerpt": "",
          "relationship": {
            "is_author": false
          },
          "detail": "",
          "question_type": "normal"
        },
        "thumbnail": "https://pica.zhimg.com/50/v2-eb1a9942190d4fe2f4041512101373f2_720w.jpg?source=b6762063",
        "excerpt": "天下武功，唯快不破。无论函数在哪，一切只为快。 函数是全部数学概念中最重要的概念之一。从数据清洗到计算再到分析与可视化，都可以见到它的身影： 表格软件——excel（内置了400多个函数）：作为目前用户覆盖最广、数量最多的数据办公软件表单软件——简道云（内置73个）：表单型apaas平台报表软件——Finereport（内置200余个）：专业级数据分析软件大屏软件——powerBI、FineBI：专业级可视化软件可见，在数据的各个领域（…",
        "excerpt_new": "天下武功，唯快不破。无论函数在哪，一切只为快。 函数是全部数学概念中最重要的概念之一。从数据清洗到计算再到分析与可视化，都可以见到它的身影： 表格软件——excel（内置了400多个函数）：作为目前用户覆盖最广、数量最多的数据办公软件表单软件——简道云（内置73个）：表单型apaas平台报表软件——Finereport（内置200余个）：专业级数据分析软件大屏软件——powerBI、FineBI：专业级可视化软件可见，在数据的各个领域（…",
        "preview_type": "default",
        "preview_text": "",
        "reshipment_settings": "disallowed",
        "content": "<p></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-5b8787ed99578a4ddaeaeb46cda1712f_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"780\" data-rawheight=\"428\" data-original-token=\"v2-dc81304d3c2bdf5f0e6081698e314072\" class=\"origin_image zh-lightbox-thumb\" width=\"780\" data-original=\"https://picx.zhimg.com/v2-5b8787ed99578a4ddaeaeb46cda1712f_r.jpg\"/></figure><p data-pid=\"pQDEpEzS\">天下武功，唯快不破。无论函数在哪，一切只为快。</p><p data-pid=\"sck90_co\">函数是全部数学概念中最重要的概念之一。从数据清洗到计算再到分析与可视化，都可以见到它的身影：</p><ul><li data-pid=\"j-k6FWXh\">表格软件——excel（内置了400多个函数）：作为目前用户覆盖最广、数量最多的数据办公软件</li><li data-pid=\"5CGlgERz\">表单软件——简道云（内置73个）：表单型apaas平台</li><li data-pid=\"M2OfsFtF\">报表软件——Finereport（内置200余个）：专业级数据分析软件</li><li data-pid=\"KaYjsIzx\">大屏软件——powerBI、FineBI：专业级可视化软件</li></ul><p data-pid=\"selgZvaY\">可见，在数据的各个领域（表格表单、报表、大屏），<b>函数基本都被作为必需配置。</b></p><p data-pid=\"-2MpniYI\"><b>抛砖引玉讲一下：</b></p><h2>表格和函数</h2><p data-pid=\"Ig94s__c\">excel作为典型的表格软件，其函数约有400多个，覆盖数据计算需求的方方面面：</p><p data-pid=\"JupZVYgN\"><b>99个财务函数+11个逻辑函数+27个文本函数+49个时间日期函数+16个查找和引用函数+60个数学和三角函数</b></p><ol><li data-pid=\"LfMNqYo1\">【财务函数】：IF、SUM、MAX、MIN、SUMIF、COUNTIF、VLOOKUP是日常工作种会遇到的基础函数，除此之外，财务类还会遇到一些函数：例如FV、PV、PMT、RATE、VDB、EFFECT函数 。</li><li data-pid=\"MLqEP7zg\">【逻辑函数】：不管你是从事哪个行业，只要日常接触数据处理，这几个函数应该经常会用到。</li><li data-pid=\"iZ7aBdSy\">【文本函数】：Excel文本函数主要基于文本数据执行文本提取，合并，清洗，查找，替换，计算等功能。常用函数有FIND、CODE、CLEAN、MID、SEARCH、TEXT等。</li><li data-pid=\"9p63-Gcp\">【时间日期函数】：时间和日期函数基于日期和时间的转换、计算、汇总等功能。如计算工龄，日期文本转换等。</li><li data-pid=\"Rvh4mAmt\">【查找引用函数】：常用有VLOOKUP、INDIRECT、ROW、MATCH等函数。</li><li data-pid=\"dJwXhwPf\">【数学三角函数】：这类函数用于处理复杂的数学和三角运算，除专业人员外，日常一般工作不会涉及。</li></ol><p data-pid=\"SAr8P6M1\">这么多函数，对于普通excel用户，光理解就耗费半天。</p><p data-pid=\"5-O6CE_w\">坊间也因此<b>流传了不少万能公式，能够帮我们自如地运用多个函数，更快捷地解决问题。比如下面这个：</b></p><h2><b>万能公式——INDEX+SMALL+IF+ROW+IFERROR</b></h2><blockquote data-pid=\"3ncXGVyS\"><b>能够解决90%的一对多查询问题。</b></blockquote><p data-pid=\"FnMicGTx\"><b>用法：</b>比如要从下图数据中查找&#34;销售1部&#34;的全部数据（标黄部分）：</p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-5a3bf4f184a41947b9b22d0031c5a249_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"770\" data-rawheight=\"339\" data-original-token=\"v2-713b46231218c88a1b1bd0e7986d00bc\" class=\"origin_image zh-lightbox-thumb\" width=\"770\" data-original=\"https://pic4.zhimg.com/v2-5a3bf4f184a41947b9b22d0031c5a249_r.jpg\"/></figure><p data-pid=\"8Qzzh9w2\">第一步：判断“销售1部”的行号，通过ROW函数把“销售1部”筛选出来。所选单元格中，符合”销售1部“则输出对应行号，不符则输出”FALSE&#34;。</p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-26de8a1f5c420768ca8fa4b0368c28bb_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"386\" data-original-token=\"v2-2f6808158fdb52c6a07a52b2ee016839\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://picx.zhimg.com/v2-26de8a1f5c420768ca8fa4b0368c28bb_r.jpg\"/></figure><p data-pid=\"nwOXbmX-\">由于它是一个数组函数，所以点击CTRL+Shift+Enter完成，输出为FALSE,说明与查找目标值不符。</p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-2ce5661ed172e428efdcf3bac31749f6_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"287\" data-original-token=\"v2-47e0544b5d5626d479a11818d50e6481\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pic3.zhimg.com/v2-2ce5661ed172e428efdcf3bac31749f6_r.jpg\"/></figure><p data-pid=\"yJGZokxp\">嵌套SMALL函数，按从小到大的顺序取第n个值，返回所有满足条件的对应行号。</p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-8e56e02490a10fde289b6bcdd2114fd2_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"420\" data-original-token=\"v2-0249ac507997b67fa2becb9ca8d42d3e\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pic3.zhimg.com/v2-8e56e02490a10fde289b6bcdd2114fd2_r.jpg\"/></figure><p data-pid=\"Z9CLcVJF\">用INDEX函数引用所选区域行列的交叉内容，选择区域A3-A10,引用行数3，6，7，用INDEX返回所选行数的内容，即“销售1部”。</p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-03815654216e70ddf5b771af5a754ccf_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"981\" data-rawheight=\"363\" data-original-token=\"v2-9bf27f38934c6f770360594d6e57130c\" class=\"origin_image zh-lightbox-thumb\" width=\"981\" data-original=\"https://pic4.zhimg.com/v2-03815654216e70ddf5b771af5a754ccf_r.jpg\"/></figure><p data-pid=\"kERaHdNo\">完整公式及数据结果如下：</p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-9cf5c783be063c2c1b6cf91b306eda2c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"348\" data-original-token=\"v2-fd5eaf1a97080f6034a9c2eb67903b05\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pic1.zhimg.com/v2-9cf5c783be063c2c1b6cf91b306eda2c_r.jpg\"/></figure><h2>表单和函数</h2><p data-pid=\"aKq8RsWV\">在目前国内软件厂商中，表单做到专业级的较少。</p><p data-pid=\"RaLdoXtW\">简道云作为早期的apaas原生厂商，以表单为基底，因此经过近些年发展，在公式与函数的应用上，趋于成熟。函数配置更偏向低复杂度，对于普通办公族友好。</p><p data-pid=\"jk43RAkx\"><b>19个文本函数+20个日期函数+21个数学函数+6个逻辑函数+7个高级函数：</b></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-c69c3273afa32a08f017ca67d5231005_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"651\" data-original-token=\"v2-56ba328db57b5e3f81cd7d53bfb92746\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pic4.zhimg.com/v2-c69c3273afa32a08f017ca67d5231005_r.jpg\"/></figure><h3>组合用法1——自动化计算销售提成</h3><p data-pid=\"sRriTFHu\"><b>背景：</b>「销售上报」表单记录了销售员的每日销售数据，到月底财务需要填写「提成表」计算出某一销售员、某一月份的销售额之和，以便计算出每个人的提成数据。</p><ul><li data-pid=\"rVaS-5jw\"><b>所用函数：</b>CONCATENATE、MAPX、SUM。其中，MAPX函数在这种情况下，检索值与检索范围就是销售姓名+月份。</li><li data-pid=\"NQOJOcg4\"><b>最终实现效果：</b><a href=\"https://link.zhihu.com/?target=https%3A//t6ixa9nyl6.jiandaoyun.com/f/6041c964b785470007c3c16d\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">点击体验</a></li></ul><p data-pid=\"x58fXD1C\"><b>实现步骤：</b></p><p data-pid=\"tnDmZsHT\">（1）在「销售上报」表单中添加一个辅助字段，并编辑函数，值为「姓名+销售日期对应的年月」。</p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-258582fb99b7debb519ae93ec61250d6_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"679\" data-original-token=\"v2-ec882c974772a861df884a6f8cd23a65\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pic3.zhimg.com/v2-258582fb99b7debb519ae93ec61250d6_r.jpg\"/></figure><p data-pid=\"jIZNw7eb\">在录入数据时，辅助字段也会通过公式得到值，以供「提成表」中的MAPX函数调用。</p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-ee7846efa3b15047455ca35ecff35320_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"954\" data-original-token=\"v2-bd941753f35d9c18c222f43b3e25fb4c\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pica.zhimg.com/v2-ee7846efa3b15047455ca35ecff35320_r.jpg\"/></figure><p data-pid=\"64CYaEe_\">（2）在「提成表」中同样也需要添加这个辅助字段，并编辑函数，值为「姓名+当前统计的月份」。</p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-ee7846efa3b15047455ca35ecff35320_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"954\" data-original-token=\"v2-bd941753f35d9c18c222f43b3e25fb4c\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pica.zhimg.com/v2-ee7846efa3b15047455ca35ecff35320_r.jpg\"/></figure><p data-pid=\"430c1MTq\">（3）对销售总额编辑公式，值为MAPX(‘SUM’,辅助字段,辅助字段,销售额)</p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-98689ce31cbdb45efb310e11857c426d_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1052\" data-rawheight=\"685\" data-original-token=\"v2-273b75477afb799e962727ae910bac0e\" class=\"origin_image zh-lightbox-thumb\" width=\"1052\" data-original=\"https://pic2.zhimg.com/v2-98689ce31cbdb45efb310e11857c426d_r.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-f93adb17edebb52d04b567f24e123bca_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"836\" data-original-token=\"v2-a34c84cb1d8802d3321dc8b0daa87931\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pic3.zhimg.com/v2-f93adb17edebb52d04b567f24e123bca_r.jpg\"/></figure><p data-pid=\"HsWKXEuz\">（4）对提成计算字段编辑公式，销售总额低于1000提成比例为0.1，超过1000提成比例为0.2</p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-46d48d5fa38d1e2c9f0a329a52788abb_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"678\" data-rawheight=\"152\" data-original-token=\"v2-dedb36d6ba07d220c9d7e538ac99dbfc\" class=\"origin_image zh-lightbox-thumb\" width=\"678\" data-original=\"https://pic4.zhimg.com/v2-46d48d5fa38d1e2c9f0a329a52788abb_r.jpg\"/></figure><p data-pid=\"W2D1Is5j\">（5）看一下效果：</p><p data-pid=\"NsIgMf3Y\">动图中左边为「销售上报」中的已有数据，右边为「提成表」录入数据的界面。</p><p data-pid=\"W2NczJ5h\">在填写日期时，任意选择统计月份中的任意一天即可，公式会自动提取出年月。</p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-cf103c0652cbc233a94104c0f6429819_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"446\" data-original-token=\"v2-792edb353638538a35bbb53e5782a211\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://picx.zhimg.com/v2-cf103c0652cbc233a94104c0f6429819_r.jpg\"/></figure><h3>组合用法2——根据身份证号码自动算性别</h3><p data-pid=\"-4fIl3_3\">如何根据身份证号码自动算性别？这里用一个典型的例子来给大家启发。</p><blockquote data-pid=\"BqW0Axjh\">需要解释的是，身份证号码第17位为性别位，奇数为男性，偶数为女性。</blockquote><ul><li data-pid=\"7tLkjJ0y\"><b>所用函数</b>：IF、MID、MOD、VALUE，实现：在表单里输入身份证号码，自动生成性别。</li><li data-pid=\"mRrJ4zoL\"><b>最终实现效果：</b><a href=\"https://link.zhihu.com/?target=https%3A//t6ixa9nyl6.jiandaoyun.com/f/6041c964b785470007c3c16d\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">点击体验</a></li></ul><p data-pid=\"zOl7j4f8\"><b>实现步骤：</b></p><p data-pid=\"2rS7JEZA\">方法一：身份证的第17位数为奇数的时候，返回“男”，否则返回“女”。</p><div class=\"highlight\"><pre><code class=\"language-text\">公式： IF(MOD(VALUE(MID(身份证号,17,1)),2)==1,&#34;男&#34;,&#34;女&#34;)</code></pre></div><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-48e7d3d7ae461066aa696f90cb312f5b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"144\" data-original-token=\"v2-48e7d3d7ae461066aa696f90cb312f5b\" data-default-watermark-src=\"https://pic2.zhimg.com/v2-48e7d3d7ae461066aa696f90cb312f5b_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pic2.zhimg.com/v2-48e7d3d7ae461066aa696f90cb312f5b_r.jpg\"/></figure><p data-pid=\"-HY5EPw8\">方法二：身份证的第17位数为1,3,5,7,9的时候，返回“男”，否则返回“女”。</p><div class=\"highlight\"><pre><code class=\"language-text\">公式： IF(OR(MID(身份证号,17,1)==1,MID(身份证号,17,1)==3,MID(身份证号,17,1)==5,MID(身份证号,17,1)==7,MID(身份证号,17,1)==9),&#34;男&#34;,&#34;女&#34;)</code></pre></div><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-e7373cb23cda3341424f0486302974a7_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"155\" data-original-token=\"v2-e7373cb23cda3341424f0486302974a7\" data-default-watermark-src=\"https://pic2.zhimg.com/v2-e7373cb23cda3341424f0486302974a7_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pic2.zhimg.com/v2-e7373cb23cda3341424f0486302974a7_r.jpg\"/></figure><p data-pid=\"K830tA1D\">最终效果：</p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-11277c184636adb8b107eb53975ba5dd_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"640\" data-original-token=\"v2-063721292e166f5879175cee5e432139\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pic2.zhimg.com/v2-11277c184636adb8b107eb53975ba5dd_r.jpg\"/></figure><p data-pid=\"hmJtb-5M\">关于表单中的函数，组合用法还有很多，不一一列举了，感兴趣进这些专题看：</p><p data-pid=\"YbBYvAe-\"><a href=\"https://link.zhihu.com/?target=https%3A//hc.jiandaoyun.com/video/10530\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">公式与函数视频教程​hc.jiandaoyun.com</a></p><p data-pid=\"AMYbMFOu\">注：像简道云这样的表单型软件，由于本质是apaas，因此更为偏向数据管理与协同，和流程绑定，从而建立起各种各样的管理应用。</p><p data-pid=\"kloMwB99\">因此与表格及报表软件相比，函数的复杂度上会弱化，但上手迅速和操作的快捷性上，也大大得到提升。</p><blockquote data-pid=\"EeMPtdZl\">apaas科普：<br/>apaas主要是提供一种框架，从应用和数据层面入手，让业务人员不需要学代码就能自己设计出一个管理软件。<br/>典型的apaas设计逻辑——在简道云中，通过【表单】实现堆叠搭建，利用【流程工具】将业务点串联起来，借助【仪表盘】进行数据展现与分析。（如图）</blockquote><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-2501120ce9f2101f0cf5b9ce7536ab18_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"290\" data-original-token=\"v2-2935fcbb5a3c2a987dc94b425a7e3d53\" class=\"origin_image zh-lightbox-thumb\" width=\"720\" data-original=\"https://pic1.zhimg.com/v2-2501120ce9f2101f0cf5b9ce7536ab18_r.jpg\"/></figure><blockquote data-pid=\"9hDH-MSG\">此处要补录制一个视频，记得或有人提醒就补，记不得就算了。</blockquote><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-da0bea9e200493f6a2e4e26cee7e2b95_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"394\" data-original-token=\"v2-f981b169146a120343f6424dfd28deb2\" class=\"origin_image zh-lightbox-thumb\" width=\"720\" data-original=\"https://picx.zhimg.com/v2-da0bea9e200493f6a2e4e26cee7e2b95_r.jpg\"/></figure><h2>报表和函数</h2><p data-pid=\"9uC3ChOO\">国内报表做到专业级的不少，其中finereport作为老牌产品，在数据运算上具有深厚功底，函数类型与复杂度并不弱于excel，内置了200个函数左右，能够支撑大规模数据运算：</p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-c8b45bdc6e5b5ded08cffe95c52f650c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"646\" data-original-token=\"v2-82c59f73c70b1e6c4f21f3fdf1bc2e9c\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pic3.zhimg.com/v2-c8b45bdc6e5b5ded08cffe95c52f650c_r.jpg\"/></figure><p data-pid=\"AUP-17sS\">由于实在太多，就不展开思维导图了，感兴趣可以查看文档，有对应每个函数的使用规则及介绍：</p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-b1eb9f7dbf2e1aafae75c59cb6ab2931_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"392\" data-original-token=\"v2-c0611467fafa4bd63e5b4d433f7f2545\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://picx.zhimg.com/v2-b1eb9f7dbf2e1aafae75c59cb6ab2931_r.jpg\"/></figure><blockquote data-pid=\"kjqJPxVh\">传送门：<span class=\"nolink\">https://help.fanruan.com/finereport/doc-view-831.html</span></blockquote><h3>组合用法1——从乱码中提取数字</h3><p data-pid=\"fW2mlyln\">我们想从下面这个目标字符串中提取出所有的数字，并重新组合成一个字符串，该如何做呢？</p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-0d9ec4e427c210e664465c70454ffdd5_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"152\" data-rawheight=\"346\" data-original-token=\"v2-0d9ec4e427c210e664465c70454ffdd5\" data-default-watermark-src=\"https://pic2.zhimg.com/v2-0d9ec4e427c210e664465c70454ffdd5_b.jpg\" class=\"content_image\" width=\"152\"/></figure><p data-pid=\"h2LUXbMb\"><b>实现思路：</b>先将字符串分割成数组，再对数组每一项进行筛选，保留下数字，最后以字符串输出。</p><p data-pid=\"n639h5fY\">1）先利用 split( ) 函数进行分割，这里要分割每一项，所以分割符为空：=split(目标字符串,&#34;&#34;)</p><p data-pid=\"Ua5baWd6\">2）利用 GREPARRAY( ) 函数对上一步结果进行筛选，这里使用了 regexp( ) 函数来判断是否是数字：=GREPARRAY(上一步结果, regexp(item, &#34;[0-9]&#34;))</p><p data-pid=\"R4pHHASn\">3）使用 JOINARRAY( ) 函数将数组以字符串方式输出，拼接符为空：=JOINARRAY(上一步结果, &#34;&#34;)</p><p data-pid=\"pZQP-JIO\">4）综合起来，公式就是=JOINARRAY(GREPARRAY(split(目标字符串, &#34;&#34;), regexp(item, &#34;[0-9]&#34;)), &#34;&#34;)，</p><p data-pid=\"gFvdalTb\">提取步骤如图：</p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-24e29f383a2fee60e348bde2e85519ab_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"494\" data-rawheight=\"242\" data-original-token=\"v2-bde8fd582ca78f352c2f363a69b5ed32\" class=\"origin_image zh-lightbox-thumb\" width=\"494\" data-original=\"https://pic4.zhimg.com/v2-24e29f383a2fee60e348bde2e85519ab_r.jpg\"/></figure><h3>组合用法2——将数字金额转化成大写中文</h3><p data-pid=\"PJgE-GAN\">在票据、落款类报表中，为防止随意涂改作假，常需将金额数字转换为大写中文人民币形式，此时可使用 <a href=\"https://link.zhihu.com/?target=https%3A//sspai.com/link%3Ftarget%3Dhttps%253A%252F%252Fhelp.fanruan.com%252Ffinereport%252Fdoc-view-824.html%2525233\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Cnmoney函数</a>，但如果想要直接展示大写金额同时显示小数格式，不展示为人民币形式该如何实现呢？</p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-cab823a84df865ed65624ce2e4cfe92a_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"112\" data-original-token=\"v2-cab823a84df865ed65624ce2e4cfe92a\" data-default-watermark-src=\"https://pic3.zhimg.com/v2-cab823a84df865ed65624ce2e4cfe92a_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pic3.zhimg.com/v2-cab823a84df865ed65624ce2e4cfe92a_r.jpg\"/></figure><p data-pid=\"bB9AwX3Q\">这种情况下，我们使用NUMTO()、CONCATENATE()、MAPARRAY()等函数组合运用，通过字符转化，替换，拼接等方式，将其转化为中文格式输出即可。</p><p data-pid=\"x_JWWIkI\">1）新建一张普通报表，右击任意单元格(例如A1单元格)，输入数值1234.123：</p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-876fa86da692e4aab96e6b94708c6dc7_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"729\" data-original-token=\"v2-a543370a52e38c43b6dc075bf00e8a2c\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://picx.zhimg.com/v2-876fa86da692e4aab96e6b94708c6dc7_r.jpg\"/></figure><p data-pid=\"q6ozSVci\">2）选中 B1 单元格，输入公式：</p><div class=\"highlight\"><pre><code class=\"language-text\">=CONCATENATE(REPLACE(CNMONEY(LEFT(A1, FIND(&#34;.&#34;, A1) - 1)), &#34;圆整&#34;, &#34;&#34;), &#34;点&#34;, REPLACE(MAPARRAY(split(mid(A1, FIND(&#34;.&#34;, A1) + 1, 100), &#34;&#34;), SWITCH(item, &#39;0&#39;, &#34;零&#34;, &#39;1&#39;, &#34;壹&#34;, &#39;2&#39;, &#34;贰&#34;, &#34;3&#34;, &#34;叁&#34;, &#39;4&#39;, &#34;肆&#34;, &#34;5&#34;, &#34;伍&#34;, &#34;6&#34;, &#34;陆&#34;, &#39;7&#39;, &#34;柒&#34;, &#39;8&#39;, &#34;捌&#34;, &#39;9&#39;, &#34;玖&#34;)), &#34;,&#34;, &#34;&#34;))</code></pre></div><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-8500002e4ad74dbdde13947aecd0825a_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"136\" data-original-token=\"v2-8500002e4ad74dbdde13947aecd0825a\" data-default-watermark-src=\"https://pica.zhimg.com/v2-8500002e4ad74dbdde13947aecd0825a_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pica.zhimg.com/v2-8500002e4ad74dbdde13947aecd0825a_r.jpg\"/></figure><p data-pid=\"B7xazfpD\">由于报表软件更偏向数据分析，因此函数在其中的作用，需要能够快速运算各种数据类型，支撑起较为复杂的图表模型，从而推动一份完整的报表产生：</p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-2d42f2d58bf9a69897bbe6c9c155dedb_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"225\" data-original-token=\"v2-6b685e31f0e694f72876b969a6243c90\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://picx.zhimg.com/v2-2d42f2d58bf9a69897bbe6c9c155dedb_r.jpg\"/></figure><p data-pid=\"38XYw0U-\">除了这些以外，函数在大屏软件中的类型及用法也不少，默默无闻为高逼格的数据可视化做出不少贡献，如果点赞多，后面再补充进来。</p><p data-pid=\"MZbVgXTQ\"><b>天下武功，唯快不破。无论函数在哪，一切只为快。</b></p><p data-pid=\"mWyW1sgo\">以上。</p>",
        "relationship": {
          "is_thanked": false,
          "is_nothelp": false,
          "voting": 0
        },
        "is_labeled": false,
        "visited_count": 20336,
        "thumbnails": [
          "https://picx.zhimg.com/50/v2-eb1a9942190d4fe2f4041512101373f2_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-52c2047fa734c592693e45f95dabdbca_720w.jpg?source=b6762063",
          "https://pic1.zhimg.com/50/v2-71231189c252596e1c375b365f4dfb6f_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-71231189c252596e1c375b365f4dfb6f_720w.jpg?source=b6762063",
          "https://pic1.zhimg.com/50/v2-5d6b054dc475a27662ca1f1d3819fbb0_720w.jpg?source=b6762063",
          "https://pic1.zhimg.com/50/v2-4fc7b62a05a4ff85b8a38033c9201752_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-216ddc0b08e97a4651ff1f137983825f_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-37e7b2cf01c54c4c497fd7021d58ca43_720w.jpg?source=b6762063",
          "https://pic1.zhimg.com/50/v2-84149fbccd7b448c8a78fa4ed3629564_720w.jpg?source=b6762063"
        ],
        "favorite_count": 913,
        "answer_type": "normal",
        "is_navigator": false,
        "navigator_vote": false,
        "vote_next_step": "vote"
      },
      "brief": "{\"source\": \"TS\", \"type\": \"answer\", \"id\": 3531143372}",
      "attached_info": "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",
      "action_card": false
    },
    {
      "id": "99_1755822316.681",
      "type": "feed",
      "offset": 99,
      "verb": "TOPIC_ACKNOWLEDGED_ANSWER",
      "created_time": 1755822316,
      "updated_time": 1755822316,
      "target": {
        "id": "1937638500909418414",
        "type": "answer",
        "url": "https://api.zhihu.com/answers/1937638500909418414",
        "author": {
          "id": "fea653398dd4046e1c0b80dfa5a2c7cb",
          "url": "https://api.zhihu.com/people/fea653398dd4046e1c0b80dfa5a2c7cb",
          "user_type": "people",
          "url_token": "hei-tai-lao-gui",
          "name": "欧狼Ohwolf",
          "headline": "态度兑现天赋，热爱可抵万难",
          "avatar_url": "https://picx.zhimg.com/50/v2-c6e5fb4005dc6a363d3b627e3002ceba_l.jpg?source=b6762063",
          "is_org": false,
          "gender": 1,
          "followers_count": 146,
          "is_following": false,
          "is_followed": false
        },
        "created_time": 1754749018,
        "updated_time": 1755763195,
        "voteup_count": 578,
        "thanks_count": 12,
        "comment_count": 38,
        "is_copyable": false,
        "question": {
          "id": "642536933",
          "type": "question",
          "url": "https://api.zhihu.com/questions/642536933",
          "author": {
            "id": "f02117d31bf04ee8f0cc08d81e6e60d0",
            "url": "https://api.zhihu.com/people/f02117d31bf04ee8f0cc08d81e6e60d0",
            "user_type": "people",
            "url_token": "19-52-13-12",
            "name": "缘糯米团",
            "headline": "",
            "avatar_url": "https://pic1.zhimg.com/50/v2-f97e8f7a981b327fe2383a242eac002c_l.jpg?source=b6762063",
            "is_org": false,
            "gender": 0,
            "followers_count": 67,
            "is_following": false,
            "is_followed": false
          },
          "title": "引体向上的能力对男生来说有多重要？",
          "created": 1706866623,
          "answer_count": 0,
          "follower_count": 0,
          "comment_count": 1,
          "bound_topic_ids": [
            3970,
            36075,
            61060
          ],
          "is_following": false,
          "excerpt": "",
          "relationship": {
            "is_author": false
          },
          "detail": "",
          "question_type": "normal"
        },
        "excerpt": "如果只能练一个项目，我推荐5km。 如果只能练两个项目，我推荐加深蹲。 如果只能练三个项目，我推荐加引体向上。 稍微解释一下。 个人的见解。 三大肌群实用性：腿＞背＞胸 肌肉实用性：后侧链＞前侧链 有氧与力量：心肺能力＞肌肉做功能力 所以推荐大家先把心肺能力提高，再去练力量，首选长跑。 腿部肌肉占比大，对提高肌肉量有显著优势，次选深蹲。 作为功能性的代言人引体只能屈居第三了。 如果让我接着推荐，下面这些也很不…",
        "excerpt_new": "如果只能练一个项目，我推荐5km。 如果只能练两个项目，我推荐加深蹲。 如果只能练三个项目，我推荐加引体向上。 稍微解释一下。 个人的见解。 三大肌群实用性：腿＞背＞胸 肌肉实用性：后侧链＞前侧链 有氧与力量：心肺能力＞肌肉做功能力 所以推荐大家先把心肺能力提高，再去练力量，首选长跑。 腿部肌肉占比大，对提高肌肉量有显著优势，次选深蹲。 作为功能性的代言人引体只能屈居第三了。 如果让我接着推荐，下面这些也很不…",
        "preview_type": "default",
        "preview_text": "",
        "reshipment_settings": "disallowed",
        "content": "<p data-pid=\"_u_iCKoj\">如果只能练一个项目，我推荐5km。</p><p data-pid=\"YpB-dRay\">如果只能练两个项目，我推荐加深蹲。</p><p data-pid=\"teTufWw-\">如果只能练三个项目，我推荐加引体向上。</p><hr/><p data-pid=\"_3Xf2wFt\">稍微解释一下。</p><p data-pid=\"Zsw9yLGm\">个人的见解。</p><p data-pid=\"lmaDQOsu\">三大肌群实用性：腿＞背＞胸</p><p data-pid=\"qgvq9k7S\">肌肉实用性：后侧链＞前侧链</p><p data-pid=\"wg3oTjKw\">有氧与力量：心肺能力＞肌肉做功能力</p><p data-pid=\"cUOZc84W\">所以推荐大家先把心肺能力提高，再去练力量，首选长跑。</p><p data-pid=\"ULjWOKsm\">腿部肌肉占比大，对提高肌肉量有显著优势，次选深蹲。</p><p data-pid=\"1aq_CT5l\">作为功能性的代言人引体只能屈居第三了。</p><p data-pid=\"aQ4F-12c\">如果让我接着推荐，下面这些也很不错。</p><p data-pid=\"VCmk08tT\">有氧训练：游泳，冲刺间歇跑。</p><p data-pid=\"4-lLAyRG\">力量训练：硬拉，双杠臂屈伸，高翻。</p><p data-pid=\"0IUquvmU\">等身体素质提高了，运动表现也提升了，可以试着转专项，羽毛球、足球、篮球、攀岩等等。</p><p data-pid=\"Tz-mMxrl\">一个六边形战士就这么诞生了。</p>",
        "relationship": {
          "is_thanked": false,
          "is_nothelp": false,
          "voting": 0
        },
        "is_labeled": false,
        "visited_count": 38588,
        "favorite_count": 810,
        "answer_type": "normal",
        "is_navigator": false,
        "navigator_vote": false,
        "vote_next_step": "vote"
      },
      "brief": "{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1937638500909418414}",
      "attached_info": "CpEGCNyT/PDV2JSqnQEQBBoJNzQxMzg4NjgwINqw3cQGKMIEMCZAY0orChZUU19TT1VSQ0VfRkVFRFJFX01TX1YyEgEwGAAgADoKeyJyYXciOiIifUooCh1UU19TT1VSQ0VfTkVBUkxJTkVfQ09OVEVOVF9WMhIBMBgAIAA6AEouChlUU19TT1VSQ0VfRkVFRFJFX01TX0hRX1YyEgEwGAAgADoKeyJyYXciOiIifVoJMTA1MDYzNjAxYiBmMDc1YmIwMGMyOWY0YzMzNjI1YTU5YmIzNTFhZTBhN3ITMTkzNzYzODUwMDkwOTQxODQxNIoBCTY0MjUzNjkzM6oBCXJlY29tbWVuZMIBIGZlYTY1MzM5OGRkNDA0NmUxYzBiODBkZmE1YTJjN2Ni8gEKCAwSBk5vcm1hbPIBKAgKEiQ5MWY5ZTA3Ni02ODdjLTRjNjAtODNmOS0yMTVlMTg1NWJmNmbyAQYICxICMTeCAgCIAp2zqfmMM5ICIGZlYTY1MzM5OGRkNDA0NmUxYzBiODBkZmE1YTJjN2NimgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZcoCFENvbnRlbnRBZ2VXZWlnaHRSdWxl2gIWVFNfU09VUkNFX0ZFRURSRV9NU19WMugCAvoCC05PUk1BTF9GTE9XigMgOTI2NTMyMTQ5ZjY1NGM0N2JlMmY3MzcyOTg4ODVhZmaaAw0KAnYyEAAaBW90aGVyqAO8rQLYAwDqAw5mZWVkcmVfbXNfZ2F0ZfoDHxIMVU5LTk9XTl9NT0RFIAAqDU5PX0lNQUdFX01PREWABACIBACSBAZOb3JtYWyaBAEyoAQAqAQAsAQAugQGbWFudWFswgQDMTU5yAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAADgSfWkP4EFAAAAAAAAAACJBV5CjDMIVNk/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBRGQBgCgBmWoBgCSAi4KCTc0MTM4ODY4MBITMTkzNzYzODUwMDkwOTQxODQxNBgEIgpJTUFHRV9URVhU",
      "action_card": false
    },
    {
      "id": "100_1755822316.286",
      "type": "feed",
      "offset": 100,
      "verb": "TOPIC_ACKNOWLEDGED_ANSWER",
      "created_time": 1755822316,
      "updated_time": 1755822316,
      "target": {
        "id": "1941864184984893054",
        "type": "answer",
        "url": "https://api.zhihu.com/answers/1941864184984893054",
        "author": {
          "id": "9db1786c69ac17be085f17414f02cc26",
          "url": "https://api.zhihu.com/people/9db1786c69ac17be085f17414f02cc26",
          "user_type": "people",
          "url_token": "xiao-xiao-xie-72-48",
          "name": "和风细雨",
          "headline": "空闲人",
          "avatar_url": "https://pica.zhimg.com/50/v2-99a270aeaf04c4932718132834c3e117_l.jpg?source=b6762063",
          "is_org": false,
          "gender": 1,
          "badge": [
            {
              "type": "identity_people",
              "description": "市政工程高级工程师证书持证人"
            }
          ],
          "followers_count": 290,
          "is_following": false,
          "is_followed": false
        },
        "created_time": 1755756499,
        "updated_time": 1755756499,
        "voteup_count": 1,
        "thanks_count": 0,
        "comment_count": 1,
        "is_copyable": true,
        "question": {
          "id": "5092629857",
          "type": "question",
          "url": "https://api.zhihu.com/questions/5092629857",
          "author": {
            "id": "069107e999cfd80b8a90fb3f84636713",
            "url": "https://api.zhihu.com/people/069107e999cfd80b8a90fb3f84636713",
            "user_type": "people",
            "url_token": "bing-liang-lb",
            "name": "江寒的号",
            "headline": "文学探索自我，商业解释一切。",
            "avatar_url": "https://picx.zhimg.com/50/v2-43e267bb6a476419f3ff777660ec33d2_l.jpg?source=b6762063",
            "is_org": false,
            "gender": 1,
            "badge": [
              {
                "type": "identity_people",
                "description": "高新区狮山寒暄有术传媒工作室 经营者"
              }
            ],
            "followers_count": 49169,
            "is_following": false,
            "is_followed": false
          },
          "title": "分享一下你近期的生活感悟？",
          "created": 1732520235,
          "answer_count": 0,
          "follower_count": 0,
          "comment_count": 0,
          "bound_topic_ids": [
            100099,
            3677279
          ],
          "is_following": false,
          "excerpt": "",
          "relationship": {
            "is_author": false
          },
          "detail": "",
          "question_type": "normal"
        },
        "excerpt": "引言 八月的岛城，临海的缘故，这里的风要比内陆大一些、凉一些，却依然吹不走湿热带来的烦闷，海边便成了傍晚最佳的去处。前几日，后海海岸的落日余晖成了打卡圣地，漫天红艳的晚霞中，一轮红日缓缓落下，虽未亲眼所见，只在照片中便感受到这波澜壮阔的落日美景。我不喜欢蹭热闹，偶尔开车路过后海，也是匆匆一瞥，确实此处风景如画，值得一看。 早些年头，为了远方的不同旖旎风光而去旅行，人到中年，为了心中片刻安宁选择短暂…",
        "excerpt_new": "引言 八月的岛城，临海的缘故，这里的风要比内陆大一些、凉一些，却依然吹不走湿热带来的烦闷，海边便成了傍晚最佳的去处。前几日，后海海岸的落日余晖成了打卡圣地，漫天红艳的晚霞中，一轮红日缓缓落下，虽未亲眼所见，只在照片中便感受到这波澜壮阔的落日美景。我不喜欢蹭热闹，偶尔开车路过后海，也是匆匆一瞥，确实此处风景如画，值得一看。 早些年头，为了远方的不同旖旎风光而去旅行，人到中年，为了心中片刻安宁选择短暂…",
        "preview_type": "default",
        "preview_text": "",
        "reshipment_settings": "allowed",
        "content": "<h2>引言</h2><p data-pid=\"nBQzfybc\"> 八月的岛城，临海的缘故，这里的风要比内陆大一些、凉一些，却依然吹不走湿热带来的烦闷，海边便成了傍晚最佳的去处。前几日，后海海岸的落日余晖成了打卡圣地，漫天红艳的晚霞中，一轮红日缓缓落下，虽未亲眼所见，只在照片中便感受到这波澜壮阔的落日美景。我不喜欢蹭热闹，偶尔开车路过后海，也是匆匆一瞥，确实此处风景如画，值得一看。<br/> 早些年头，为了远方的不同旖旎风光而去旅行，人到中年，为了心中片刻安宁选择短暂离开。前后心境的变换，在我看来，是必要的、不可控的。不以自我意志转移，又或者是由内而发，等你回看时，才晓得「欲买桂花同载酒，终不似少年游」的真实感。明明知道自己心境一变再变，停下来成了一种奢望，走下去却也步履维艰，这大致上是我一点不成熟的感受，又或者本身不够出彩，形成的平庸的无奈的一种生活感悟。</p><h2> 海边小息</h2><p data-pid=\"CofXjdDt\"> 海边岛城的好处，就是可以随时看海，选一处冷门的海边，没有熙熙攘攘的游客，没有铺天盖地的管理，有的只是宁静。在落日余晖的映照下，面朝大海，空气里弥漫着轻微的海腥味，更多的是清凉舒适。<br/> 光着脚，走在沙滩上，眺望远方，一望无际的海，远处的海乘着浪花，由远及近，然后再由近到远，刚刚没过脚背的海水传递着远方的讯息，这是我与远处的海为数不多的近距离交流，是一种自在的享受。海浪就这样后浪推着前浪，前赴后继的向我奔来，而后又褪去；我亦是沿着海岸线一步一步走着，回头来时的脚印被磨平，早已无迹可寻。可我的的确确是从那边走来，能够证明我走过的只有脚下刚刚踩出的脚印，可我的心却已经在这场交流中获得短暂的安逸，这是我来此的目的，并非我要打卡海边美景，所以外在的痕迹已经毫无用处。<br/> 行至远方，就如同林深见鹿那般，在这片刻宁静中，将一切外界所给予的不愉快丢掉，得见本我，此刻可能就是李白笔下「相看两不厌，唯有敬亭山」，现实的我与理想中的自己，在此刻像是至交好友，他懂我的无奈，我也晓得他的向往。在这微妙的意境里，说是与自己和解也好，亦或者说是让自己小息一会也罢，总而言之，此刻我已经重获力量，不为世俗琐事所累，停下来享受一番。</p><h2> 生活不止</h2><p data-pid=\"hMPunaiW\"> 提起生活，便不自觉的想起普希金的假如生活欺骗了你，似乎能够如同普希金那般乐观面对生活；可转头就想起作家李娟说的那句过不好是常态，初听此句有点匪夷所思，慢慢的认同，人终究是难以摆脱人性的支配。<br/> 昨夜，因为孩子学习费用的事情，与妻子产生一些分歧，或许妻子是对的，再苦也不能苦了孩子的教育。但是身处土建行业我，前几年还庆幸是房地产形势不好，可这萧瑟的风终究席卷整个土建行业，周遭被降薪裁员的信息充斥着，自己也是游走在被降薪的边缘。36 岁的不好不差的年龄，高位接盘房产造成 3 年内亏完数年的薪资，同时作为运维行业没有享受前几年基建的高额收入。似乎真的过不好这生活。可作为一个个体，在如此大背景下，又能如何呢，只有硬着头皮走下去，走下去才有下一步的可能。<br/> 生活的苟且，似乎让人一味地低着头不知疲倦的赶着路，就如同拉磨的牛，终其一生的努力，仍被困在那方寸间。怎么才能更好的走下去，人不是那拉磨的牛，要知进退，退一步是为了更好的走下去，可退一步更需要人生定力与智慧。想法上，退一步是海阔天空，不要有太多的物欲追求，别人拥有的自己也要拥有或者一味地追求更好。生活上，退一步是有的放矢，减少不必要的生活支出，秋天的第一杯奶茶类的消费远不如一家人周末聚餐或者一起看一场电影。<br/> 走下去，是一个永恒的目标。怎么走，却是未知的变数。两者之间隔着我们自己。<br/> </p>",
        "relationship": {
          "is_thanked": false,
          "is_nothelp": false,
          "voting": 0
        },
        "is_labeled": false,
        "visited_count": 24,
        "favorite_count": 1,
        "answer_type": "normal",
        "is_navigator": false,
        "navigator_vote": false,
        "vote_next_step": "vote"
      },
      "brief": "{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1941864184984893054}",
      "attached_info": "CuAFCNyT/PDV2JSqnQEQBBoJNzQzMjYwMDYyINPvmsUGKAEwAUBkSiQKGVRTX1NPVVJDRV9XQVJNX1VQX05PUk1BTDISATAYACAAOgBKKAodVFNfU09VUkNFX1dBUk1VUF9QUkVUUkFJTl9JMkkSATAYACAAOgBaCTExMTk5NTE5MGIgZjA3NWJiMDBjMjlmNGMzMzYyNWE1OWJiMzUxYWUwYTdyEzE5NDE4NjQxODQ5ODQ4OTMwNTSKAQo1MDkyNjI5ODU3qgEJcmVjb21tZW5kwgEgOWRiMTc4NmM2OWFjMTdiZTA4NWYxNzQxNGYwMmNjMjbyAQoIDBIGTm9ybWFs8gEoCAoSJGUzNjRmM2JmLWYxN2ItNDU2Zi1iMTY5LTc5Yjk0MjM0M2RkNPIBBggLEgIxN4ICAIgCnbOp+YwzkgIgOWRiMTc4NmM2OWFjMTdiZTA4NWYxNzQxNGYwMmNjMjaaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygIYQ29udGVudFdhcm1VcEJyZWFrSW5SdWxl2gIZVFNfU09VUkNFX1dBUk1fVVBfTk9STUFMMugCA/oCC05PUk1BTF9GTE9XigMgOTI2NTMyMTQ5ZjY1NGM0N2JlMmY3MzcyOTg4ODVhZmaaAw0KAnYyEAAaBW90aGVyqAMY2AMA6gMTcHJldHJhaW5faTJpX3JlY2FsbPoDHxIMVU5LTk9XTl9NT0RFIAAqDU5PX0lNQUdFX01PREWABACIBACSBAZOb3JtYWyaBAEzoAQAqAQAsAQAugQCYWnCBAM0MDDIBADSBA/mjqjojZDlt7Lmm7TmlrDYBADwBAD5BAAAAMCA4X8/gQUAAAAAAAAAAIkFXkKMMwhU2T+SBQCaBQNkZnSiBQNkZnSyBQExuQUAAAAAAAAAANAFAOAFAOgFAPAFEZAGAKAGZqgGAZICLgoJNzQzMjYwMDYyEhMxOTQxODY0MTg0OTg0ODkzMDU0GAQiCklNQUdFX1RFWFQ=",
      "action_card": false
    },
    {
      "id": "101_1755822316.63",
      "type": "feed",
      "offset": 101,
      "verb": "TOPIC_ACKNOWLEDGED_ARTICLE",
      "created_time": 1755822316,
      "updated_time": 1755822316,
      "target": {
        "id": "1941856605491668311",
        "type": "article",
        "url": "https://api.zhihu.com/articles/1941856605491668311",
        "author": {
          "id": "4b96fe2b3fca770b393300abdebea7e5",
          "url": "https://api.zhihu.com/people/4b96fe2b3fca770b393300abdebea7e5",
          "user_type": "people",
          "url_token": "mlpod",
          "name": "机器学习POD",
          "headline": "MLPOD.COM 公众号：机器学习POD",
          "avatar_url": "https://picx.zhimg.com/50/v2-2e77a8d66a53bc03c77b3e4d404cdbf7_l.jpg?source=b6762063",
          "is_org": false,
          "gender": 1,
          "badge": [
            {
              "type": "identity_people",
              "description": "百度 高级算法工程师"
            }
          ],
          "followers_count": 1157,
          "is_following": false,
          "is_followed": false
        },
        "title": "Qwen团队提出CHORD训练流程：动态融合 SFT 与 RL",
        "comment_permission": "all",
        "created": 1755754702,
        "updated": 1755754702,
        "voteup_count": 33,
        "voting": 0,
        "comment_count": 1,
        "linkbox": {
          "category": "",
          "pic": "",
          "title": "",
          "url": ""
        },
        "excerpt": "大型语言模型 (LLM) 的后训练 (Post-training) 通常依赖于两种主流范式：监督微调 (Supervised Fine-Tuning, SFT) 和强化学习 (Reinforcement Learning, RL)。SFT 主要通过模仿高质量的专家数据来学习，而 RL 则通过与环境的交互和反馈进行探索性学习。将两者结合的传统做法——先进行 SFT 再进行 RL (SFT-then-RL)——虽然直观，但在实践中常常表现不佳，甚至不如单纯的 RL。其根本原因在于，来自外部专家的“离策略 (off-polic…",
        "excerpt_new": "大型语言模型 (LLM) 的后训练 (Post-training) 通常依赖于两种主流范式：监督微调 (Supervised Fine-Tuning, SFT) 和强化学习 (Reinforcement Learning, RL)。SFT 主要通过模仿高质量的专家数据来学习，而 RL 则通过与环境的交互和反馈进行探索性学习。将两者结合的传统做法——先进行 SFT 再进行 RL (SFT-then-RL)——虽然直观，但在实践中常常表现不佳，甚至不如单纯的 RL。其根本原因在于，来自外部专家的“离策略 (off-polic…",
        "preview_type": "default",
        "preview_text": "",
        "content": "<p data-pid=\"Sw-8DSdu\">大型语言模型 (LLM) 的后训练 (Post-training) 通常依赖于两种主流范式：监督微调 (Supervised Fine-Tuning, SFT) 和强化学习 (Reinforcement Learning, RL)。SFT 主要通过模仿高质量的专家数据来学习，而 RL 则通过与环境的交互和反馈进行探索性学习。将两者结合的传统做法——先进行 SFT 再进行 RL (SFT-then-RL)——虽然直观，但在实践中常常表现不佳，甚至不如单纯的 RL。其根本原因在于，来自外部专家的“离策略 (off-policy)”数据可能会严重干扰模型在 SFT 阶段已经建立的内部模式，导致模型性能下降，并可能在后续的 RL 阶段陷入过拟合。</p><p data-pid=\"wmkXWxHH\">为了解决这一难题，来自阿里巴巴的研究团队发表了一篇题为《On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting》的论文。</p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-25cfd4b45cc8965bc86330c2451b1aab_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1732\" data-rawheight=\"626\" data-original-token=\"v2-1c0474bf3502bfdf9d7306fed0a54423\" class=\"origin_image zh-lightbox-thumb\" width=\"1732\" data-original=\"https://pic2.zhimg.com/v2-25cfd4b45cc8965bc86330c2451b1aab_r.jpg\"/></figure><ul><li data-pid=\"iQKXor8l\">论文标题：On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting</li><li data-pid=\"JKF0EcQV\">论文链接：<a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2508.11408\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">arxiv.org/pdf/2508.1140</span><span class=\"invisible\">8</span><span class=\"ellipsis\"></span></a></li></ul><p data-pid=\"1BD8r6eb\">该论文从一个全新的视角——“离策略 vs. 在策略 (off-policy vs. on-policy)”——审视了 SFT 与 RL 的关系，并提出了一个名为 <b>CHORD (Controllable Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic Weighting)</b> 的创新框架。CHORD 框架不再将 SFT 视为一个独立的预处理阶段，而是将其重新定义为在策略 RL 过程中的一个动态加权的辅助目标。</p><p data-pid=\"JQ4zi4zp\">该框架的核心是一个双重控制机制：</p><ol><li data-pid=\"6LM-gnCC\"><b>全局系数 (Global Coefficient) <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/></b> ：该系数从整体上调控专家数据（离策略）的影响力，引导模型从初期的模仿学习平滑地过渡到后期的探索性学习（在策略）。</li><li data-pid=\"xHUEn3Ma\"><b>逐词权重函数 (Token-wise Weighting Function) <img src=\"https://www.zhihu.com/equation?tex=%5Cphi%28%5Ccdot%29\" alt=\"\\phi(\\cdot)\" eeimg=\"1\"/></b> ：该函数在更细粒度的层面上对专家数据进行学习，通过降低对模型现有模式干扰较大的词元 (token) 的权重，来维持学习过程的稳定性，同时保留模型自身的探索能力。</li></ol><p data-pid=\"PzGpEgqZ\">通过这种动态加权的和谐机制，CHORD 能够在有效吸收专家知识的同时，避免破坏模型原有的推理能力，从而在多个基准测试中显著超越了传统的 SFT-then-RL 范式和其他基线方法，实现了更稳定、高效的学习过程。</p><h3>1. 引言</h3><p data-pid=\"G0GAxnkF\">大型语言模型 (LLM) 在数学推理、代码生成、工具使用等领域取得了显著的进展。这些成就的背后，离不开两个关键的后训练技术：监督微调 (SFT) 和强化学习 (RL)。</p><ul><li data-pid=\"mMfOKYLL\"><b>监督微调 (SFT)</b> ：SFT 依赖于高质量的专家示例数据，通过模仿学习的方式来塑造模型的行为模式。它的优点是直接、有效，能够快速让模型掌握特定的技能。但其缺点也同样明显：<br/> </li><ul><li data-pid=\"AGHc1CFV\"><b>数据依赖性</b>：SFT 的效果高度依赖于专家数据的质量和数量。</li><li data-pid=\"AlQGDiTG\"><b>泛化能力有限</b>：可能导致模型只会“背诵”而无法真正泛化。</li><li data-pid=\"Ex37nrID\"><b>暴露偏差 (Exposure Bias)</b> ：由于训练时只接触“正确答案”，模型在自主生成时可能会因遇到未见过的中间状态而偏离轨道。</li></ul><br/><li data-pid=\"cnPwOLy6\"><b>强化学习 (RL)</b> ：与 SFT 不同，RL 鼓励模型主动探索，通过环境的直接反馈（奖励信号）来学习和优化策略，从而发现可能比专家更优的解决方案。这使得 RL 在泛化能力上通常优于 SFT。然而，RL 的探索过程可能是低效的，甚至会带来风险：<br/> </li><ul><li data-pid=\"yhO0qbDa\"><b>策略退化 (Policy Degradation)</b> ：模型可能会因为熵坍塌 (entropy collapse) 或对次优策略的过度利用而导致性能下降。</li></ul></ul><p data-pid=\"KFTXuQrl\">为了结合两者的优点并规避各自的缺点，业界最常用也最直接的方法就是 <b>“先 SFT，后 RL” (SFT-then-RL)</b> 的序列化范式。这种方法的初衷很美好：SFT 为 RL 提供一个良好的起点和有效的探索先验，帮助其跳出局部最优；而 RL 的在策略学习机制则可以缓解 SFT 带来的暴露偏差和对静态数据的过拟合。</p><p data-pid=\"1idR5oRY\">然而，理想很丰满，现实很骨感。大量的实证研究，包括本文的实验（如下图所示），都表明 SFT-then-RL 范式并不总能胜过单纯的 RL 方法，有时甚至会产生负面效果。这引出了一个核心问题：<b>为什么简单的“SFT+RL”组合拳打不出预期的效果？</b></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-44ae4ee67ec2090660262a766f1239d3_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"844\" data-rawheight=\"714\" data-original-token=\"v2-693384c5c2d70b9ae7f654665eb3b929\" class=\"origin_image zh-lightbox-thumb\" width=\"844\" data-original=\"https://pic4.zhimg.com/v2-44ae4ee67ec2090660262a766f1239d3_r.jpg\"/><figcaption>训练范式对比图</figcaption></figure><p data-pid=\"TNJWo5iN\">上图展示了在 Open-R1 数据集上训练 Qwen2.5-1.5B-Instruct 模型的结果。可以清晰地看到，无论是使用 10k 还是 40k 样本进行 SFT 后再进行 RL，其最终性能（准确率）都劣于直接使用纯 RL 进行训练的模型。这一现象促使研究者们深入探究其背后的根本原因。</p><h3>2. 问题剖析</h3><p data-pid=\"zJLxA3ID\">为了探究 SFT-then-RL 范式失败的深层原因，研究团队进行了一项关键实验。他们使用由 Deepseek-R1 模型生成的专家数据对 Qwen2.5-7B-Instruct 模型进行 SFT，并在训练过程中持续评估模型在 MATH-500 数据集上的准确率。学习曲线揭示了一个被称为 <b>“迁移-适应-过拟合” (shift-readapt-overfit)</b> 的三阶段动态过程。</p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-fbea0f9de1d3d39a4bdf4f1ea67bacc1_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"872\" data-rawheight=\"730\" data-original-token=\"v2-48a17ef9529a74007518f3afd7014c43\" class=\"origin_image zh-lightbox-thumb\" width=\"872\" data-original=\"https://pic2.zhimg.com/v2-fbea0f9de1d3d39a4bdf4f1ea67bacc1_r.jpg\"/><figcaption>“迁移-适应-过拟合”过程图</figcaption></figure><p data-pid=\"41onLIyS\">这个过程可以分解为三个 distinct 阶段：</p><ol><li data-pid=\"vK0cy-Sh\"><b>迁移阶段 (Shift)</b> ：在训练初期，模型性能不升反降。这是因为专家数据（离策略）的推理模式与模型自身已建立的模式存在显著差异。强制模型去拟合这些外部模式会破坏其内部的稳定结构，导致能力暂时性地退化。这个问题在存在暴露偏差的情况下会进一步加剧，因为模型在推理时需要处理自己生成的、与专家数据分布不同的上下文。<br/> </li><li data-pid=\"iUfKz2WU\"><b>适应阶段 (Readapt)</b> ：随着 SFT 的继续，模型的策略 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%5Ctheta\" alt=\"\\pi_\\theta\" eeimg=\"1\"/> 开始逐渐与专家的模式对齐，能够生成与专家类似的响应。此时，模型性能开始回升，并逐步接近甚至超越初始水平。在这个阶段，模型对自身原有模式的依赖性降低，从而在一定程度上缓解了暴露偏差问题。但与此同时，这也可能抑制了模型进行自我探索的潜力。<br/> </li><li data-pid=\"8UVWhKKd\"><b>过拟合阶段 (Overfit)</b> ：如果长时间在有限的专家数据上进行训练，模型最终会不可避免地走向过拟合。这不仅会导致模型在未见过的数据上泛化能力下降，还会使其输出的多样性大幅减少。更关键的是，这种过拟合会严重限制模型在后续 RL 阶段进行有效探索的能力。<br/> </li></ol><p data-pid=\"9qsjbHVH\">这个三阶段的动态过程清晰地揭示了 SFT-then-RL 范式的内在脆弱性。简单地将两个阶段分开，使得我们很难精确地控制离策略专家数据的影响，也难以把握从 SFT 转换到 RL 的最佳时机。尤其当专家数据的推理模式与模型原有模式差异巨大时，这种两阶段方法的局限性就更加凸显。</p><h3>3. CHORD 框架</h3><p data-pid=\"4ztkBTlq\">基于以上洞察，论文提出了一种全新的统一框架——CHORD，旨在将 SFT 和 RL 无缝地融合在一起。CHORD 的核心思想是，<b>将 SFT 重新定义为在策略 RL 过程中的一个动态加权的辅助损失项，而不是一个独立的训练阶段</b>。</p><p data-pid=\"TvOeDKxQ\">为此，CHORD 设计了一个双重控制机制，分别从宏观和微观层面来精细地调控离策略专家数据的影响。</p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-a8065f5af7db14f2dc7403e4ed7be69e_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1708\" data-rawheight=\"780\" data-original-token=\"v2-373306811212825a6efea57d1dbf24f1\" class=\"origin_image zh-lightbox-thumb\" width=\"1708\" data-original=\"https://pic1.zhimg.com/v2-a8065f5af7db14f2dc7403e4ed7be69e_r.jpg\"/><figcaption>CHORD 框架概览</figcaption></figure><h3>3.1 宏观调控：全局系数 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/></h3><p data-pid=\"MGd9DZ2Q\">首先，为了从整体上控制专家数据的影响力，CHORD 引入了一个混合损失函数：</p><p data-pid=\"5io8bL6t\"><img src=\"https://www.zhihu.com/equation?tex=L_%7B%5Ctext%7BHybrid%7D%7D%28%5Ctheta%29+%3D+%281+-+%5Cmu%29+L_%7B%5Ctext%7BGRPO%7D%7D%28%5Ctheta%29+%2B+%5Cmu+L_%7B%5Ctext%7BSFT%7D%7D%28%5Ctheta%29+%5C%5C\" alt=\"L_{\\text{Hybrid}}(\\theta) = (1 - \\mu) L_{\\text{GRPO}}(\\theta) + \\mu L_{\\text{SFT}}(\\theta) \\\\\" eeimg=\"1\"/></p><p data-pid=\"3By6etIG\">其中：</p><ul><li data-pid=\"IRXcYJ8m\"><img src=\"https://www.zhihu.com/equation?tex=L_%7B%5Ctext%7BGRPO%7D%7D%28%5Ctheta%29\" alt=\"L_{\\text{GRPO}}(\\theta)\" eeimg=\"1\"/> 是在策略 RL 的损失，这里采用了 Group Relative Policy Optimization (GRPO) 算法的损失函数。GRPO 是一种高效的策略梯度算法，它通过比较一组候选响应的相对好坏来更新策略，而不需要一个独立的价值网络，因此在内存和计算效率上具有优势。其形式化的目标函数如下：<br/> <img src=\"https://www.zhihu.com/equation?tex=L_%7B%5Ctext%7BGRPO%7D%7D%28%5Ctheta%29+%3D+-%5Cfrac%7B1%7D%7BB+%5Ccdot+K%7D+%5Csum_%7Bi%3D1%7D%5E%7BB%7D+%5Csum_%7Bk%3D1%7D%5E%7BK%7D+%5Csum_%7Bt%3D1%7D%5E%7B%7C%5Ctau_%7Bi%2Ck%7D%7C%7D+%5Cmin+%5Cleft%28+r_%7Bi%2Ck%2Ct%7D%28%5Ctheta%29+A_%7Bi%2Ck%7D%2C+%5Ctext%7Bclip%7D%28r_%7Bi%2Ck%2Ct%7D%28%5Ctheta%29%2C+1-%5Cepsilon%2C+1%2B%5Cepsilon%29+A_%7Bi%2Ck%7D+%5Cright%29+%5C%5C\" alt=\"L_{\\text{GRPO}}(\\theta) = -\\frac{1}{B \\cdot K} \\sum_{i=1}^{B} \\sum_{k=1}^{K} \\sum_{t=1}^{|\\tau_{i,k}|} \\min \\left( r_{i,k,t}(\\theta) A_{i,k}, \\text{clip}(r_{i,k,t}(\\theta), 1-\\epsilon, 1+\\epsilon) A_{i,k} \\right) \\\\\" eeimg=\"1\"/> 这里的 <img src=\"https://www.zhihu.com/equation?tex=r_%7Bi%2Ck%2Ct%7D%28%5Ctheta%29\" alt=\"r_{i,k,t}(\\theta)\" eeimg=\"1\"/> 是重要性采样比率，用于将在旧策略下采样的数据调整为适用于当前策略的更新，<img src=\"https://www.zhihu.com/equation?tex=A_%7Bi%2Ck%7D\" alt=\"A_{i,k}\" eeimg=\"1\"/> 是优势函数，表示当前响应相对于组内平均响应的好坏。<br/> </li><li data-pid=\"vqb4RIoO\"><img src=\"https://www.zhihu.com/equation?tex=L_%7B%5Ctext%7BSFT%7D%7D%28%5Ctheta%29\" alt=\"L_{\\text{SFT}}(\\theta)\" eeimg=\"1\"/> 是标准的监督微调损失，即最小化专家响应的负对数似然：<br/> <img src=\"https://www.zhihu.com/equation?tex=L_%7B%5Ctext%7BSFT%7D%7D%28%5Ctheta%29+%3D+-%5Cfrac%7B1%7D%7BB%7D+%5Csum_%7Bi%3D1%7D%5E%7BB%7D+%5Csum_%7Bt%3D1%7D%5E%7B%7Cy_i%5E%2A%7C%7D+%5Clog+%5Cpi_%5Ctheta%28y_%7Bi%2Ct%7D%5E%2A+%7C+x_i%2C+y_%7Bi%2C%3C+t%7D%5E%2A%29+%5C%5C\" alt=\"L_{\\text{SFT}}(\\theta) = -\\frac{1}{B} \\sum_{i=1}^{B} \\sum_{t=1}^{|y_i^*|} \\log \\pi_\\theta(y_{i,t}^* | x_i, y_{i,&lt; t}^*) \\\\\" eeimg=\"1\"/> </li><li data-pid=\"8zXt_GYM\"><img src=\"https://www.zhihu.com/equation?tex=%5Cmu+%5Cin+%5B0%2C+1%5D\" alt=\"\\mu \\in [0, 1]\" eeimg=\"1\"/> 是一个超参数，用于平衡 RL 损失和 SFT 损失的权重。<br/> </li></ul><p data-pid=\"Ps1okUoC\">与 SFT-then-RL 范式（可以看作是 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 从 1 突变为 0 的二进制调度）和交错训练（可以看作是周期性的 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 调度）不同，CHORD 采用了一种<b>平滑衰减的 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 调度策略</b>。</p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-884928c8c947a38c0a6860251b8fa799_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"796\" data-rawheight=\"714\" data-original-token=\"v2-7adacf986650ce3632b8a3afad80f118\" class=\"origin_image zh-lightbox-thumb\" width=\"796\" data-original=\"https://picx.zhimg.com/v2-884928c8c947a38c0a6860251b8fa799_r.jpg\"/><figcaption>CHORD-\\mu 的平滑过渡</figcaption></figure><p data-pid=\"0dTWHiDc\">如上图所示，在训练初期，<img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 的值较高，模型被鼓励更多地向离策略的专家数据学习，快速吸收其知识和模式。随着训练的进行，<img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 的值逐渐衰减，训练的重心随之平滑地转移到在策略的 RL 探索上，使得模型能够在吸收专家知识的基础上，进一步探索更优的策略，同时避免对专家数据的过拟合。这种平滑过渡的策略，被证明在缓解暴露偏差方面卓有成效。</p><p data-pid=\"2kl94l03\">然而，仅有全局系数 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 的调控（在论文中被称为 CHORD-<img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/>）仍然不够完美。实验表明，尽管 CHORD-<img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 的性能优于 SFT-then-RL，其学习曲线仍然表现出类似“迁移-适应”的模式，即奖励在初期会先下降再上升。同时，模型的行为模式（如响应长度）也趋向于完全模仿专家。这说明，离策略数据在某种程度上仍然在干扰模型的原生模式，并抑制了其自主探索。</p><p data-pid=\"wdBZ-IZ6\">为了实现更精细的控制，让模型能够“取其精华，去其糟粕”地学习，而非全盘模仿，CHORD 引入了第二个控制机制。</p><h3>3.2 微观调控：逐词权重函数 <img src=\"https://www.zhihu.com/equation?tex=%5Cphi%28%5Ccdot%29\" alt=\"\\phi(\\cdot)\" eeimg=\"1\"/></h3><p data-pid=\"HrwtvlOA\">为了从更细的粒度上控制离策略数据的影响，CHORD 提出了一个逐词的权重函数 <img src=\"https://www.zhihu.com/equation?tex=%5Cphi%28%5Ccdot%29\" alt=\"\\phi(\\cdot)\" eeimg=\"1\"/>。这个设计的灵感来源于重要性采样 (Importance Sampling, IS) 的思想。IS 通过词元的生成概率来重新加权损失，旨在稳定离策略数据的学习过程。具体来说，它会降低那些在当前策略下生成概率很低的词元（即与模型当前认知差异巨大的词元）的权重，从而避免这些“异常值”对模型造成过大的冲击。</p><p data-pid=\"AzdWPCWB\">然而，传统的 IS 策略存在一个问题：它在抑制破坏性更新的同时，也可能过度强化模型已有的高概率行为，忽略那些虽然概率较低但可能包含新知识的词元，最终导致策略熵的快速下降，使模型变得过于自信，陷入次优解。</p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-a55eb186fd9d783ec8e04c4b031e8b04_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"676\" data-original-token=\"v2-69a590b2ae64556b6852d37247394b9a\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pica.zhimg.com/v2-a55eb186fd9d783ec8e04c4b031e8b04_r.jpg\"/><figcaption>不同策略下的熵损失对比</figcaption></figure><p data-pid=\"9WLSp4w8\">上图对比了纯 RL、混合 RL（无 IS）和混合 RL（有 IS）的策略熵损失。可以看到，混合专家数据（W/O IS）会导致熵急剧上升，表明模型原有模式被迅速破坏。而加入 IS（With IS）虽然稳定了训练，但熵的下降速度比纯 RL 更快，这正是探索能力受限的体现。</p><p data-pid=\"zvZ3com7\">为了解决这个问题，CHORD 设计了一种新颖的、非单调的逐词权重函数：</p><p data-pid=\"AVt-44qr\"><img src=\"https://www.zhihu.com/equation?tex=%5Cphi%28y_t%5E%2A%3B+%5Cpi_%5Ctheta%29+%3D+p_t+%281+-+p_t%29+%5C%5C\" alt=\"\\phi(y_t^*; \\pi_\\theta) = p_t (1 - p_t) \\\\\" eeimg=\"1\"/></p><p data-pid=\"iFo8QtD7\">其中，<img src=\"https://www.zhihu.com/equation?tex=p_t+%3D+%5Cpi_%5Ctheta%28y_t%5E%2A+%7C+x%2C+y_%7B%3C+t%7D%5E%2A%29\" alt=\"p_t = \\pi_\\theta(y_t^* | x, y_{&lt; t}^*)\" eeimg=\"1\"/> 是模型生成专家词元 <img src=\"https://www.zhihu.com/equation?tex=y_t%5E%2A\" alt=\"y_t^*\" eeimg=\"1\"/> 的概率。</p><p data-pid=\"qAvh3hIr\">这个函数是一个开口向下的抛物线，其特性非常巧妙：</p><ul><li data-pid=\"XXNQBbcC\">当 <img src=\"https://www.zhihu.com/equation?tex=p_t\" alt=\"p_t\" eeimg=\"1\"/> 趋近于 0（模型认为这个词元极不可能出现）或趋近于 1（模型已经完全掌握了这个词元）时，权重 <img src=\"https://www.zhihu.com/equation?tex=%5Cphi%28%5Ccdot%29\" alt=\"\\phi(\\cdot)\" eeimg=\"1\"/> 都会趋近于 0。</li><li data-pid=\"yFbjGg3U\">当 <img src=\"https://www.zhihu.com/equation?tex=p_t+%3D+0.5\" alt=\"p_t = 0.5\" eeimg=\"1\"/>（模型最不确定时）时，权重达到最大值。</li></ul><p data-pid=\"BQhH4xY4\">从信息论的角度看，<img src=\"https://www.zhihu.com/equation?tex=p_t%281-p_t%29\" alt=\"p_t(1-p_t)\" eeimg=\"1\"/> 正是生成词元 <img src=\"https://www.zhihu.com/equation?tex=y_t%5E%2A\" alt=\"y_t^*\" eeimg=\"1\"/> 这个二元事件的熵，它衡量了模型对于该词元的不确定性。因此，这种加权方式天然地将学习的重点偏向于那些模型<b>最不确定</b>的词元。它创造了一个“学习甜点区” (learning sweet spot)：</p><ul><li data-pid=\"-ZD8PS9R\"><b>避免干扰</b>：对于模型认为极不可能的词元（<img src=\"https://www.zhihu.com/equation?tex=p_t+%5Cto+0\" alt=\"p_t \\to 0\" eeimg=\"1\"/>），给予低权重，防止其对现有策略造成剧烈冲击。</li><li data-pid=\"SMYQRlUe\"><b>防止冗余</b>：对于模型已经高度自信的词元（<img src=\"https://www.zhihu.com/equation?tex=p_t+%5Cto+1\" alt=\"p_t \\to 1\" eeimg=\"1\"/>），也给予低权重，避免在已经学会的知识上浪费梯度，从而防止熵过快坍塌，保留探索能力。</li><li data-pid=\"CgoS5RAa\"><b>聚焦学习</b>：将主要的学习资源集中在那些对模型来说既新颖（informative）又不过于离谱（not so divergent）的词元上。</li></ul><p data-pid=\"dRwZg-lp\">最终，CHORD 的 SFT 损失函数被更新为：</p><p data-pid=\"-iTG-JU3\"><img src=\"https://www.zhihu.com/equation?tex=L_%7B%5Ctext%7BSFT-%7D%5Cphi%7D%28%5Ctheta%29+%3D+-%5Cmathbb%7BE%7D_%7B%28x%2C+y%5E%2A%29+%5Csim+D_%7B%5Ctext%7BSFT%7D%7D%7D+%5Cleft%5B+%5Csum_%7Bt%3D1%7D%5E%7B%7Cy%5E%2A%7C%7D+%5Cphi%28y_t%5E%2A%3B+%5Cpi_%5Ctheta%29+%5Ccdot+%5Clog+%5Cpi_%5Ctheta%28y_t%5E%2A+%7C+x%2C+y_%7B%3C+t%7D%5E%2A%29+%5Cright%5D+%5C%5C\" alt=\"L_{\\text{SFT-}\\phi}(\\theta) = -\\mathbb{E}_{(x, y^*) \\sim D_{\\text{SFT}}} \\left[ \\sum_{t=1}^{|y^*|} \\phi(y_t^*; \\pi_\\theta) \\cdot \\log \\pi_\\theta(y_t^* | x, y_{&lt; t}^*) \\right] \\\\\" eeimg=\"1\"/></p><p data-pid=\"5RfVL1m1\">将这个新的 <img src=\"https://www.zhihu.com/equation?tex=L_%7B%5Ctext%7BSFT-%7D%5Cphi%7D\" alt=\"L_{\\text{SFT-}\\phi}\" eeimg=\"1\"/> 替换掉原始的 <img src=\"https://www.zhihu.com/equation?tex=L_%7B%5Ctext%7BSFT%7D%7D\" alt=\"L_{\\text{SFT}}\" eeimg=\"1\"/>，就构成了 CHORD 框架的最终形态（在论文中被称为 CHORD-<img src=\"https://www.zhihu.com/equation?tex=%5Cphi\" alt=\"\\phi\" eeimg=\"1\"/>）。它通过全局系数 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 和逐词权重函数 <img src=\"https://www.zhihu.com/equation?tex=%5Cphi%28%5Ccdot%29\" alt=\"\\phi(\\cdot)\" eeimg=\"1\"/> 的双重控制，实现了对离策略专家数据影响力的全面、动态和细粒度的调控。</p><h3>4. 实验验证与分析</h3><p data-pid=\"tae0SeHt\">为了验证 CHORD 框架的有效性，研究团队进行了一系列详尽的实验。</p><h3>4.1 实验设置</h3><ul><li data-pid=\"6b6812Gz\"><b>模型</b>：主要使用 Qwen2.5-7B-Instruct 模型作为策略模型。选择该模型的原因是其推理模式与提供专家数据的 Deepseek-R1 模型存在显著差异，这能更好地考验框架处理策略分布差异的能力。</li><li data-pid=\"3ISkmoHI\"><b>数据集</b>：实验在 OpenR1-Math-220k 数据集上进行，这是一个包含由 Deepseek-R1 生成的数学问题和解题轨迹的大规模数据集。实验中，采样了 5k 个实例用于 SFT，20k 个实例用于 RL，两者没有交集。</li><li data-pid=\"7sQqhZ46\"><b>评估</b>：模型的能力从两个维度进行评估： </li></ul><ol><li data-pid=\"bFN9Qb-m\"><b>领域内推理能力</b>：在多个广泛使用的数学基准测试上进行评估，包括 AIME24, AIME25, 和 AMC。</li><li data-pid=\"95FPwKkK\"><b>通用推理能力</b>：在 MMLU-pro 基准测试上进行评估，以考察模型在后训练过程中通用能力的潜在提升或退化。</li></ol><ul><li data-pid=\"I6OcxrhR\"><b>基线方法</b>： </li><ul><li data-pid=\"mmXISalO\"><b>Original Model</b>：未经任何微调的 Qwen2.5-7B-Instruct。</li><li data-pid=\"RafxAhDe\"><b>SFT-only</b>：只进行 SFT。分为 <code>SFT-light</code>（单 epoch，低学习率）和 <code>SFT-best</code>（经过详尽超参搜索的最优 SFT 模型）。</li><li data-pid=\"ivkCvy7m\"><b>RL-only</b>：只使用 GRPO 进行 RL 训练。</li><li data-pid=\"-vlHr8Ce\"><b>SFT+RL</b>：传统的 SFT-then-RL 范式。</li><li data-pid=\"yjsvoNT7\"><b>LUFFY</b>：一种将专家数据混入 RL rollout 组并重塑重要性采样比率的方法。</li></ul></ul><h3>4.2 性能对比</h3><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-fc1c9a86eb5151a07e7ab0829cfdd697_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1426\" data-rawheight=\"600\" data-original-token=\"v2-ae40a38d129578a62d845b1912ee575e\" class=\"origin_image zh-lightbox-thumb\" width=\"1426\" data-original=\"https://pic4.zhimg.com/v2-fc1c9a86eb5151a07e7ab0829cfdd697_r.jpg\"/><figcaption>模型性能对比表</figcaption></figure><p data-pid=\"Hfxn-zv_\">实验结果（如上表所示）清晰地展示了 CHORD 框架的优越性：</p><ul><li data-pid=\"TwSnfBzJ\"><b>SFT 的必要性与局限性</b>：<code>SFT-light</code> 的性能甚至不如原始模型，这印证了不恰当的 SFT 会损害模型能力。而经过充分优化的 <code>SFT-best</code> 则表现出强大的性能。这说明 SFT 并非“即插即用”，需要精细调优。</li><li data-pid=\"fo-yBbqn\"><b>SFT+RL vs. CHORD-<img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/></b> ：<code>SFT-best+RL</code> 相比 <code>SFT-best</code> 有了进一步提升，证明了 RL 阶段的必要性。然而，采用平滑过渡策略的 <code>CHORD-μ</code> 在所有数学基准上都优于 <code>SFT-best+RL</code>，这充分说明了 CHORD 统一框架相比于僵化的两阶段范式的优越性。</li><li data-pid=\"5MXzt5CG\"><b>CHORD-<img src=\"https://www.zhihu.com/equation?tex=%5Cphi\" alt=\"\\phi\" eeimg=\"1\"/> 的全面胜出</b>：集成了双重控制机制的 <code>CHORD-φ</code> 在所有评估的基准（包括领域内和通用推理）上都取得了最佳性能，一致性地超越了所有基线方法。这强有力地证明了双重控制机制在灵活调控离策略专家数据影响方面的有效性。<code>CHORD-φ</code> 能够有选择性地将 SFT 损失应用于非破坏性的词元，从而在整合专家知识的同时不损害模型的基础能力，实现了离策略专家学习和在策略探索的稳健结合。</li></ul><h3>4.3 推理模式分析</h3><p data-pid=\"w9noayNa\">除了性能指标，研究团队还分析了不同方法训练出的模型的响应长度，以探究它们对推理模式的影响。</p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-185b4b3970a41c9dffa4d1d8a3cbb00e_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1660\" data-rawheight=\"642\" data-original-token=\"v2-a62362a2f553a487e07a5380b3b5f911\" class=\"origin_image zh-lightbox-thumb\" width=\"1660\" data-original=\"https://pic1.zhimg.com/v2-185b4b3970a41c9dffa4d1d8a3cbb00e_r.jpg\"/><figcaption>不同方法平均响应长度统计&amp;不同方法响应长度变化曲线</figcaption></figure><p data-pid=\"rYBooxot\">分析发现：</p><ul><li data-pid=\"i9S8NdCZ\">专家数据（Expert Data）的平均长度（6132）远大于 Qwen 模型的原始响应长度（659）。</li><li data-pid=\"SGra1UYy\">经过 SFT 训练后，模型的响应长度显著增加，趋向于模仿专家的“冗长”风格。</li><li data-pid=\"nVigcdQi\">加入 RL 阶段后 (<code>SFT-light+RL</code> 和 <code>SFT-best+RL</code>)，响应长度有所缩短，说明 RL 的在策略探索鼓励模型寻找更高效的表达方式。</li><li data-pid=\"42PcLNUd\"><code>CHORD-μ</code> 的响应长度变化趋势与 SFT-then-RL 类似，先增长后回落。</li><li data-pid=\"asaoVW5Z\"><code>CHORD-φ</code> 的响应长度则处于 SFT-then-RL 和纯 RL 之间，达到了一种平衡。通过逐词权重的调节，<code>CHORD-φ</code> 学会了有选择性地整合专家模式，比如在自身的“思想链”中策略性地加入验证步骤，而不是简单地全盘模仿。这使得它既能生成结构良好、逻辑清晰的响应，又能吸收专家的优秀策略，做到“博采众长，自成一派”。</li></ul><h3>4.4 消融实验：<img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=%5Cphi\" alt=\"\\phi\" eeimg=\"1\"/> 的作用</h3><ul><li data-pid=\"HjwC65Hb\"><b>动态 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> vs. 固定 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/></b> ：实验对比了动态衰减的 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 调度与多个固定的 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 值。结果表明，任何固定的 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 值都无法达到动态调度的性能水平，甚至可能不如纯 RL。这说明静态地混合离策略和在策略学习目标，会让模型在两种可能冲突的推理模式之间“左右为难”，无法收敛到稳定且高性能的状态。动态 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 的平滑过渡策略则有效地解决了这一冲突。</li></ul><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-4a4b2ccada13ff784a8b5c849e0d1ea6_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1636\" data-rawheight=\"634\" data-original-token=\"v2-fd70cc8be3bf3b2976beec11b8c10806\" class=\"origin_image zh-lightbox-thumb\" width=\"1636\" data-original=\"https://pic3.zhimg.com/v2-4a4b2ccada13ff784a8b5c849e0d1ea6_r.jpg\"/><figcaption>动态与固定μ值的对比&amp;动态与固定μ值的奖励曲线</figcaption></figure><ul><li data-pid=\"hCRp4XXT\"><b><img src=\"https://www.zhihu.com/equation?tex=%5Cphi%28%5Ccdot%29\" alt=\"\\phi(\\cdot)\" eeimg=\"1\"/> 的稳定作用</b>：通过对比有无 <img src=\"https://www.zhihu.com/equation?tex=%5Cphi%28%5Ccdot%29\" alt=\"\\phi(\\cdot)\" eeimg=\"1\"/> 函数的训练过程，可以发现 <img src=\"https://www.zhihu.com/equation?tex=%5Cphi%28%5Ccdot%29\" alt=\"\\phi(\\cdot)\" eeimg=\"1\"/> 的引入带来了显著的稳定性和性能提升。在熵损失曲线上，<code>CHORD-φ</code> 避免了熵的过早坍塌和剧烈波动，维持了探索和利用之间的良好平衡。在奖励曲线上，<code>CHORD-φ</code> 实现了稳定持续的增长，最终达到比纯 RL 高得多的水平。这证明了逐词权重函数在有效统一 SFT 和 RL 阶段中的关键作用。</li></ul><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-8f95fb928f792a0f7dc456f78ca39a75_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1638\" data-rawheight=\"632\" data-original-token=\"v2-43bab56282901c574272a7952137d628\" class=\"origin_image zh-lightbox-thumb\" width=\"1638\" data-original=\"https://pic2.zhimg.com/v2-8f95fb928f792a0f7dc456f78ca39a75_r.jpg\"/><figcaption>有无φ(·)的熵损失曲线&amp;有无φ(·)的奖励曲线</figcaption></figure><h2>点评</h2><p data-pid=\"66yjnFsv\">论文最大的亮点之一是对 SFT-then-RL 范式失败原因的精准剖析。提出的“迁移-适应-过拟合” (shift-readapt-overfit) 动态过程，为理解“为什么外部专家数据会‘水土不服’”提供了一个非常清晰的理论框架。这个诊断不仅基于理论推测，更有实验数据（图2的学习曲线）作为支撑，极具说服力。这使得论文的出发点非常坚实。</p><p data-pid=\"V_YLDPYO\">论文强调其解决的是在一个已经经过指令微调（Instruction-tuned）的模型上继续训练的场景，这与许多从基础模型（Base Model）开始训练的“Zero-RL”工作有所不同。这是一个很好的切入点，但也引出了一个问题：如果从一个基础模型开始，同时使用专家数据和 RL 进行训练，CHORD 框架相比于其他方法（如 SRFT、Reft 等）是否仍有优势？论文虽然在附录中讨论了基础模型和指令模型的差异，但主实验中缺乏与这些“Zero-RL”方法的直接对比。</p><hr/><p data-pid=\"0PGlYSiK\">往期文章：</p><ul><li data-pid=\"nBXlOoRL\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/QSi580SJ2RFewyFirAe65A\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">深挖RLVR探索机制：SFT专攻Pass@k，RL强化Pass@1</a><br/> </li><li data-pid=\"W2ql-YnG\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/6eL81bfF-VD8bv5X4BNn1A\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">人大&amp;百度提出ReasonRank：让LLM学会在排序中“思考”</a><br/> </li><li data-pid=\"Nk74v_tT\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/nphSwb-BeTw_BPEZOHmAkg\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">深度解析 Seed Diffusion：来自字节跳动的高速推理扩散语言模型</a><br/> </li><li data-pid=\"Cp4w8t0f\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/QO48LHQue1QLGl-Pjq0mVA\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">HuggingFace榜一论文：大模型强化学习中的熵机制</a><br/> </li><li data-pid=\"WuvZnHNV\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/jQOLmaCaYrQhw6QPiW-5qg\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">字节Seed：Pass@k作为reward可以有效平衡探索与利用</a><br/> </li><li data-pid=\"geSuVFoy\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/l7uoz8jXXbBZsDWpttEy3Q\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">深入探讨RL4LLM：解决低概率词元的“过度主导”问题</a><br/> </li><li data-pid=\"s6G4teIg\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/1iPrfpw9JxO7f4P0kdHvKg\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">浙大Posterior-GRPO：结合PRM和ORM来优化大模型</a><br/> </li><li data-pid=\"qsepIdUu\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/dwkaKRSxtE6UNc2c1lUuUg\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">微软新作GFPO：治疗DeepSeek R1的“话痨”，冗长响应减少80%</a><br/> </li><li data-pid=\"KnyiF_HF\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/iRnfdDsCPJZRdft20I7Gag\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">周志华团队新作：通过IRL挖掘LLM内生奖励，首次理论证明RL对LLM有效性</a><br/> </li><li data-pid=\"D-hnsrTC\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/7anXynv6LQe8KnlflaYayg\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">FlashRL：引入截断重要性采样，解决Rollout训练不匹配，RL加速可达1.75×</a><br/> </li><li data-pid=\"SW0JsBqq\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/KHoY64zRa34_mW_F6wozSg\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">超越二元奖励：训练语言模型审视自身的不确定性</a><br/> </li><li data-pid=\"5AyJ79gi\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/Y9tLUSMqCUSgiMOuxhzIrw\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">RLVR的一些Tricks到底哪些有用？</a><br/> </li><li data-pid=\"Qz1qh7Ub\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/VVyezB93wb753CfXBEQADw\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">重磅开源！GLM-4.5 ARC 技术报告深度解读</a><br/> </li><li data-pid=\"T4yEbM8j\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/Ni6nilJ8lVI36r_9JJgBng\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">清华&amp;美团首次揭秘MoE：从“Massive Activations”到“Attention Sink”，探寻“超级专家”的机制</a><br/> </li><li data-pid=\"Y1KKk6E1\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/P2-Ou5II9OCDhjelxtPazA\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Diffusion：真正的王牌不是“快”，而是“超级数据学习者”</a><br/> </li><li data-pid=\"mx17h_Ya\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/rKgDfJ24m86dHhHTAFf1Xg\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">腾讯 AI Lab提出R-Zero「实现零数据自进化」</a><br/> </li><li data-pid=\"9-aBc7y2\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/-w_YzyjF8SsfdbNX0url-w\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">CompassVerifier 深度解析：为大模型打造统一、鲁棒的“裁判”与“奖励”系统</a><br/> </li><li data-pid=\"bKbDsb9L\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/XXGxRk-p5LahtqdYNnbKaA\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">一行代码，解锁SFT泛化能力：深度解读DFT如何完胜传统微调</a><br/> </li><li data-pid=\"vpqzYgME\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/0FDZPWgI_FngJ-CnzeYKRQ\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">深度解析注意力沉点：为何Transformer模型“情有独钟”于首个Token？</a><br/> </li><li data-pid=\"EkhfTXTD\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/dPemo2XCO0c7nVn4nlLZBw\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">思维链再遭质疑！距离真正可泛化推理还很远吗？</a><br/> </li><li data-pid=\"nVQzUd28\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/KoP0zv9vXIcOpI0KPOlffQ\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">告别验证器依赖：RLPR如何将大模型推理能力泛化到通用领域</a><br/> </li><li data-pid=\"QbeQpOdf\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/epiVqNj3Ud1xZs67dPv1oA\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">深入解读 OpenAI 最新开源力作：gpt-oss-120b &amp; gpt-oss-20b 模型卡</a><br/> </li><li data-pid=\"SJBzG1vl\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/5zLPXtNYpFOHrvtSrRxYvw\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">ACL2025｜AdaGroPE：免训练即插即用扩窗至128k</a><br/> </li><li data-pid=\"zTMOKVky\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/s7lpt6camh7tta-P_rPibA\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">ACL2025｜大模型响应采样理论：「描述性」与「规定性」</a><br/> </li><li data-pid=\"LMIIqEY7\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/cXDi02azAFBaobsHamkl1A\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">ACL2025｜“拉不住的弹簧”：为什么大型语言模型会“抵抗”对齐？</a><br/> </li><li data-pid=\"ZX-wwA_N\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/xdKETBSgyqlqBV30CDg5GQ\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">大模型3D可视化</a><br/> </li><li data-pid=\"oua5ypl6\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/EWRNf9rCZA225kFUzCxVug\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">GRPO等于高级版Rejection Sampling？强化学习祛魅时刻：负样本“披沙拣金”才是关键！</a><br/> </li><li data-pid=\"At0vHxFw\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/cAp_r5vv7U90ZnjgzNTF2g\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Skywork MindLink 深度解析：如何让 Qwen3 继续进化</a><br/> </li><li data-pid=\"Sgb51aG2\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/4GK1fKcGcgeDTW_ohb3uiQ\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">在数据受限场景下，Diffusion优于自回归模型</a><br/> </li><li data-pid=\"WfIzuJGv\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/_hFuFr8Zu7HmDTl3YP8tDw\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">RL+SFT 优势首融合，动态引导模型高效训练</a><br/> </li><li data-pid=\"X78tnV_J\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/t_pvG9OKbg3TWZDoQxmOiA\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">阿里通义千问放大招，告别训练崩溃！新算法 GSPO 碾压 GRPO，Qwen3 模型性能暴涨的幕后功臣</a><br/> </li><li data-pid=\"2QQnECWW\"><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/ZgG3XH-E2cEHkyKwc_bYDg\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">网友：都说了学物理的不准转计算机！「“流匹配”成ICML 2025超热议题」</a></li></ul>",
        "is_labeled": false,
        "visited_count": 821,
        "thumbnails": [
          "https://picx.zhimg.com/50/v2-693384c5c2d70b9ae7f654665eb3b929_720w.jpg?source=b6762063",
          "https://pica.zhimg.com/50/v2-48a17ef9529a74007518f3afd7014c43_720w.jpg?source=b6762063",
          "https://pic1.zhimg.com/50/v2-373306811212825a6efea57d1dbf24f1_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-7adacf986650ce3632b8a3afad80f118_720w.jpg?source=b6762063",
          "https://picx.zhimg.com/50/v2-69a590b2ae64556b6852d37247394b9a_720w.jpg?source=b6762063",
          "https://pica.zhimg.com/50/v2-a62362a2f553a487e07a5380b3b5f911_720w.jpg?source=b6762063"
        ],
        "favorite_count": 68,
        "article_type": "normal",
        "is_navigator": false,
        "navigator_vote": false,
        "vote_next_step": "vote"
      },
      "brief": "{\"source\": \"TS\", \"type\": \"article\", \"id\": 1941856605491668311}",
      "attached_info": "CvkICNyT/PDV2JSqnQEQBxoJMjYyMDUyNTgwIM7hmsUGKCEwAUBlSisKFlRTX1NPVVJDRV9GRUVEUkVfTVNfVjISATAYACAAOgp7InJhdyI6IiJ9YiBmMDc1YmIwMGMyOWY0YzMzNjI1YTU5YmIzNTFhZTBhN3ITMTk0MTg1NjYwNTQ5MTY2ODMxMaoBCXJlY29tbWVuZMIBIDRiOTZmZTJiM2ZjYTc3MGIzOTMzMDBhYmRlYmVhN2U18gEKCAwSBk5vcm1hbPIBKAgKEiRhMWU1MDgzMy0wMjQ5LTRmOTQtOWE1Ny01ZDI0M2YyYzdkMjPyAQYICxICMTeCAgCIAp2zqfmMM5ICIDRiOTZmZTJiM2ZjYTc3MGIzOTMzMDBhYmRlYmVhN2U1mgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZcoCHEJheWVzRmlyc3RMZXZlbElzb2xhdGlvblJ1bGXaAhZUU19TT1VSQ0VfRkVFRFJFX01TX1Yy6AIE+gILTk9STUFMX0ZMT1eKAyA5MjY1MzIxNDlmNjU0YzQ3YmUyZjczNzI5ODg4NWFmZpoDDQoCdjIQABoFb3RoZXKoA7UG2AMA6gMOZmVlZHJlX21zX2dhdGX6A/UDEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERTotCAIQxA0Y8gQiI3YyLTFjMDQ3NGJmMzUwMmJmZGY5ZDczMDZmZWQwYTU0NDIzOi0IAhDMBhjKBSIjdjItNjkzMzg0YzVjMmQ3MGI5YWU3ZjY1NDY2NWViM2I5Mjk6LQgEEOgGGNoFIiN2Mi00OGExN2VmOTUyOWE3NDAwNzUxOGYzYWZkNzAxNGM0MzotCAIQrA0YjAYiI3YyLTM3MzMwNjgxMTIxMjgyNWE2ZWZlYTU3ZDFkYmYyNGYxOi0IAhCcBhjKBSIjdjItN2FkYWNmOTg2NjUwY2UzNjMyYjhhM2FmYWQ4MGYxMTg6LQgEEKAGGKQFIiN2Mi02OWE1OTBiMmFlNjQ1NTZiNjg1MmQzNzI0NzM5NGI5YTotCAIQkgsY2AQiI3YyLWFlNDBhMzhkMTI5NTc4YTYyZDg0NWIxOTEyZWU1NzVlOi0IAhD8DBiCBSIjdjItYTYyMzYyYTJmNTUzYTQ4N2UwN2E1MzgwYjNiNWY5MTE6LQgCEOQMGPoEIiN2Mi1mZDcwY2M4YmUzYmYzYjI5NzZiZWVjMTFiOGMxMDgwNjotCAIQ5gwY+AQiI3YyLTQzYmFiNTYyODI5MDFjNTc0MjcyYTc5NTIxMzdkNjI4gAQAiAQAkgQGTm9ybWFsmgQBNKAEAKgEALAEALoEAmFpwgQDNDAwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAACATo2EP4EFAAAAAAAAAACJBV5CjDMIVNk/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBRGQBgCgBmeoBgCSAi4KCTI2MjA1MjU4MBITMTk0MTg1NjYwNTQ5MTY2ODMxMRgHIgpJTUFHRV9URVhU",
      "action_card": false
    }
  ],
  "paging": {
    "is_end": false,
    "is_start": false,
    "next": "https://www.zhihu.com/api/v3/feed/topstory/recommend?action=down&ad_interval=-10&after_id=101&desktop=true&end_offset=103&page_number=18&session_token=f075bb00c29f4c33625a59bb351ae0a7",
    "previous": "https://www.zhihu.com/api/v3/feed/topstory/recommend?action=pull&ad_interval=-10&before_id=101&desktop=true&end_offset=103&page_number=18&session_token=f075bb00c29f4c33625a59bb351ae0a7",
    "totals": 0
  },
  "fresh_text": "推荐已更新"
}