{"data":[{"id":"120_1750899001.983","type":"feed","offset":120,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750899001,"updated_time":1750899001,"target":{"id":"1920608399860699695","type":"article","url":"https://api.zhihu.com/articles/1920608399860699695","author":{"id":"f7772b82518893bf9db114f194b1c9a0","url":"https://api.zhihu.com/people/f7772b82518893bf9db114f194b1c9a0","user_type":"people","url_token":"codemls","name":"代码里程碑","headline":"大厂资深程序员； 北航软件工程硕士； AI编程转型中  ","avatar_url":"https://picx.zhimg.com/50/v2-6f19c88070b917f6e2f3e535a2bca3e0_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":3,"is_following":false,"is_followed":false},"title":"手把手构建TinyCodeRAG","comment_permission":"all","created":1750688822,"updated":1750688869,"voteup_count":4,"voting":0,"comment_count":0,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"手把手构建TinyCodeRAG：轻量级代码知识库解决方案在上一篇文章中，我们拆解了RAG系统的核心组件。今天，我们来点更酷的——亲自构建一个专为代码优化的TinyCodeRAG！ 快速科普：RAG（Retrieval-Augmented Generation，检索增强生成）技术通过结合外部知识库和AI生成能力，有效缓解大模型的\u0026#34;幻觉\u0026#34;问题。 你可能会好奇：\u0026#34;已有TinyRAG珠玉在前，为何再造轮子？\u0026#34; 原因有二： 首先，造轮子是最扎实的学习路径。 其次，在造轮子的过程…","excerpt_new":"手把手构建TinyCodeRAG：轻量级代码知识库解决方案在上一篇文章中，我们拆解了RAG系统的核心组件。今天，我们来点更酷的——亲自构建一个专为代码优化的TinyCodeRAG！ 快速科普：RAG（Retrieval-Augmented Generation，检索增强生成）技术通过结合外部知识库和AI生成能力，有效缓解大模型的\u0026#34;幻觉\u0026#34;问题。 你可能会好奇：\u0026#34;已有TinyRAG珠玉在前，为何再造轮子？\u0026#34; 原因有二： 首先，造轮子是最扎实的学习路径。 其次，在造轮子的过程…","preview_type":"default","preview_text":"","content":"\u003ch2\u003e手把手构建TinyCodeRAG：轻量级代码知识库解决方案\u003c/h2\u003e\u003cp data-pid=\"oHHcIPUC\"\u003e在上一篇文章中，我们拆解了RAG系统的核心组件。今天，我们来点更酷的——亲自构建一个专为代码优化的TinyCodeRAG！\u003c/p\u003e\u003cp data-pid=\"Yi9yYKlI\"\u003e  快速科普：RAG（Retrieval-Augmented Generation，检索增强生成）技术通过结合外部知识库和AI生成能力，有效缓解大模型的\u0026#34;幻觉\u0026#34;问题。\u003c/p\u003e\u003cp data-pid=\"YMVryvDk\"\u003e你可能会好奇：\u0026#34;已有TinyRAG珠玉在前，为何再造轮子？\u0026#34; 原因有二：  \u003c/p\u003e\u003cp data-pid=\"_dCc2qzy\"\u003e首先，造轮子是最扎实的学习路径。\u003c/p\u003e\u003cp data-pid=\"uBJfEEPS\"\u003e其次，在造轮子的过程中，可以想办法把它造得更好看一点，这是一个创造的过程，也令人心旷神怡。\u003c/p\u003e\u003cp data-pid=\"ii-MCSob\"\u003e于是，\u003ca href=\"https://link.zhihu.com/?target=https%3A//github.com/codemilestones/TinyCodeRAG\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003eTinyCodeRAG\u003c/a\u003e诞生了！它带来四大核心升级：\u003cbr/\u003e✅ 代码智能分块：专门解析代码数据结构，构建精准向量集\u003cbr/\u003e✅ 开箱即用：提供测试API key（用完我会定期续费）\u003cbr/\u003e✅ 模块化测试：每个组件都有独立测试用例\u003cbr/\u003e✅ 对话体验优化：完整支持多轮上下文对话  \u003c/p\u003e\u003cp data-pid=\"2-yvShzp\"\u003e话不多说，让我们一起动起来！\u003c/p\u003e\u003ch2\u003e0. 项目文件速览  \u003c/h2\u003e\u003cp data-pid=\"6k0-bLz8\"\u003e先快速过一遍项目结构（完整代码已开源）：\u003cbr/\u003e(\u003ca href=\"https://link.zhihu.com/?target=https%3A//github.com/codemilestones/TinyCodeRAG\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003egithub.com/codemileston\u003c/span\u003e\u003cspan class=\"invisible\"\u003ees/TinyCodeRAG\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e)\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003eTinyCodeRAG\n├── RAG\n│   ├── embeddings.py       # 向量化功能封装\n│   ├── chunker_text.py     # 通用文本分割器\n│   ├── chunker_code.py     # 专用代码分割器   关键创新点！\n│   ├── vector_base.py      # 轻量向量数据库\n│   ├── llm.py              # LLM接口封装\n│   ├── test_*.py           # 各模块测试脚本（共4个）\n│   ├── tiny_code_rag.py    # RAG系统整合入口\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"YkXbNT3i\"\u003e下面分别按照，向量化、文本和代码的拆分、向量库的实现、LLM的封装、TinyCodeRAG的封装应用进行介绍。每个模块均有对应的测试文件，方便大家进行理解。\u003c/p\u003e\u003ch2\u003e1.向量化引擎  \u003c/h2\u003e\u003cp data-pid=\"yOvUpNHs\"\u003e我们首先来实现RAG系统的核心基础：向量化处理。在 \u003ccode\u003eembeddings.py\u003c/code\u003e 文件中，我们定义了一个专门的类，主要负责两个关键功能：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"tFarVJjs\"\u003e\u003cb\u003e\u003ccode\u003eget_embeddings\u003c/code\u003e\u003c/b\u003e：将文本（或代码片段）转化为对应的向量表示。\u003c/li\u003e\u003cli data-pid=\"IDdk2lUL\"\u003e\u003cb\u003e\u003ccode\u003ecosine_similarity\u003c/code\u003e\u003c/b\u003e：计算两个向量之间的余弦相似度得分。\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"_mWfBgQH\"\u003e\u003cb\u003e向量生成引擎：OpenAI\u003c/b\u003e 我们选择了OpenAI的 \u003ccode\u003etext-embedding-3-small\u003c/code\u003e 模型来驱动向量生成。这个模型非常灵活，能够将\u003cb\u003e任意长度\u003c/b\u003e的输入文本（哪怕超级长），都高效地转换成一个固定长度的\u003cb\u003e1536维向量\u003c/b\u003e。这为后续的相似度计算奠定了坚实基础。\u003c/p\u003e\u003cp data-pid=\"16faUphi\"\u003e\u003cb\u003e验证：不仅仅是转换，更要看效果\u003c/b\u003e 为了确保这套向量化逻辑真正奏效，我们设计了测试用例，重点验证两个能力：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"OVojnGDW\"\u003e\u003cb\u003e文本长度适应性\u003c/b\u003e：无论输入文本是短是长，都能正确生成1536维向量。\u003c/li\u003e\u003cli data-pid=\"9RSwKQ4f\"\u003e\u003cb\u003e相似度判别有效性\u003c/b\u003e：系统是否能准确区分不同文本之间的相似程度？我们用四段关键文本进行了检验：\u003c/li\u003e\u003c/ul\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e# 对照文本\n    test_text_1 = \u0026#34;Hello, world! This is a test.\u0026#34;\n\n    # 与test_text_1 高度相关\n    test_text_2 = \u0026#34;Hello, world! This is a embedding test.\u0026#34;\n\n    # 与test_text_1 主题不同\n    test_text_3 = \u0026#34;I want to study how to use the embedding model.\u0026#34;     \n\n    # 超长文本测试\n    test_text_long = \u0026#34;... repeat long text ...\u0026#34; * 100\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"1Vk3SpvW\"\u003e测试结果符合预期：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"1J0z095C\"\u003e\u003ccode\u003etest_text_1\u003c/code\u003e 与 \u003ccode\u003etest_text_2\u003c/code\u003e 高度相关 =\u0026gt; \u003cb\u003e相似度 ≈ 0.8\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"Qu8a0_I9\"\u003e\u003ccode\u003etest_text_1\u003c/code\u003e 与 \u003ccode\u003etest_text_3\u003c/code\u003e 主题不同 =\u0026gt; \u003cb\u003e相似度 ≈ 0.1\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"NbVTM3lt\"\u003e\u003ccode\u003etest_text_1\u003c/code\u003e 与 \u003ccode\u003etest_text_long\u003c/code\u003e 也差异显著 =\u0026gt; \u003cb\u003e相似度 ≈ 0.1\u003c/b\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"gq2aXVKt\"\u003e这验证了我们的向量化和相似度计算在识别语义关联性方面是可靠和有效的。\u003c/p\u003e\u003ch2\u003e2. 文本分割模块 ✂️\u003c/h2\u003e\u003cp data-pid=\"y-5slsuo\"\u003e在构建RAG（检索增强生成）系统时，\u003cb\u003e分块\u003c/b\u003e（Chunking）是确保系统性能的关键环节，其核心在于将文本分割为长度适中且语义完整的片段。\u003c/p\u003e\u003cp data-pid=\"mMjFieWF\"\u003e为满足多格式文本处理需求，本项目实现了基于文件的文本分块模块（\u003ccode\u003echunker_text.py\u003c/code\u003e）。该模块继承自TinyRAG项目，支持解析并分块PDF、Markdown及TXT三种常见格式的文档内容。调用示例如下：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e# 读取指定路径下的文档，分块最大长度600，相邻块重叠150个字符\ndocs = ReadFiles(\u0026#39;~/workspace/tiny-universe\u0026#39;).get_content(max_token_len=600, cover_content=150)\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"F9KlfzD8\"\u003e进一步地，为适配代码库的特殊结构，我们新增了\u003cb\u003e专用代码分割器\u003c/b\u003e（\u003ccode\u003echunker_code.py\u003c/code\u003e）。与通用文本分块不同，该模块专门优化了代码处理逻辑：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"cDATEr5A\"\u003e\u003cb\u003e函数完整性保留\u003c/b\u003e：优先将同一函数代码保持在同一块中\u003c/li\u003e\u003cli data-pid=\"YRjv0Jpf\"\u003e\u003cb\u003e智能文件过滤\u003c/b\u003e：根据后缀名自动识别并处理源代码文件\u003c/li\u003e\u003cli data-pid=\"ckP8R-DF\"\u003e\u003cb\u003e目录级处理\u003c/b\u003e：支持直接输入文件夹路径进行批处理\u003c/li\u003e\u003c/ol\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e# 拆分指定目录下的源代码，保留150字符的块间重叠\ncode_docs = split_to_segment(\u0026#34;~/workspace/tiny-universe\u0026#34;, cover_content=150)\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"vGAoPsVi\"\u003e\u003cb\u003e参数说明\u003c/b\u003e：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"O7ZorNlD\"\u003e\u003ccode\u003ecover_content\u003c/code\u003e：定义相邻块之间的重叠字符数，增强上下文的语义连贯性（实际应用中可设置为0）\u003c/li\u003e\u003cli data-pid=\"pEUBvnHK\"\u003e路径兼容性：支持Mac系统的波浪号\u003ccode\u003e~\u003c/code\u003e路径，Windows用户需替换为绝对路径\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"QMtVter-\"\u003e通过\u003ccode\u003etest_chunker.py\u003c/code\u003e对\u003ccode\u003etiny-universe\u003c/code\u003e项目进行分块测试。可以查看分块后的文本内容。\u003c/p\u003e\u003ch2\u003e3. 向量数据库模块  ️\u003c/h2\u003e\u003cp data-pid=\"TrHJ4-ZT\"\u003e对于向量数据库，现在有非常多的选择，比如milvus、Pinecone、Weaviate等。甚至ES也支持向量检索。\u003c/p\u003e\u003cp data-pid=\"X5FP8mnC\"\u003e虽然当前向量数据库选择丰富，但完整部署方案存在较高运维成本，且不利于理解RAG系统的核心运作逻辑。为此我们基于TinyRAG项目实现了轻量级向量存储模块。\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003eclass VectorStore:\n    # 初始化文本存储容器\n    def __init__(self, document: List[str] = [\u0026#39;\u0026#39;]) -\u0026gt; None:  \n\n    # 调用嵌入模型将文本转化为向量（注意消耗token）\n    def get_vector(self, EmbeddingModel: BaseEmbeddings) -\u0026gt; List[List[float]]:  \n\n    # 向量数据持久化存储\n    def persist(self, path: str = \u0026#39;storage\u0026#39;):  \n\n    # 从存储路径加载预处理向量\n    def load_vector(self, path: str = \u0026#39;storage\u0026#39;) -\u0026gt; bool:  \n\n    # 计算两个向量的相似度\n    def get_similarity(self, vector1: List[float], vector2: List[float]) -\u0026gt; float:  \n\n    # 语义检索：输入查询文本，返回最相关的k个结果\n    def query(self, query: str, EmbeddingModel: BaseEmbeddings, k: int = 1) -\u0026gt; List[str]:\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"tC33PhbV\"\u003e通过load_vector()重用预存向量数据避免重复计算，显著降低token消耗。query()函数则封装了从文本编码到相似度匹配的全流程。\u003c/p\u003e\u003cp data-pid=\"86dkTiDZ\"\u003e如\u003ccode\u003etest_vector_base.py\u003c/code\u003e的示例所示，只需三步即可完成业务整合：初始化文档容器→加载/生成向量→执行语义查询：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003evector_store = VectorStore(document=doc_contents)\n\n    # 优先加载已有向量数据，不存在时实时生成\n    if not vector_store.load_vector():\n        vector_store.get_vector(OpenAIEmbedding())\n        vector_store.persist()\n\n    # 执行语义检索并打印结果\n    for doc in vector_store.query(\u0026#34;RAG 的组成部分是那些?\u0026#34;, OpenAIEmbedding(), 3):\n        print(doc)\n        print(\u0026#34;-\u0026#34;*100)\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2\u003e4. 大模型的封装  \u003c/h2\u003e\u003cp data-pid=\"rUdHXGaJ\"\u003e我们基于 OpenAI API 封装了一套简洁的 LLM 调用模块（位于 \u003ccode\u003ellm.py\u003c/code\u003e 中）。为了让大家轻松上手测试，项目里默认集成了一个\u003cb\u003e免费的测试密钥\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"yUN0E7qC\"\u003e考虑到成本限制（token消耗），目前限定使用 \u003ccode\u003eDoubao-1.5-lite-32k\u003c/code\u003e 模型。同时想聊聊 RAG 系统的一个关键点：\u003cb\u003e模型的规模不是越大越好\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"IlAUUwZC\"\u003e实际上，模型参数的选择更应该取决于你的\u003cb\u003e具体需求复杂度\u003c/b\u003e。如果你的逻辑设计本身并不复杂，使用大模型反而可能引入更多不确定性——小模型有时反而更稳。\u003c/p\u003e\u003ch2\u003e5. TinyCodeRAG系统整合  \u003c/h2\u003e\u003cp data-pid=\"ONumQtvl\"\u003e在\u003ccode\u003etiny_code_rag.py\u003c/code\u003e文件中，我们封装了TinyCodeRAG的调用逻辑，直接实现了RAG系统的核心功能。来看一下具体怎么玩转它吧：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003eif __name__ == \u0026#34;__main__\u0026#34;:\n    ## 1. 准备代码语料和文本语料\n    code_docs = split_to_segmenmt(\u0026#34;~/workspace/tiny-universe\u0026#34;, cover_content=50)\n    text_docs = ReadFiles(\u0026#39;~/workspace/tiny-universe\u0026#39;).get_content(max_token_len=600, cover_content=150)\n\n    # 将代码语料和文本语料合并\n    doc_contents = [doc.content for doc in code_docs] + text_docs\n\n    vector_store = VectorStore(document=doc_contents)\n\n    # 向量化并做持久化\n    if not vector_store.load_vector():\n        vector_store.get_vector(OpenAIEmbedding())\n        vector_store.persist()\n\n    # 2. 获取大模型\n    model = DoubaoLiteModel()\n\n    # 3. 写入用户输入，待大模型输出后，将其加入历史数据，并不断循环。\n    history = []\n    while True:\n        user_input = input(\u0026#34;请输入问题: \u0026#34;)\n        contents = vector_store.query(user_input, OpenAIEmbedding(), 3)\n        response = model.chat(user_input, history, \u0026#34;\\n\u0026#34;.join(contents))\n        print(\u0026#34;\\n\u0026#34;)\n        history.append({\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: user_input})\n        history.append({\u0026#39;role\u0026#39;: \u0026#39;assistant\u0026#39;, \u0026#39;content\u0026#39;: response})\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"hQCIM3VP\"\u003e当你准备好RAG的语料数据库后，该文件可以直接运行，并进行多轮对话。每轮对话都会包含历史数据。\u003c/p\u003e\u003ch2\u003e6. 总结\u003c/h2\u003e\u003cp data-pid=\"B9yXADrF\"\u003e本项目主要实现了RAG系统的核心逻辑，包括向量化、文本和代码的拆分、向量库的实现、LLM的封装、TinyCodeRAG的封装应用。\u003c/p\u003e\u003cp data-pid=\"qHKV1c0Q\"\u003e通过本项目，我们完整实现了：\u003cbr/\u003e  代码敏感型知识库构建\u003cbr/\u003e  检索-生成闭环系统\u003cbr/\u003e  可扩展的多轮对话框架  \u003c/p\u003e\u003cp data-pid=\"iwwgbaKz\"\u003e立即体验： \u003c/p\u003e\u003cp data-pid=\"-P2BpTiC\"\u003e\u003ca href=\"https://link.zhihu.com/?target=https%3A//github.com/codemilestones/TinyCodeRAG\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003eTinyCodeRAG\u003c/a\u003e\u003c/p\u003e\u003cp data-pid=\"ZKamtNL1\"\u003e✨ 欢迎Star/Fork/Issue三连！你的反馈是我持续优化的动力~\u003c/p\u003e\u003cp\u003e\u003c/p\u003e","is_labeled":false,"visited_count":83,"favorite_count":8,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1920608399860699695}","attached_info":"CugFCMuQ6NOAqcv3owEQBxoJMjU5NDYyNDcyILbI5cIGKAQwAEB4SiMKGFRTX1NPVVJDRV9XQVJNX1VQX0JPT1NUMhIBMBgAIAA6AEovCiRUU19TT1VSQ0VfV0FSTVVQX1RXT1RPV0VSX0VYUFYyX1RFWFQSATAYACAAOgBiIDZhNWYzZmQ0OWI2NzQwOGU3MzM3ZmZlOTkzODdlODE2chMxOTIwNjA4Mzk5ODYwNjk5Njk1qgEJcmVjb21tZW5kwgEgZjc3NzJiODI1MTg4OTNiZjlkYjExNGYxOTRiMWM5YTDyAQoIDBIGTm9ybWFs8gEoCAoSJDM3ZmZmZTEzLTIyODktNGQ1OS04M2NkLTg3MDMzNWE2MzgyOPIBBggLEgIyMYICAIgCpZHazfoykgIgZjc3NzJiODI1MTg4OTNiZjlkYjExNGYxOTRiMWM5YTCaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIYUGVyaW9kSW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxl2gIYVFNfU09VUkNFX1dBUk1fVVBfQk9PU1Qy6AID+gILTk9STUFMX0ZMT1eKAyAwY2Y0ZmFlOWVjNTE0MjNhODY5ZTU0OWVlYzYxMDRjYZoDDQoCdjIQABoFb3RoZXKoA1PYAwDqAy5jb250ZW50V2FybXVwVHdvVG93ZXJUdnBUZXh0Qm9vc3RFeHBWMlJlY2FsbGVy+gMfEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERYAEAIgEAJIEBk5vcm1hbJoEATOgBACoBACwBAC6BAJhacIEAzQwMMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAgKRCkj+BBQAAAAAAAAAAiQWPq46u84XSP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AUVkAYAoAZ5qAYBkgIuCgkyNTk0NjI0NzISEzE5MjA2MDgzOTk4NjA2OTk2OTUYByIKSU1BR0VfVEVYVA==","action_card":false},{"id":"121_1750899001.661","type":"feed","offset":121,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899001,"updated_time":1750899001,"target":{"id":"54820545132","type":"answer","url":"https://api.zhihu.com/answers/54820545132","author":{"id":"1645d589ca8e6c209db1ac35d02f1c6d","url":"https://api.zhihu.com/people/1645d589ca8e6c209db1ac35d02f1c6d","user_type":"people","url_token":"68-80-70-80","name":"清风明月","headline":"","avatar_url":"https://pic1.zhimg.com/50/v2-502719a1f8c4d3c086b71b630df35792_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":8561,"is_following":false,"is_followed":false},"created_time":1734098255,"updated_time":1734271420,"voteup_count":1392,"thanks_count":82,"comment_count":93,"is_copyable":false,"question":{"id":"5194734346","type":"question","url":"https://api.zhihu.com/questions/5194734346","author":{"id":"26ea252e8fce0a7d98897b9958f9adee","url":"https://api.zhihu.com/people/26ea252e8fce0a7d98897b9958f9adee","user_type":"people","url_token":"january-2-27","name":"早睡早起","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-cdf59e6e0fd23e7b564b00360dd4b81d_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":9,"is_following":false,"is_followed":false},"title":"上班四年，突然意识到打工没有出路，如何破局？","created":1732609324,"answer_count":0,"follower_count":0,"comment_count":31,"bound_topic_ids":[2604292,3082949],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"1、准备一部手机一张电话卡，分别注册某音、某手、某频号。用美图秀秀制作一个纯色图片，写上案例分享或法律咨询作为头像，昵称和头像一致，账号资料写法律从业者，擅长XX类案件等。 2、在西瓜视频以欠薪、执行、老赖等关键词搜索，筛选出半年内互动数据几百上千的视频，复制链接打开某信，搜索去水印，随便选一个免费的X程序，粘贴链接下载。 3、打开剪映，把下载的视频导入，掐头去尾、放大并裁剪掉标题、字幕。在视频场景切换…","excerpt_new":"1、准备一部手机一张电话卡，分别注册某音、某手、某频号。用美图秀秀制作一个纯色图片，写上案例分享或法律咨询作为头像，昵称和头像一致，账号资料写法律从业者，擅长XX类案件等。 2、在西瓜视频以欠薪、执行、老赖等关键词搜索，筛选出半年内互动数据几百上千的视频，复制链接打开某信，搜索去水印，随便选一个免费的X程序，粘贴链接下载。 3、打开剪映，把下载的视频导入，掐头去尾、放大并裁剪掉标题、字幕。在视频场景切换…","preview_type":"default","preview_text":"","reshipment_settings":"disallowed","content":"\u003cp data-pid=\"ZbRvB7RI\"\u003e1、准备一部手机一张电话卡，分别注册某音、某手、某频号。用美图秀秀制作一个纯色图片，写上案例分享或法律咨询作为头像，昵称和头像一致，账号资料写法律从业者，擅长XX类案件等。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"Xksyt42w\"\u003e2、在西瓜视频以欠薪、执行、老赖等关键词搜索，筛选出半年内互动数据几百上千的视频，复制链接打开某信，搜索去水印，随便选一个免费的X程序，粘贴链接下载。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"VC45gzOl\"\u003e3、打开剪映，把下载的视频导入，掐头去尾、放大并裁剪掉标题、字幕。在视频场景切换点切成多个片段，在不影响观看的基础上对部分片段进行镜像处理，然后加贴图、加关键帧、加画中画等。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"HQClQ6DV\"\u003e4、调整视频整体比例为16:9（竖版），背景调成灰色，重新添加醒目标题，识别字幕。标题和字幕分别放在视频上下方的灰色背景上，顶部和底部各预留1/5空白避免遮挡内容。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"e9AIq8Ia\"\u003e5、保持整体视频长度在3-5分钟，故事情节完整。选择视频中一个比较吸引人的帧作为封面，原画质导出。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"uMRzCnEJ\"\u003e6、分别上传视频到注册好的三个平台，取个吸引人的标题，不会取就在西瓜原视频标题基础上修改，加上与原视频一样的标签发布。发布时间最好在上午10-11点，或下午15-16点，或晚上8点以后。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"ReogMtX0\"\u003e7、开始不熟练，保证一天做一条视频即可，熟练后可以每天发布3-5条。如果遇到违规，不用申诉，直接删除。记住违规的点，下次选择素材或者剪辑的时候注意改正。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"2QceEAEg\"\u003e8、如果遇到私X或留言咨询法律问题，可在平台内简单沟通建立信任，然后让对方留联。此处要特别注意，新手不清楚留联的诀窍，容易违规封号。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"afIytAjn\"\u003e9、包装一个专用的W某X，用于承接流量，头像用真人头像，PYQ发布一些法律相关的知识或者案例，增加专业性和信任感。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"trS9WHf2\"\u003e10、做好咨询服务定价，初期不宜太贵，99元起最佳，可设置不同价格梯度的服务，具体的自己根据律师行业的行情酌减。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"E9Q83J7H\"\u003e11、流程跑通闭环后，可购买手机复制账号，矩阵操作，也可转出镜IP路线。注意服务质量，流量起来以后应该可以筛选出高价值客户。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"ybq2-Nm7\"\u003e12、以上为【法律咨询自媒体】项目的拆解过程，做好了可以轻松超越主业收入。此项目稍作变化，还适用于教育、心理咨询等行业。\u003c/p\u003e\u003chr/\u003e\u003cp data-pid=\"qdN8UyTE\"\u003e该项目来源于我做的第一个短视频项目【快手法律书单号】——剪辑社会热点事件，带货《民法典》赚取佣金。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"k8iiO-gK\"\u003e那是我第一次知识付费，在一位大学生处购买了法律书单号的指导视频。视频全长19分钟，包含素材搜集、去水印下载、剪辑去重、快手开店、挂车带货等全流程。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"GqOXfQe9\"\u003e这个项目我从7月中旬做到8月中旬，一个月时间赚了2300块佣金，钱虽然不多，但是却帮我打开了短视频行业的大门。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"SHRFf8Sr\"\u003e在做书单号的过程中，经常会有粉丝咨询我法律问题，印象最深的有两个。一个是东北大哥，开了家养猪场，被一家房地产公司逼拆，向我咨询打官司的成功率。另一个是位农民工，咨询欠薪问题。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"dhtvAeD3\"\u003e由于我不是法律专业出身，这些问题我一个都回答不了。后来也找过一些律师合作，但是律师都是狮子大开口，而且非常傲慢，所以最后没有把这个业务延伸下去。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"fab7xkDC\"\u003e正好刷到这个问题，题主本身就是律师，非常适合这个项目，自己就可以做闭环。所以把流程分享出来，希望有需求的朋友可以借鉴。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"bs1yrsQM\"\u003e以上，欢迎三连。\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":203113,"favorite_count":3538,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 54820545132}","attached_info":"Cs4GCMuQ6NOAqcv3owEQBBoJNzA0MDgwMzUxIM/68LoGKPAKMF1AeUpICh9UU19TT1VSQ0VfWlJFQ0FMTF9JVEVNQ0ZfVVBWT1RFEh9kb2NfdHlwZTogQW5zd2VyCmlkOiA2ODI3ODU2MDAKGAAgADoAWgkxMTIwMTU1MDViIDZhNWYzZmQ0OWI2NzQwOGU3MzM3ZmZlOTkzODdlODE2cgs1NDgyMDU0NTEzMooBCjUxOTQ3MzQzNDaqAQlyZWNvbW1lbmTCASAxNjQ1ZDU4OWNhOGU2YzIwOWRiMWFjMzVkMDJmMWM2ZPIBCggMEgZOb3JtYWzyASgIChIkM2E1MzNlZmMtNzNiYy00NzA1LTk1MmEtNDNkYmRlY2MzMWVi8gEGCAsSAjIxggIAiAKlkdrN+jKSAiAxNjQ1ZDU4OWNhOGU2YzIwOWRiMWFjMzVkMDJmMWM2ZJoCAMoCFlNob3JJbnRlcmVzdFdlaWdodFJ1bGXKAhZBY3Rpb25TaG9ySW50ZXJlc3RSdWxlygIbSW50ZXJhY3Rpb25TaG9ySW50ZXJlc3RSdWxlygIWUmV2aXNpdFZhbHVlV2VpZ2h0UnVsZcoCGFBlcmlvZEludGVyZXN0V2VpZ2h0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZcoCFENvbnRlbnRBZ2VXZWlnaHRSdWxl2gIfVFNfU09VUkNFX1pSRUNBTExfSVRFTUNGX1VQVk9URegCAvoCC05PUk1BTF9GTE9XigMgMGNmNGZhZTllYzUxNDIzYTg2OWU1NDllZWM2MTA0Y2GaAw0KAnYyEAAaBW90aGVyqAPpsgzYAwDqAxt0ZXh0QWxsU2l0ZUhxQWN0aW9uSXRlbUNGVjL6Ax8SDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFgAQAiAQAkgQGTm9ybWFsmgQBMqAEAKgEALAEALoEBm1hbnVhbMIEAzE2MMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAgEf8wT+BBQAAAAAAAAAAiQWPq46u84XSP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AUVkAYAoAZ6qAYDkgImCgk3MDQwODAzNTESCzU0ODIwNTQ1MTMyGAQiCklNQUdFX1RFWFQ=","action_card":false},{"id":"122_1750899001.490","type":"feed","offset":122,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899001,"updated_time":1750899001,"target":{"id":"3197150635","type":"answer","url":"https://api.zhihu.com/answers/3197150635","author":{"id":"5ecc95409be25055f1e75500c0b787c4","url":"https://api.zhihu.com/people/5ecc95409be25055f1e75500c0b787c4","user_type":"people","url_token":"hua-han-lu-11","name":"真理往事","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-26daec67fd65f68595b27601f1f18af4_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":5571,"is_following":false,"is_followed":false},"created_time":1693838918,"updated_time":1717061524,"voteup_count":3844,"thanks_count":227,"comment_count":433,"is_copyable":false,"question":{"id":"604202999","type":"question","url":"https://api.zhihu.com/questions/604202999","author":{"id":"e0ced20991ef07d82074929f4f06cfcd","url":"https://api.zhihu.com/people/e0ced20991ef07d82074929f4f06cfcd","user_type":"people","url_token":"wei-xin-yong-hu-yi-mo-fan-hua-123","name":"微信用户一抹繁华123","headline":"","avatar_url":"https://pic1.zhimg.com/50/v2-6c272edcbe9f6816b46d77ab24ba20c4_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":570,"is_following":false,"is_followed":false},"title":"托亲戚办一件小事，花了1000块请客吃饭，之后让我出钱，该怎么办?","created":1685592737,"answer_count":0,"follower_count":0,"comment_count":36,"bound_topic_ids":[41509,182451,389415],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"《史记》当中有一个老故事不是把这种事讲明白了吗。 范蠡一家离开越国，先在齐国住了一段时间，后又到了陶地。他认为陶地道路通畅，做生意可以发财致富，于是自称陶朱公，与自己的儿子一齐做了商人，没过多久就积累了丰厚的家资。 在陶地，朱公生了小儿子。小儿子长大后，陶朱公的二儿子因为杀人被楚国拘捕了。自古以来，凡是家有千金的犯人不会在闹市中被处死，因此，朱公决定派小儿子去探望二儿子，并让他带一千镒黄金。就在小…","excerpt_new":"《史记》当中有一个老故事不是把这种事讲明白了吗。 范蠡一家离开越国，先在齐国住了一段时间，后又到了陶地。他认为陶地道路通畅，做生意可以发财致富，于是自称陶朱公，与自己的儿子一齐做了商人，没过多久就积累了丰厚的家资。 在陶地，朱公生了小儿子。小儿子长大后，陶朱公的二儿子因为杀人被楚国拘捕了。自古以来，凡是家有千金的犯人不会在闹市中被处死，因此，朱公决定派小儿子去探望二儿子，并让他带一千镒黄金。就在小…","preview_type":"default","preview_text":"","reshipment_settings":"disallowed","content":"\u003cp data-pid=\"SahnSzOL\"\u003e《史记》当中有一个老故事不是把这种事讲明白了吗。\u003c/p\u003e\u003cp data-pid=\"CHiqdY3Q\"\u003e范蠡一家离开越国，先在齐国住了一段时间，后又到了陶地。他认为陶地道路通畅，做生意可以发财致富，于是自称陶朱公，与自己的儿子一齐做了商人，没过多久就积累了丰厚的家资。\u003c/p\u003e\u003cp data-pid=\"3esswk9R\"\u003e　　在陶地，朱公生了小儿子。小儿子长大后，陶朱公的二儿子因为杀人被楚国拘捕了。自古以来，凡是家有千金的犯人不会在闹市中被处死，因此，朱公决定派小儿子去探望二儿子，并让他带一千镒黄金。就在小儿子即将出发时，大儿子说：“我是长子，现在弟弟犯了罪，父亲不派我去，却派小弟，说明我是不肖之子。”说完就要自杀。其母见状就对朱公说：“现在派小三子去，未必能救老二的命，但眼看老大说自杀就自杀，该如何是好？”不得已，朱公只好派大儿子去，并写了一封信要他送给旧日的好友庄生，同时交代说：“你到楚国后，把金子送到庄生家，一切听从他的吩咐，千万不要与他发生争执。”\u003c/p\u003e\u003cp data-pid=\"LAHUd3YH\"\u003e　　老大到了楚国，依照父亲的嘱咐如数向庄生进献了黄金。庄生说：“你现在赶快离开，千万不要留在这里，即使在你弟弟释放后，也不要问原因。”老大口中答应，但并没有真的离开，而是偷偷留在了楚国，并用自己另外私带的黄金贿赂楚国主事的达官贵人。\u003c/p\u003e\u003cp data-pid=\"JsTSx1-u\"\u003e　　庄生由于廉洁正直而闻名于楚国，从楚王至下，对他都很尊重。黄金送来后，他对妻子说：“这是陶朱公的钱，以后全部还给他，千万不要动用。”\u003c/p\u003e\u003cp data-pid=\"RKQE3Fth\"\u003e　　庄生找了一个机会入宫见楚王，以天象有变将对楚国有危害为由劝楚王实行德政，楚王于是准备实行大赦。接受了贿赂的楚国达官贵人把这一消息告诉了老大。他寻思，既然实行大赦，弟弟自然可以释放了，那一千镒黄金不就等于白白给庄生了吗？于是他又返回见庄生。庄生一见他惊奇地问：“你没有离开吗？”长子说：“没有，当初我为弟弟的事情而来，现在楚国要实行大赦了，我的弟弟自然可以得到释放，所以特来向您告辞。”庄生听出了话里的意思就说：“你自己到房间里取黄金吧。”老大暗自庆幸黄金失而复得。\u003c/p\u003e\u003cp data-pid=\"BmzvfEsH\"\u003e　　庄生因为遭到长子的愚弄而深感羞愧，他又入宫会见楚王，说：“现在，外面很多人都在议论陶地富翁朱公的儿子杀人后被关在楚国，他家派人用金钱贿赂君王左右的人，因此并不是君王体恤楚国人而实行大赦，而是因为朱公儿子才大赦的。”楚王听罢大怒，于是他命令先杀掉朱公的儿子，之后才下达大赦的诏令。\u003c/p\u003e\u003cp data-pid=\"65BFtLHO\"\u003e　　长子只好带着弟弟的尸体回家了。母亲和乡邻们都十分悲痛，只有朱公笑着说：“我就知道老大救不了老二，不是他不爱自己的弟弟，只是他从小就与我生活在一起，经受过各种苦难，知道生活的艰难，所以把钱财看得很重。而老三一生下来就在蜜罐子里，哪里知道钱财来得不易，弃之也毫不吝惜，本来我是打算让他去的。老大不能弃财，所以最终害了自己的弟弟，这很合乎事理的，不要悲痛了。我日夜盼的也就是老二的尸首能回来。”\u003c/p\u003e\u003cp data-pid=\"R9JlAtbF\"\u003e史记·越王勾践世家\u003c/p\u003e\u003cp data-pid=\"VZB9j_UH\"\u003e朱公居陶，生少子。少子及壮，而朱公中男杀人，囚于楚。朱公曰：“杀人而死，职也。然吾闻千金之子不死于市。”告其少子往视之。乃装黄金千溢，置褐器中，载以一牛车。且遣其少子，朱公长男固请欲行，朱公不听。长男曰：“家有长子曰家督，今弟有罪，大人不遣，乃遣少弟，是吾不肖。”欲自杀。其母为言曰：“今遣少子，未必能生中子也，而先空亡长男，柰何？”朱公不得已而遣长子，为一封书遗故所善庄生。曰：“至则进千金于庄生所，听其所为，慎无与争事。”长男既行，亦自私赍数百金。 [1] \u003c/p\u003e\u003cp data-pid=\"5QOYNBpo\"\u003e至楚，庄生家负郭，披藜藋到门，居甚贫。然长男发书进千金，如其父言。庄生曰：“可疾去矣，慎毋留！即弟出，勿问所以然。”长男既去，不过庄生而私留，以其私赍献遗楚国贵人用事者。\u003c/p\u003e\u003cp data-pid=\"_5xI8oK9\"\u003e庄生虽居穷阎，然以廉直闻于国，自楚王以下皆师尊之。及朱公进金，非有意受也，欲以成事后复归之以为信耳。故金至，谓其妇曰：“此朱公之金。有如病不宿诫，后复归，勿动。”而朱公长男不知其意，以为殊无短长也。\u003c/p\u003e\u003cp data-pid=\"UyRiJlcT\"\u003e庄生闲时入见楚王，言“某星宿某，此则害于楚”。楚王素信庄生，曰：“今为奈何？”庄生曰：“独以德为可以除之。”楚王曰：“生休矣，寡人将行之。”王乃使使者封三钱之府。楚贵人惊告朱公长男曰：“王且赦。”曰：“何以也？”曰：“每王且赦，常封三钱之府。昨暮王使使封之。”朱公长男以为赦，弟固当出也，重千金虚弃庄生，无所为也，乃复见庄生。庄生惊曰：“若不去邪？”长男曰：“固未也。初为事弟，弟今议自赦，故辞生去。”庄生知其意欲复得其金，曰：“若自入室取金。”长男即自入室取金持去，独自欢幸。 [2] \u003c/p\u003e\u003cp data-pid=\"w_icHSKx\"\u003e庄生羞为儿子所卖，乃入见楚王曰：“臣前言某星事，王言欲以修德报之。今臣出，道路皆言陶之富人朱公之子杀人囚楚，其家多持金钱赂王左右，故王非能恤楚国而赦，乃以朱公子故也。”楚王大怒曰：“寡人虽不德耳，奈何以朱公之子故而施惠乎！”令论杀朱公子，明日遂下赦令。朱公长男竟持其弟丧归。\u003c/p\u003e\u003cp data-pid=\"oL5q0zIi\"\u003e至，其母及邑人尽哀之，唯朱公独笑，曰：“吾固知必杀其弟也！彼非不爱其弟，顾有所不能忍者也。是少与我俱，见苦，为生难，故重弃财。至如少弟者，生而见我富，乘坚驱良逐狡兔，岂知财所从来，故轻弃之，非所惜吝。前日吾所为欲遣少子，固为其能弃财故也。而长者不能，故卒以杀其弟，事之理也，无足悲者。吾日夜固以望其丧之来也。” \u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":698029,"favorite_count":1859,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 3197150635}","attached_info":"CoUGCMuQ6NOAqcv3owEQBBoJNjExMzgxODI1IMbc16cGKIQeMLEDQHpKLwoGSXRlbUNGEh9kb2NfdHlwZTogQW5zd2VyCmlkOiA3MTU2MzE1NjIKGAAgADoAWgg5NjU0NzUzMmIgNmE1ZjNmZDQ5YjY3NDA4ZTczMzdmZmU5OTM4N2U4MTZyCjMxOTcxNTA2MzWKAQk2MDQyMDI5OTmqAQlyZWNvbW1lbmTCASA1ZWNjOTU0MDliZTI1MDU1ZjFlNzU1MDBjMGI3ODdjNPIBCggMEgZOb3JtYWzyASgIChIkM2RiZWZhN2ItMWJkMy00MjliLWE3MjItNjFjMDU4MzQxZWJl8gEGCAsSAjIxggIAiAKlkdrN+jKSAiA1ZWNjOTU0MDliZTI1MDU1ZjFlNzU1MDBjMGI3ODdjNJoCAMoCFlNob3JJbnRlcmVzdFdlaWdodFJ1bGXKAhZBY3Rpb25TaG9ySW50ZXJlc3RSdWxlygIbSW50ZXJhY3Rpb25TaG9ySW50ZXJlc3RSdWxlygIYUGVyaW9kSW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygIUQ29udGVudEFnZVdlaWdodFJ1bGXaAgZJdGVtQ0boAgL6AgtOT1JNQUxfRkxPV4oDIDBjZjRmYWU5ZWM1MTQyM2E4NjllNTQ5ZWVjNjEwNGNhmgMNCgJ2MhAAGgVvdGhlcqgDrc0q2AMA6gMfdGV4dEFsbFNpdGVNdkhpZ2hBY3Rpb25JdGVtQ0ZWMfoDHxIMVU5LTk9XTl9NT0RFIAAqDU5PX0lNQUdFX01PREWABACIBACSBAZOb3JtYWyaBAEyoAQAqAQAsAQAugQGbWFudWFswgQDMTYwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAABAA+W9P4EFAAAAAAAAAACJBY+rjq7zhdI/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBRWQBgCgBnuoBgCSAiUKCTYxMTM4MTgyNRIKMzE5NzE1MDYzNRgEIgpJTUFHRV9URVhU","action_card":false},{"id":"123_1750899001.206","type":"feed","offset":123,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899001,"updated_time":1750899001,"target":{"id":"3327057736","type":"answer","url":"https://api.zhihu.com/answers/3327057736","author":{"id":"1523336500d5599d74678f4655a1b0fd","url":"https://api.zhihu.com/people/1523336500d5599d74678f4655a1b0fd","user_type":"people","url_token":"ai-ting-qia-nong-de-alex","name":"顶格思维笔记","headline":"重塑你的三观，震撼你的灵魂","avatar_url":"https://picx.zhimg.com/50/v2-c170c62bb644ef156a54b890b3ca2bad_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":595,"is_following":false,"is_followed":false},"created_time":1702641520,"updated_time":1719926103,"voteup_count":5500,"thanks_count":801,"comment_count":626,"is_copyable":true,"question":{"id":"613282723","type":"question","url":"https://api.zhihu.com/questions/613282723","author":{"id":"ed29c09032812ab66a0a17a0ba30f8d4","url":"https://api.zhihu.com/people/ed29c09032812ab66a0a17a0ba30f8d4","user_type":"people","url_token":"81-54-3-1-10","name":"锦鲤","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-61bcb2cc999db8c1c287ef549ac31c29_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":0,"is_following":false,"is_followed":false},"title":"家境贫寒你会责怪父母吗？","created":1689928106,"answer_count":0,"follower_count":0,"comment_count":50,"bound_topic_ids":[9578,73796,122701,75370,181881],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"之前在外网上看到台湾学者陈志武说过一句话，感触颇深。 他说，穷人生孩子，本质上是一种经济投资行为，一针见血。 由于穷人本性贪婪，他们的要求是，低成本，高回报。 想想你小时候爸妈经常对你说过的话，是不是如此。 他们告诉你，学习要和成绩好的学生对比，吃穿上能吃饱穿暖就行了，不要和那些家庭好的孩子对比。 为什么他们会这么说呢？ 因为本质上要掩盖他们在这个社会上生存的无能，放弃在这个社会继续进取，给你扣上一定…","excerpt_new":"之前在外网上看到台湾学者陈志武说过一句话，感触颇深。 他说，穷人生孩子，本质上是一种经济投资行为，一针见血。 由于穷人本性贪婪，他们的要求是，低成本，高回报。 想想你小时候爸妈经常对你说过的话，是不是如此。 他们告诉你，学习要和成绩好的学生对比，吃穿上能吃饱穿暖就行了，不要和那些家庭好的孩子对比。 为什么他们会这么说呢？ 因为本质上要掩盖他们在这个社会上生存的无能，放弃在这个社会继续进取，给你扣上一定…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"kyrClw2z\"\u003e之前在外网上看到台湾学者陈志武说过一句话，感触颇深。\u003c/p\u003e\u003cp data-pid=\"63zeI-HD\"\u003e他说，穷人生孩子，本质上是一种经济投资行为，一针见血。\u003c/p\u003e\u003cp data-pid=\"MeL09v8B\"\u003e由于穷人本性贪婪，他们的要求是，低成本，高回报。\u003c/p\u003e\u003cp data-pid=\"kFiY9CC3\"\u003e想想你小时候爸妈经常对你说过的话，是不是如此。\u003c/p\u003e\u003cp data-pid=\"oHCTG4BM\"\u003e他们告诉你，学习要和成绩好的学生对比，吃穿上能吃饱穿暖就行了，不要和那些家庭好的孩子对比。\u003c/p\u003e\u003cp data-pid=\"Mvcpi96I\"\u003e为什么他们会这么说呢？\u003c/p\u003e\u003cp data-pid=\"iCFDlLoW\"\u003e因为本质上要掩盖他们在这个社会上生存的无能，放弃在这个社会继续进取，给你扣上一定大大的振兴家族帽子。\u003c/p\u003e\u003cp data-pid=\"pyWaCA-L\"\u003e吃穿和家庭差的孩子对比，他就不需要在你身上投入更多，尽可能减少本金。\u003c/p\u003e\u003cp data-pid=\"7ctLUO7L\"\u003e成绩和好学生比，他的回报就可能高很多，要是能考上名牌大学进体制内就更好了。\u003c/p\u003e\u003cp data-pid=\"zGqz1VHc\"\u003e最后为了保证回报稳定，再拿二十年的养育之恩这座大山压在你头上。\u003c/p\u003e\u003cp data-pid=\"KGk9YnNe\"\u003e等你每次想脱离他们的时候，想到这恩重如山的养育之恩，你内心深处就会涌出一股深深的愧疚感，然后以妥协告终。\u003c/p\u003e\u003cp data-pid=\"d8cFJdvy\"\u003e一旦你相信了孝道，中了父母亲情的毒，那么你这一辈子在他们面前都挺不直腰、投不起头，被他们的恩情绑架，玩弄于股掌之间。\u003c/p\u003e\u003cp data-pid=\"A-cHKr-3\"\u003e自然，从此以后，你的人生就不可能幸福，也无法接受更赚钱的方法，只能和他们一样老老实实打工，一辈子碌碌无为，继续贫穷，你的后代也会跟你一样贫穷，直到穷不过三代。\u003c/p\u003e\u003cp data-pid=\"xbel9clj\"\u003e穷人家的孩子，大概率也是穷人，这是个扎心的真相，很少有例外，是大自然的客观规律，不以人的意志为转移。\u003c/p\u003e\u003cp data-pid=\"EP8Xs0PN\"\u003e一方面是基因遗传问题，穷人继承了父母的劣质基因，你的努力不过就是重复性的操作，没有任何成长性的进步，你的努力怎么可能有效果。别人有富人基因，即使胡乱来玩玩都有名师指点，贵人带路，随便做点什么都能成事，你终尽一生的努力可能都赶不上人家的起跑线。\u003c/p\u003e\u003cp data-pid=\"iuqlawN_\"\u003e另一方面，从小生活的环境不好，身边有两个没眼界、自卑懦弱的粗人，他们就会把身上所有的坏习惯和旧思维传到你身上，把自己的想法强加在你头脑里，那么你自然跟他们一样平庸。\u003c/p\u003e\u003cp data-pid=\"Z2-SJWEB\"\u003e人在底层，接触到的信息非常有限，而父母早在你小时候就给你植入了一些垃圾文化，勤俭节约，不能攀比，人要知足常乐。都是穷人家的教育，再也没有不同的观点给你清洁清洁你的大脑了。\u003c/p\u003e\u003cp data-pid=\"3QLn4VTW\"\u003e甚至把吃亏和苦难当作理所当然，把父母对你的伤害合理化，活成了一个没有自我，不敢独立思考，只会听话的工具人。\u003c/p\u003e\u003cp data-pid=\"iNOepUEi\"\u003e那有没有出口呢？\u003c/p\u003e\u003cp data-pid=\"clsMKFEb\"\u003e肯定有的。换个信息源，多接触接触以前觉得“大逆不道”的信息。\u003c/p\u003e\u003cp data-pid=\"vcF5apTw\"\u003e我之前分享的每一个观点，都是对底层认知的推翻，如果你看了这些“毁三观”的话，觉得如沐春风，甚至看着特别爽，那么恭喜你，你就是有希望脱离出底层的一员。\u003c/p\u003e\u003cp data-pid=\"CeGXj0BX\"\u003e首先一点，就是离开父母。因为大多数人在三十岁之前过得不幸福，没有赚到钱，一定是因为你的父母造成的，他们给你传达错误的认知，坏习惯影响着你，如果你继续跟他们待在一起，你身上的毛病只会越来越多。\u003c/p\u003e\u003cp data-pid=\"XMVhJUWM\"\u003e人要学会独处，学会一个人生活，你和父母待在一起住，他们永远把你当成长不大的小孩，久而久之，你也真的是个长不大的巨婴了。\u003c/p\u003e\u003cp data-pid=\"7OF9wIzG\"\u003e很多人结婚之后，还把父母看得特别重，经常回家，把老婆看的跟陌生人一样，处处挑剔，我说你这是何必呢，那你当初跟人家结婚干嘛来着？好玩呢？\u003c/p\u003e\u003cp data-pid=\"qd3qsZ5N\"\u003e总之，任何时候，不要太把父母当回事，他们对你的态度基本是场投资，钱到位了，什么问题都解决了，有钱才他们才相信你是真的长大独立了，成熟了，打再多电话不如打笔钱，懂得都懂。\u003c/p\u003e\u003cp data-pid=\"-KWcG845\"\u003e另一个，从底层翻身，是一个人的事情，不要企图拉上朋友，也不要跟朋友说。\u003c/p\u003e\u003cp data-pid=\"30aJSA4K\"\u003e能做你的朋友，基本是穷人。\u003c/p\u003e\u003cp data-pid=\"KQ-Xcu1T\"\u003e穷人的认知里，父母是天，父母是自己的一切，做什么都要考虑下父母的意见，找个工作都要离家近，结果你跟他说，离开父母，人家能不跟你急嘛？\u003c/p\u003e\u003cp data-pid=\"jv5Nt6Lm\"\u003e成长路上，都是孤独的，都是不被理解的。\u003c/p\u003e\u003cp data-pid=\"r6VKb1YU\"\u003e你想想，之前大家都是毛毛虫，吃着菜叶爬来爬去挺好的，现在你想变蝴蝶了，怎么可能不记恨你。\u003c/p\u003e\u003cp data-pid=\"LtnLBArP\"\u003e凭什么你要变蝴蝶，是嫌弃我们这不好啦？万一你真变成了岂不是看不上我们，不行，说什么也要阻止你。\u003c/p\u003e\u003cp data-pid=\"8neCIlpd\"\u003e如果你已经取得了成果非要发好心，那么最后的结果一定是你被拉下水，摧毁你所有的努力成果。\u003c/p\u003e\u003cp data-pid=\"qynO78Ai\"\u003e真正要做的事情，对神明都不要说。\u003c/p\u003e\u003cp data-pid=\"v0Yzz31w\"\u003e任何事情，自己偷偷决定偷偷努力就好。\u003c/p\u003e\u003cp data-pid=\"6mSR7eFv\"\u003e成王败寇，这个世界都是对人不对事的。\u003c/p\u003e\u003cp data-pid=\"VB-Flsbh\"\u003e你混好了，他们自然能得到他们的鼓掌，他们也会说当初就没看错你，真心相信你。\u003c/p\u003e\u003cp data-pid=\"s5Xu4gi-\"\u003e你如果没有成果，就扯开嗓门告诉父母，告诉朋友，迎接你的只有无尽的教育和嘲笑。\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":382511,"favorite_count":6031,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 3327057736}","attached_info":"CqYGCMuQ6NOAqcv3owEQBBoJNjM0OTk4MjE4IPD+8KsGKPwqMPIEQHtKMAobVFNfU09VUkNFX0JBU0lDX0lORk9fUkVDQUxMEgEwGAAgADoKeyJyYXciOiIifVoIOTg1NjU0MzliIDZhNWYzZmQ0OWI2NzQwOGU3MzM3ZmZlOTkzODdlODE2cgozMzI3MDU3NzM2igEJNjEzMjgyNzIzqgEJcmVjb21tZW5kwgEgMTUyMzMzNjUwMGQ1NTk5ZDc0Njc4ZjQ2NTVhMWIwZmTyAQoIDBIGTm9ybWFs8gEoCAoSJGFiNjI1NGE4LTgzYzAtNGJlZC1hNzNmLTk3NWFiYzE1ZDc2OPIBBggLEgIyMYICAIgCpZHazfoykgIgMTUyMzMzNjUwMGQ1NTk5ZDc0Njc4ZjQ2NTVhMWIwZmSaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIWQWN0aW9uU2hvckludGVyZXN0UnVsZcoCG0ludGVyYWN0aW9uU2hvckludGVyZXN0UnVsZcoCFlJldmlzaXRWYWx1ZVdlaWdodFJ1bGXKAhhQZXJpb2RJbnRlcmVzdFdlaWdodFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXKAhRDb250ZW50QWdlV2VpZ2h0UnVsZdoCG1RTX1NPVVJDRV9CQVNJQ19JTkZPX1JFQ0FMTOgCA/oCC05PUk1BTF9GTE9XigMgMGNmNGZhZTllYzUxNDIzYTg2OWU1NDllZWM2MTA0Y2GaAw0KAnYyEAAaBW90aGVyqAOvrBfYAwDqAxFiYXNpY19pbmZvX3JlY2FsbPoDHxIMVU5LTk9XTl9NT0RFIAAqDU5PX0lNQUdFX01PREWABACIBACSBAZOb3JtYWyaBAEzoAQAqAQAsAQAugQGbWFudWFswgQDMTYwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAAAAy6C+P4EFAAAAAAAAAACJBY+rjq7zhdI/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBRWQBgCgBnyoBgCSAiUKCTYzNDk5ODIxOBIKMzMyNzA1NzczNhgEIgpJTUFHRV9URVhU","action_card":false},{"id":"124_1750899001.911","type":"feed","offset":124,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899001,"updated_time":1750899001,"target":{"id":"1921207217618657471","type":"answer","url":"https://api.zhihu.com/answers/1921207217618657471","author":{"id":"dc5a90fc805cf599eb18a15ce6580f72","url":"https://api.zhihu.com/people/dc5a90fc805cf599eb18a15ce6580f72","user_type":"people","url_token":"xiao-lu-guo-47","name":"旅游家卢果","headline":"始于人品  终于教养\n不关注不回私信 ","avatar_url":"https://pic1.zhimg.com/50/v2-1d4fab49cfc65cd9bd213c0d0d192b8a_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":558,"is_following":false,"is_followed":false},"created_time":1750831494,"updated_time":1750831494,"voteup_count":0,"thanks_count":0,"comment_count":9,"is_copyable":true,"question":{"id":"1912075901795039156","type":"question","url":"https://api.zhihu.com/questions/1912075901795039156","author":{"id":"a9a25b73cea389a2eaf8a3c98d09ef82","url":"https://api.zhihu.com/people/a9a25b73cea389a2eaf8a3c98d09ef82","user_type":"people","url_token":"19-41-64-84-59","name":"崮山客","headline":"养娃||打工||弄花||写文||读书||溜达","avatar_url":"https://picx.zhimg.com/50/v2-15ca67863cbdfd69c252229058208e6c_l.jpg?source=b6762063","is_org":false,"gender":1,"badge":[{"type":"identity_people","description":"教师资格证持证人"}],"followers_count":2129,"is_following":false,"is_followed":false},"title":"那些每天写知乎、按时打卡的人是怎么坚持下来的？","created":1748654419,"answer_count":0,"follower_count":0,"comment_count":4,"bound_topic_ids":[1352665,2063000],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"我有段时间真的坚持很好，而且那段时间自己都感觉自己文绉绉的，语出惊人，最近懒了，没坚持输出，口齿不伶俐了，有点矛盾，天天按时输出，打卡，表达，最后得到的并不多，相反，不输出时候，还有流量，只能把这个当成一个树洞，去吐槽，不敢发朋友圈的，往这里面写，也不错，就是发泄。","excerpt_new":"我有段时间真的坚持很好，而且那段时间自己都感觉自己文绉绉的，语出惊人，最近懒了，没坚持输出，口齿不伶俐了，有点矛盾，天天按时输出，打卡，表达，最后得到的并不多，相反，不输出时候，还有流量，只能把这个当成一个树洞，去吐槽，不敢发朋友圈的，往这里面写，也不错，就是发泄。","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"petXYCpS\"\u003e我有段时间真的坚持很好，而且那段时间自己都感觉自己文绉绉的，语出惊人，最近懒了，没坚持输出，口齿不伶俐了，有点矛盾，天天按时输出，打卡，表达，最后得到的并不多，相反，不输出时候，还有流量，只能把这个当成一个树洞，去吐槽，不敢发朋友圈的，往这里面写，也不错，就是发泄。\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":30,"favorite_count":0,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1921207217618657471}","attached_info":"CuYFCMuQ6NOAqcv3owEQBBoJNzMzOTM2Nzk4IIaj7sIGKAAwCUB8SiQKGVRTX1NPVVJDRV9XQVJNX1VQX05PUk1BTDISATAYACAAOgBaCTExNTE3ODUzN2IgNmE1ZjNmZDQ5YjY3NDA4ZTczMzdmZmU5OTM4N2U4MTZyEzE5MjEyMDcyMTc2MTg2NTc0NzGKARMxOTEyMDc1OTAxNzk1MDM5MTU2qgEJcmVjb21tZW5kwgEgZGM1YTkwZmM4MDVjZjU5OWViMThhMTVjZTY1ODBmNzLyAQoIDBIGTm9ybWFs8gEoCAoSJGNlMmQzNGY2LTY3M2ItNGEwNy05MTc5LWIxNDFiNWNiMmRjNPIBBggLEgIyMYICAIgCpZHazfoykgIgZGM1YTkwZmM4MDVjZjU5OWViMThhMTVjZTY1ODBmNzKaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIYUGVyaW9kSW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygIYQ29udGVudFdhcm1VcEJyZWFrSW5SdWxl2gIZVFNfU09VUkNFX1dBUk1fVVBfTk9STUFMMugCAvoCC05PUk1BTF9GTE9XigMgMGNmNGZhZTllYzUxNDIzYTg2OWU1NDllZWM2MTA0Y2GaAw0KAnYyEAAaBW90aGVyqAMe2AMA6gMfdGV4dF8xMmhvdXJfdW5pZmluc2hlZF9yZWNhbGxlcvoDHxIMVU5LTk9XTl9NT0RFIAAqDU5PX0lNQUdFX01PREWABACIBACSBAZOb3JtYWyaBAEyoAQAqAQAsAQAugQCYWnCBAM0MDDIBADSBA/mjqjojZDlt7Lmm7TmlrDYBADwBAD5BAAAAKBaCZs/gQUAAAAAAAAAAIkFj6uOrvOF0j+SBQCaBQNkZnSiBQNkZnSyBQExuQUAAAAAAAAAANAFAOAFAOgFAPAFFZAGAKAGfagGAZICLgoJNzMzOTM2Nzk4EhMxOTIxMjA3MjE3NjE4NjU3NDcxGAQiCklNQUdFX1RFWFQ=","action_card":false},{"id":"125_1750899001.682","type":"feed","offset":125,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899001,"updated_time":1750899001,"target":{"id":"1918399620058452261","type":"answer","url":"https://api.zhihu.com/answers/1918399620058452261","author":{"id":"1b6f0e39c36672a4fc5221f7eea28e45","url":"https://api.zhihu.com/people/1b6f0e39c36672a4fc5221f7eea28e45","user_type":"people","url_token":"tnli","name":"数字灵猴","headline":"努力往巨人的肩膀上爬","avatar_url":"https://pic1.zhimg.com/50/v2-e5bc8bc6e7b7e89996e5ea3daf947127_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":42,"is_following":false,"is_followed":false},"created_time":1750162111,"updated_time":1750162111,"voteup_count":10,"thanks_count":0,"comment_count":0,"is_copyable":true,"question":{"id":"443599861","type":"question","url":"https://api.zhihu.com/questions/443599861","author":{"id":"ced2033428bed24b82e8608125f9b697","url":"https://api.zhihu.com/people/ced2033428bed24b82e8608125f9b697","user_type":"people","url_token":"yang-jiang-feng-66-82","name":"呦呦鹿鸣","headline":"ml ai","avatar_url":"https://picx.zhimg.com/50/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":118,"is_following":false,"is_followed":false},"title":"广告排序模型，如何做广告的冷启动？ 从排序的角度讲，有哪些方法？除了加入商品的泛化特征，还有什么方法？","created":1612854506,"answer_count":0,"follower_count":0,"comment_count":0,"bound_topic_ids":[1462,17454,44434],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"thumbnail":"https://picx.zhimg.com/50/v2-47bf0a3672e9487ba534bd1ba3cce4d0_720w.jpg?source=b6762063","excerpt":"Paper：Ads Recommendation in a Collapsed and Entangled World Link：https://arxiv.org/pdf/2403.00793 Tencent， KDD ’24, August 25–29, 2024, Barcelona, Spain摘要本文介绍腾讯广告推荐系统，重点探讨 广告推荐表征学习的关键挑战与实践方案。首先提出多类型特征编码方法，在序列特征、数值特征和预训练嵌入特征中保留先验知识（prior knowledge）。随后研究特征表征的两大难题：嵌入维度坍缩（dimensional collapse）和跨场景兴趣…","excerpt_new":"Paper：Ads Recommendation in a Collapsed and Entangled World Link：https://arxiv.org/pdf/2403.00793 Tencent， KDD ’24, August 25–29, 2024, Barcelona, Spain摘要本文介绍腾讯广告推荐系统，重点探讨 广告推荐表征学习的关键挑战与实践方案。首先提出多类型特征编码方法，在序列特征、数值特征和预训练嵌入特征中保留先验知识（prior knowledge）。随后研究特征表征的两大难题：嵌入维度坍缩（dimensional collapse）和跨场景兴趣…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cblockquote data-pid=\"DWz51Y3P\"\u003e\u003ci\u003ePaper：Ads Recommendation in a Collapsed and Entangled World\u003c/i\u003e\u003cbr/\u003e\u003ci\u003eLink：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2403.00793\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/pdf/2403.0079\u003c/span\u003e\u003cspan class=\"invisible\"\u003e3\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/i\u003e\u003cbr/\u003e\u003ci\u003eTencent， KDD ’24, August 25–29, 2024, Barcelona, Spain\u003c/i\u003e\u003c/blockquote\u003e\u003chr/\u003e\u003ch2\u003e摘要\u003c/h2\u003e\u003cp data-pid=\"G2wtyywd\"\u003e本文介绍腾讯广告推荐系统，重点探讨\u003cb\u003e\u003cu\u003e广告推荐表征学习\u003c/u\u003e\u003c/b\u003e的关键挑战与实践方案。首先提出\u003cu\u003e多类型特征编码方法\u003c/u\u003e，在\u003cu\u003e序列特征、数值特征和预训练嵌入特征中保留先验知识（prior knowledge）\u003c/u\u003e。随后研究特征表征的两大难题：\u003cb\u003e\u003cu\u003e嵌入维度坍缩（dimensional collapse）\u003c/u\u003e\u003c/b\u003e和跨场景\u003cb\u003e\u003cu\u003e兴趣纠缠（ interest entanglement）\u003c/u\u003e\u003c/b\u003e，并提出解决方案以获得解耦的、鲁棒性好的特征表征。在模型训练方面，提出若干方法来提升训练效率、减少偏差并增强探索能力。此外，提出三套工具，用于分析特征相关性、维度坍缩和兴趣纠缠问题。本文的研究内容，是基于腾讯广告推荐团队十年来的技术积累，总结了\u003cu\u003e通用的模型架构设计原则，并提供可直接落地使用的解决方案和分析工具\u003c/u\u003e。文中所有涉及到到的性能指标，均来自于腾讯在线广告平台，该平台日均处理数千亿请求，为数亿用户提供数百万广告服务。\u003c/p\u003e\u003ch2\u003e1 引言\u003c/h2\u003e\u003cp data-pid=\"3W0FxdUn\"\u003e市场规模价值数十亿美元的在线广告产业，是机器学习成功应用的典范。各式各样的广告，包括搜索广告、上下文广告、展示广告和短视频广告等，都高度依赖于广告CTR或CVR的准确、高效且可靠的模型训练与预测。\u003c/p\u003e\u003cp data-pid=\"pd_tls0a\"\u003e过去十年间，深度学习（DL）在计算机视觉学习（CV）[23,34]、自然语言处理（NLP）[1,16,62]和推荐系统[41,77]等领域取得显著成功。\u003cu\u003eDL的有效性很大程度上取决于数据表征的方式\u003c/u\u003e[3,67,68]。研究者在CV和NLP领域对数据的表征学习进行广泛而深入的探索，包括先验知识（priors）[62]、平滑性与维度灾难（curse of dimensionality）[5]、层次化抽象（depth and abstraction）[4]、特征因子解耦（disentangling factors of variations）[68]以及表征均匀性（uniformity of representation）[28,30]等。\u003c/p\u003e\u003cp data-pid=\"tLh7EKJQ\"\u003e在推荐系统领域，大量研究聚焦\u003cb\u003e\u003cu\u003e表征学习（representation learning ）\u003c/u\u003e\u003c/b\u003e技术，\u003cu\u003e包括处理多样化特征[9,19,32,79,81]、通过显性或隐性的特征交互以捕捉特征相关性[12,20,37,45,51,60,66]、解决用户复杂行为中的兴趣纠缠问题[69]（尤其在多任务multi-task[43,59]，多场景multi-scenario[7,54,83]下）、以及通过自监督（self-supervised）学习增强数据表征[63,84]\u003c/u\u003e。尽管这些表征学习研究有所进展，但在大规模工业级广告推荐系统中，表征学习还有若干的基础性问题仍未得到解决。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"C62CTK2A\"\u003e\u003cb\u003e\u003ci\u003e表征先验约束（Priors for Representation）\u003c/i\u003e\u003c/b\u003e：生产系统往往包含不同来源的多样化特征，包括序列特征（如用户点击/转化历史序列）、数值特征（如语义保持的广告ID）、来自外部预训练模型（如GNNLLM或）的embedding特征。在推荐系统中编码这些特征时，保持其固有先验（priors）属性至关重要。\u003c/li\u003e\u003cli data-pid=\"KiZ2s0oF\"\u003e\u003cb\u003e\u003ci\u003e维度坍缩（Dimensional Collapse）现象\u003c/i\u003e\u003c/b\u003e：在编码过程中，所有特征被映射为 维embedding向量，这些embedding向量会在模型训练过程中进行学习。然而发现许多特征embedding，往往只占据低维子空间（lower-dimensional subspace），未能充分利用 维空间的表达能力。这种维度坍缩不仅造成参数浪费（parameter wastage），还影响推荐模型的扩展能力。\u003c/li\u003e\u003cli data-pid=\"2fVTyD2_\"\u003e\u003cb\u003e\u003ci\u003e兴趣纠缠（Interest Entanglement）问题\u003c/i\u003e\u003c/b\u003e：广告推荐系统中，用户最终决策响应，可能由许多复杂的潜在因素（underlying factor）决定，特别是在多任务或多场景联合学习场景。现有共享嵌入（shared-embedding ）方法[6,43,59]由于采用同一纠缠式（entangled）embedding的表征方法，往往难以充分解耦这些潜在影响因素。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"Mc158AZt\"\u003e本文针对上述挑战提出系统性解决方案。全文结构如下：第2节概述模型架构，以鸟瞰系统全貌；第3节聚焦时序（temporal）、序数（ordinal）和距离（distance）等先验特征的编码技术，将其统一整合到表征中；第4节剖析嵌入维度坍缩的根源，并提出缓解方案；第5节探讨跨任务、跨场景的兴趣纠缠问题，以及应对方法；第6节阐述常用的模型训练技术；第7节则提供开箱即用的工具集，用于分析特征相关性、维度坍缩与兴趣纠缠。受篇幅限制，本文无法逐一详述各方法细节，具体技术实现请参见各章节引用的相关文献。\u003c/p\u003e\u003ch2\u003e2 系统概览\u003c/h2\u003e\u003cp data-pid=\"EhlaxRBS\"\u003e本文提出的广告推荐模型的单任务学习架构如图1所示。本模型采用业界通用的\u003cb\u003e\u003cu\u003e\u0026#34;嵌入-显式交互\u0026#34;（Embedding \u0026amp; Explicit Interaction）框架\u003c/u\u003e\u003c/b\u003e[41,77]，\u003cu\u003e包含四大核心模块：特征编码模块（feature encoding）、多嵌入查询模块（multi-embedding lookup）、专家模块（experts）（含特征交互与多层感知机）以及分类塔模块（classification tower）\u003c/u\u003e。特征编码模块中，针对不同类型特征，采用不同的特征编码方法。多嵌入查询模块包括多个embedding表，针对每个特征，通过特征编码生成的ID，查询到多组embedding向量。专家模块中，来自同一查询表的embedding向量进行显式交互，再交由包含非线性变换的多层感知机（MLP）处理。分类塔模块中，将接收到的专家模块输出进行门控加权和（gate-weighted sum）处理，最终通过sigmoid激活函数生成预测结果。多任务学习架构版本见图4。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-4cbcc4102f007a3c9fb4de93fa314747_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"4160\" data-rawheight=\"2094\" data-original-token=\"v2-4cbcc4102f007a3c9fb4de93fa314747\" class=\"origin_image zh-lightbox-thumb\" width=\"4160\" data-original=\"https://picx.zhimg.com/v2-4cbcc4102f007a3c9fb4de93fa314747_r.jpg\"/\u003e\u003cfigcaption\u003e图1：单任务学习中基于多嵌入（Multi-Embedding）的异构MoE架构。包含四大核心模块：特征编码、多嵌入查询、专家系统（特征交互与多层感知机）及分类Tower。\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"Rrh_2UD2\"\u003e在单任务学习场景（如CTR预测）中，模型采用单分类塔结构（图1）。而在多任务学习（MTL）场景下，比如CVR模型中不同的转化行为会被建模为独立的学习任务[48]，模型则采用多塔（multiple-tower）架构（以及对应的门控机制），每个分类塔专注于特定转化类型的训练与推理。针对多任务学习中出现的兴趣纠缠问题，第5节将详述模型架构的改进方案，以实现用户兴趣有效解耦（disentanglement）。\u003c/p\u003e\u003cp data-pid=\"gBidIUri\"\u003e本团队负责腾讯广告的整个推荐算法链路，涵盖召回（retrieval）、粗排模块（pre-ranking）、CTR预测（pCTR）、浅层CVR预测（pCVR，包含各种转化行为类型）、深度CVR预测（pDCVR）及长期价值预测（pLTV）。由于这些模块在模型架构设计原则层面上具有高度的共性，本文重点以pCTR和pCVR为单任务和多任务学习的代表性模型展开讨论。模型已广泛应用于微信朋友圈（社交信息流）、视频号（短视频流）、公众号（订阅）、腾讯新闻、腾讯视频（长视频平台）及DSP等腾讯全广告推荐场景业务。\u003c/p\u003e\u003ch2\u003e3 特征编码方法\u003c/h2\u003e\u003cp data-pid=\"0-02cHij\"\u003e工业级广告推荐系统的特征来源和种类多样，主要包含\u003cb\u003e\u003cu\u003e序列（sequence）特征、数值（numeric）特征和嵌入（embedding）特征\u003c/u\u003e\u003c/b\u003e等类型。在特征编码过程中，我们最大程度地保留其\u003cb\u003e\u003cu\u003e时序性（temporal）、序数性（ordinal）和距离（相似度，similarity）\u003c/u\u003e\u003c/b\u003e等先验特性。\u003c/p\u003e\u003ch3\u003e3.1 序列特征\u003c/h3\u003e\u003cp data-pid=\"ukvNz7QC\"\u003e\u003cu\u003e用户历史行为反映其兴趣偏好，是推荐系统的关键特征，其在语义（semantic）和时序（temporal）上，与目标广告存在着双重相关性\u003c/u\u003e[82]。例如，当预测用户对广告的响应时，与广告语义相关（如行为与广告同属一个类别）或时间邻近的广告互动行为更具预测价值。\u003c/p\u003e\u003cp data-pid=\"semfBqS7\"\u003e为此，我们提出\u003cb\u003e\u003cu\u003e时序兴趣模块（Temporal Interest Module，TIM）\u003c/u\u003e\u003c/b\u003e[82]，用于建模\u003cb\u003e\u003cu\u003e（行为语义、目标语义、行为时序、目标时序）四元关联性\u003c/u\u003e\u003c/b\u003e：  \u003cimg src=\"https://www.zhihu.com/equation?tex=%28behavior%5C_semantic%2C+target%5C_semantic%2C+behavior%5C_temporal%2C+target%5C_temporal%29\" alt=\"(behavior\\_semantic, target\\_semantic, behavior\\_temporal, target\\_temporal)\" eeimg=\"1\"/\u003e 。具体而言，TIM在语义编码（semantic encoding）[17,80,81]基础上，引入目标感知（Target-aware）的时序编码（Temporal Encoding），如行为与目标的相对位置或时间间隔，以捕捉四元关联性。TIM采用目标感知注意力（Target-aware Attention）和目标感知表征（Target-aware Representation），在注意力和表征两个层面实现行为与目标的\u003cb\u003e\u003cu\u003e显式四维交互（explicit 4-way interaction）\u003c/u\u003e\u003c/b\u003e，如图2(a)所示。\u003cb\u003e\u003cu\u003e用户行为序列 \u003cimg src=\"https://www.zhihu.com/equation?tex=H\" alt=\"H\" eeimg=\"1\"/\u003e\u003c/u\u003e\u003c/b\u003e 可数学表达为：\u003c/p\u003e\u003cp data-pid=\"LUHiTj2s\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=u_%7BTIM%7D+%3D+%5Csum_%7BX_i+%5Cin+H%7D%5E%7B%7D%7B%5Calpha%28%5Ctilde%7Be%7D_i%2C%5Ctilde%7Bv%7D_t%29+%5Ccdot+%28%5Ctilde%7Be%7D_i+%5Codot+%5Ctilde%7Bv%7D_t%29++++++%7D++\" alt=\"u_{TIM} = \\sum_{X_i \\in H}^{}{\\alpha(\\tilde{e}_i,\\tilde{v}_t) \\cdot (\\tilde{e}_i \\odot \\tilde{v}_t)      }  \" eeimg=\"1\"/\u003e  (1)\u003c/p\u003e\u003cp data-pid=\"KZxpNTZB\"\u003e其中\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Calpha%28%5Ctilde%7Be%7D_i%2C%5Ctilde%7Bv%7D_t%29+\" alt=\"\\alpha(\\tilde{e}_i,\\tilde{v}_t) \" eeimg=\"1\"/\u003e 表示行为 \u003cimg src=\"https://www.zhihu.com/equation?tex=+\" alt=\" \" eeimg=\"1\"/\u003e 与目标 \u003cimg src=\"https://www.zhihu.com/equation?tex=+\" alt=\" \" eeimg=\"1\"/\u003e 的目标感知注意力权重（target-aware attention），\u003cimg src=\"https://www.zhihu.com/equation?tex=%28%5Ctilde%7Be%7D_i+%5Codot+%5Ctilde%7Bv%7D_t%29+\" alt=\"(\\tilde{e}_i \\odot \\tilde{v}_t) \" eeimg=\"1\"/\u003e 为目标感知表征（target-aware representation）。 \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Ctilde%7Be%7D_i%3De_i+%5Coplus+P_%7Bf%28X_i%29%7D\" alt=\"\\tilde{e}_i=e_i \\oplus P_{f(X_i)}\" eeimg=\"1\"/\u003e 表示第\u003cimg src=\"https://www.zhihu.com/equation?tex=+\" alt=\" \" eeimg=\"1\"/\u003e个行为的时序编码嵌入，即语义嵌入（semantic embedding） \u003cimg src=\"https://www.zhihu.com/equation?tex=e_i\" alt=\"e_i\" eeimg=\"1\"/\u003e 与目标感知时序编码 \u003cimg src=\"https://www.zhihu.com/equation?tex=P_%7Bf%28X_i%29%7D\" alt=\"P_{f(X_i)}\" eeimg=\"1\"/\u003e 的逐元素相加，后者可以是行为相对于目标的位置编码，或是离散化（discretized）时间间隔编码。值得注意的是，\u003cu\u003e目标感知表征 \u003cimg src=\"https://www.zhihu.com/equation?tex=%28%5Ctilde%7Be%7D_i+%5Codot+%5Ctilde%7Bv%7D_t%29+\" alt=\"(\\tilde{e}_i \\odot \\tilde{v}_t) \" eeimg=\"1\"/\u003e类似于特征交互层，显式建模行为特征与目标的交互关系，这与基于因子分解机（FM）的显式特征交互模型[31,37,49,52,66]原理一致\u003c/u\u003e。近期研究[74]也论证了此类显式建模行为与目标交互在表征学习中的重要性。\u003c/p\u003e\u003cp data-pid=\"lvCWPtZs\"\u003e\u003cb\u003e生产环境部署效果\u003c/b\u003e。实际应用中，我们\u003cu\u003e同时采用相对位置和时间间隔进行时序编码\u003c/u\u003e。\u003cu\u003eTIM模块的输出会与特征交互模块DCN V2[66]和GwPFM（后文详述）的输出拼接在一起\u003c/u\u003e。该模块已应用于微信各广告场景的CTR/CVR预测任务中的用户点击或者转化序列特征处理上。实际效果显示，TIM模块为广告pCTR预测类任务带来1.93%的GMV提升，为游戏和电商行业的长期价值预测(pLTV)任务中带来2.45%的GMV提升。通过分析发现，\u003cu\u003e模型在时间间隔嵌入（time interval embedding）中学习到的衰减模式（decaying pattern）比相对位置嵌入（relative position embedding）更为显著\u003c/u\u003e，这主要是由于用户对的广告点击行为较为稀疏，使得时间间隔信息更具区分度。\u003c/p\u003e\u003ch3\u003e3.2 数值特征\u003c/h3\u003e\u003cp data-pid=\"am2_C4bE\"\u003e与ID类特征不同，数值/序数特征（如Age_20≺Age_30）具有内生\u003cb\u003e\u003cu\u003e偏序关系\u003c/u\u003e\u003c/b\u003e。为保持此序数先验知识，我们采用NaryDis编码[9]的简化版本——\u003cb\u003e\u003cu\u003e多进制系统编码(Multiple Numeral Systems Encoding，MNSE)\u003c/u\u003e\u003c/b\u003e。该方法通过二进制、三进制和十进制等不同进制获取特征编码，并为这些编码分配可学习的embedding向量（图2(b)所示）。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-adee7bbe93cc0e5050836e916599f1b3_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2453\" data-rawheight=\"840\" data-original-token=\"v2-adee7bbe93cc0e5050836e916599f1b3\" class=\"origin_image zh-lightbox-thumb\" width=\"2453\" data-original=\"https://pic4.zhimg.com/v2-adee7bbe93cc0e5050836e916599f1b3_r.jpg\"/\u003e\u003cfigcaption\u003e图2：时序兴趣模块TIM（左）与多进制系统编码MNSE（右）的结构示意图，分别用于处理序列特征以及数值和预训练嵌入特征。\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"ORoibOF1\"\u003e以特征值\u0026#34;51\u0026#34;为例，其二进制编码为\u0026#34;{6_1,5_1,4_0,3_0,2_1,1_1}\u0026#34;，三进制编码为\u0026#34;{6_0,5_0,4_1,3_2,2_2,1_0}\u0026#34;。所有离散编码，首先经过嵌入层映射为稠密向量表示，随后采用求和池化（sum-pooling）操作，聚合这些向量，最终生成融合多进制信息的特征表征。为提高计算效率，我们移除了原NaryDis[9]中的内外注意力机制。对于连续特征值 \u003cimg src=\"https://www.zhihu.com/equation?tex=v\" alt=\"v\" eeimg=\"1\"/\u003e ，其编码结果可表示为：\u003c/p\u003e\u003cp data-pid=\"naxeKnfn\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=f_%7BMNS%7D%28v%29+%3D+%5B%5Csum_%7Bk%3D1%7D%5E%7BK_2%7D%7BX_%7B2k%2BB_k%7D%5E%7B%282%29%7D%7D%2C++%5Csum_%7Bk%3D1%7D%5E%7BK_3%7D%7BX_%7B3k%2BC_k%7D%5E%7B%283%29%7D%7D%2C+...++%2C+%5Csum_%7Bk%3D1%7D%5E%7BK_n%7D%7BX_%7Bnk%2BN_k%7D%5E%7B%28n%29%7D%7D++++++%5D\" alt=\"f_{MNS}(v) = [\\sum_{k=1}^{K_2}{X_{2k+B_k}^{(2)}},  \\sum_{k=1}^{K_3}{X_{3k+C_k}^{(3)}}, ...  , \\sum_{k=1}^{K_n}{X_{nk+N_k}^{(n)}}      ]\" eeimg=\"1\"/\u003e ，  （2）\u003c/p\u003e\u003cp data-pid=\"6e1XuZeO\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=B%3DFunc%5C_binary%28v%29%2C+C%3Dfunc%5C_ternary%28v%29%2C...\" alt=\"B=Func\\_binary(v), C=func\\_ternary(v),...\" eeimg=\"1\"/\u003e \u003c/p\u003e\u003cp data-pid=\"dpOn_EV4\"\u003e其中 \u003cimg src=\"https://www.zhihu.com/equation?tex=X_%7B2k%2BB_k%7D%5E%7B%282%29%7D\" alt=\"X_{2k+B_k}^{(2)}\" eeimg=\"1\"/\u003e 和 \u003cimg src=\"https://www.zhihu.com/equation?tex=X_%7B3k%2BC_k%7D%5E%7B%283%29%7D\" alt=\"X_{3k+C_k}^{(3)}\" eeimg=\"1\"/\u003e 分别为二进制与三进制的embedding字典，其编码长度分别为 \u003cimg src=\"https://www.zhihu.com/equation?tex=K_2\" alt=\"K_2\" eeimg=\"1\"/\u003e 和 \u003cimg src=\"https://www.zhihu.com/equation?tex=K_3\" alt=\"K_3\" eeimg=\"1\"/\u003e。 \u003cimg src=\"https://www.zhihu.com/equation?tex=func_binary\" alt=\"func_binary\" eeimg=\"1\"/\u003e 与 \u003cimg src=\"https://www.zhihu.com/equation?tex=func_ternary\" alt=\"func_ternary\" eeimg=\"1\"/\u003e 是将连续特征 \u003cimg src=\"https://www.zhihu.com/equation?tex=v\" alt=\"v\" eeimg=\"1\"/\u003e 转换为对应编码的二值化(binarization)与三值化(ternarization)函数。\u003c/p\u003e\u003cp data-pid=\"BnBNSciF\"\u003e\u003cb\u003e生产环境部署效果\u003c/b\u003e。广告系统通常采用自增或随机生成的ID来标识广告，ID自身含有的信息量有限，但每条广告的创意素材蕴含着丰富的视觉语义信息。为此，我们引入新的\u003cb\u003e\u003cu\u003e视觉语义ID（Visual Semantic ID）\u003c/u\u003e\u003c/b\u003e来替代原有标识，以保持广告间的视觉相似性信息。具体实现上，我们通过视觉模型提取广告图像的embedding表征，并使用局部敏感哈希（LSH）[64]等算法来保持视觉相似性。\u003cu\u003e通过预训练视觉模型提取广告图像的embedding特征，并采用局部敏感哈希算法[64]生成保持视觉相似性的视觉语义ID。视觉语义ID作为数值特征输入时，我们采用最小范数缩放（Minimum Norm Scaling，MNS)）技术保持其序数特性（ordinal priors）\u003c/u\u003e。实际数据显示，在微信朋友圈广告pCVR预测任务中实现1.13%的GMV提升，新广告的增益效果更为显著，达到1.74%。同时，相似广告对同一用户的预测分数\u003cb\u003e\u003cu\u003e变异系数（coefficient of variation）\u003c/u\u003e\u003c/b\u003e从2.44%显著降低至0.30%，验证了该方法能有效\u003cb\u003e\u003cu\u003e保持视觉相似性先验\u003c/u\u003e\u003c/b\u003e。\u003c/p\u003e\u003ch3\u003e3.3 embedding特征\u003c/h3\u003e\u003cp data-pid=\"7qdYRrHX\"\u003e除主干模型外，我们可能还会训练一个独立模型（如LLM或GNN）来学习实体（user或者item）的embedding表征。借助图模型或自监督语言模型，在更大规模或差异化的数据集上进行训练，从不同视角来捕捉user-item关系，为主干模型提供差异化的信息补充。然而，将这些预训练的embedding应用到主干模型上，有一个很关键的问题：\u003cu\u003e内外模型的嵌入空间（embedding space）不同，可能存在巨大的语义鸿沟（semantic gap）\u003c/u\u003e（主干推荐模型中的ID embedding体现其协同过滤语义（collaborative semantics）[36,79]）。\u003c/p\u003e\u003cp data-pid=\"6GOVrkTJ\"\u003e我们提出\u003cb\u003e\u003cu\u003e相似性编码embedding方法（Similarity Encoding Embedding）\u003c/u\u003e\u003c/b\u003e以缓解此类语义鸿沟。以GNN为例，当获得预训练user-item的嵌入对 \u003cimg src=\"https://www.zhihu.com/equation?tex=%28%5Cbar%7Be%7D_u%2C%5Cbar%7Be%7D_i%29\" alt=\"(\\bar{e}_u,\\bar{e}_i)\" eeimg=\"1\"/\u003e 后，首先基于图embedding相似度函数（如GraphSage[22]的cosine），计算相似度权重 \u003cimg src=\"https://www.zhihu.com/equation?tex=w_%7Bsim%7D%28u%2Ci%29\" alt=\"w_{sim}(u,i)\" eeimg=\"1\"/\u003e ，其形式化定义为：\u003c/p\u003e\u003cp data-pid=\"n_Ymyj-V\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=w_%7Bsim%7D%28u%2Ci%29+%3D+sim%28%5Cbar%7Be%7D_u%2C%5Cbar%7Be%7D_i%29\" alt=\"w_{sim}(u,i) = sim(\\bar{e}_u,\\bar{e}_i)\" eeimg=\"1\"/\u003e    （3）\u003c/p\u003e\u003cp data-pid=\"10T2CksG\"\u003e该相似度评分本质为序数值（ordinal value），因此可沿用前文所述面向数值特征的\u003cu\u003e多进制系统编码方法（MNSE），将其转换成可学习嵌入表示（ learnable embedding）：\u003cb\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=e_%7Bsim%7D%28u%2Ci%29%3Df_%7BMNS%7D%28w_%7Bsim%7D%28u%2C+i%29%29\" alt=\"e_{sim}(u,i)=f_{MNS}(w_{sim}(u, i))\" eeimg=\"1\"/\u003e\u003c/b\u003e\u003c/u\u003e 。转换后，该embedding与推荐系统中的其他ID embedding联合训练。由此，原始空间的相似性先验知识通过相似度评分与编码转换得以保留。相似性编码嵌入 \u003cimg src=\"https://www.zhihu.com/equation?tex=e_%7Bsim%7D%28u%2Ci%29\" alt=\"e_{sim}(u,i)\" eeimg=\"1\"/\u003e 在与推荐ID embedding完成对齐后，输入到广告主干模型。\u003c/p\u003e\u003cp data-pid=\"aE43og5I\"\u003e进一步地，借助该embedding编码策略，大语言模型（LLM）的知识可以向推荐系统迁移融合。首先，将LLM模型转换为encoder架构，用下句预测等基础任务进行预训练，使其获得语义嵌入编码能力（semantic embedding）。随后，使用广告高质量样本进行微调（finetune），这种\u003cb\u003e\u003cu\u003e对比对齐（contrastive alignment）机制\u003c/u\u003e\u003c/b\u003e使LLM模型生成高质量的预训练用户embedding \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbar%7Be%7D_u\" alt=\"\\bar{e}_u\" eeimg=\"1\"/\u003e 和广告embedding \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbar%7Be%7D_i\" alt=\"\\bar{e}_i\" eeimg=\"1\"/\u003e 。基于LLM的相似性先验知识(simi-larity priors)，类比GNN的相似性编码embedding方法，实现语义空间对齐。\u003c/p\u003e\u003cp data-pid=\"YRnEE6Su\"\u003e\u003cb\u003e生产环境部署效果\u003c/b\u003e。我们在用户-广告（或者用户-物料）二部图上，训练GraphSage[22]模型，以目标点击行为作为边关系。将GNN embedding经相似性编码处理的表征输出，与特征交互层的表征输出拼接（concatenate）。GNN embedding方案已在微信多个场景成功落地，朋友圈、视频号和小程序场景的pCTR预测优化分别实现1.21%、0.59%和1.47%的GMV提升。另AB测试显示，引入LLM embedding后，视频号场景pCVR优化带来2.55%的GMV提升，pCTR优化带来1.41%的GMV提升。\u003c/p\u003e\u003ch2\u003e4 抗维度坍缩（DIMENSIONAL COLLAPSE）方法\u003c/h2\u003e\u003cp data-pid=\"t8jjN4A8\"\u003e经编码后，所有特征均embedding化表示，然后通过类FM模型[20，31，33，37，49，51，52，58，66]进行显式特征交互。然而，\u003cb\u003e\u003cu\u003e显式特征交互会引发embedding维度坍缩[21]问题\u003c/u\u003e\u003c/b\u003e。本节首先解释维度坍缩现象，继而提出\u003cb\u003e\u003cu\u003e两种多嵌入（multi-embedding）方案\u003c/u\u003e\u003c/b\u003e，以及一种\u003cb\u003e\u003cu\u003e抗坍缩（collapse-resilient）特征交互函数\u003c/u\u003e\u003c/b\u003e以缓解该问题。\u003c/p\u003e\u003ch3\u003e4.1 嵌入维度坍缩（Embedding Dimensional Collapse）\u003c/h3\u003e\u003cp data-pid=\"sw0Rm5yP\"\u003e近期研究[1,18,78]表明，拥有数十亿甚至数万亿参数的Transformer等大模型（如GPT-4[1]、LLaMA[61]）能取得卓越性能。受此启发，我们探索了广告推荐模型的规模化方法。推荐系统的embedding参数通常\u003cu\u003e占据模型参数的绝大部分，如在我们的生产模型中，超过99.99%的参数来自特征embedding层。为此，我们通过增大embedding维度 \u003cimg src=\"https://www.zhihu.com/equation?tex=K\" alt=\"K\" eeimg=\"1\"/\u003e （如从64增至192）来扩大模型的规模，但这并未带来显著的性能提升，有时甚至导致效果变差\u003c/u\u003e。\u003c/p\u003e\u003cp data-pid=\"y_5jm-1a\"\u003e我们对embedding矩阵进行奇异谱分析（singular spectral analysis）[30]，发现维度坍缩现象。具体表现为，多数奇异值趋近于零，说明\u003cu\u003e许多特征的embedding仅分布在低维子空间（lower-dimensional subspace），而非完整的embedding空间\u003c/u\u003e[21,28]。大量坍缩的embedding维度没有实际意义，导致\u003cu\u003e\u003cb\u003e模型容量（capacity）严重浪费\u003c/b\u003e\u003c/u\u003e。更关键的是，这直接导致单纯通过\u003cu\u003e增加dimension长度来扩展模型的方法[2,21]失灵\u003c/u\u003e。\u003c/p\u003e\u003cp data-pid=\"5Nyj7E1L\"\u003e\u003cu\u003e维度坍缩的根因，源于特征显式交互模块中，某些特征字段（fields）的维度坍缩会引发其他字段embedding的连锁坍缩效应\u003c/u\u003e。以性别特征为例，\u003cu\u003e其基数（cardinality）\u003cimg src=\"https://www.zhihu.com/equation?tex=N_%7BGen%7D\" alt=\"N_{Gen}\" eeimg=\"1\"/\u003e极低，其embedding仅能张成\u003cimg src=\"https://www.zhihu.com/equation?tex=N_%7BGen%7D\" alt=\"N_{Gen}\" eeimg=\"1\"/\u003e-维空间。当\u003cimg src=\"https://www.zhihu.com/equation?tex=N_%7BGen%7D\" alt=\"N_{Gen}\" eeimg=\"1\"/\u003e远小于embedding维度 \u003cimg src=\"https://www.zhihu.com/equation?tex=K\" alt=\"K\" eeimg=\"1\"/\u003e （ \u003cimg src=\"https://www.zhihu.com/equation?tex=N_%7BGen%7D+%5Cll+K\" alt=\"N_{Gen} \\ll K\" eeimg=\"1\"/\u003e ）时，低维embedding与其它高维embedding（\u003cimg src=\"https://www.zhihu.com/equation?tex=K\" alt=\"K\" eeimg=\"1\"/\u003e维空间）进行特征交互，将使高维embeddin坍缩成\u003cimg src=\"https://www.zhihu.com/equation?tex=N_%7BGen%7D\" alt=\"N_{Gen}\" eeimg=\"1\"/\u003e-维子空间（subspace）\u003c/u\u003e。\u003c/p\u003e\u003ch3\u003e4.2 多嵌入范式（Multi-Embedding Paradigm）\u003c/h3\u003e\u003cp data-pid=\"daeGXqwE\"\u003e为缓解广告推荐系统规模化时的embedding维度坍缩问题，我们提出多嵌入范式方案[21]。\u003cu\u003e该方案突破传统的单嵌入范式（single-embedding paradigm），每个特征从多个嵌入表中查询若干embedding向量\u003c/u\u003e。\u003cu\u003e来自同一嵌入表的特征embedding向量，将在对应专家模块（expert） \u003cimg src=\"https://www.zhihu.com/equation?tex=+\" alt=\" \" eeimg=\"1\"/\u003e 中进行特征交互学习\u003c/u\u003e。有 \u003cimg src=\"https://www.zhihu.com/equation?tex=T\" alt=\"T\" eeimg=\"1\"/\u003e 个嵌入表的模型形式化定义为：\u003c/p\u003e\u003cp data-pid=\"kpMQA7vd\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5Cbegin%7Baligned%7D+%5Cbm%7Be%7D_i%5E%7B%28t%29%7D+%26%3D%7B%28+%5Cbm%7BE%7D_i%5E%7B%28t%29%7D%29%7D%5E%7B%5Ctop%7D%5Cmathbb%7B1%7D_%7Bx_i%7D%2C+%5Cquad+%5Cforall+i%5Cin%5C%7B1%2C2%2C...%2CN%5C%7D%2C+%5C%5C+h%5E%7B%28t%29%7D+%26%3D+I%5E%7B%28t%29%7D%5Cleft%28%5Cbm%7Be%7D_1%5E%7B%28t%29%7D%2C%5Cbm%7Be%7D_2%5E%7B%28t%29%7D%2C...%2C%5Cbm%7Be%7D_N%5E%7B%28t%29%7D%5Cright%29%2C+%5C%5C++h+%26%3D+%5Cfrac%7B1%7D%7BT%7D%5Csum_%7Bt%3D1%7D%5ET+g%5E%7B%28t%29%7Dh%5E%7B%28t%29%7D%2C+%5C+%5Chat%7By%7D+%3D+F%28h%29%2C+%5Cend%7Baligned%7D+%5Cend%7Bequation%7D\" alt=\"\\begin{equation} \\begin{aligned} \\bm{e}_i^{(t)} \u0026amp;={( \\bm{E}_i^{(t)})}^{\\top}\\mathbb{1}_{x_i}, \\quad \\forall i\\in\\{1,2,...,N\\}, \\\\ h^{(t)} \u0026amp;= I^{(t)}\\left(\\bm{e}_1^{(t)},\\bm{e}_2^{(t)},...,\\bm{e}_N^{(t)}\\right), \\\\  h \u0026amp;= \\frac{1}{T}\\sum_{t=1}^T g^{(t)}h^{(t)}, \\ \\hat{y} = F(h), \\end{aligned} \\end{equation}\" eeimg=\"1\"/\u003e\u003c/p\u003e\u003cp data-pid=\"ffdf2zy-\"\u003e其中 \u003cimg src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/\u003e 表示嵌入表索引， \u003cimg src=\"https://www.zhihu.com/equation?tex=g\" alt=\"g\" eeimg=\"1\"/\u003e 为专家模块的门控函数（gating function）， \u003cimg src=\"https://www.zhihu.com/equation?tex=F%28%5Ccdot%29\" alt=\"F(\\cdot)\" eeimg=\"1\"/\u003e 为最终分类器（classifier）。需要注意的是，\u003cb\u003e\u003cu\u003e专家模块 \u003cimg src=\"https://www.zhihu.com/equation?tex=I\" alt=\"I\" eeimg=\"1\"/\u003e 中必须包含ReLU等非线性单元\u003c/u\u003e\u003c/b\u003e，否则该模型将退化为单嵌入范式[21]，完整架构如图1所示。\u003c/p\u003e\u003cp data-pid=\"Xd0dsOCP\"\u003e\u003cu\u003e多嵌入范式为推荐模型规模化提供有效途径\u003c/u\u003e。相较于简单增加共享嵌入（shared embedding）维度，该范式通过为每个特征学习多组嵌入（multiple embeddings）以实现\u003cu\u003e\u003cb\u003e参数扩展（parameter scaling）\u003c/b\u003e\u003c/u\u003e。实验表明，采用此范式后，模型性能随参数规模提升而持续改善。同时学习多组embedding在过去是一项很有挑战的工程[2]。\u003c/p\u003e\u003cp data-pid=\"HeBcSmY-\"\u003e\u003cb\u003e生产环境部署效果\u003c/b\u003e。\u003cu\u003e本平台几乎所有pCTR模型均采用多嵌入范式\u003c/u\u003e。具体实现中，我们同时训练多种特征交互专家模块，包括GwPFM（FFM的改进变体，后文详述）、IPNN[51]、DCN V2和FlatDNN等，并维护多组embedding表。每个专家模块共享其中一组embedding表，我们称其为\u003cb\u003e\u003cu\u003e多嵌入范式异构专家混合架构（Heterogeneous Mixture-of-Experts with Multi-Embedding）\u003c/u\u003e\u003c/b\u003e。这与DHEN[75]方案不同，其采用单一共享embedding表。\u003cu\u003e朋友圈广告场景中，pCTR模型中使用GwPFM、IPNN、FlatDNN三个专家模块及两组embedding表，其中GwPFM与FlatDNN共享第一个embedding表，IPNN使用第二个embedding表，相比其单嵌入模式，朋友圈pCTR模型优化获得3.9%的GMV提升，这是近十年来最显著的效果提升之一\u003c/u\u003e。\u003c/p\u003e\u003ch3\u003e4.3 GwPFM：多嵌入范式的简化实现\u003c/h3\u003e\u003cp data-pid=\"hc9ARlQH\"\u003e场感知因子分解机（FFM）[31]本质上也可视为多嵌入范式的实现形式，其中也学习了特征的多个embedding向量表示。具体地，对含 \u003cimg src=\"https://www.zhihu.com/equation?tex=M\" alt=\"M\" eeimg=\"1\"/\u003e 个字段（fields）的数据集，FFM为每个特征 \u003cimg src=\"https://www.zhihu.com/equation?tex=x_i\" alt=\"x_i\" eeimg=\"1\"/\u003e 学习 \u003cimg src=\"https://www.zhihu.com/equation?tex=M-1\" alt=\"M-1\" eeimg=\"1\"/\u003e 个embedding向量 \u003cimg src=\"https://www.zhihu.com/equation?tex=%5C%7B%5Cbm%7Be%7D_%7Bi%2CF_l%7D+%7CF_l+%5Cne+F%28i%29%5C%7D\" alt=\"\\{\\bm{e}_{i,F_l} |F_l \\ne F(i)\\}\" eeimg=\"1\"/\u003e 。特征\u003cimg src=\"https://www.zhihu.com/equation?tex=x_i\" alt=\"x_i\" eeimg=\"1\"/\u003e与第 \u003cimg src=\"https://www.zhihu.com/equation?tex=j\" alt=\"j\" eeimg=\"1\"/\u003e 个特征交互时，FFM会根据特征 \u003cimg src=\"https://www.zhihu.com/equation?tex=j\" alt=\"j\" eeimg=\"1\"/\u003e 选择 \u003cimg src=\"https://www.zhihu.com/equation?tex=x_i\" alt=\"x_i\" eeimg=\"1\"/\u003e 对应的特征embedding向量，即 \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbm%7Be%7D_%7Bi%2CF_j%7D+\" alt=\"\\bm{e}_{i,F_j} \" eeimg=\"1\"/\u003e ，其中 \u003cimg src=\"https://www.zhihu.com/equation?tex=F%28j%29\" alt=\"F(j)\" eeimg=\"1\"/\u003e 表示特征\u003cimg src=\"https://www.zhihu.com/equation?tex=j\" alt=\"j\" eeimg=\"1\"/\u003e所属字段）。\u003c/p\u003e\u003cp data-pid=\"prF4mxzZ\"\u003e尽管FFM[31]较FM效果更好，但FFM参数量过大，比FM参数量多出 \u003cimg src=\"https://www.zhihu.com/equation?tex=M-2\" alt=\"M-2\" eeimg=\"1\"/\u003e 倍（ \u003cimg src=\"https://www.zhihu.com/equation?tex=M\" alt=\"M\" eeimg=\"1\"/\u003e 通常为数百量级），导致实际工业部署面临巨大的空间复杂度挑战。为此，我们提出\u003cu\u003e将特征embedding数量与字段数量解耦：将 \u003cimg src=\"https://www.zhihu.com/equation?tex=M\" alt=\"M\" eeimg=\"1\"/\u003e 个字段划分为 \u003cimg src=\"https://www.zhihu.com/equation?tex=P\" alt=\"P\" eeimg=\"1\"/\u003e 个字段组（field parts），每个特征仅需学习 \u003cimg src=\"https://www.zhihu.com/equation?tex=+\" alt=\" \" eeimg=\"1\"/\u003e 个embedding向量\u003c/u\u003e。通过设置较小的 \u003cimg src=\"https://www.zhihu.com/equation?tex=P\" alt=\"P\" eeimg=\"1\"/\u003e 值，可有效控制模型总参数量。\u003c/p\u003e\u003cp data-pid=\"efX63cv2\"\u003e为有效捕捉特征字段间（field-pair-wise）相关性以提升模型性能[49]，最直接的方法是计算所有字段对（field pair）的权重，但这将导致 \u003cimg src=\"https://www.zhihu.com/equation?tex=O%28M%5E2%29\" alt=\"O(M^2)\" eeimg=\"1\"/\u003e 的计算复杂度。为降低计算复杂度，我们创新性地将特征字段划分为若干\u003cb\u003e\u003cu\u003e字段群（field groups）\u003c/u\u003e\u003c/b\u003e，仅需学习字段群间的权重。该方法被命名为\u003cb\u003e\u003cu\u003e分组加权感知因子分解机（Group-weighted Part-aware Factorization Machines, GwPFM）\u003c/u\u003e\u003c/b\u003e，公式定义为：\u003c/p\u003e\u003cp data-pid=\"cnm70F4L\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5CPhi+%3D+%5Csum_%7Bi%3D1%7D%5E%5Coplus+%5Csum%5E%5Coplus_%7Bj%3Di%2B1%7D+x_i+x_j+%5Clangle+%5Cbm%7Be%7D_%7Bi%2CP%28j%29%7D%2C+%5Cbm%7Be%7D_%7Bj%2CP%28i%29%7D+%5Crangle+r_%7BG%28i%29%2CG%28j%29%7D+%5Cend%7Bequation%7D\" alt=\"\\begin{equation} \\Phi = \\sum_{i=1}^\\oplus \\sum^\\oplus_{j=i+1} x_i x_j \\langle \\bm{e}_{i,P(j)}, \\bm{e}_{j,P(i)} \\rangle r_{G(i),G(j)} \\end{equation}\" eeimg=\"1\"/\u003e ，  （4）\u003c/p\u003e\u003cp data-pid=\"4oJur1Cn\"\u003e其中\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Coplus+++\" alt=\"\\oplus   \" eeimg=\"1\"/\u003e表示逐元素求和， \u003cimg src=\"https://www.zhihu.com/equation?tex=P%28i%29\" alt=\"P(i)\" eeimg=\"1\"/\u003e 与 \u003cimg src=\"https://www.zhihu.com/equation?tex=G%28j%29\" alt=\"G(j)\" eeimg=\"1\"/\u003e 分别表示特征 \u003cimg src=\"https://www.zhihu.com/equation?tex=i\" alt=\"i\" eeimg=\"1\"/\u003e 所属字段组与字段群， \u003cimg src=\"https://www.zhihu.com/equation?tex=r_%7BG%28i%29%2CG%28j%29%7D\" alt=\"r_{G(i),G(j)}\" eeimg=\"1\"/\u003e为可学习的字段群间权重。\u003c/p\u003e\u003cp data-pid=\"oYQPoB5u\"\u003e\u003cb\u003e生产环境部署效果。\u003c/b\u003e我们将所有特征字段（fields）划分为两部分：第一部分包含与目标广告无关的用户字段（user fields）及上下文字段（context-side fields），第二部分仅含广告相关字段（ad fields）。基于业务领域知识，将第一部分的字段划分为 \u003cimg src=\"https://www.zhihu.com/equation?tex=G\" alt=\"G\" eeimg=\"1\"/\u003e 个字段群（field groups），通常\u003cb\u003e\u003cu\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=G%5Clt50\" alt=\"G\\lt50\" eeimg=\"1\"/\u003e 以控制规模\u003c/u\u003e\u003c/b\u003e。第二部分字段则保持为单一字段群，\u003cb\u003e\u003cu\u003e避免在线推理复杂度激增\u003c/u\u003e\u003c/b\u003e。GwPFM于2018年上线，在多个核心模块与业务场景应用至今。\u003c/p\u003e\u003ch3\u003e4.4 超越多嵌入范式：抗坍缩特征交互（Collapse Resilient Feature Interaction）\u003c/h3\u003e\u003cp data-pid=\"v882UiiD\"\u003e除多嵌入范式外，我们进一步探索特征embedding向量的交互函数优化。传统方法如FM中，采用向量间逐元素内积的计算方式： \u003cimg src=\"https://www.zhihu.com/equation?tex=f%28%5Cbm%7Be%7D_i%2C%5Cbm%7Be%7D_j%29%3D%5Cbm%7Be%7D_i%5Codot+%5Cbm%7Be%7D_j%29\" alt=\"f(\\bm{e}_i,\\bm{e}_j)=\\bm{e}_i\\odot \\bm{e}_j)\" eeimg=\"1\"/\u003e 。但最新研究[30]表明，\u003cu\u003e直接计算embedding间距离会引发维度坍缩现象\u003c/u\u003e。现有的解决方案是，在embedding距离计算前添加投影矩阵（projection matrix）处理，可以有效缓解此问题[30]。\u003c/p\u003e\u003cp data-pid=\"dP-Y-iAI\"\u003e在广告推荐场景中，我们验证发现，在交互计算前，使用\u003cb\u003e\u003cu\u003e字段对投影矩阵（field-pair wise projection matrix）\u003c/u\u003e\u003c/b\u003e \u003cimg src=\"https://www.zhihu.com/equation?tex=+M_%7BF%28i%29%5Crightarrow+F%28j%29%7D+%5Cin+R%5E%7BK%5Ctimes+K%7D\" alt=\" M_{F(i)\\rightarrow F(j)} \\in R^{K\\times K}\" eeimg=\"1\"/\u003e （如FiBiNET、FmFM[58]和DCN V2[66]等模型），能显著抑制嵌入坍缩[21,29]。交互函数形式化定义为：\u003c/p\u003e\u003cp data-pid=\"EBad257s\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+f_%7B%5Ctext%7BProj%7D%7D%28%5Cbm%7Be%7D_i%2C%5Cbm%7Be%7D_j%29+%3D+%28%5Cbm%7Be%7D_i+M_%7BF%28i%29%5Cto+F%28j%29%7D%29+%5Codot+%5Cbm%7Be%7D_j+%5Cend%7Bequation%7D\" alt=\"\\begin{equation} f_{\\text{Proj}}(\\bm{e}_i,\\bm{e}_j) = (\\bm{e}_i M_{F(i)\\to F(j)}) \\odot \\bm{e}_j \\end{equation}\" eeimg=\"1\"/\u003e   (5)\u003c/p\u003e\u003ch2\u003e5 兴趣解耦（INTEREST ENTANGLEMENT）方法\u003c/h2\u003e\u003cp data-pid=\"KG6A6Skq\"\u003e广告推荐系统中，用户行为受特定任务或场景下的兴趣驱动。当前，多任务/多场景联合训练渐成趋势，通过\u003cb\u003e\u003cu\u003e跨场景信息共享\u003c/u\u003e\u003c/b\u003e提升模型精度。然而现有方法（如MMoE[43]与PLE[59]）主要采用\u003cb\u003e\u003cu\u003e共享嵌入范式（shared-embedding paradigm）\u003c/u\u003e\u003c/b\u003e[6,43,48,59,70]，为每个用户和广告学习独立的embedding表征。这将引发\u003cu\u003e不同任务场景下用户兴趣的潜在冲突，造成嵌入表征的纠缠问题[56]，最终导致负迁移效应（negative transfer）\u003c/u\u003e。\u003c/p\u003e\u003cp data-pid=\"kV1ssV6k\"\u003e图3展示了TikTok公开数据集中用户兴趣的耦合性（entanglement of user interest），该数据集包含两个任务：点赞（Like）和完播（Finish）。我们筛选出一组矛盾的用户SS，这些配对在单任务点赞嵌入（single task Like embedding）中的欧氏距离（Euclidean distance）位于后40%（图3a），而在单任务完播嵌入（single task Finish embedding）中却位于前40%（图3b）。我们绘制了这些配对的距离分布情况。\u003c/p\u003e\u003cp data-pid=\"OvRtL_6Y\"\u003e图3揭示了TikTok公开数据集中用户兴趣的纠缠现象（entanglement of user interest），该数据集包含点赞（Like）与完播（Finish）双任务。我们筛选出一组矛盾的user-item对 \u003cimg src=\"https://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"/\u003e ，在点赞单任务的embedding空间中，其欧氏距离（Euclidean distance）位于后40%分位（图3-a）；而在完播单任务的embedding空间中，却位居前40%分位（图3-b）。图3-c展示其在PLE（Progressive Layered Extraction，渐进分层提取）的共享embedding空间中的距离分布，\u003cu\u003ePLE对多数样本学习到较大距离，其分布趋势与完播单任务相似，却与点赞单任务迥异\u003c/u\u003e。\u003c/p\u003e\u003cp data-pid=\"j17yyq-x\"\u003e本节针对多任务场景学习和辅助学习（auxiliary learning）中的兴趣纠缠问题，提出两种解决方案。下文以多任务学习（MTL）为例展开讨论，所述原理同样适用于多场景学习（MSL）。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-a0bbb3298a3d103d5fa346b18d1431be_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2327\" data-rawheight=\"1121\" data-original-token=\"v2-a0bbb3298a3d103d5fa346b18d1431be\" class=\"origin_image zh-lightbox-thumb\" width=\"2327\" data-original=\"https://pic1.zhimg.com/v2-a0bbb3298a3d103d5fa346b18d1431be_r.jpg\"/\u003e\u003cfigcaption\u003e图3：单嵌入MTL模型中的兴趣纠缠现象，及STEM模型的解耦效果。纠缠的user-item对集合S（纯色显示）与全体集合（斜线显示）在不同embedding空间的距离分布：(a)点赞embedding、(b)完播embedding、(c)PLE共享embedding，以及STEM模型中的(d)点赞独立embedding、(e)完播独立embedding和(f)共享embedding\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3\u003e5.1 多任务学习（MTL）的自适应混合专家（AME）架构\u003c/h3\u003e\u003cp data-pid=\"k8ssX6G1\"\u003e为解决兴趣纠缠问题，我们采用\u003cb\u003e\u003cu\u003e共享与任务专属嵌入（Shared and Task-specific EMbedding, STEM）\u003c/u\u003e\u003c/b\u003e范式[56]。\u003cu\u003e通过任务专属embedding学习用户在不同任务中的差异化兴趣，同时保留共享embedding（shared embedding）\u003c/u\u003e。如图3(d)和3(e)所示，\u003cu\u003e任务专属嵌入实现任务间的embedding解耦效果，允许不同任务学习到各自独立的兴趣embedding\u003cb\u003e。\u003c/b\u003e\u003c/u\u003e我们设计了一组专家模块，可以由特定任务独享，也可以多任务共享。针对任务专属塔（task-specific towers），提出\u003cb\u003e\u003cu\u003e全前向-任务专属后向的门控机制（All Forward Task-specific Backward gating mechanism）\u003c/u\u003e\u003c/b\u003e[56]：每个任务塔接收所有专家的前向输出，但仅向对应专家模块和共享专家后向更新梯度。\u003c/p\u003e\u003cp data-pid=\"1dmMfnAw\"\u003e广告pCVR预测场景中，通常将每种广告转化类型视为独立的学习任务[48]。广告实际的生产环境往往包含数十至数百种转化类型[48]，为每个任务单独学习一个embedding表显然不可行。为此，\u003cu\u003e我们首先将转化类型分组，每组作为一个任务单元，同时固定embedding表数量，不受任务分组数量的影响，实现两者解耦。随后，通过门控机制（gating mechanism），动态路由embedding表与任务分组间的连接\u003c/u\u003e。但需注意的是，这些embedding表可能会因对称性（symmetry）而相互纠缠。\u003c/p\u003e\u003cp data-pid=\"lzGIKpHU\"\u003e为此，我们为不同embedding表设置差异化的embedding长度，构建了\u003cb\u003e\u003cu\u003e非对称多嵌入范式（Asymmetric Multi-Embedding paradigm, AME）。\u003c/u\u003e\u003c/b\u003e如图4所示，\u003cu\u003e数据量较少的轻量级任务只需较小的模型容量（model capacity），通过门控机制路由至低维embedding表；数据密集的重量级任务则需更高容量，则被路由至高维embedding表。这种非对称设计有效解决了传统对称架构中嵌入表相互纠缠的问题\u003c/u\u003e。其他解耦学习技术如[39,44]所述方法亦可协同应用。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-fb1f5656e48854099869ffc8b19172ba_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2188\" data-rawheight=\"542\" data-original-token=\"v2-fb1f5656e48854099869ffc8b19172ba\" class=\"origin_image zh-lightbox-thumb\" width=\"2188\" data-original=\"https://pica.zhimg.com/v2-fb1f5656e48854099869ffc8b19172ba_r.jpg\"/\u003e\u003cfigcaption\u003e图4：不同范式的架构对比。多嵌入（ME）范式只适用于单任务学习，不具备表征解耦能力。STEM和AME均适用多任务学习：STEM由任务专属embedding实现表征解耦，而AME则借助不同维度embedding表。STEM-AL（辅助学习版STEM）专为辅助学习设计，为主任务学习专属embedding，通过多任务更新共享embedding。\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"s9MFu4hY\"\u003e\u003cb\u003e与多嵌入（Multi-Embedding, ME）范式的关联分析\u003c/b\u003e。多嵌入范式主要用于解决单任务学习中的嵌入维度坍缩问题。相较而言，共享与任务专属嵌入（STEM）和非对称多嵌入（AME）范式则专注于跨任务场景下的用户兴趣表征解耦。验证发现，\u003cu\u003e当将AME方法应用于pCTR单任务时，相较于ME，性能并无显著提升；而将ME用于多任务学习形成的ME-MMoE方案[56]，效果会逊于STEM[56]和AME。这主要是由于嵌入对称性（symmetric embeddings）引发的多任务间潜在纠缠问题导致\u003c/u\u003e。\u003c/p\u003e\u003cp data-pid=\"pOHGWRm2\"\u003e\u003cb\u003e生产环境部署效果\u003c/b\u003e。我们的pCVR模型，将100+种转化类型进行分组，约30个任务塔（towers）。采用AME范式处理，embedding表的维度分别为16、32和64。验证发现，\u003cu\u003e相较于单embedding范式（维度 \u003cimg src=\"https://www.zhihu.com/equation?tex=K%3D64\" alt=\"K=64\" eeimg=\"1\"/\u003e ）的基线模型PLE，AME在朋友圈、公众号和新闻这三个场景中的平均AUC分别提升0.32%、0.24%和0.48%，带动GMV分别增长4.2%、3.9%和7.1%（ABTest）\u003c/u\u003e。值得注意的是，在小规模任务（如支付转化类型任务）中AUC提升达0.35%、0.27%和0.78%，显著优于大任务。此外，增大PLE模型容量（\u003cimg src=\"https://www.zhihu.com/equation?tex=K%3D128\" alt=\"K=128\" eeimg=\"1\"/\u003e）反而导致性能下降，这一现象印证了单纯增加参数量并非解决之道。\u003c/p\u003e\u003ch3\u003e5.2 基于STEM的辅助学习架构（STEM-based Auxiliary Learning，STEM-AL）\u003c/h3\u003e\u003cp data-pid=\"nZYidB_O\"\u003e在工业级推荐系统中，当需要聚焦主任务（main task）性能提升时，可通过利用辅助任务（auxiliary tasks）的信号特征来增强主任务表现。以pCTR任务为例，核心目标是预测\u003cb\u003e\u003cu\u003e可转化点击（convertible click）\u003c/u\u003e\u003c/b\u003e，这类点击将引导用户进入落地页并最终完成转化。除该关键信号外，系统还收集用户对广告的其他行为数据，包括点赞、收藏、评论、点踩（dislike）以及视频广告停留时长（dwell time）等。借助这些辅助任务，可有效提升主任务的预测性能。\u003c/p\u003e\u003cp data-pid=\"_BG2eWoU\"\u003e为避免辅助任务干扰主任务的用户兴趣表征学习，我们基于STEM范式[56]构建STEM-AL架构。如图4所示，与STEM和AME平等对待所有任务所不同的是，\u003cb\u003e\u003cu\u003eSTEM-AL将任务A设为主任务，任务B作为辅助任务以增强任务A性能\u003c/u\u003e\u003c/b\u003e。该架构包含两个embedding表，及两个对应的交互专家模块。\u003cu\u003e第一个embedding表（亦即主embedding表，main embedding table）专供主任务塔（primary task tower）使用，且仅接收主任务的前向传播与BP传播，以确保主任务表征学习不受其他任务干扰。第二embedding表（亦即共享嵌入表，shared embedding table）则同时服务于两个任务塔，这样主任务可以吸纳辅助任务的知识信息\u003c/u\u003e。在推理阶段，系统仅保留主任务塔，移除辅助任务塔。\u003c/p\u003e\u003cp data-pid=\"-0FJAWcU\"\u003e\u003cb\u003e生产环境部署效果\u003c/b\u003e。我们将STEM-AL架构应用于提升pCTR性能。以小程序场景的pCTR作为主任务，朋友圈场景的pCTR作为辅助任务，采用STEM-AL后，主任务CTR提升1.16%。当同时引入朋友圈和视频号的pCTR作为辅助任务时，小程序场景的CTR提升幅度可达2.93%。\u003c/p\u003e\u003ch2\u003e6 模型训练\u003c/h2\u003e\u003cp data-pid=\"Dtki26lA\"\u003e本节阐述广告模型训练中的若干挑战及解决方案。CTR与CVR预测任务通常建模为监督学习问题，其优化目标为最小化损失函数： \u003cimg src=\"https://www.zhihu.com/equation?tex=+L+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%5Ctext%7BBCE%7D%28y_i%2C+f%28x_i%29%29+\" alt=\" L = \\frac{1}{N}\\sum_{i=1}^{N} \\text{BCE}(y_i, f(x_i)) \" eeimg=\"1\"/\u003e ，其中 \u003cimg src=\"https://www.zhihu.com/equation?tex=y_i%E2%80%8B%3D1\" alt=\"y_i​=1\" eeimg=\"1\"/\u003e 表示正样本（如点击行为）， \u003cimg src=\"https://www.zhihu.com/equation?tex=y_i%E2%80%8B%3D0\" alt=\"y_i​=0\" eeimg=\"1\"/\u003e 表示负样本（如未点击行为）， \u003cimg src=\"https://www.zhihu.com/equation?tex=x_i%E2%80%8B\" alt=\"x_i​\" eeimg=\"1\"/\u003e 为输入特征。二元交叉熵（Binary Cross Entropy）损失函数定义为： \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5Ctext%7BBCE%7D%28y_i%2Cf_i%29+%3D+-y_i+%5Clog+%5Csigma%28f_i%29+-+%281-y_i%29%5Clog%281-%5Csigma%28f_i%29%29+%5Cend%7Bequation%7D\" alt=\"\\begin{equation} \\text{BCE}(y_i,f_i) = -y_i \\log \\sigma(f_i) - (1-y_i)\\log(1-\\sigma(f_i)) \\end{equation}\" eeimg=\"1\"/\u003e 。\u003c/p\u003e\u003ch3\u003e6.1 梯度消失与排序损失（Gradient Vanishing and Ranking Loss）\u003c/h3\u003e\u003cp data-pid=\"EQOs10uB\"\u003e最新研究发现[35,53]，\u003cu\u003e在线广告场景中，结合二元交叉熵损失（BCE loss）与辅助排序损失（auxiliary ranking loss）可显著提升模型性能\u003c/u\u003e。然而，该组合形式的功效机制尚未被充分认知和解释。我们尝试从新的视角[40]展开分析：\u003cu\u003e当正样本稀疏（如pCTR模型中点击率仅0.1%-2%）时，仅使用BCE损失函数时，负样本会出现梯度消失（gradient vanishing）\u003c/u\u003e。实证与理论分析均表明[40]，BCE与排序损失函数组合后梯度显著增大。这一改进使得验证集和训练集上的BCE loss值进一步降低——前者意味着模型分类能力的提升，后者则反映算法优化过程的改善。详细推导建议参阅文献[40]。\u003c/p\u003e\u003cp data-pid=\"UOkx6tHY\"\u003e\u003cb\u003e生产环境部署效果\u003c/b\u003e。该损失组合方案已广泛应用于微信朋友圈和视频号广告的pCTR模型，分别带来0.57%和1.08%的GMV提升。所有pLTV模型部署后，实现5.99%的LTV-GMV增长。此外，\u003cu\u003e该方法有效减少预测偏差，尤其对低预测分值样本效果显著\u003c/u\u003e。\u003c/p\u003e\u003ch3\u003e6.2 重复曝光与加权采样（Weighted Sampling）\u003c/h3\u003e\u003cp data-pid=\"6qqSYJEr\"\u003e重复曝光即短期内向用户重复展示相同或相似广告，此虽能强化广告认知，但可能损害用户体验。为此，我们开发\u003cu\u003e\u003cb\u003e重复曝光权重（Repetitive Exposure Weight, REW）\u003c/b\u003e模块，通过降低重复广告的预测分数来控制其曝光量\u003c/u\u003e。\u003cu\u003e其核心思想是为重复展示的负样本分配更高权重\u003c/u\u003e。\u003c/p\u003e\u003cp data-pid=\"8rsqVT0o\"\u003e具体中，对每个标记为负样本的重复曝光，我们在原始损失函数中设置权重 \u003cimg src=\"https://www.zhihu.com/equation?tex=w_%7Brep%7D+%5Cgeq+1\" alt=\"w_{rep} \\geq 1\" eeimg=\"1\"/\u003e ：\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+L%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7Dw_%7B%5Ctext%7Brep%7D%7D+%5Ccdot+%5Ctext%7BBCE%7D%28y_i%2Cf%28x_i%29%29+%5Cend%7Bequation%7D\" alt=\"\\begin{equation} L=\\frac{1}{N}\\sum_{i=1}^{N}w_{\\text{rep}} \\cdot \\text{BCE}(y_i,f(x_i)) \\end{equation}\" eeimg=\"1\"/\u003e 。该权重综合考量曝光频次（ \u003cimg src=\"https://www.zhihu.com/equation?tex=w_%7B%5Ctext%7Bcount%7D%7D\" alt=\"w_{\\text{count}}\" eeimg=\"1\"/\u003e ）与时间衰减（ \u003cimg src=\"https://www.zhihu.com/equation?tex=w_%7B%5Ctext%7Brecency%7D%7D\" alt=\"w_{\\text{recency}}\" eeimg=\"1\"/\u003e ）：\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+w_%7B%5Ctext%7Brep%7D%7D+%3D+%5Calpha+%5Ccdot+w_%7B%5Ctext%7Bcount%7D%7D+%2B+%281-%5Calpha%29+%5Ccdot+w_%7B%5Ctext%7Brecency%7D%7D+%5Cend%7Bequation%7D\" alt=\"\\begin{equation} w_{\\text{rep}} = \\alpha \\cdot w_{\\text{count}} + (1-\\alpha) \\cdot w_{\\text{recency}} \\end{equation}\" eeimg=\"1\"/\u003e，其中\u003cimg src=\"https://www.zhihu.com/equation?tex=w_%7B%5Ctext%7Bcount%7D%7D\" alt=\"w_{\\text{count}}\" eeimg=\"1\"/\u003e按用户历史曝光次数（经时间衰减）计算，\u003cimg src=\"https://www.zhihu.com/equation?tex=w_%7B%5Ctext%7Brecency%7D%7D\" alt=\"w_{\\text{recency}}\" eeimg=\"1\"/\u003e则基于最近一次重复曝光的时间间隔。值得注意的是，这种加权会导致模型的整体偏差（重复曝光负样本整体提权）。我们通过为正样本引入纠偏权重进行校正：\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+w_%7B%5Ctext%7Bdebias%7D%7D+%3D+%5Cleft%28%5Csum_%7Bi%3D1%7D%5E%7BN%7D%281-y_i%29%5Ccdot+w_%7B%5Ctext%7Brep%7D%7D%2F%5Csum_%7Bi%3D1%7D%5E%7BN%7D%281-y_i%29%5Cright%29+%5Cend%7Bequation%7D\" alt=\"\\begin{equation} w_{\\text{debias}} = \\left(\\sum_{i=1}^{N}(1-y_i)\\cdot w_{\\text{rep}}/\\sum_{i=1}^{N}(1-y_i)\\right) \\end{equation}\" eeimg=\"1\"/\u003e。\u003c/p\u003e\u003cp data-pid=\"u2aqR2Q_\"\u003e\u003cb\u003e生产环境部署效果\u003c/b\u003e。该模块已应用于腾讯公众号、新闻及Video的广告pCTR模型，广告重复曝光率分别降低14.7%、7.8%和9.7%。\u003c/p\u003e\u003ch3\u003e6.3 在线学习与转化延迟回传\u003c/h3\u003e\u003cp data-pid=\"OUvHVp4k\"\u003e我们采用在线学习机制训练pCTR和pCVR模型，训练的样本在实时更新。pCVR模型面临转化延迟反馈的特殊挑战。现有解决方案[8,72]中，当广告延迟转化数据回传出现剧烈波动时，模型会产生显著偏差。例如某些广告主可能不定期集中上报历史转化数据，导致瞬时CVR观测值异常偏高，而在其他时段，广告主又无转化事件上报。为此，我们提出\u003cb\u003e\u003cu\u003e基于转化反馈方差（conversion feedback variance）的动态在线学习方法\u003c/u\u003e\u003c/b\u003e：\u003cu\u003e当方差较小时，表明观测CVR与历史CVR接近，可快速更新样本；当方差较大时，则设置等待时间确保转化数据稳定性，降低因回传波动带来的高偏差风险\u003c/u\u003e。\u003c/p\u003e\u003cp data-pid=\"o0zjZBfT\"\u003e\u003cb\u003e生产环境部署效果\u003c/b\u003e。该方法已应用于腾讯广告多个场景的pCVR模型，包括朋友圈、视频号和公众号。整体GMV提升0.3%、1.49%和1.14%，（上线3天内的）新广告GMV提升达2.48%、0.8%和4.34%。所有场景中新广告的预估偏差超过10%降至1%以内。\u003c/p\u003e\u003ch3\u003e6.4 基于不确定性估计（Uncertainty Estimates）的探索机制\u003c/h3\u003e\u003cp data-pid=\"zW01xp9t\"\u003e截止目前，我们的研究重点在于提升模型对pCTR和pCVR的精准预测能力，以通过广告精排实现收益最大化（maximize exploitation）。并没有过多着墨于模型的探索机制（neglecting the exploration）。然而，大量研究表明，\u003cu\u003e平衡探索与利用机制（E\u0026amp;E）非常重要，特别是对冷启动广告（cold-start ads）\u003c/u\u003e。鉴于此，我们提出采用\u003cu\u003e\u003cb\u003e贝叶斯方式（Bayesian perspective）\u003c/b\u003e\u003c/u\u003e进行CTR建模，相应地，\u003cu\u003e预估模型\u003c/u\u003e不\u003cu\u003e再输出单点估计值，而是预测包含不确定性估计（uncertainty estimations）的概率分布\u003c/u\u003e。\u003c/p\u003e\u003cp data-pid=\"ia7c4PhN\"\u003e具体地，我们引入\u003cu\u003e\u003cb\u003e高斯过程（Gaussian Process, GP）\u003c/b\u003e作为先验分布（prior distribution），用以表征未知的真实CTR函数\u003c/u\u003e。\u003cu\u003e通过观测数据获取后验分布（posterior distribution）的预测值与不确定性估计（uncertainty estimation）\u003c/u\u003e。\u003c/p\u003e\u003cp data-pid=\"IKKITit_\"\u003e通过将高斯过程生成的不确定性估计与经典老虎机算法（bandit algorithms）（特别是汤普森采样，Thompson Sampling, TS）相结合，我们能够有效平衡探索与利用（E\u0026amp;E），从而显著提升长期收益。其数学表达为：\u003c/p\u003e\u003cp data-pid=\"bXRIRdrM\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=pCTR_%7BTS%7D%E2%80%8B%3D%5Csigma%28%5Ctilde%7Bf%7D%E2%80%8B%29%EF%BC%8C%E5%85%B6%E4%B8%AD%5Ctilde%7Bf%7D%E2%80%8B%E2%80%8B%5Csim+N%28%5Cmu%28x%5E%5Cstar%E2%80%8B%29%2C%5Csum_%7B%7D%5E%7B%7D%7B%28x%5E%5Cstar%E2%80%8B%29%7D%29\" alt=\"pCTR_{TS}​=\\sigma(\\tilde{f}​)，其中\\tilde{f}​​\\sim N(\\mu(x^\\star​),\\sum_{}^{}{(x^\\star​)})\" eeimg=\"1\"/\u003e，  （6）\u003c/p\u003e\u003cp data-pid=\"Y3cPbnIi\"\u003e其中， \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cmu%28x%5E%5Cstar%E2%80%8B%29\" alt=\"\\mu(x^\\star​)\" eeimg=\"1\"/\u003e 与 \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Csum_%7B%7D%5E%7B%7D%7B%28x%5E%5Cstar%E2%80%8B%29%7D\" alt=\"\\sum_{}^{}{(x^\\star​)}\" eeimg=\"1\"/\u003e 分别表示测试数据点 \u003cimg src=\"https://www.zhihu.com/equation?tex=x%5E%5Cstar\" alt=\"x^\\star\" eeimg=\"1\"/\u003e对应的后验对数几率(posterior logit) \u003cimg src=\"https://www.zhihu.com/equation?tex=f%28x%5E%5Cstar%29\" alt=\"f(x^\\star)\" eeimg=\"1\"/\u003e 的均值与方差。\u003c/p\u003e\u003cp data-pid=\"bVSQhSkd\"\u003e\u003cb\u003e生产环境部署效果\u003c/b\u003e。基于GP的模型已在微信朋友圈的pCTR模型上线，实现GMV提升1.92%。\u003c/p\u003e\u003ch2\u003e7 分析工具\u003c/h2\u003e\u003cp data-pid=\"g1PHDCL5\"\u003e本节介绍若干表征学习（representation learning）的现成分析工具，用于分析特征相关性（feature correlation）、检测嵌入坍缩（embedding collapse）程度以及用户兴趣纠缠（interest entanglement）现象。相关分析代码已发布在：\u003ca href=\"https://link.zhihu.com/?target=https%3A//github.com/junwei-pan/RecScope\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003egithub.com/junwei-pan/R\u003c/span\u003e\u003cspan class=\"invisible\"\u003eecScope\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e。\u003c/p\u003e\u003ch3\u003e7.1 特征相关性分析（Feature Correlation）\u003c/h3\u003e\u003cp data-pid=\"ar37DqtH\"\u003e我们可通过\u003cb\u003e\u003cu\u003e互信息（mutual information\u003c/u\u003e\u003c/b\u003e）[49,82]量化特征与目标的相关性。一定约束条件下，特征相关性可通过特征 \u003cimg src=\"https://www.zhihu.com/equation?tex=X\" alt=\"X\" eeimg=\"1\"/\u003e 与用户响应 \u003cimg src=\"https://www.zhihu.com/equation?tex=Y\" alt=\"Y\" eeimg=\"1\"/\u003e （亦即label）的互信息 \u003cimg src=\"https://www.zhihu.com/equation?tex=MI\" alt=\"MI\" eeimg=\"1\"/\u003e 来表示。比如针对序列特征（sequential features），度量特定目标类别下行为（behavior）在特定位置\u003cimg src=\"https://www.zhihu.com/equation?tex=X_%7Bcon_b%7D%E2%80%8B%E2%80%8B\" alt=\"X_{con_b}​​\" eeimg=\"1\"/\u003e与目标（target）类别用户响应 \u003cimg src=\"https://www.zhihu.com/equation?tex=Y_%7Bcon_t%7D\" alt=\"Y_{con_t}\" eeimg=\"1\"/\u003e 之间的\u003cb\u003e\u003cu\u003e语义-时序相关性（semantic-temporal correlation）\u003c/u\u003e\u003c/b\u003e。当行为与目标的约束（constraints）条件（如 \u003cimg src=\"https://www.zhihu.com/equation?tex=con_b\" alt=\"con_b\" eeimg=\"1\"/\u003e 与 \u003cimg src=\"https://www.zhihu.com/equation?tex=con_t\" alt=\"con_t\" eeimg=\"1\"/\u003e ）确定后，相关性可量化为：\u003c/p\u003e\u003cp data-pid=\"BPnhVr1m\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=Cor%3DMI%28X_%7Bcon_b%7D%E2%80%8B%E2%80%8B%2CY_%7Bcon_t%7D%E2%80%8B%E2%80%8B%29\" alt=\"Cor=MI(X_{con_b}​​,Y_{con_t}​​)\" eeimg=\"1\"/\u003e ，(7)\u003c/p\u003e\u003cp data-pid=\"Q7Hl4QWK\"\u003e再比如，首先筛选目标类别为 \u003cimg src=\"https://www.zhihu.com/equation?tex=c_t\" alt=\"c_t\" eeimg=\"1\"/\u003e 的样本子集，随后对类别为\u003cimg src=\"https://www.zhihu.com/equation?tex=c_t\" alt=\"c_t\" eeimg=\"1\"/\u003e和不同位置 \u003cimg src=\"https://www.zhihu.com/equation?tex=p\" alt=\"p\" eeimg=\"1\"/\u003e （或不同时间间隔）的行为特征，其相关性可表示为：\u003c/p\u003e\u003cp data-pid=\"vK59jxMZ\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=Cor%3DMI%28X_%7BC%28X%29%3Dc_i%E2%80%8B%5Cwedge+P%28X%29%3Dp%7D%E2%80%8B%2CY_%7BC%28Y%29%3Dc_t%E2%80%8B%7D%E2%80%8B%29\" alt=\"Cor=MI(X_{C(X)=c_i​\\wedge P(X)=p}​,Y_{C(Y)=c_t​}​)\" eeimg=\"1\"/\u003e ，(8)\u003c/p\u003e\u003cp data-pid=\"Z34QvARN\"\u003e通过该度量方法，我们观察到两类显著的相关性：其一为\u003cb\u003e\u003cu\u003e语义相关性​（semantic correlation）\u003c/u\u003e\u003c/b\u003e，目标同类的用户行为，比非同类行为有更强的关联性；其二为\u003cb\u003e\u003cu\u003e时序相关性​（temporal correlation）\u003c/u\u003e\u003c/b\u003e，最近行为比时序较远行为的关联强度呈现显著衰减趋势。详见文献[82]。\u003c/p\u003e\u003ch3\u003e7.2 嵌入维度坍缩（Embedding Dimensional Collapse）\u003c/h3\u003e\u003cp data-pid=\"8wfkZ76d\"\u003e当嵌入向量（embedding vectors）的分布局限于低维子空间时，即发生维度坍缩（dimensional collapse）现象。参照文献[30]的方法，可通过各特征字段的embedding矩阵进行奇异值分解（SVD）进行量化维度坍缩情况。特别地，给定特征字段 \u003cimg src=\"https://www.zhihu.com/equation?tex=i\" alt=\"i\" eeimg=\"1\"/\u003e 的嵌入矩阵 \u003cimg src=\"https://www.zhihu.com/equation?tex=E_i+%5Cin+R%5E%7BN_i+%5Ctimes+K%7D\" alt=\"E_i \\in R^{N_i \\times K}\" eeimg=\"1\"/\u003e ，经SVD分解\u003cimg src=\"https://www.zhihu.com/equation?tex=E_i%3DU%5Csum+V%5E%5Cast%2C+%5Csum+%3Ddiag%28%5Csigma%5Ek%29\" alt=\"E_i=U\\sum V^\\ast, \\sum =diag(\\sigma^k)\" eeimg=\"1\"/\u003e ，后获取奇异值 \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Csigma%5Ek\" alt=\"\\sigma^k\" eeimg=\"1\"/\u003e 。若部分奇异值过小，则表明存在维度坍缩。进一步，可采用\u003cb\u003e\u003cu\u003e信息丰度（Information Abundance, IA）\u003c/u\u003e\u003c/b\u003e[21]指标来量化embedding矩阵的坍缩程度，其定义为所有奇异值之和与最大奇异值的比值：\u003c/p\u003e\u003cp data-pid=\"7CmshQ_I\"\u003e​\u003cb\u003e定义7.1（信息丰度IA）​\u003c/b\u003e​：设矩阵 \u003cimg src=\"https://www.zhihu.com/equation?tex=E%5Cin+R%5E%7BD%5Ctimes+K%7D\" alt=\"E\\in R^{D\\times K}\" eeimg=\"1\"/\u003e 及其奇异值分解 \u003cimg src=\"https://www.zhihu.com/equation?tex=E+%3D+U%5Csum+V+%3D+%5Csum_%7Bk%3D1%7D%5EK+%5Csigma_k+u_k+v_k%5ET\" alt=\"E = U\\sum V = \\sum_{k=1}^K \\sigma_k u_k v_k^T\" eeimg=\"1\"/\u003e ，则 \u003cimg src=\"https://www.zhihu.com/equation?tex=E\" alt=\"E\" eeimg=\"1\"/\u003e 的信息丰度（Information Abundance, IA）为\u003c/p\u003e\u003cp data-pid=\"OsRLHUC8\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=IA%28E%29%3D%5Cfrac%7B%7C%7C%5Csigma%7C%7C_1%7D%7B%7C%7C%5Csigma%7C%7C_%5Cinfty%7D\" alt=\"IA(E)=\\frac{||\\sigma||_1}{||\\sigma||_\\infty}\" eeimg=\"1\"/\u003e \u003c/p\u003e\u003ch3\u003e7.3 兴趣纠缠（Interest Entanglement）\u003c/h3\u003e\u003cp data-pid=\"HJbcSAag\"\u003e广告推荐系统中，用户响应的决策背后受多因素驱动，可通过如下方法分析其纠缠现象。首先，筛选embedding表征矛盾的user-item对集合 \u003cimg src=\"https://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"/\u003e （其embedding距离在任务A中较大而在任务B中较小）；其次，绘制\u003cimg src=\"https://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"/\u003e基于以下任务类型的embedding距离分布：a) 单任务模型；b) 共享嵌入（shared-embedding）多任务模型（如PLE）；c) STEM中各任务专属embedding与共享嵌入。图3已展示此类分析实例。\u003c/p\u003e\u003ch2\u003e8 相关工作\u003c/h2\u003e\u003cp data-pid=\"rxmX1xz2\"\u003e\u003cb\u003e特征编码（Feature Encoding）\u003c/b\u003e———用户行为序列建模已有广泛研究[10,17,25,32,50,57,80,81]。数值特征处理可分为非离散化方法[13,47,51]与离散化方法[9,19]两类。随着大语言模型（LLM）研究的快速发展，\u003cb\u003e\u003cu\u003e如何利用这些外部预训练模型的嵌入表征成为推荐系统的新研究方向\u003c/u\u003e\u003c/b\u003e[26,27,36,38,73,79]。\u003c/p\u003e\u003cp data-pid=\"SZQbH6or\"\u003e\u003cb\u003e特征交互与维度坍缩（Dimensional Collapse）\u003c/b\u003e———显式/隐式特征交互的骨干架构（backbone architecture）研究已相当丰富，从浅层模型FM[52]、FFM[31]、FwFM[49]和FmFM[58]，到深度模型Wide \u0026amp; Deep[12]、DeepFM[20]、xDeepFM[37]、AutoInt[55]、DCN V2[66]和FinalMLP[45]，详见综述[71,76]。\u003cb\u003e\u003cu\u003e完全坍缩（complete collapse）现象\u003c/u\u003e\u003c/b\u003e在自监督学习（SSL）[11,67]与专家混合系统（MoE）[30]中已有深入研究，而维度坍缩问题则在自监督学习[28]与对比学习（contrastive learning）[30]领域获得关注。\u003c/p\u003e\u003cp data-pid=\"s6dGO7SA\"\u003e\u003cu\u003e\u003cb\u003eMTL与TDL中的兴趣纠缠（Interest Entanglement）\u003c/b\u003e———\u003cb\u003e负迁移（negative transfer）\u003c/b\u003e\u003c/u\u003e始终是多任务学习（MTL）与多领域学习（MDL）的核心挑战。共享嵌入范式在MTL[6,43,48,59,70]和MDL[7,54,83]中被广泛采用。解耦表征学习（Disentangled Representation Learning，DRL）旨在识别并分离embeddings中的潜在解释因子（underlying explanatory factors）[3]，该技术也已广泛应用于推荐系统[39,44,68,69]。\u003c/p\u003e\u003cp data-pid=\"g9iCe1AE\"\u003e\u003cb\u003e工业级系统\u003c/b\u003e———现有工业级推荐系统研究[13,14,15,24,42,46,65,74]多聚焦工程实现，而本研究更侧重表征学习问题，特别是从维度坍缩与兴趣纠缠角度进行探讨。\u003c/p\u003e\u003ch2\u003e9 结论\u003c/h2\u003e\u003cp data-pid=\"OBoD8zDJ\"\u003e本文系统阐述了工业级广告推荐系统的设计与实践。重点从表征学习（representation learning）视角出发：提出基于固有先验知识（inherent priors）的特征编码方法，给出维度坍缩（dimensional collapse）与兴趣纠缠（interest entanglement）问题的解决方案，并分享若干训练经验与分析工具。期待本研究能为该领域的未来发展提供启示。\u003c/p\u003e\u003ch2\u003e致谢\u003c/h2\u003e\u003cp data-pid=\"bQXqwbSY\"\u003e谨此向以下同仁（音译，按姓氏拼音排序）致以诚挚谢意，感谢他们所作的重要贡献：蔡晨、蔡成飞、陈根保、陈荣、陈细华、程俊文、程曦、崔畅、邓超、邓贵和、邓慧婷、邓一鸣、冯志祥、顾海杰、顾卫波、郭超男、胡贤、黄荣庚、黄树东、江仁杰、蒋亭宇、康俊峰、康凯、孔维杰、李彪、李聪、李凯欣、李玲玲、李锐、李晓波、李毅、李玉雄、李昭华、林力伟、刘文博、刘越、刘子君、卢华、罗飞衡、吕超、牟磊、欧阳震、任帅、石学宇、宋勋、孙佳瑜、谭燕、汤辉、王恒欢、王宏发、王少颖、王晓晨、王媛、温世峰、翁耕雨、吴海洋、吴钦臣、吴瑞倩、吴正涛、吴志远、邢大田、熊腾飞、徐升、徐泽恩、杨月奎、杨兆焕、叶长安、尹成国、应秋芳、游九龙、岳明、曾迪飞、曾子建、翟俊杰、张安然、张浩然、张继红、张阔、张凌寒、张瑞峰、张上玉、张天津、张雅倩、赵文哲、郑宇飞、钟尔恒、周龙沙、周琦。\u003c/p\u003e\u003ch2\u003e参考文献\u003c/h2\u003e\u003cblockquote data-pid=\"JvBRK5Sb\"\u003e[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 (2023).\u003cbr/\u003e[2] Newsha Ardalani, Carole-Jean Wu, Zeliang Chen, Bhargav Bhushanam, and Adnan Aziz. 2022. Understanding Scaling Laws for Recommendation Models. arXiv preprint arXiv:2208.08489 (2022).\u003cbr/\u003e[3] Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence 35, 8 (2013), 1798-1828.\u003cbr/\u003e[4] Yoshua Bengio and Olivier Delalleau. 2011. On the expressive power of deep architectures. In International conference on algorithmic learning theory. Springer, 18-36.\u003cbr/\u003e[5] Yoshua Bengio, Olivier Delalleau, and Nicolas Roux. 2005. The curse of highly variable functions for local kernel machines. Advances in neural information processing systems 18 (2005).\u003cbr/\u003e[6] Rich Caruana. 1997. Multitask learning. Machine learning 28, 1 (1997), 41-75.\u003cbr/\u003e[7] Jianxin Chang, Chenbin Zhang, Yiqun Hui, Dewei Leng, Yanan Niu, Yang Song, and Kun Gai. 2023. Pepnet: Parameter and embedding personalized network for infusing with personalized prior information. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 3795-3804.\u003cbr/\u003e[8] Olivier Chapelle. 2014. Modeling delayed feedback in display advertising. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 1097-1105.\u003cbr/\u003e[9] Bo Chen, Huifeng Guo, Weiwen Liu, Yue Ding, Yunzhe Li, Wei Guo, Yichao Wang, Zhicheng He, Ruiming Tang, and Rui Zhang. 2022. Numerical Feature Representation with Hybrid N-ary Encoding. In Proceedings of the 31st ACM International Conference on Information \u0026amp; Knowledge Management. 2984-2993.\u003cbr/\u003e[10] Qiwei Chen, Huan Zhao, Wei Li, Pipei Huang, and Wenwu Ou. 2019. Behavior sequence transformer for e-commerce recommendation in alibaba. In Proceedings of the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data. 1-4.\u003cbr/\u003e[11] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A simple framework for contrastive learning of visual representations. In International conference on machine learning. PMLR, 1597-1607.\u003cbr/\u003e[12] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide \u0026amp; deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems. 7-10.\u003cbr/\u003e[13] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In Proceedings of the 10th ACM conference on recommender systems. 191-198.\u003cbr/\u003e[14] Daniel Crankshaw, Xin Wang, Guilio Zhou, Michael J Franklin, Joseph E Gonzalez, and Ion Stoica. 2017. Clipper: A {Low-Latency}online prediction serving system. In 14th USENIX Symposium on Networked Systems Design and Implementation (NSDI 17). 613-627.\u003cbr/\u003e[15] James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, et al. 2010. The YouTube video recommendation system. In Proceedings of the fourth ACM conference on Recommender systems. 293-296.\u003cbr/\u003e[16] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).\u003cbr/\u003e[17] Yufei Feng, Fuyu Lv, Weichen Shen, Menghan Wang, Fei Sun, Yu Zhu, and Keping Yang. 2019. Deep session interest network for click-through rate prediction. In International Joint Conference on Artificial Intelligence (IJCAI). 2301-2307.\u003cbr/\u003e[18] Tao Gong, Chengqi Lyu, Shilong Zhang, Yudong Wang, Miao Zheng, Qian Zhao, Kuikun Liu, Wenwei Zhang, Ping Luo, and Kai Chen. 2023. Multimodal-gpt: A vision and language model for dialogue with humans. arXiv preprint arXiv:2305.04790 (2023).\u003cbr/\u003e[19] Huifeng Guo, Bo Chen, Ruiming Tang, Weinan Zhang, Zhenguo Li, and Xiuqiang He. 2021. An embedding learning framework for numerical features in ctr prediction. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \u0026amp; Data Mining. 2910-2918.\u003cbr/\u003e[20] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017).\u003cbr/\u003e[21] Xingzhuo Guo, Junwei Pan, Ximei Wang, Baixu Chen, Jie Jiang, and Mingsheng Long. 2024. On the Embedding Collapse when Scaling up Recommendation Models. International Conference on Machine Learning (ICML) (2024).\u003cbr/\u003e[22] Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. Advances in neural information processing systems 30 (2017).\u003cbr/\u003e[23] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770-778.\u003cbr/\u003e[24] Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, et al. 2014. Practical lessons from predicting clicks on ads at facebook. In International Workshop on Data Mining for Online Advertising (ADKDD). 1-9.\u003cbr/\u003e[25] Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939 (2015).\u003cbr/\u003e[26] Yupeng Hou, Zhankui He, Julian McAuley, and Wayne Xin Zhao. 2023. Learning vector-quantized item representation for transferable sequential recommenders. In Proceedings of the ACM Web Conference 2023. 1162-1171.\u003cbr/\u003e[27] Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, and Ji-Rong Wen. 2022. Towards universal sequence representation learning for recommender systems. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 585-593.\u003cbr/\u003e[28] Tianyu Hua, Wenxiao Wang, Zihui Xue, Sucheng Ren, Yue Wang, and Hang Zhao. 2021. On feature decorrelation in self-supervised learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 9598-9608.\u003cbr/\u003e[29] Tongwen Huang, Zhiqi Zhang, and Junlin Zhang. 2019. FiBiNET: combining feature importance and bilinear feature interaction for click-through rate prediction. In Proceedings of the 13th ACM Conference on Recommender Systems. 169-177.\u003cbr/\u003e[30] Li Jing, Pascal Vincent, Yann LeCun, and Yuandong Tian. 2021. Understanding Dimensional Collapse in Contrastive Self-supervised Learning. In ICLR.\u003cbr/\u003e[31] Yuchin Juan, Yong Zhuang, Wei-Sheng Chin, and Chih-Jen Lin. 2016. Field-aware factorization machines for CTR prediction. In Proceedings of the 10th ACM Conference on Recommender Systems (RecSys). 43-50.\u003cbr/\u003e[32] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 197-206.\u003cbr/\u003e[33] Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization techniques for recommender systems. Computer 42, 8 (2009), 30-37.\u003cbr/\u003e[34] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classification with deep convolutional neural networks. In NeurIPS.\u003cbr/\u003e[35] Cheng Li, Yue Lu, Qiaozhu Mei, Dong Wang, and Sandeep Pandey. 2015. Click-through prediction for advertising in twitter timeline. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1959-1968.\u003cbr/\u003e[36] Xiangyang Li, Bo Chen, Lu Hou, and Ruiming Tang. 2023. CTRL: Connect Tabular and Language Model for CTR Prediction. arXiv preprint arXiv:2306.02841 (2023).\u003cbr/\u003e[37] Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xdeepfm: Combining explicit and implicit feature interactions for recommender systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD). 1754-1763.\u003cbr/\u003e[38] Jianghao Lin, Bo Chen, Hangyu Wang, Yunjia Xi, Yanru Qu, Xinyi Dai, Kangning Zhang, Ruiming Tang, Yong Yu, and Weinan Zhang. 2024. ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction. In Proceedings of the ACM on Web Conference 2024. 3319-3330.\u003cbr/\u003e[39] Zhutian Lin, Junwei Pan, Haibin Yu, Xi Xiao, Ximei Wang, Zhixiang Feng, Shifeng Wen, Shudong Huang, Lei Xiao, and Jie Jiang. 2024. Disentangled Representation with Cross Experts Covariance Loss for Multi-Domain Recommendation. arXiv preprint arXiv:2405.12706 (2024).\u003cbr/\u003e[40] Zhutian Lin, Juwei Pan, Shangyu Zhang, Ximei Wang, Xi Xiao, Shudong Huang, Lei Xiao, and Jie Jiang. 2024. Understanding the Ranking Loss for Recommendation with Sparse User Feedback. In ACM SIGKDD International Conference on Knowledge Discovery \u0026amp; Data Mining (KDD).\u003cbr/\u003e[41] Fan Liu, Huilin Chen, Zhiyong Cheng, Anan Liu, Liqiang Nie, and Mohan Kankanhalli. 2022. Disentangled multimodal representation learning for recommendation. IEEE Transactions on Multimedia (2022).\u003cbr/\u003e[42] Quan Lu, Shengjun Pan, Liang Wang, Junwei Pan, Fengdan Wan, and Hongxia Yang. 2017. A practical framework of conversion rate prediction for online display advertising. In Proceedings of the ADKDD\u0026#39;17. 1-9.\u003cbr/\u003e[43] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H. Chi. 2018. Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts. In KDD. ACM, 1930-1939.\u003cbr/\u003e[44] Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, and Wenwu Zhu. 2019. Learning disentangled representations for recommendation. Advances in neural information processing systems 32 (2019).\u003cbr/\u003e[45] Kelong Mao, Jieming Zhu, Liangcai Su, Guohao Cai, Yuru Li, and Zhenhua Dong. 2023. FinalMLP: An Enhanced Two-Stream MLP Model for CTR Prediction. arXiv preprint arXiv:2304.00902 (2023).\u003cbr/\u003e[46] H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et al. 2013. Ad click prediction: a view from the trenches. In ACM SIGKDD International conference on Knowledge Discovery \u0026amp; Data Mining (KDD). 1222-1230.\u003cbr/\u003e[47] Maxim Naumov, Dheevatsa Mudigere, Hao-Jun Michael Shi, Jianyu Huang, Narayanan Sundaraman, Jongsoo Park, Xiaodong Wang, Udit Gupta, Carole-Jean Wu, Alisson G Azzolini, et al. 2019. Deep learning recommendation model for personalization and recommendation systems. arXiv preprint arXiv:1906.00091 (2019).\u003cbr/\u003e[48] Junwei Pan, Yizhi Mao, Alfonso Lobos Ruiz, Yu Sun, and Aaron Flores. 2019. Predicting different types of conversions with multi-task learning in online advertising. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026amp; Data Mining. 2689-2697.\u003cbr/\u003e[49] Junwei Pan, Jian Xu, Alfonso Lobos Ruiz, Wenliang Zhao, Shengjun Pan, Yu Sun, and Quan Lu. 2018. Field-weighted factorization machines for click-through rate prediction in display advertising. In Proceedings of the 2018 World Wide Web Conference (WWW). 1349-1357.\u003cbr/\u003e[50] Qi Pi, Guorui Zhou, Yujing Zhang, Zhe Wang, Lejian Ren, Ying Fan, Xiaoqiang Zhu, and Kun Gai. 2020. Search-based user interest modeling with lifelong sequential behavior data for click-through rate prediction. In ACM International Conference on Information \u0026amp; Knowledge Management (CIKM). 2685-2692.\u003cbr/\u003e[51] Yanru Qu, Han Cai, Kan Ren, Weinan Zhang, Yong Yu, Ying Wen, and Jun Wang. 2016. Product-based neural networks for user response prediction. In 2016 IEEE 16th International Conference on Data Mining (ICDM). IEEE, 1149-1154.\u003cbr/\u003e[52] Steffen Rendle. 2010. Factorization machines. In 2010 IEEE International Conference on Data Mining (ICDM). IEEE, 995-1000.\u003cbr/\u003e[53] Xiang-Rong Sheng, Jingyue Gao, Yueyao Cheng, Siran Yang, Shuguang Han, Hongbo Deng, Yuning Jiang, Jian Xu, and Bo Zheng. 2023. Joint Optimization of Ranking and Calibration with Contextualized Hybrid Model. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 4813-4822.\u003cbr/\u003e[54] Xiang-Rong Sheng, Liqin Zhao, Guorui Zhou, Xinyao Ding, Binding Dai, Qiang Luo, Siran Yang, Jingshan Lv, Chi Zhang, Hongbo Deng, et al. 2021. One model to serve all: Star topology adaptive recommender for multi-domain ctr prediction. In Proceedings of the 30th ACM International Conference on Information \u0026amp; Knowledge Management. 4104-4113.\u003cbr/\u003e[55] Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming Zhang, and Jian Tang. 2019. Autoint: Automatic feature interaction learning via self-attentive neural networks. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM). 1161-1170.\u003cbr/\u003e[56] Liangcai Su, Junwei Pan, Ximei Wang, Xi Xiao, Shijie Quan, Xihua Chen, and Jie Jiang. 2024. STEM: Unleashing the Power of Embeddings for Multi-task Recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 38. 9002-9010.\u003cbr/\u003e[57] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In ACM International Conference on Information and Knowledge Management (CIKM). 1441-1450.\u003cbr/\u003e[58] Yang Sun, Junwei Pan, Alex Zhang, and Aaron Flores. 2021. Fm2: Field-matrixed factorization machines for recommender systems. In Proceedings of the Web Conference 2021. 2828-2837.\u003cbr/\u003e[59] Hongyan Tang, Junning Liu, Ming Zhao, and Xudong Gong. 2020. Progressive Layered Extraction (PLE): A Novel Multi-Task Learning (MTL) Model for Personalized Recommendations. In RecSys. ACM, 269-278.\u003cbr/\u003e[60] Zhen Tian, Ting Bai, Wayne Xin Zhao, Ji-Rong Wen, and Zhao Cao. 2023. Euler-Net: Adaptive Feature Interaction Learning via Euler\u0026#39;s Formula for CTR Prediction. arXiv preprint arXiv:2304.10711 (2023).\u003cbr/\u003e[61] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023).\u003cbr/\u003e[62] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NeurIPS.\u003cbr/\u003e[63] Fangye Wang, Yingxu Wang, Dongsheng Li, Hansu Gu, Tun Lu, Peng Zhang, and Ning Gu. 2023. CL4CTR: A Contrastive Learning Framework for CTR Prediction. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining. 805-813.\u003cbr/\u003e[64] Hongya Wang, Jiao Cao, LihChyun Shu, and Davood Rafiei. 2013. Locality sensitive hashing revisited: filling the gap between theory and algorithm analysis. In Proceedings of the 22nd ACM International Conference on Information \u0026amp; Knowledge Management. 1969-1978.\u003cbr/\u003e[65] Jun Wang, Weinan Zhang, Shuai Yuan, et al. 2017. Display advertising with real-time bidding (RTB) and behavioural targeting. Foundations and Trends® in Information Retrieval 11, 4-5 (2017), 297-435.\u003cbr/\u003e[66] Ruoxi Wang, Rakesh Shivanna, Derek Cheng, Sagar Jain, Dong Lin, Lichan Hong, and Ed Chi. 2021. DCN-V2: Improved deep \u0026amp; cross network and practical lessons for web-scale learning to rank systems. In Proceedings of the Web Conference. 1785-1797.\u003cbr/\u003e[67] Tongzhou Wang and Phillip Isola. 2020. Understanding contrastive representation learning through alignment and uniformity on the hypersphere. In International Conference on Machine Learning. PMLR, 9929-9939.\u003cbr/\u003e[68] Xin Wang, Hong Chen, Si\u0026#39;ao Tang, Zihao Wu, and Wenwu Zhu. 2022. Disentangled representation learning. arXiv preprint arXiv:2211.11695 (2022).\u003cbr/\u003e[69] Xin Wang, Hong Chen, Yuwei Zhou, Jianxin Ma, and Wenwu Zhu. 2022. Disentangled representation learning for recommendation. IEEE Transactions on Pattern Analysis and Machine Intelligence 45, 1 (2022), 408-424.\u003cbr/\u003e[70] Enneng Yang, Junwei Pan, Ximei Wang, Haibin Yu, Li Shen, Xihua Chen, Lei Xiao, Jie Jiang, and Guibing Guo. 2023. Adatask: A task-aware adaptive learning rate approach to multi-task learning. In Proceedings of the AAAI Conference on Artificial Intelligence. 10745-10753.\u003cbr/\u003e[71] Yanwu Yang and Panyu Zhai. 2022. Click-through rate prediction in online advertising: A literature review. Information Processing \u0026amp; Management 59, 2 (2022), 102853.\u003cbr/\u003e[72] Shota Yasui, Gota Morishita, Fujita Komei, and Masashi Shibata. 2020. A feedback shift correction in predicting conversion rates under delayed feedback. In Proceedings of The Web Conference 2020. 2740-2746.\u003cbr/\u003e[73] Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, Yunzhu Pan, and Yongxin Ni. 2023. Where to go next for recommender systems? id-vs. modality-based recommender models revisited. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2639-2649.\u003cbr/\u003e[74] Jiaqi Zhai, Lucy Liao, Xing Liu, Yueming Wang, Rui Li, Xuan Cao, Leon Gao, Zhaojie Gong, Fangda Gu, Michael He, et al. 2024. Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations. arXiv preprint arXiv:2402.17152 (2024).\u003cbr/\u003e[75] Buyun Zhang, Liang Luo, Xi Liu, Jay Li, Zeliang Chen, Weilin Zhang, Xiaohan Wei, Yuchen Hao, Michael Tsang, Wenjun Wang, et al. 2022. DHEN: A deep and hierarchical ensemble network for large-scale click-through rate prediction. arXiv preprint arXiv:2203.11014 (2022).\u003cbr/\u003e[76] Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2019. Deep learning based recommender system: A survey and new perspectives. ACM computing surveys (CSUR) 52, 1 (2019), 1-38.\u003cbr/\u003e[77] Weinan Zhang, Jiarui Qin, Wei Guo, Ruiming Tang, and Xiuqiang He. 2021. Deep learning for click-through rate estimation. arXiv preprint arXiv:2104.10584 (2021).\u003cbr/\u003e[78] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. A survey of large language models. arXiv preprint arXiv:2303.18223 (2023).\u003cbr/\u003e[79] Bowen Zheng, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, and Ji-Rong Wen. 2023. Adapting large language models by integrating collaborative semantics for recommendation. arXiv preprint arXiv:2311.09049 (2023).\u003cbr/\u003e[80] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Deep interest evolution network for click-through rate prediction. In AAAI Conference on Artificial Intelligence. 5941-5948.\u003cbr/\u003e[81] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In ACM SIGKDD International Conference on Knowledge Discovery \u0026amp; Data Mining. 1059-1068.\u003cbr/\u003e[82] Haolin Zhou, Junwei Pan, Xinyi Zhou, Xihua Chen, Jie Jiang, Xiaofeng Gao, and Guihai Chen. 2024. Temporal Interest Network for User Response Prediction. In Companion Proceedings of the ACM on Web Conference 2024. 413-422.\u003cbr/\u003e[83] Jie Zhou, Xianshuai Cao, Wenhao Li, Kun Zhang, Chuan Luo, and Qian Yu. 2023. HiNet: A Novel Multi-Scenario \u0026amp; Multi-Task Learning Approach with Hierarchical Information Extraction. arXiv preprint arXiv:2303.06095 (2023).\u003cbr/\u003e[84] Kun Zhou, Hui Wang, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng Zhang, Zhongyuan Wang, and Ji-Rong Wen. 2020. S3-rec: Self-supervised learning for sequential recommendation with mutual information maximization. In Proceedings of the 29th ACM international conference on information \u0026amp; knowledge management. 1893-1902.\u003c/blockquote\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":232,"thumbnails":["https://picx.zhimg.com/50/v2-47bf0a3672e9487ba534bd1ba3cce4d0_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-a199c67e314f2698c49415f88d00395b_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-0a474aabbca3524d3d6a95f49516f6af_720w.jpg?source=b6762063"],"favorite_count":25,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1918399620058452261}","attached_info":"Cq0HCMuQ6NOAqcv3owEQBBoJNzMyNjg2MDIxIL+1xcIGKAowAEB9SkEKLFRTX1NPVVJDRV9UV09UT1dFUl9TSE9SVElOVEVSRVNUX1JFQ0FMTF9URVhUEgEwGAAgADoKeyJyYXciOiIifVoINjA4NTYwNzhiIDZhNWYzZmQ0OWI2NzQwOGU3MzM3ZmZlOTkzODdlODE2chMxOTE4Mzk5NjIwMDU4NDUyMjYxigEJNDQzNTk5ODYxqgEJcmVjb21tZW5kwgEgMWI2ZjBlMzljMzY2NzJhNGZjNTIyMWY3ZWVhMjhlNDXyAQoIDBIGTm9ybWFs8gEoCAoSJDJlYjE3YmExLWM1MTItNGE2MS1hZDk1LTNiNjYyNjRhY2ViOPIBBggLEgIyMYICAIgCpZHazfoykgIgMWI2ZjBlMzljMzY2NzJhNGZjNTIyMWY3ZWVhMjhlNDWaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygIcQmF5ZXNGaXJzdExldmVsSXNvbGF0aW9uUnVsZdoCLFRTX1NPVVJDRV9UV09UT1dFUl9TSE9SVElOVEVSRVNUX1JFQ0FMTF9URVhU6AID+gILTk9STUFMX0ZMT1eKAyAwY2Y0ZmFlOWVjNTE0MjNhODY5ZTU0OWVlYzYxMDRjYZoDDQoCdjIQABoFb3RoZXKoA+gB2AMA6gMaZmVlZF9hdHRtX3R3b3Rvd2VyX3YyX3RleHT6A9sBEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERTotCAIQwCAYrhAiI3YyLTRjYmNjNDEwMmYwMDdhM2M5ZmI0ZGU5M2ZhMzE0NzQ3Oi0IAhCVExjIBiIjdjItYWRlZTdiYmU5M2NjMGU1MDUwODM2ZTkxNjU5OWYxYjM6LQgDEJcSGOEIIiN2Mi1hMGJiYjMyOThhM2QxMDNkNWZhMzQ2YjE4ZDE0MzFiZTotCAMQjBEYngQiI3YyLWZiMWY1NjU2ZTQ4ODU0MDk5ODY5ZmZjOGIxOTE3MmJhgAQAiAQAkgQGTm9ybWFsmgQBM6AEAKgEALAEALoEAmFpwgQDNDAwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAACA6SiTP4EFAAAAAAAAAACJBY+rjq7zhdI/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBRWQBgCgBn6oBgCSAi4KCTczMjY4NjAyMRITMTkxODM5OTYyMDA1ODQ1MjI2MRgEIgpJTUFHRV9URVhU","action_card":false}],"paging":{"is_end":false,"is_start":false,"next":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=down\u0026ad_interval=-10\u0026after_id=125\u0026desktop=true\u0026end_offset=126\u0026page_number=22\u0026session_token=6a5f3fd49b67408e7337ffe99387e816","previous":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=pull\u0026ad_interval=-10\u0026before_id=125\u0026desktop=true\u0026end_offset=126\u0026page_number=22\u0026session_token=6a5f3fd49b67408e7337ffe99387e816","totals":0},"fresh_text":"推荐已更新"}
