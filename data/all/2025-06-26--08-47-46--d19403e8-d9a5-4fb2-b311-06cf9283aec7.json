{"data":[{"id":"48_1750898911.638","type":"feed","offset":48,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750898911,"updated_time":1750898911,"target":{"id":"1884533787947406755","type":"article","url":"https://api.zhihu.com/articles/1884533787947406755","author":{"id":"40c307d000bf6ee3e803a5fe29386619","url":"https://api.zhihu.com/people/40c307d000bf6ee3e803a5fe29386619","user_type":"people","url_token":"mindsriverponder","name":"MindsRiverPonder","headline":"深度学习爱好者","avatar_url":"https://pic1.zhimg.com/50/v2-97f7ca03829398ea8716877782a1ee10_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":550,"is_following":false,"is_followed":false},"title":"RAG手把手制作教程::使用QwQ-plus API+streamlit快速构建RAG","image_url":"https://picx.zhimg.com/v2-b384bed7624ffb7558e8d6d44ec261bc.jpg?source=7e7ef6e2\u0026needBackground=1","comment_permission":"all","created":1742191632,"updated":1742191632,"voteup_count":28,"voting":0,"comment_count":12,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"一、前言 [公式] 本文将使用streamlit和QwQ-plus API逐步快速地搭建一个带页面的简单RAG。如有错误，恳请批评指正！ [公式] 前些日子QwQ这个模型出来了，（这个模型的名字太可爱了(。•ω•。)ノ♡），一些指标能和deepseek掰手腕，百听不如一试，今天就用这个模型和RAG打配合。 [公式] 顺带提一嘴，本文除了介绍如何制作这个简易的RAG，还会指出可以优化的地方。先来看一下我的页面：   二、本RAG工作流程 [公式] 在写代码之前…","excerpt_new":"一、前言 [公式] 本文将使用streamlit和QwQ-plus API逐步快速地搭建一个带页面的简单RAG。如有错误，恳请批评指正！ [公式] 前些日子QwQ这个模型出来了，（这个模型的名字太可爱了(。•ω•。)ノ♡），一些指标能和deepseek掰手腕，百听不如一试，今天就用这个模型和RAG打配合。 [公式] 顺带提一嘴，本文除了介绍如何制作这个简易的RAG，还会指出可以优化的地方。先来看一下我的页面：   二、本RAG工作流程 [公式] 在写代码之前…","preview_type":"default","preview_text":"","content":"\u003ch2\u003e一、前言\u003c/h2\u003e\u003cp data-pid=\"q5vyMq79\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 本文将使用streamlit和QwQ-plus API逐步快速地搭建一个带页面的简单RAG。如有错误，恳请批评指正！\u003c/p\u003e\u003cp data-pid=\"M1mCukMC\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 前些日子QwQ这个模型出来了，（这个模型的名字太可爱了(。•ω•。)ノ♡），一些指标能和deepseek掰手腕，百听不如一试，今天就用这个模型和RAG打配合。\u003c/p\u003e\u003cp data-pid=\"lA2V-PFA\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 顺带提一嘴，本文除了介绍如何制作这个简易的RAG，还会指出可以优化的地方。\u003c/p\u003e\u003cp data-pid=\"sk3ZMTfl\"\u003e先来看一下我的页面：\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-b0f083a4d4c8410638ec5cc51a1e01ec_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1099\" data-rawheight=\"828\" data-original-token=\"v2-35073be17ea78cb2b183346b0a2e4335\" class=\"origin_image zh-lightbox-thumb\" width=\"1099\" data-original=\"https://pic3.zhimg.com/v2-b0f083a4d4c8410638ec5cc51a1e01ec_r.jpg\"/\u003e\u003cfigcaption\u003e页面\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3\u003e二、本RAG工作流程\u003c/h3\u003e\u003cp data-pid=\"t7ZQKrA4\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 在写代码之前，我觉得有必要梳理一下本文RAG的工作流程，以至于不会对代码犯懵。RAG流程图如下所示：\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-7c25858c72a0506d67b149e849e6309e_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1474\" data-rawheight=\"3840\" data-original-token=\"v2-c288eeee547130aa1ceee582f6c7adb2\" class=\"origin_image zh-lightbox-thumb\" width=\"1474\" data-original=\"https://pic3.zhimg.com/v2-7c25858c72a0506d67b149e849e6309e_r.jpg\"/\u003e\u003cfigcaption\u003e本RAG工作流程\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2\u003e三、代码讲解\u003c/h2\u003e\u003ch3\u003e3.1先下载一些必要的库\u003c/h3\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e!pip install langchain-openai chromadb langchain-community langchain langchain_huggingface langgraph typing-extensions streamlit requests pypdf openai\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"b0Fv5IEe\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 紧接着import进来\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003efrom langchain_community.vectorstores import Chroma  # Chroma向量数据库，用于存储和检索向量\nfrom langchain_core.messages import HumanMessage, AIMessage, ToolMessage  # 消息类型定义，用于对话管理\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter  # 文本分割器，用于将长文本分割成块\nfrom langgraph.graph import END, StateGraph, START  \nfrom langgraph.prebuilt import ToolNode  \nfrom langgraph.graph.message import add_messages  \nfrom typing_extensions import TypedDict, Annotated \nfrom typing import Sequence  \nimport re  \nimport os  \nimport streamlit as st  # 构建用户界面\nfrom langchain.tools.retriever import create_retriever_tool  # 创建检索器工具\nimport pypdf  # 用于处理PDF文件的库\nfrom openai import OpenAI  # 用于调用qwq-plus API\nfrom langchain_huggingface import HuggingFaceEmbeddings\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e3.2定义加载本地知识库的函数\u003c/h3\u003e\u003cp data-pid=\"sIwlcuWy\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 第一步，我们得先把知识加载进来。\u003c/p\u003e\u003cp data-pid=\"Y-x4o2tg\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 注意嗷，你需要在本地先创建一个名为knowledge_base的文件夹（知识库），然后把你喜欢的pdf和txt文件扔进去。下面这个函数就会自动遍历知识库目录，将知识加载进来。\u003c/p\u003e\u003cp data-pid=\"zJ30jgTn\"\u003e✨✨可改进之处：\u003c/p\u003e\u003cp data-pid=\"DOeL-9Ap\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e ①我这个代码只支持pdf和txt文件，你可以尝试扩充支持的文件格式，比如markdown等等。\u003c/p\u003e\u003cp data-pid=\"eT7LXgPo\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e ②使用更好的pdf解析器\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e# 定义加载文件函数，支持txt和pdf文件\ndef load_files(folder = \u0026#34;knowledge_base\u0026#34;):\n    \u0026#34;\u0026#34;\u0026#34;\n    加载并处理 knowledge_base 文件夹中的 txt 和 pdf 文件，返回文本内容列表\n    \u0026#34;\u0026#34;\u0026#34;\n    if not os.path.exists(folder):\n        raise ValueError(f\u0026#34;文件夹不存在: {folder}，请你先创建文件夹，再将知识扔进去\u0026#34;)  # 如果文件夹不存在则抛出异常\n    texts = []\n\n    # 遍历 knowledge_base 文件夹中的所有文件\n    for filename in os.listdir(folder):\n        path = os.path.join(folder, filename)\n        if filename.endswith(\u0026#39;.txt\u0026#39;):\n            with open(path, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f:\n                text = f.read()  # 读取 txt 文件内容\n                texts.append(text)\n        elif filename.endswith(\u0026#39;.pdf\u0026#39;):\n            pdf = pypdf.PdfReader(path)  # 打开 PDF 文件\n            text = \u0026#34;\u0026#34;\n            for page in pdf.pages:\n                extracted = page.extract_text()  # 提取每页文本\n                if extracted:\n                    text += extracted\n            texts.append(text)\n        else:\n            raise ValueError(f\u0026#34;不支持的文件类型: {filename}\u0026#34;)  # 遇到其他文件类型则抛出异常\n    return texts\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e3.3知识分块\u003c/h3\u003e\u003cp data-pid=\"4_11WSFd\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 计算机不想三口一头猪，我们得把大的知识文件分成一个一个的小块块，当然，更多是方便检索。试想一下，如果我们不分块，把整本书塞进计算机嘴里，当我们查询一些问题时，计算机压根就不用检索了（因为数据库就这么一件东西），直接把这本书拍你脑瓜上。如果我们分块了，把细糠喂给计算机，计算机就会从众多块块中检索最有用的块块。\u003c/p\u003e\u003cp data-pid=\"X5wS5HOZ\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 注意嗷，将知识文档切分为多大的块块没有一个固定的说辞，你可以通过下面chunk_size这个参数控制每个块块的大小\u003c/p\u003e\u003cp data-pid=\"pV52t4gB\"\u003e✨✨可改进之处：\u003c/p\u003e\u003cp data-pid=\"Va_icbdp\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~+\" alt=\"~~~~~ \" eeimg=\"1\"/\u003e ①可以引入语义分块，而不是固定n个字符分一个块，这样子能有效保护语义完整性。\u003c/p\u003e\u003cp data-pid=\"uSNKYHwi\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e ②采用二次动态分块，将分好的块块里面的“代码”、“表格”等特殊识别出来，形成一个独立的块\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e# 加载文件中的文本\nall_texts = load_files()\n\n# 初始化递归字符文本分割器（每个块400字符，重叠50字符）\nsplitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n\n# 将所有文本转换为文档对象\nall_docs = []\nfor text in all_texts:\n    docs = splitter.create_documents([text])  # 将每个文本分割为文档块\n    all_docs.extend(docs)\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e3.4将分块的知识映射为向量，存入向量数据库\u003c/h3\u003e\u003cp data-pid=\"UhMcYtF9\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 把知识分为块块之后，终究还是冰冷的文字，得把这些块块变为数字，映射为向量，计算机才会吃下去。\u003c/p\u003e\u003cp data-pid=\"-sov-is0\"\u003e我们使用嵌入模型all-mpnet-base-v2将知识块映射为向量，将它存进向量数据库里面。\u003c/p\u003e\u003cp data-pid=\"jiNOO0zE\"\u003e✨✨可改进之处：你可以选用更强大的嵌入模型，你可以参考一下MTEB榜单（Massive Text Embedding Benchmark），选取合适大小和性能的模型。当然，不同嵌入模型的引入方法可能会有些许差别。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-49278586026faa9acb27a89b2d4053e0_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1770\" data-rawheight=\"697\" data-original-token=\"v2-24ff1048feaa72b83988b0efa8e4efcf\" class=\"origin_image zh-lightbox-thumb\" width=\"1770\" data-original=\"https://pica.zhimg.com/v2-49278586026faa9acb27a89b2d4053e0_r.jpg\"/\u003e\u003cfigcaption\u003eMTEB榜单\u003c/figcaption\u003e\u003c/figure\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e# 这个模型在很多嵌入任务上表现都很好，而且相对较小。\nmodel_name = \u0026#34;sentence-transformers/all-mpnet-base-v2\u0026#34;\n\n# 如果你希望明确使用GPU（如果有的话）\nmodel_kwargs = {\u0026#39;device\u0026#39;: \u0026#39;cuda\u0026#39;} # 或者 \u0026#39;cpu\u0026#39; \nencode_kwargs = {\u0026#39;normalize_embeddings\u0026#39;: True} # 是否标准化嵌入向量\n\nembeddings = HuggingFaceEmbeddings(\n    model_name=model_name,\n    model_kwargs=model_kwargs,\n    encode_kwargs=encode_kwargs)\n\n# 创建单一知识库的向量存储\nvectorstore = Chroma.from_documents(documents=all_docs, embedding=embeddings,persist_directory=\u0026#34;./vector_db\u0026#34;, collection_name=\u0026#34;knowledge_collection\u0026#34;)\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"qDxb3NfF\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e ！！！！！注意：我的代码是在colab上运行的，不用配置hugging face token，如果你在其他地方运行这段代码，你需要加上以下代码，配置hugging face token。\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003eimport os\nos.environ[\u0026#39;HF_ENDPOINT\u0026#39;] = \u0026#39;https://hf-mirror.com\u0026#39;   #可选\nfrom huggingface_hub import login\nhf_token = \u0026#34;XXX\u0026#34;  #去hugging face官网免费申请一个token\nlogin(hf_token)\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e3.5定义知识检索器\u003c/h3\u003e\u003cp data-pid=\"1KViXq6g\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 咱们把知识块块映射为向量存入数据库后，得有一个专门的检索器呀，制定一下检索规则，总不能随手捞一点知识块块给你吧。\u003c/p\u003e\u003cp data-pid=\"iILiBVxF\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 下面代码的定义的检索逻辑就是：先从向量库中快速召回10个候选文档（fetch_k=10），使用MMR算法，对10个文档进行多样性筛选，保留相关性高且多样性好的子集，紧接着用 cross-encoder对筛选后的文档进行精细化打分，最后选择最终得分最高的3个文档（k=3）。\u003c/p\u003e\u003cp data-pid=\"8FxzolKA\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 这里浅浅讲一下MMR（Maximal Marginal Relevance）算法：\u003c/p\u003e\u003cp data-pid=\"blURE7xR\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 在检索结果的过程中，我们既要保证与查询相关，又要避免返回大量内容重复的文档，可是传统检索（如余弦相似度）可能返回多个高度相似但冗余的结果（例如同一事件的多篇报道）。上面是语文解释，让我们配合数学公式看看：\u003c/p\u003e\u003cp data-pid=\"TLjNGmhp\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=MMR+%3D+argmax_%7Bd+%5Cin+D+%5Csetminus+S%7D+%5Cleft%5B+%5Clambda+%5Ccdot+%5Ctext%7Bsim%7D%28q%2C+d%29+-+%281+-+%5Clambda%29+%5Ccdot+%5Cmax_%7Bd_i+%5Cin+S%7D+%5Ctext%7Bsim%7D%28d%2C+d_i%29+%5Cright%5D\" alt=\"MMR = argmax_{d \\in D \\setminus S} \\left[ \\lambda \\cdot \\text{sim}(q, d) - (1 - \\lambda) \\cdot \\max_{d_i \\in S} \\text{sim}(d, d_i) \\right]\" eeimg=\"1\"/\u003e \u003c/p\u003e\u003cp data-pid=\"1q3WpoCg\"\u003e符号解释：\u003c/p\u003e\u003cul\u003e\u003cul\u003e\u003cli data-pid=\"vV3ebOLX\"\u003eq：查询（query）\u003c/li\u003e\u003cli data-pid=\"g8A89Sby\"\u003eD：候选文档集合\u003c/li\u003e\u003cli data-pid=\"vDAI9IkE\"\u003eS：已选文档集合\u003c/li\u003e\u003cli data-pid=\"60g5QIx8\"\u003eλ（即 \u003ccode\u003elambda_mult\u003c/code\u003e）：权衡参数（0.0~1.0）\u003c/li\u003e\u003cli data-pid=\"VsYNz2cJ\"\u003esim：相似度函数（如余弦相似度）\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cp data-pid=\"o73XUjD7\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 工作流程：从向量库中召回 \u003ccode\u003efetch_k\u003c/code\u003e 个候选文档。第一轮选择与查询最相关的文档。后续轮次选择与查询相关度高 \u003cb\u003e且与已选文档差异大\u003c/b\u003e 的文档。直到选出 k 个文档后停止。其中，\u003ccode\u003elambda_mult\u003c/code\u003e控制相关性权重，当λ→1：摘取更相关的内容；λ→0：摘取更多样化的内容。\u003c/p\u003e\u003cp data-pid=\"WBUtCbJ1\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 还是举个例子更直观\u003c/p\u003e\u003cp data-pid=\"VHtXLjyF\"\u003e假设查询是 \u003ci\u003e\u0026#34;如何学习机器学习\u0026#34;\u003c/i\u003e，候选文档包括：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"yEIUYY36\"\u003eDoc1: 机器学习入门教程（相关度0.9）\u003c/li\u003e\u003cli data-pid=\"lQTSX7nz\"\u003eDoc2: 深度学习实战（相关度0.8）\u003c/li\u003e\u003cli data-pid=\"Tuz1NjZH\"\u003eDoc3: 机器学习入门书籍推荐（相关度0.85）\u003c/li\u003e\u003cli data-pid=\"H1Zc2Leb\"\u003e\u003cb\u003e传统检索\u003c/b\u003e：可能返回 Doc1 和 Doc3（相关度高但内容重复）。\u003c/li\u003e\u003cli data-pid=\"XFKxbTF1\"\u003e\u003cb\u003eMMR（λ=0.5）\u003c/b\u003e：可能返回 Doc1（最高相关）和 Doc2（内容差异大）。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"Gmmi2YUQ\"\u003e✨✨可改进之处：这个模块可改进的地方就多啦，比如检索方法，我这里使用MMR，你也可以使用别的，如bm25等等，当然，不局限于使用一种方法，可以多种方法混合，将不同方法给予不一样的权重，进行混合检索。\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e# 初始化 cross-encoder 模型，这里选择 \u0026#34;cross-encoder/ms-marco-MiniLM-L-6-v2\u0026#34; 模型\ncross_encoder = CrossEncoder(\u0026#34;cross-encoder/ms-marco-MiniLM-L-6-v2\u0026#34;)\n\ndef cross_encoder_reranker(documents, query):\n    \u0026#34;\u0026#34;\u0026#34;\n    使用 cross-encoder 对候选文档进行重排序。\n\n    参数：\n        documents: 文档对象列表，每个文档需包含文本内容（例如 page_content 属性）。\n        query: 查询文本。\n\n    返回：\n        按 cross-encoder 得分降序排序后的文档列表。\n    \u0026#34;\u0026#34;\u0026#34;\n    # 构建 (query, 文档内容) 对列表，假定每个文档的文本存储在 page_content 属性中\n    pairs = [(query, doc.page_content) for doc in documents]\n    # 使用 cross-encoder 模型预测相关性得分\n    scores = cross_encoder.predict(pairs)\n    # 将文档与对应的得分组合，并按得分降序排序\n    ranked_docs = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)\n    # 返回排序后的文档列表\n    return [doc for doc, score in ranked_docs]\n\n# 从向量存储创建混合检索器，并使用 cross-encoder 进行重排序\nretriever = vectorstore.as_retriever(\n    search_type=\u0026#34;mmr\u0026#34;,  \n    search_kwargs={\n        \u0026#34;k\u0026#34;: 3,            # 最终返回 top 3 个文档\n        \u0026#34;fetch_k\u0026#34;: 10,     # 先拉取 10 个候选文档，再进行重排序\n        \u0026#34;lambda_mult\u0026#34;: 0.5 # MMR 参数，控制相关性与多样性的权衡\n    },\n    reranker=cross_encoder_reranker  # 使用 cross-encoder 进行重排序\n)\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003e3.6创建检索器工具\u003c/h3\u003e\u003cp data-pid=\"OTn_iqno\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 这里其实是借助了Agent的思路，将检索包装成工具，让模型在碰到检索任务时会使用这个工具。\u003c/p\u003e\u003cp data-pid=\"V3_Wd9vg\"\u003e✨✨可改进之处：现在工具列表只有一个工具，你可以动态扩充工具呀，比如扩充一个计算器工具，不过后续的代码需要有一定的修改。\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e# 创建知识库检索工具\nknowledge_tool = create_retriever_tool(retriever, \u0026#34;knowledge_db_tool\u0026#34;, \u0026#34;从知识库里面找信息\u0026#34;)\n\n# 工具列表\ntools = [knowledge_tool]\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e3.7定义Agent状态类型\u003c/h3\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003eclass AgentState(TypedDict):\n    messages: Annotated[Sequence[AIMessage | HumanMessage | ToolMessage], add_messages]\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e3.8调用大模型进行响应\u003c/h3\u003e\u003cp data-pid=\"MEJ60Q-C\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 这里你得去阿里云百炼大模型申请一个API。（新人注册有免费的百万token）\u003c/p\u003e\u003cp data-pid=\"_IBFTxMc\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 然后将API填入代码中api_key=\u0026#34;XXX\u0026#34;的“XXX”地方\u003c/p\u003e\u003cp data-pid=\"dkPDMTeJ\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 当然，你也可以使用deepseek，只需要将model=\u0026#34;qwq-plus\u0026#34;改为model=\u0026#34;deepseek-r1\u0026#34;，一共支持200多个模型，具体你可以在申请API的地方看看可以支持哪些模型。\u003c/p\u003e\u003ca href=\"https://link.zhihu.com/?target=https%3A//bailian.console.aliyun.com/%3Faccounttraceid%3Dcbf55a2d4b7c4dbfbea8717ea5e4990fvnqv%23/model-market/detail/qwq-plus\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e申请API\u003c/a\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e# 定义从qwq-plus API获取响应的函数，支持流式输出\ndef get_response_from_qwq(prompt):\n    \u0026#34;\u0026#34;\u0026#34;\n    使用qwq-plus API获取响应，支持流式输出\n    参数：prompt - 用户提示词\n    返回：response_text - 完整的响应文本\n    \u0026#34;\u0026#34;\u0026#34;\n    client = OpenAI(\n        api_key=\u0026#34;XXX\u0026#34;,  # 从环境变量获取API密钥\n        base_url=\u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34;  # qwq-plus API的基URL\n    )\n    messages = [{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: prompt}]  # 构建消息列表\n    completion = client.chat.completions.create(\n        model=\u0026#34;qwq-plus\u0026#34;,  # 使用qwq-32b模型\n        messages=messages,\n        stream=True  # 启用流式输出\n    )\n    response_text = \u0026#34;\u0026#34;\n    for chunk in completion:\n        if chunk.choices:\n            delta = chunk.choices[0].delta  # 获取当前块的增量\n            if delta.content:\n                response_text += delta.content  # 累积响应内容\n    return response_text\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e3.9定义Agent及其配套工作流程的函数\u003c/h3\u003e\u003cp data-pid=\"8bdXnCtO\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 这一块代码我觉得使用流程图的方式更能展现逻辑.\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-35225e6d20e3ac755d599d467d1f8a73_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"748\" data-rawheight=\"762\" data-original-token=\"v2-a5728b675902c8ab4541d9b23ba3bd1f\" class=\"origin_image zh-lightbox-thumb\" width=\"748\" data-original=\"https://pic2.zhimg.com/v2-35225e6d20e3ac755d599d467d1f8a73_r.jpg\"/\u003e\u003c/figure\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003edef agent(state: AgentState):\n    \u0026#34;\u0026#34;\u0026#34;主代理函数，处理用户输入并决定后续操作\u0026#34;\u0026#34;\u0026#34;\n    print(\u0026#34;---调用代理---\u0026#34;)\n    messages = state[\u0026#34;messages\u0026#34;]\n    user_message = messages[0].content if isinstance(messages[0], HumanMessage) else messages[0][1]\n\n    # 构建结构化提示词\n    prompt = f\u0026#34;\u0026#34;\u0026#34;根据用户问题：\u0026#34;{user_message}\u0026#34;\n\n    如果问题与知识库相关，严格使用以下格式回复：\n    SEARCH: \u0026lt;搜索关键词\u0026gt;\n\n    否则直接回答。\n    \u0026#34;\u0026#34;\u0026#34;\n\n    # 调用qwq-plus API获取响应\n    response_text = get_response_from_qwq(prompt)\n\n    # 解析响应并执行相应操作\n    if \u0026#34;SEARCH:\u0026#34; in response_text:\n        query = response_text.split(\u0026#34;SEARCH:\u0026#34;)[1].strip()  # 提取搜索关键词\n        results = retriever.invoke(query)  # 使用检索器搜索\n        return {\u0026#34;messages\u0026#34;: [AIMessage(content=f\u0026#39;Action: knowledge_db_tool\\n{{\u0026#34;query\u0026#34;: \u0026#34;{query}\u0026#34;}}\\n\\nResults: {str(results)}\u0026#39;)]}\n    else:\n        return {\u0026#34;messages\u0026#34;: [AIMessage(content=response_text)]}\n\ndef simple_grade_documents(state: AgentState):\n    \u0026#34;\u0026#34;\u0026#34;评估检索结果质量\u0026#34;\u0026#34;\u0026#34;\n    messages = state[\u0026#34;messages\u0026#34;]\n    last_message = messages[-1]\n    print(\u0026#34;正在评估消息:\u0026#34;, last_message.content)\n\n    # 检查是否包含有效检索结果\n    if \u0026#34;Results: [Document\u0026#34; in last_message.content:\n        print(\u0026#34;---找到文档，进入生成阶段---\u0026#34;)\n        return \u0026#34;generate\u0026#34;\n    else:\n        print(\u0026#34;---未找到文档，尝试重写问题---\u0026#34;)\n        return \u0026#34;rewrite\u0026#34;\n\ndef generate(state: AgentState):\n    \u0026#34;\u0026#34;\u0026#34;生成最终答案\u0026#34;\u0026#34;\u0026#34;\n    print(\u0026#34;---生成最终答案---\u0026#34;)\n    messages = state[\u0026#34;messages\u0026#34;]\n    question = messages[0].content\n    last_message = messages[-1]\n\n    # 提取文档内容\n    docs = \u0026#34;\u0026#34;\n    if \u0026#34;Results: [\u0026#34; in last_message.content:\n        results_start = last_message.content.find(\u0026#34;Results: \u0026#34;)\n        docs = last_message.content[results_start:]\n\n    # 构建提示词，基于知识库文档生成答案\n    prompt = f\u0026#34;\u0026#34;\u0026#34;根据知识库提供的文档回答用户问题：\n    问题：{question}\n    文档：{docs}\n    请重点提取和整合相关信息。\n    \u0026#34;\u0026#34;\u0026#34;\n\n    # 调用qwq-plus API生成总结\n    response_text = get_response_from_qwq(prompt)\n    return {\u0026#34;messages\u0026#34;: [AIMessage(content=response_text)]}\n\ndef rewrite(state: AgentState):\n    \u0026#34;\u0026#34;\u0026#34;重写问题以提高清晰度\u0026#34;\u0026#34;\u0026#34;\n    print(\u0026#34;---重写问题---\u0026#34;)\n    messages = state[\u0026#34;messages\u0026#34;]\n    original_question = messages[0].content\n\n    # 构建提示词，请求重写问题\n    prompt = f\u0026#34;请将这个问题改写得更具体明确：{original_question}\u0026#34;\n\n    # 调用qwq-plus API进行问题重写\n    response_text = get_response_from_qwq(prompt)\n    return {\u0026#34;messages\u0026#34;: [AIMessage(content=response_text)]}\n\n# 正则表达式匹配工具调用模式\ntools_pattern = re.compile(r\u0026#34;Action: .*\u0026#34;)\n\ndef custom_tools_condition(state: AgentState):\n    \u0026#34;\u0026#34;\u0026#34;判断是否需要调用工具\u0026#34;\u0026#34;\u0026#34;\n    messages = state[\u0026#34;messages\u0026#34;]\n    last_message = messages[-1]\n    content = last_message.content\n\n    print(\u0026#34;正在检查工具条件:\u0026#34;, content)\n    if tools_pattern.match(content):\n        print(\u0026#34;转向检索...\u0026#34;)\n        return \u0026#34;tools\u0026#34;\n    print(\u0026#34;转向结束...\u0026#34;)\n    return END\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e3.10构建状态流程图\u003c/h3\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003eworkflow = StateGraph(AgentState)\n\n# 添加节点\nworkflow.add_node(\u0026#34;agent\u0026#34;, agent)\nretrieve_node = ToolNode(tools)\nworkflow.add_node(\u0026#34;retrieve\u0026#34;, retrieve_node)\nworkflow.add_node(\u0026#34;rewrite\u0026#34;, rewrite)\nworkflow.add_node(\u0026#34;generate\u0026#34;, generate)\n\n# 设置节点关系\nworkflow.add_edge(START, \u0026#34;agent\u0026#34;)  # 初始节点\n\n# 条件分支：判断是否需要工具调用\nworkflow.add_conditional_edges(\n    \u0026#34;agent\u0026#34;,\n    custom_tools_condition,\n    {\n        \u0026#34;tools\u0026#34;: \u0026#34;retrieve\u0026#34;,  # 需要工具调用\n        END: END  # 直接结束\n    }\n)\n\n# 检索后判断结果质量\nworkflow.add_conditional_edges(\u0026#34;retrieve\u0026#34;, simple_grade_documents)\nworkflow.add_edge(\u0026#34;generate\u0026#34;, END)  # 生成后结束\nworkflow.add_edge(\u0026#34;rewrite\u0026#34;, \u0026#34;agent\u0026#34;)  # 重写后回到agent\n\n# 编译工作流\napp = workflow.compile()\n\ndef process_question(user_question, app, config):\n    \u0026#34;\u0026#34;\u0026#34;处理用户问题的完整流程\u0026#34;\u0026#34;\u0026#34;\n    events = []\n    for event in app.stream({\u0026#34;messages\u0026#34;: [HumanMessage(content=user_question)]}, config):\n        events.append(event)\n    return events\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e3.11创建页面\u003c/h3\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003est.title(\u0026#34;   简单RAG QWQ-plus \u0026#34;)\nst.write(\u0026#34;---\u0026#34;)\n\nst.write(\u0026#34;\u0026#34;\u0026#34;\n###   使用指南\n1. 在文本框中输入您的问题\n2. 点击\u0026#34;获取答案\u0026#34;进行处理\n3. 查看检索结果和最终答案\n\n###   示例问题\n- 1.请你讲解线性链条件随机场\n- 2.熟读猫娘相处手册，你应该知道怎么做了吧？\n- 3.114514是什么意思？\n\u0026#34;\u0026#34;\u0026#34;)\n\nquery = st.text_area(\u0026#34;输入您的问题：\u0026#34;, height=100, placeholder=\u0026#34;例如：猫娘平时都在干啥\u0026#34;)\n\nwith st.container():\n    if st.button(\u0026#34;  获取答案\u0026#34;, use_container_width=True):\n        if query:\n            with st.spinner(\u0026#39;正在处理您的问题...\u0026#39;):\n                # 执行处理流程\n                events = process_question(query, app, {\u0026#34;configurable\u0026#34;: {\u0026#34;thread_id\u0026#34;: \u0026#34;1\u0026#34;}})\n\n                # 显示处理结果\n                for event in events:\n                    if \u0026#39;agent\u0026#39; in event:\n                        with st.expander(\u0026#34;  处理步骤\u0026#34;, expanded=True):\n                            content = event[\u0026#39;agent\u0026#39;][\u0026#39;messages\u0026#39;][0].content\n                            if \u0026#34;Results:\u0026#34; in content:\n                                st.write(\u0026#34;###   检索到的文档：\u0026#34;)\n                                docs_start = content.find(\u0026#34;Results: \u0026#34;)\n                                docs = content[docs_start:]\n                                st.info(docs)\n                    elif \u0026#39;generate\u0026#39; in event:\n                        st.write(\u0026#34;### ✨ 最终答案：\u0026#34;)\n                        st.success(event[\u0026#39;generate\u0026#39;][\u0026#39;messages\u0026#39;][0].content)\n        else:\n            st.warning(\u0026#34;⚠️ 请先输入问题！\u0026#34;)\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2\u003e3.12运行\u003c/h2\u003e\u003cp data-pid=\"aKYzMNRc\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 把上述代码全都塞进一个python文件里面，尽量不要用jupyter notebook。\u003c/p\u003e\u003cp data-pid=\"LkHvYbw4\"\u003e在终端输入（假设文件名叫app.py）：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003estreamlit run app.py\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2\u003e四、结果测试\u003c/h2\u003e\u003cp data-pid=\"vxPzsiaR\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 我用AI写了3000字的“猫娘相处手册”，把它扔给知识库，让AI慢慢品味。\u003c/p\u003e\u003cp data-pid=\"2OxJF9Ro\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 我提问：“怎么区分真正的猫娘和喜欢cosplay的人”\u003c/p\u003e\u003cp data-pid=\"xpq_tiiW\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 下面是它检索到的文档，检索了3个文档分块，其中两个是一样的，毕竟才3000字，文档分块也是有限的，与query高相似度的文档就更少了。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-fef6003b71a8abfd1eaa59995411c893_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1029\" data-rawheight=\"774\" data-original-token=\"v2-f01fe9e127dba2e0c2483c7b25923ce2\" class=\"origin_image zh-lightbox-thumb\" width=\"1029\" data-original=\"https://pic4.zhimg.com/v2-fef6003b71a8abfd1eaa59995411c893_r.jpg\"/\u003e\u003cfigcaption\u003e检索到的文档\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"FSa5fSB3\"\u003e下面是他结合文档内容给出的最终回复：\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-ef3aada648db246669d60aa0db67419e_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"918\" data-rawheight=\"783\" data-original-token=\"v2-a6c32efabb3c9f123628519056b7141b\" class=\"origin_image zh-lightbox-thumb\" width=\"918\" data-original=\"https://pic3.zhimg.com/v2-ef3aada648db246669d60aa0db67419e_r.jpg\"/\u003e\u003c/figure\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-3cf33222cdcdf1c7f7f1f6df783bfe12_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"907\" data-rawheight=\"766\" data-original-token=\"v2-6f1166c2136e4cb19e2d276b5b14efed\" class=\"origin_image zh-lightbox-thumb\" width=\"907\" data-original=\"https://pica.zhimg.com/v2-3cf33222cdcdf1c7f7f1f6df783bfe12_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"USKKat_z\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 如果我问他一个与知识库无关的内容，比如“114514”是什么意思？\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-8bd5e4dd06f1683455593498066a2056_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"880\" data-rawheight=\"307\" data-original-token=\"v2-f1e35e559ce2bcd14aff96d1339f7c8e\" class=\"origin_image zh-lightbox-thumb\" width=\"880\" data-original=\"https://pic3.zhimg.com/v2-8bd5e4dd06f1683455593498066a2056_r.jpg\"/\u003e\u003c/figure\u003e\u003ch2\u003e五、总结\u003c/h2\u003e\u003cp data-pid=\"UXRaRtVU\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=~~~~~\" alt=\"~~~~~\" eeimg=\"1\"/\u003e 本文章构建的RAG算是比较初级的，仍有很多地方可以优化，打造更强的RAG，因此，我接下来准备写一篇逐步优化RAG的文章。（虽然不知道会托更多久）。\u003c/p\u003e","is_labeled":false,"visited_count":1428,"thumbnails":["https://picx.zhimg.com/v2-b384bed7624ffb7558e8d6d44ec261bc.jpg?source=7e7ef6e2\u0026needBackground=1","https://picx.zhimg.com/50/v2-4f9b4b04c0467a0570a8b8335d520982_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-9da088d5eabf68ac0b05e07c00356423_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-497778239a0ebdecde3b341675443834_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-f44fb84d79cb3adc24d0f0a42d728aae_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-e97b5c919a18324561dababdf33ef9f2_720w.jpg?source=b6762063","https://pica.zhimg.com/50/v2-7acea20e54b76c2910b652e95e0a94ff_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-91b00efea0faf17ede59b96ab4959b20_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-1e9b4590703edf2c370dfa2e20759598_720w.jpg?source=b6762063"],"favorite_count":85,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1884533787947406755}","attached_info":"CroJCLi+kpC/2NTfiAEQBxoJMjU1MTMwNjg2IJD43r4GKBwwDEAwSjAKBkl0ZW1DRhIgZG9jX3R5cGU6IEFydGljbGUKaWQ6IDIzODUwMDA0NgoYACAAOgBiIDZhNWYzZmQ0OWI2NzQwOGU3MzM3ZmZlOTkzODdlODE2chMxODg0NTMzNzg3OTQ3NDA2NzU1ggFfaHR0cHM6Ly9waWN4LnpoaW1nLmNvbS92Mi1iMzg0YmVkNzYyNGZmYjc1NThlOGQ2ZDQ0ZWMyNjFiYy5qcGc/c291cmNlPTdlN2VmNmUyJm5lZWRCYWNrZ3JvdW5kPTGqAQlyZWNvbW1lbmTCASA0MGMzMDdkMDAwYmY2ZWUzZTgwM2E1ZmUyOTM4NjYxOfIBCggMEgZOb3JtYWzyASgIChIkOWUyNzI2OGItY2NiYS00Zjc0LWI5MDgtMzZhZDhhMGQ4ZWM38gEFCAsSATmCAgCIAvPQ1M36MpICIDQwYzMwN2QwMDBiZjZlZTNlODAzYTVmZTI5Mzg2NjE5mgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCGFBlcmlvZEludGVyZXN0V2VpZ2h0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZcoCFENvbnRlbnRBZ2VXZWlnaHRSdWxl2gIGSXRlbUNG6AID+gILTk9STUFMX0ZMT1eKAyA0ODYwOGQ0OTk0YjQ0YjYyODRiZmQ0YjNiMDhmMjdlNJoDDQoCdjIQABoFb3RoZXKoA5QL2AMA6gMVdGV4dEFsbFNpdGVNdkl0ZW1DRlYy+gPGAxIMVU5LTk9XTl9NT0RFIAAqDU5PX0lNQUdFX01PREU6LQgCEMsIGLwGIiN2Mi0zNTA3M2JlMTdlYTc4Y2IyYjE4MzM0NmIwYTJlNDMzNTotCAMQwgsYgB4iI3YyLWMyODhlZWVlNTQ3MTMwYWExY2VlZTU4MmY2YzdhZGIyOi0IAhDqDRi5BSIjdjItMjRmZjEwNDhmZWFhNzJiODM5ODhiMGVmYThlNGVmY2Y6LQgDEOwFGPoFIiN2Mi1hNTcyOGI2NzU5MDJjOGFiNDU0MWQ5YjIzYmEzYmQxZjotCAIQhQgYhgYiI3YyLWYwMWZlOWUxMjdkYmEyZTBjMjQ4M2M3YjI1OTIzY2UyOi0IAhCWBxiPBiIjdjItYTZjMzJlZmFiYjNjOWYxMjM2Mjg1MTkwNTZiNzE0MWI6LQgCEIsHGP4FIiN2Mi02ZjExNjZjMjEzNmU0Y2IxOWUyZDI3NmI1YjE0ZWZlZDotCAIQ8AYYswIiI3YyLWYxZTM1ZTU1OWNlMmJjZDE0YWZmOTZkMTMzOWY3YzhlOi0IAhCADxi4CCIjdjItYjM4NGJlZDc2MjRmZmI3NTU4ZThkNmQ0NGVjMjYxYmOABACIBACSBAZOb3JtYWyaBAEzoAQAqAQAsAQAugQCYWnCBAM0MDDIBADSBA/mjqjojZDlt7Lmm7TmlrDYBADwBAD5BAAAAIApIqM/gQUAAAAAAAAAAIkFiXD7/HhR0j+SBQCaBQNkZnSiBQNkZnSyBQExuQUAAAAAAAAAANAFAOAFAOgFAPAFCZAGAKAGMKgGAZICLgoJMjU1MTMwNjg2EhMxODg0NTMzNzg3OTQ3NDA2NzU1GAciCklNQUdFX1RFWFQ=","action_card":false},{"id":"49_1750898911.421","type":"feed","offset":49,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750898911,"updated_time":1750898911,"target":{"id":"1911103917124722972","type":"article","url":"https://api.zhihu.com/articles/1911103917124722972","author":{"id":"81d482c51f516790f18259244efcd73d","url":"https://api.zhihu.com/people/81d482c51f516790f18259244efcd73d","user_type":"people","url_token":"16-69-60-47","name":"rust-lake","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-a10a963cf7890c182c09c8975fa25755_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":22,"is_following":false,"is_followed":false},"title":"最新最热乎的大模型应用面经","comment_permission":"all","created":1748422719,"updated":1748869650,"voteup_count":132,"voting":0,"comment_count":13,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"github 上是最新的内容，知乎上的可能会是旧的。 https://github.com/AngleMAXIN/llm-interview/tree/main 有人觉的面经很简单，可以看我 面试内容 \u0026amp; 难度 的说明。 # 大模型应用开发面经 ## 时间范围 近半年 ## 实际面过的公司 阿里、腾讯、美团、字节、快手、同程、京东、360、keep、滴滴、印象笔记、作业帮、彩云科技、蓝色光标、江城互娱、Aviagames、Hungry Stdios、深言科技、即时科技、RockFlow、格灵深瞳、百融云创、印象笔记、网龙、 HiDream.ai 、昆仑万维…","excerpt_new":"github 上是最新的内容，知乎上的可能会是旧的。 https://github.com/AngleMAXIN/llm-interview/tree/main 有人觉的面经很简单，可以看我 面试内容 \u0026amp; 难度 的说明。 # 大模型应用开发面经 ## 时间范围 近半年 ## 实际面过的公司 阿里、腾讯、美团、字节、快手、同程、京东、360、keep、滴滴、印象笔记、作业帮、彩云科技、蓝色光标、江城互娱、Aviagames、Hungry Stdios、深言科技、即时科技、RockFlow、格灵深瞳、百融云创、印象笔记、网龙、 HiDream.ai 、昆仑万维…","preview_type":"default","preview_text":"","content":"\u003cp\u003e\u003c/p\u003e\u003cp data-pid=\"ZGDomlpJ\"\u003egithub 上是最新的内容，知乎上的可能会是旧的。\u003c/p\u003e\u003ca href=\"https://link.zhihu.com/?target=https%3A//github.com/AngleMAXIN/llm-interview/tree/main\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003egithub.com/AngleMAXIN/l\u003c/span\u003e\u003cspan class=\"invisible\"\u003elm-interview/tree/main\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003cp data-pid=\"txeb9YTs\"\u003e有人觉的面经很简单，可以看我 \u003cb\u003e\u003ci\u003e面试内容 \u0026amp; 难度\u003c/i\u003e\u003c/b\u003e 的说明。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"Bb7FqTj1\"\u003e# 大模型应用开发面经\u003c/p\u003e\u003cp data-pid=\"U5gobvcG\"\u003e## 时间范围\u003c/p\u003e\u003cp data-pid=\"u_6vbmgq\"\u003e近半年\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"P6NYMVG4\"\u003e## 实际面过的公司\u003c/p\u003e\u003cp data-pid=\"nQFHoQKP\"\u003e阿里、腾讯、美团、字节、快手、同程、京东、360、keep、滴滴、印象笔记、作业帮、彩云科技、蓝色光标、江城互娱、Aviagames、Hungry Stdios、深言科技、即时科技、RockFlow、格灵深瞳、百融云创、印象笔记、网龙、 \u003ca href=\"https://link.zhihu.com/?target=http%3A//hidream.ai/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003eHiDream.ai\u003c/a\u003e、昆仑万维、数驱互动、Authing\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"fmzH0AAw\"\u003e## 先说总结\u003c/p\u003e\u003cp data-pid=\"0-x2op8Z\"\u003e### 面试内容 \u0026amp; 难度\u003c/p\u003e\u003cp data-pid=\"YDvn9Ps0\"\u003e- 个人觉得，在llm应用的面试题上，没有太多复杂、高深的问题，不像上来让你说一下分布式锁怎么设计然后死扣设计细节或是描述一下MVCC原理这种偏高难度的八股文问题（当然也遇到了一两次），究其原因以下几点，一是大模型应用目前仍没有很成熟且被广泛接纳的方案，都还在探索；二是很多公司今年刚开始all in AI（我司all进去的比较早点），面试官也懂得不多，例如RAG这个东西，大部分的面试题无非是“你觉得RAG中最难的是什么？（文档切割喽）”、“你是怎么解决幻觉问题的？”，“微调和RAG的区别是啥？”等等，如果你做过RAG加上你经常看技术文章结合你的“侃侃而谈”，基本面试官都觉得ok。但这里着重说一下我觉得当前非常重要且极大概率提升面试通过率的的一个技术点，就是**掌握微调原理并且做过动手做过微调工作再加上动手部署过大模型**，这是我面试中最常被问到而又只能说没做过的问题，当然大部分公司都有专门的算法团队去做这件事，自己到没机会参与其中，也是可以理解的。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"6hpUJdW8\"\u003e- 算法题：一半是DP问题，还有一部分难度是easy的问题，总体上都是“老熟人”，**但是，你即使写出来，面试不一定就能过**，有的干脆就不考算法题。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"968-6EUR\"\u003e- 八股文：明显比之前少很多，这个和面试的岗位有关系，LLM应用的岗位更偏实践，所有很多一面就是leader面，直接问项目，除非一面也不懂LLM的东西，就会考八股文，**但总的来说，八股少了，但是绝对不可以不准备，好几次挂在这上面，别小瞧它。**\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"F-yjQJ-9\"\u003e- 岗位内容：\u003c/p\u003e\u003cp data-pid=\"UPaFaSXf\"\u003e  - 游戏公司：基本上是LLM + AB test for 游戏策划；BI 分析；游戏社区客服助手；\u003c/p\u003e\u003cp data-pid=\"nWYhLNRl\"\u003e  - toC: Agent 个人助手\u003c/p\u003e\u003cp data-pid=\"nYSNci_C\"\u003e  - toB: Agent for 解决方案\u003c/p\u003e\u003cp data-pid=\"sqQY8oeg\"\u003e  - other: 通用 Agent 平台；公司内部AI助手、平台；Agent for 运维\u003c/p\u003e\u003cp data-pid=\"gxHiOroc\"\u003e### offer\u003c/p\u003e\u003cp data-pid=\"oPxoFYg8\"\u003e- 会有很多横向对比，如果你期望薪资比较高，对方说要在等等，基本上凉了。\u003c/p\u003e\u003cp data-pid=\"eY90of2G\"\u003e- 大部分涨幅基本是不到20%的，但我的期望是30%左右，最后还是拿到了（要有一点点耐心，还要有一定的运气）。\u003c/p\u003e\u003cp data-pid=\"oQ7jh0HA\"\u003e- 不要眼高手低，先拿一个低于自己预期的offer，再慢慢谈，前提是公司想要你。\u003c/p\u003e\u003cp data-pid=\"siYGzEWp\"\u003e- 规划好时间，集中面试，集中对比，由于我时间线拉的过长，后面安排的很乱。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"iUu8efWt\"\u003e### 再总结\u003c/p\u003e\u003cp data-pid=\"hdrR8XPW\"\u003e- 每次面完都要复盘，没答好的问题，一定要重新梳理答案。\u003c/p\u003e\u003cp data-pid=\"ZXBOGjwU\"\u003e- 没把握问题的可以直接说不会，别给个你自己都听不懂的答案。\u003c/p\u003e\u003cp data-pid=\"iBR3fCvv\"\u003e- 简历一定要让大模型润色，但自己要check一遍，别吹过头了。\u003c/p\u003e\u003cp data-pid=\"0K_mm4ov\"\u003e- 多看技术文章，扩展技术视野，提高二面面试官对你的印象。\u003c/p\u003e\u003cp data-pid=\"Tmnbp06_\"\u003e- 表达一定要流畅清晰，不要断断续续的，面试官会觉得你思路不清晰。\u003c/p\u003e\u003cp data-pid=\"ZjzEFXe6\"\u003e- 项目效果评估是个很重要的问题，不管你的技术多炫酷，终究还是要看效果，看落地效果。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"Ru0s2RJX\"\u003e## 面试题\u003c/p\u003e\u003cp data-pid=\"BIQ6ikvP\"\u003e\u0026gt; 这里想到多少写多少\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"VMQalh1H\"\u003e### LLM 基础\u003c/p\u003e\u003cp data-pid=\"d0HMVWyo\"\u003e- 大模型是怎么训练出来的？\u003c/p\u003e\u003cp data-pid=\"Zd1URxzE\"\u003e- Transform 的架构，Encoder 和 Decoder 是什么？\u003c/p\u003e\u003cp data-pid=\"X8mIa39j\"\u003e- Function Call 是怎么训练的？\u003c/p\u003e\u003cp data-pid=\"8rPixqfh\"\u003e- 微调的方案有哪些？自己做过没有？\u003c/p\u003e\u003cp data-pid=\"_exwEj8k\"\u003e- 大模型分词器是什么？\u003c/p\u003e\u003cp data-pid=\"0ugISejj\"\u003e- Embedding 是什么？你们用的那个模型？\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"hBIeh0Js\"\u003e### Lib\u003c/p\u003e\u003cp data-pid=\"e_m08SCY\"\u003e- 介绍一下 langchian\u003c/p\u003e\u003cp data-pid=\"oIfsC9iS\"\u003e- 介绍一下 autogen\u003c/p\u003e\u003cp data-pid=\"OlKOg6rh\"\u003e- 有没有用过大模型的网关框架（litellm）\u003c/p\u003e\u003cp data-pid=\"yzSV3trW\"\u003e- 为什么手搓agent，而不是用框架？\u003c/p\u003e\u003cp data-pid=\"DxoDz9BM\"\u003e- mcp 是什么？和Function Call 有什么区别？有没有实践过？\u003c/p\u003e\u003cp data-pid=\"l0gE4DwW\"\u003e- A2A 了解吗？\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"T10Q4kqv\"\u003e### Prompt\u003c/p\u003e\u003cp data-pid=\"i1WDXLUh\"\u003e- ReAct 是啥？怎么实现的？\u003c/p\u003e\u003cp data-pid=\"DhQ9es9I\"\u003e- CoT 是啥？为啥效果好呢？有啥缺点？\u003c/p\u003e\u003cp data-pid=\"Qp8bnVGE\"\u003e- Prompt Caching 是什么？\u003c/p\u003e\u003cp data-pid=\"bPARn-i2\"\u003e- 温度值/top-p/top-k 分别是什么？各个场景下的最佳设置是什么？\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"T13-dWr1\"\u003e### RAG\u003c/p\u003e\u003cp data-pid=\"TcYAV9mI\"\u003e- 你介绍一下RAG 是什么？最难的地方是哪？\u003c/p\u003e\u003cp data-pid=\"B0U2dXYU\"\u003e- 文档切割策略有哪些？怎么规避语义被切割掉的问题？\u003c/p\u003e\u003cp data-pid=\"16T3C4z8\"\u003e- 多路召回是什么？\u003c/p\u003e\u003cp data-pid=\"gvU9pNkB\"\u003e- 文档怎么存的？粒度是多大？用的什么数据库？\u003c/p\u003e\u003cp data-pid=\"rG6isVW0\"\u003e- 为啥要用到图数据库？\u003c/p\u003e\u003cp data-pid=\"rROwfoKx\"\u003e- 向量数据库的对比有没有做过？Qdrant 性能如何？量级是多大？有没有性能瓶颈？\u003c/p\u003e\u003cp data-pid=\"25XNoweQ\"\u003e- 怎么规避大模型的幻觉？\u003c/p\u003e\u003cp data-pid=\"LHDzksQX\"\u003e- 微调和RAG的优劣势？\u003c/p\u003e\u003cp data-pid=\"rb1xfbrs\"\u003e- **怎么量化你的回答效果？** 例如检索的效果、回答的效果。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"FqXyNakq\"\u003e### workflow\u003c/p\u003e\u003cp data-pid=\"t08kyTat\"\u003e- 怎么做的任务拆分？**为什么要拆分？** 效果如何？怎么提升效果？\u003c/p\u003e\u003cp data-pid=\"4o4FCUT-\"\u003e- text2sql 怎么做的？怎么提高准确率？\u003c/p\u003e\u003cp data-pid=\"zB0RkKba\"\u003e- 如何润色query，目的是什么？\u003c/p\u003e\u003cp data-pid=\"PvuZW7-u\"\u003e- code-generation 是什么做的？如何确保准确性？\u003c/p\u003e\u003cp data-pid=\"5vJ86p8n\"\u003e- 现在再让你设计你会怎么做？（replan）\u003c/p\u003e\u003cp data-pid=\"cLrEHgth\"\u003e- **效果是怎么量化的？**\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"q5BntbRW\"\u003e### Agent\u003c/p\u003e\u003cp data-pid=\"SmPFgphH\"\u003e- 介绍一下你的 Agent 项目\u003c/p\u003e\u003cp data-pid=\"s7h-DDTV\"\u003e- 长短期记忆是怎么做的？记忆是怎么存的？粒度是多少？怎么用的？\u003c/p\u003e\u003cp data-pid=\"-0cGbGah\"\u003e- Function Call 是什么做的？\u003c/p\u003e\u003cp data-pid=\"wzD_Swy6\"\u003e- 你最大的难题是什么？你是怎么提高效果的？怎么降低延迟的？\u003c/p\u003e\u003cp data-pid=\"7l_CorhM\"\u003e- 端到端延迟如何优化的？\u003c/p\u003e\u003cp data-pid=\"tpA3wh9S\"\u003e- 介绍一下single-agent、multi-agent的设计方案有哪些？\u003c/p\u003e\u003cp data-pid=\"SY3CHxE1\"\u003e- 反思机制是什么做的？为什么要用反思？\u003c/p\u003e\u003cp data-pid=\"6y7cIbLY\"\u003e- 如何看待当下的LLM应用的趋势和方向\u003c/p\u003e\u003cp data-pid=\"gjtQlKqF\"\u003e- 为什么要用Webrtc？它和ws的区别是什么？\u003c/p\u003e\u003cp data-pid=\"rfX5952v\"\u003e- agent服务高可用、稳健性是怎么保证的？\u003c/p\u003e\u003cp data-pid=\"EurNgK1x\"\u003e- llm 服务并发太高了怎么办？\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"OnmqpyUL\"\u003e### 系统设计题\u003c/p\u003e\u003cp data-pid=\"sRnz5fSu\"\u003e- 短链系统\u003c/p\u003e\u003cp data-pid=\"YJOATUpL\"\u003e- 分布式锁的设计\u003c/p\u003e\u003cp data-pid=\"1IuVrf03\"\u003e- 给你一部长篇小说，怎么做文档切割？\u003c/p\u003e\u003cp data-pid=\"ux-KIOwH\"\u003e- 怎么做到论文翻译，并且格式尽可能和原来的统一\u003c/p\u003e\u003cp data-pid=\"2YCJa0nN\"\u003e- 游戏社区客服助手设计。如何绑定游戏黑话，如何利用好公司内部的文档\u003c/p\u003e\u003cp data-pid=\"3DaJJf5H\"\u003e- 结合线上问题快速定位项目工程代码有问题的地方\u003c/p\u003e\u003cp data-pid=\"9IuL5Uu9\"\u003e- 有很多结构化和非结构化数据，怎么分析，再怎么得出我要的结论。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"ZMAjwnxL\"\u003e### 八股\u003c/p\u003e\u003cp data-pid=\"CFJtQvTW\"\u003e- go的内存分配策略、GMP、GC\u003c/p\u003e\u003cp data-pid=\"t7Sms9Cj\"\u003e- python 的内存分配策略、GC\u003c/p\u003e\u003cp data-pid=\"I_7p1X5j\"\u003e- redis 用过那些？mget 底层什么实现的？、zset怎么实现的？\u003c/p\u003e\u003cp data-pid=\"qryb_WRN\"\u003e- mysql 索引怎么设计最好？数据库隔离级别？mvcc是怎么实现的？\u003c/p\u003e\u003cp data-pid=\"JmvYUWUc\"\u003e- 分布式锁是什么实现的？\u003c/p\u003e\u003cp data-pid=\"CR9PXuqD\"\u003e- kafka的 reblance 是什么？会产生那些问题？怎么保证数据不丢?\u003c/p\u003e\u003cp data-pid=\"ZwtyZiAr\"\u003e- fastapi 设计原理？\u003c/p\u003e\u003cp data-pid=\"rqp62SrY\"\u003e- go 中 net/http 如何处理的tcp粘包问题\u003c/p\u003e\u003cp data-pid=\"YZ4R-F59\"\u003e- http2 是什么？比http1.1有什么优势？\u003c/p\u003e\u003cp data-pid=\"W2drG9nM\"\u003e- Linux 网络性能调优的方式\u003c/p\u003e\u003cp data-pid=\"eFwoI2su\"\u003e- 如何定位Linux中的pid、端口号等等\u003c/p\u003e\u003cp\u003e\u003c/p\u003e","is_labeled":false,"visited_count":4539,"favorite_count":424,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1911103917124722972}","attached_info":"CqMFCLi+kpC/2NTfiAEQBxoJMjU4MzE1OTc4IL+g28EGKIQBMA1AMUowCgZJdGVtQ0YSIGRvY190eXBlOiBBcnRpY2xlCmlkOiAyNDczMzQ1MDkKGAAgADoAYiA2YTVmM2ZkNDliNjc0MDhlNzMzN2ZmZTk5Mzg3ZTgxNnITMTkxMTEwMzkxNzEyNDcyMjk3MqoBCXJlY29tbWVuZMIBIDgxZDQ4MmM1MWY1MTY3OTBmMTgyNTkyNDRlZmNkNzNk8gEKCAwSBk5vcm1hbPIBKAgKEiRiYThmMmFhNy01ZGE0LTQ0ODYtODAzOC1mMTUyMWJiMjAyMzHyAQUICxIBOYICAIgC9NDUzfoykgIgODFkNDgyYzUxZjUxNjc5MGYxODI1OTI0NGVmY2Q3M2SaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygITRW1iU2ltSXNvbGF0aW9uUnVsZdoCBkl0ZW1DRugCA/oCC05PUk1BTF9GTE9XigMgNDg2MDhkNDk5NGI0NGI2Mjg0YmZkNGIzYjA4ZjI3ZTSaAw0KAnYyEAAaBW90aGVyqAO7I9gDAOoDH3RleHRBbGxTaXRlTXZIaWdoQWN0aW9uSXRlbUNGVjH6Ax8SDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFgAQAiAQAkgQGTm9ybWFsmgQBM6AEAKgEALAEALoEBm1hbnVhbMIEAzE3MMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAAEJ5sT+BBQAAAAAAAAAAiQWJcPv8eFHSP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AUJkAYAoAYxqAYDkgIuCgkyNTgzMTU5NzgSEzE5MTExMDM5MTcxMjQ3MjI5NzIYByIKSU1BR0VfVEVYVA==","action_card":false},{"id":"50_1750898911.314","type":"feed","offset":50,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750898911,"updated_time":1750898911,"target":{"id":"1917938475702949163","type":"answer","url":"https://api.zhihu.com/answers/1917938475702949163","author":{"id":"4e8c59575ffd24dc9c1164899c7629cc","url":"https://api.zhihu.com/people/4e8c59575ffd24dc9c1164899c7629cc","user_type":"people","url_token":"qqq-37-37","name":"QQQ","headline":"公众号：张介子笔记","avatar_url":"https://pica.zhimg.com/50/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":554,"is_following":false,"is_followed":false},"created_time":1750052166,"updated_time":1750839726,"voteup_count":301,"thanks_count":15,"comment_count":12,"is_copyable":true,"question":{"id":"313830485","type":"question","url":"https://api.zhihu.com/questions/313830485","author":{"id":"e28d77099a91565e601626b4578a17ff","url":"https://api.zhihu.com/people/e28d77099a91565e601626b4578a17ff","user_type":"people","url_token":"chun-cui-44-61","name":"纯粹","headline":"商","avatar_url":"https://pic1.zhimg.com/50/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":10,"is_following":false,"is_followed":false},"title":"目前为止，你总结出的最大人生经验是什么？","created":1551225668,"answer_count":0,"follower_count":0,"comment_count":147,"bound_topic_ids":[307,404,740,1053,1546],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"当年天涯上有一个帖子，讲的是以“感觉驱动论”颠覆传统成功学，揭示人生意义在于捕捉专属自我的精神体验，提出“接纳原生条件、激活内在力量感”的核心生存哲学，彻底解构世俗羡慕链。 天涯论坛：《30岁前必须明白的真相》 作者：佚名 原文完整版PDF：https://v.wkbrowser.com/s/ftkRmzzXWLI/ 以下是原文内容，或许对你有所帮助： 我思考了很多年的人生，得出一个结论，人就是为了某种感觉而活着的。这种感觉，可能是一种愉悦的情绪，可能是一种踏…","excerpt_new":"当年天涯上有一个帖子，讲的是以“感觉驱动论”颠覆传统成功学，揭示人生意义在于捕捉专属自我的精神体验，提出“接纳原生条件、激活内在力量感”的核心生存哲学，彻底解构世俗羡慕链。 天涯论坛：《30岁前必须明白的真相》 作者：佚名 原文完整版PDF：https://v.wkbrowser.com/s/ftkRmzzXWLI/ 以下是原文内容，或许对你有所帮助： 我思考了很多年的人生，得出一个结论，人就是为了某种感觉而活着的。这种感觉，可能是一种愉悦的情绪，可能是一种踏…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"z8bJi7T9\"\u003e当年天涯上有一个帖子，讲的是以“感觉驱动论”颠覆传统成功学，揭示人生意义在于捕捉专属自我的精神体验，提出“接纳原生条件、激活内在力量感”的核心生存哲学，彻底解构世俗羡慕链。\u003c/p\u003e\u003cp data-pid=\"FDsH1Xkr\"\u003e\u003cb\u003e天涯论坛：《30岁前必须明白的真相》\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"wVOe47HB\"\u003e\u003cb\u003e作者：佚名\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"u60_-tH-\"\u003e\u003cb\u003e原文完整版PDF：\u003c/b\u003e\u003ca href=\"https://link.zhihu.com/?target=https%3A//v.wkbrowser.com/s/ftkRmzzXWLI/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003ev.wkbrowser.com/s/ftkRm\u003c/span\u003e\u003cspan class=\"invisible\"\u003ezzXWLI/\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003cp data-pid=\"K3_JzP92\"\u003e以下是原文内容，或许对你有所帮助：\u003c/p\u003e\u003cp data-pid=\"R2qpvx_R\"\u003e我思考了很多年的人生，得出一个结论，人就是为了某种感觉而活着的。这种感觉，可能是一种愉悦的情绪，可能是一种踏实的满足感，可能是虚荣的快乐，可能是一种幸福的安全感，也可能是一种充满力量的感觉。也可能是一种高高在上的优越感，又可能是一种占了便宜的得到意外之财的惊喜感，也可能是吃饱的饱腹感，吃辣的时候的刺激感。\u003c/p\u003e\u003cp data-pid=\"sf4kTDN9\"\u003e所有的所有，人所作的一切，都是为了感觉而生。\u003c/p\u003e\u003cp data-pid=\"XKXl_wya\"\u003e人生的所有意义，都建立于感觉之上，就连一个母亲在临死前拯救自己的孩子，牺牲自己，也是因为体内的催产素和肾上腺素等等激素刺激，大脑产生了一种责任感和使命感。\u003c/p\u003e\u003cp data-pid=\"ijB6sU2A\"\u003e如果没有这种责任感，母亲就不会牺牲自己救下孩子。\u003c/p\u003e\u003cp data-pid=\"3cXfEtg7\"\u003e人为感觉而活，人被感觉所驱动，也为感觉而死。你之所以会羡慕别人的人生，是因为你对某种感觉的执念太深了，或者你对你从来没有得到的感觉的幻想太美好。\u003c/p\u003e\u003cp data-pid=\"T4m1axx5\"\u003e但人的感觉不是只有一种，而是千千万万种。就好像味觉又酸甜苦辣咸一样，人体内的情绪和体验感觉，只会更丰富，丰富到你一生也没有办法完全体验完。\u003c/p\u003e\u003cp data-pid=\"i1HQHpgK\"\u003e所以，我认清了一个现实，就是人在有限的生命和时间里，能体验到的感觉，是极其有限的。特别是原生条件越差，能体验的感觉就越少。\u003c/p\u003e\u003cp data-pid=\"FaYIw9_m\"\u003e这就是命。\u003c/p\u003e\u003cp data-pid=\"tWtzTsEA\"\u003e就算是原生条件很好的人，也有无法体验过的感觉。\u003c/p\u003e\u003cp data-pid=\"MdmkE2Vo\"\u003e例如，穷孩子不会体验过富二代那些纸醉金迷的生活，因为在那个时间里，穷孩子正在热血偾涨，冲劲十足地备战高考。\u003c/p\u003e\u003cp data-pid=\"FhHlhqdh\"\u003e享受物质快乐的感觉是感觉，难道那种热血十足，内心充满力量，对未来有无限美好期盼的奋战的感觉，就不是感觉吗？\u003c/p\u003e\u003cp data-pid=\"7CYEmXNj\"\u003e所谓的肉体也好，物质也好，最后都是为了让你体验某种感觉的媒介而已。\u003c/p\u003e\u003cp data-pid=\"OsXzkM1y\"\u003e最重要的是你心里的感觉。你感受不到，即使再好吃的食物，再美丽的珠宝放在你面前，你也会无动于衷。\u003c/p\u003e\u003cp data-pid=\"_k-8OQmM\"\u003e所以，我就明白了一个道理，所有东西都不重要，感觉才是最重要的。\u003c/p\u003e\u003cp data-pid=\"gU_k_mHH\"\u003e有些感觉，如果我一出生的时候没有，那我可能一辈子也不会拥有。\u003c/p\u003e\u003cp data-pid=\"7GhowsoL\"\u003e但有些感觉，我有的，别人未必会有。\u003c/p\u003e\u003cp data-pid=\"UBOlSY24\"\u003e世界就是这样的，有得必有失，你享受了年少成名的喜悦，你就无法获得大器晚成，欲望累积到极致再释放的快乐。\u003c/p\u003e\u003cp data-pid=\"dIhhBPsE\"\u003e你享受了不劳而获的快乐，你就享受不到通过努力获得自己想要的东西的快乐。\u003c/p\u003e\u003cp data-pid=\"eZMDCiWM\"\u003e你沉迷于当一个富二代的快乐，沉迷享受的快乐，你就没有办法体验富一代，自己创造价值的快乐。\u003c/p\u003e\u003cp data-pid=\"_gERWp7l\"\u003e世界是不公平的，同时也是公平的。\u003c/p\u003e\u003cp data-pid=\"jt-YV7Mn\"\u003e所以，看清楚这一点，我就再也不羡慕别人的快乐和感觉了。\u003c/p\u003e\u003cp data-pid=\"OUycsDdi\"\u003e因为我知道了，人生最重要的事情，就是认清你自己，找到你属于你的自己真正的快乐和感觉，去抓住那些本来就属于你的快乐和感觉，追求那些你可以追求得到的快乐和感觉。\u003c/p\u003e\u003cp data-pid=\"5n8o-4z8\"\u003e而不是作为一只鱼，却羡慕鸟能飞，作为一只鸟，却羡慕鱼能在水里畅游。\u003c/p\u003e\u003cp data-pid=\"_lMUPN5s\"\u003e你要先把自己的快乐和感觉抓住，懂吗？\u003c/p\u003e\u003cp data-pid=\"BP54cu8O\"\u003e不要再羡慕别人的快乐的时候，忘记了自己的快乐，甚至因为羡慕别人而郁郁寡欢，虚度了光阴，最后连自己的快乐都没抓住。\u003c/p\u003e\u003cp data-pid=\"_fUDOBoz\"\u003e你可以说你出身多好，背景多牛逼，有多厉害，获得受别人追捧的快乐。\u003c/p\u003e\u003cp data-pid=\"7oNJjHCd\"\u003e我也可以因为出身低微，但是一路逆行而上，最终成就一个坚韧而强大的自己而自豪。\u003c/p\u003e\u003cp data-pid=\"oYihqz4L\"\u003e你大可说自己的一身衣服多值钱，多好看，多稀有。但我这一身靠自己锻炼来的肌肉，也不差。\u003c/p\u003e\u003cp data-pid=\"HPYqTf9p\"\u003e我没有办法一出生就含着金钥匙，但我会靠自己的汗水和付出，得到我自己的“金钥匙”。\u003c/p\u003e\u003cp data-pid=\"fGzSuFHU\"\u003e只是我的金钥匙，和你的金钥匙，未必是同一把。\u003c/p\u003e\u003cp data-pid=\"PZ1aOhNS\"\u003e我想要的，也未必就是你嘴里的那把金钥匙。\u003c/p\u003e\u003cp data-pid=\"SyBQUPWt\"\u003e所以，我也从来不会因为自己的出身低微而自卑，也不会羡慕别人出生优渥就嫉妒羡慕。\u003c/p\u003e\u003cp data-pid=\"Z8fp9ajj\"\u003e因为我就是我。I am what i am.\u003c/p\u003e\u003cp data-pid=\"yBqTAB5s\"\u003e我从来不需要过一个不属于我的生活，和羡慕一个不属于我的人生。因为我知道，羡慕也没有用。\u003c/p\u003e\u003cp data-pid=\"iwUoqSYr\"\u003e我只能抓住那些原本就属于我的人生的东西。\u003c/p\u003e\u003cp data-pid=\"BIROsHBd\"\u003e我也没必要融入不属于我的圈子，成为我不应该成为的人。\u003c/p\u003e\u003cp data-pid=\"NeI2V_Sb\"\u003e我出生在广西，我也不会张口闭口就是京爷沪爷。因为我为自己的家乡而自豪，我为自己的出身而自信。\u003c/p\u003e\u003cp data-pid=\"rQ2yljiT\"\u003e贫穷落后暴力的环境，让我的眼界狭窄，不够优雅和没见过世面，但是给我带来了旺盛的生命力和狂放不羁，充满野性，永远不被驯服的自由的心。\u003c/p\u003e\u003cp data-pid=\"ShaIPlAg\"\u003e我从来不觉得我作为一个南蛮，作为一个广西人有什么不好。\u003c/p\u003e\u003cp data-pid=\"jgnrbltc\"\u003e你生活在一个优渥的家庭环境中，可能从小就见过各种世面，体验过各种物质快乐。\u003c/p\u003e\u003cp data-pid=\"klHtpfnj\"\u003e但我生活在大自然里，我从小就和动物和山野打交道，我也能感受到最原始的生命气息和快乐。\u003c/p\u003e\u003cp data-pid=\"O4lO_mJD\"\u003e你可能一言一行都是优雅和有教养的，但我的一举一动，都是充满活力和爆发力的。\u003c/p\u003e\u003cp data-pid=\"WKHwxMU-\"\u003e你可能从小到大都生活美满，从未遭受过暴力，但我所处的暴力环境，却造就了我不畏惧暴力和强权的性格。\u003c/p\u003e\u003cp data-pid=\"c4BljzDf\"\u003e我从来不觉得人一定要出生在哪里，拥有什么天赋或者外在物质，然后根据什么样的价值观活着。\u003c/p\u003e\u003cp data-pid=\"yHid-tCv\"\u003e我活着，我就会找到自己活着的意义和快乐，找到属于我自己的感觉。因为我就是我。\u003c/p\u003e\u003cp data-pid=\"4u4a2uKe\"\u003e你有你谦虚的时候，受人爱戴的快乐，我也有我狂傲的时候，那种自信溢出的感觉。\u003c/p\u003e\u003cp data-pid=\"r59kjQgn\"\u003e我从来没觉得谁对谁错，谁就应该按照谁的方式活着，不然就是失败和错误的。\u003c/p\u003e\u003cp data-pid=\"Tn5dksgx\"\u003e这个世界是包容的。\u003c/p\u003e\u003cp data-pid=\"53bUENS1\"\u003e如果我能包容别人，我就能包容我自己。\u003c/p\u003e\u003cp data-pid=\"o9R5rK97\"\u003e如果我可以羡慕我自己，我就不必去羡慕别人。\u003c/p\u003e\u003cp data-pid=\"yP54SBAE\"\u003e所以，我为什么要去羡慕别人的人生呢？\u003c/p\u003e\u003cp data-pid=\"61Nda4MP\"\u003e我把自己能抓住的抓住就好了，按照我自己认可的方式活着就好了。\u003c/p\u003e\u003cp data-pid=\"cGDs1W80\"\u003e你有你的天赋异禀，我也有我的坚持不懈。\u003c/p\u003e\u003cp data-pid=\"7pEJHil8\"\u003e你是天龙，那我就是地虎。\u003c/p\u003e\u003cp data-pid=\"G19oBxt7\"\u003e羡慕别人的人生，只会浪费我的时间，让我无法成为我本应该成为的自己。\u003c/p\u003e\u003cp data-pid=\"2uAE9ao5\"\u003e老天原本给了你一些馈赠，但是你却没有抓住。你总是在埋怨世界，埋怨社会，而从来看不到那些从黑暗和绝望中生长出来的花朵，发现不了它们身上顽强的生命力。\u003c/p\u003e\u003cp data-pid=\"1-DcAHJU\"\u003e所以，我时刻提醒着自己，我是谁，我应该做什么，我的人生应该是什么样的。而不会去关注别人的人生是怎么样的。那和我没有关系。\u003c/p\u003e\u003cp data-pid=\"FhmyoI_e\"\u003e而且，我告诉你吧。\u003c/p\u003e\u003cp data-pid=\"3_Phfb2o\"\u003e我所体验过的感觉当中，那些外在的虚荣的快乐，和内在的精神上的力量感，是完全不同的。\u003c/p\u003e\u003cp data-pid=\"1FjRLeVZ\"\u003e前者是短暂而虚浮的，而后者是日益强盛的。\u003c/p\u003e\u003cp data-pid=\"zsR4uTWd\"\u003e当第一次有人夸你聪明的时候，你会很快乐，但第一百次夸你聪明的时候，你就再也不可能找到第一次被夸的时候的快乐了。\u003c/p\u003e\u003cp data-pid=\"4c8jgoEB\"\u003e我从小到大，被无数次夸过聪明，帅气，运动能力强，工作能力强，游戏打得好。但这些感觉，都不及内心拥有力量的，拥有生命力和冲劲的感觉的十分之一。\u003c/p\u003e\u003cp data-pid=\"KAAnkbe9\"\u003e在我看来，做一件事情的冲劲和力量感，远比做到一件事情快乐，更比因为这件事情的收获的物质快乐。\u003c/p\u003e\u003cp data-pid=\"morZuNh8\"\u003e也就是说，推动人前进的力量感，大于做到一件事情的成就感，更大于获得物质收获的虚荣感。\u003c/p\u003e\u003cp data-pid=\"_-3RkAdu\"\u003e这种力量感，也是我必生在追求的东西。只要能一直维持这种力量感，让我保持奋斗和冲劲、战斗的状态。\u003c/p\u003e\u003cp data-pid=\"e0VA20WU\"\u003e那种饱满到每一个细胞都充满力量的感觉，那种因为有着极强的力量感和控制感而产生的自信和狂傲。那其实最后做不做得到一件事情，得没得到一些物质成就，已经不重要了。\u003c/p\u003e\u003cp data-pid=\"u-uOT_5e\"\u003e因为我已经得到了我想要的东西了。就是一颗纯粹的，充满力量和自信、冲劲十足，韧性十足的绝对自由和野性的心。\u003c/p\u003e\u003cp data-pid=\"ruSRZOLc\"\u003e这颗心，才是我体验过的世界上最美好，最极致的感觉。\u003c/p\u003e\u003cp data-pid=\"MPHY8iyd\"\u003e其他的那些，什么学历、智商、样貌、财富、名气，都是锦上添花的浮云而已。\u003c/p\u003e\u003cp data-pid=\"kzqq6G51\"\u003e有最好，没有我也不会太在乎。\u003c/p\u003e\u003cp data-pid=\"Vg-HEcCR\"\u003e所以，你根本不需要羡慕别人的人生，而是想想，怎么去激活和获得那颗你想要的心就行了。\u003c/p\u003e\u003cp data-pid=\"PDxdaTu3\"\u003e拥有那颗心给你带来的感觉和快乐，是任何东西都无法比拟的。\u003c/p\u003e\u003cp data-pid=\"avKF3ku5\"\u003e因为你是自由而独立强大，你就是你自己。\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":11709,"favorite_count":680,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1917938475702949163}","attached_info":"Cp4FCLi+kpC/2NTfiAEQBBoJNzMyNDUzMDQ1IMbavsIGKK0CMAxAMkogChVUU19TT1VSQ0VfVEhFTUVfTUVSR0USATAYACAAOgBaCDMyMDE2NDc1YiA2YTVmM2ZkNDliNjc0MDhlNzMzN2ZmZTk5Mzg3ZTgxNnITMTkxNzkzODQ3NTcwMjk0OTE2M4oBCTMxMzgzMDQ4NaoBCXJlY29tbWVuZMIBIDRlOGM1OTU3NWZmZDI0ZGM5YzExNjQ4OTljNzYyOWNj8gEKCAwSBk5vcm1hbPIBKAgKEiQxZDdjYTJkZC01MGJlLTRkMjEtODM5Ny0xZTk5MjQwMjAyM2LyAQUICxIBOYICAIgC9NDUzfoykgIgNGU4YzU5NTc1ZmZkMjRkYzljMTE2NDg5OWM3NjI5Y2OaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxl2gIVVFNfU09VUkNFX1RIRU1FX01FUkdF6AID+gILTk9STUFMX0ZMT1eKAyA0ODYwOGQ0OTk0YjQ0YjYyODRiZmQ0YjNiMDhmMjdlNJoDDQoCdjIQABoFb3RoZXKoA71b2AMA6gMbVGhlbWVNZXJnZU5ld1YxUG9vbFJlY2FsbGVy+gMfEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERYAEAIgEAJIEBk5vcm1hbJoEATOgBACoBACwBAC6BAZtYW51YWzCBAMxNzDIBADSBA/mjqjojZDlt7Lmm7TmlrDYBADwBAD5BAAAAOBUXqo/gQUAAAAAAAAAAIkFiXD7/HhR0j+SBQCaBQNkZnSiBQNkZnSyBQExuQUAAAAAAAAAANAFAOAFAOgFAPAFCZAGAKAGMqgGAJICLgoJNzMyNDUzMDQ1EhMxOTE3OTM4NDc1NzAyOTQ5MTYzGAQiCklNQUdFX1RFWFQ=","action_card":false},{"id":"51_1750898911.540","type":"feed","offset":51,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750898911,"updated_time":1750898911,"target":{"id":"34421869185","type":"answer","url":"https://api.zhihu.com/answers/34421869185","author":{"id":"3ed87ddd75365ea6c110f9c98b0cc5c8","url":"https://api.zhihu.com/people/3ed87ddd75365ea6c110f9c98b0cc5c8","user_type":"people","url_token":"perfectisshit","name":"PerfectIsShit","headline":"没什么意思，就是闲来逛逛，不是681","avatar_url":"https://picx.zhimg.com/50/v2-b568f4c5cb3da8a38926ce157825c47d_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":1114,"is_following":false,"is_followed":false},"created_time":1731909857,"updated_time":1736066931,"voteup_count":2383,"thanks_count":83,"comment_count":111,"is_copyable":false,"question":{"id":"379531809","type":"question","url":"https://api.zhihu.com/questions/379531809","author":{"id":"ed95b35090df775a6e938bbf70dc74ef","url":"https://api.zhihu.com/people/ed95b35090df775a6e938bbf70dc74ef","user_type":"people","url_token":"feng-yiyang-zi-you-34-73","name":"知乎用户PuA19g","headline":"","avatar_url":"https://pic1.zhimg.com/50/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":2,"is_following":false,"is_followed":false},"title":"许多公式都有π和e，可能的原因有什么？","created":1584205150,"answer_count":0,"follower_count":0,"comment_count":15,"bound_topic_ids":[1291,2253,10522,23606,41290],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"π和e本质是对连续和无穷的描述。 这符合大自然的基本规律。 e最本质的特性，就是所有自然数阶乘倒数之和。 其余的求导不变性，微分方程通解，其实都是后来派生出来的特征。阶乘是离散意味，所有自然数是连续意味，因此 e是动态的离散和连续的微观统一。π最本质的特性，是所有自然数倒数平方之和＝π²/6。其余的圆函数（三角）这种几何特征，也是后来派生出来的，毕竟直线（自然数）就是直径无穷大的圆。因此 π是静态的离散…","excerpt_new":"π和e本质是对连续和无穷的描述。 这符合大自然的基本规律。 e最本质的特性，就是所有自然数阶乘倒数之和。 其余的求导不变性，微分方程通解，其实都是后来派生出来的特征。阶乘是离散意味，所有自然数是连续意味，因此 e是动态的离散和连续的微观统一。π最本质的特性，是所有自然数倒数平方之和＝π²/6。其余的圆函数（三角）这种几何特征，也是后来派生出来的，毕竟直线（自然数）就是直径无穷大的圆。因此 π是静态的离散…","preview_type":"default","preview_text":"","reshipment_settings":"disallowed","content":"\u003cp data-pid=\"RgnzIkla\"\u003eπ和e本质是对连续和无穷的描述。\u003c/p\u003e\u003cp data-pid=\"EhJCZ5rN\"\u003e这符合大自然的基本规律。\u003c/p\u003e\u003cp data-pid=\"72sI0wtG\"\u003ee最本质的特性，就是所有自然数阶乘倒数之和。\u003c/p\u003e\u003cp data-pid=\"1kT73lJb\"\u003e其余的求导不变性，微分方程通解，其实都是后来派生出来的特征。阶乘是离散意味，所有自然数是连续意味，因此\u003cb\u003ee是动态的离散和连续的微观统一。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"l9iay6vr\"\u003eπ最本质的特性，是所有自然数倒数平方之和＝π²/6。其余的圆函数（三角）这种几何特征，也是后来派生出来的，毕竟直线（自然数）就是直径无穷大的圆。因此\u003cb\u003eπ是静态的离散和连续的宏观统一。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"tbv_gQWE\"\u003e由此来看上帝欧拉公式，是动静结合的大一统，数域统一到复数域，代数闭域。\u003c/p\u003e\u003cp data-pid=\"aArpCFtT\"\u003e另外π的本质为什么带平方，是因为需要用勾股定理，勾股定理是欧几里得空间平直特征的体现。\u003c/p\u003e\u003ca data-draft-node=\"block\" data-draft-type=\"link-card\" href=\"https://zhuanlan.zhihu.com/p/343834569?utm_psn=1841847755233976322\" data-image=\"https://pic3.zhimg.com/v2-c7d13a4ab80f3df8bd58c8899cd5b2a4_r.jpg\" data-image-width=\"1728\" data-image-height=\"724\" class=\"internal\"\u003eDahridReam：正整数倒数的平方和（巴塞尔问题）\u003c/a\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-ae0eb137912405bb03446a1e903dc6be_1440w.jpg\" data-rawwidth=\"1080\" data-rawheight=\"339\" data-size=\"normal\" data-original-token=\"v2-8582e5311b3e04307f5217a8dec9584b\" data-default-watermark-src=\"https://picx.zhimg.com/v2-c7044d267d63f721975374b51a8a68bf_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ae0eb137912405bb03446a1e903dc6be_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"RUY9a3vY\"\u003e这个问题说的挺好的。\u003c/p\u003e\u003chr/\u003e\u003cp data-pid=\"qkuV9VVw\"\u003e认识客观规律的时间顺序和客观本质发展的顺序并不相同，就像微积分实际发展顺序和课本讲的逻辑顺序也不一致，学完微积分，按理论来说，应该先有微分后积分，历史上确实相反的，这和历史社会发展需求密切相关。我们总是先朴素的接受π是圆周率这个客观事实，这是社会生产力导致的结果。但是并不一定说明圆周率就是π的本质。只不过用的频率太高了，所以封装个π的概念。\u003cb\u003e在我看来π只是一个中间件。\u003c/b\u003e在最平凡的欧几里得世界里，就不应该有所谓的曲线，都应该是直的。只不过微积分给我们一套以直代曲的方法，让曲线无穷精确分解成直线，曲线是无穷小分解，圆则是无穷大构造，就是直线实际上是无穷大直径圆构成的，这样结合勾股定理就可以推出π²/6这个更加和谐统一的形式。但是使用频率来看，对π封装肯定是最优解。就像牛顿力学对f的封装，不能说f是运动的本质。但是这并不妨碍牛顿力学的伟大。\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":227059,"favorite_count":2825,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 34421869185}","attached_info":"CucFCLi+kpC/2NTfiAEQBBoJNzAwMDAwMzM2IOGx67kGKM8SMG9AM0otCh1UU19TT1VSQ0VfRkVFRF9VU0VSX0VYUEVSVF9DRhIGOTA2OTg0GAAgADoAWgg0NjYxODg4MWIgNmE1ZjNmZDQ5YjY3NDA4ZTczMzdmZmU5OTM4N2U4MTZyCzM0NDIxODY5MTg1igEJMzc5NTMxODA5qgEJcmVjb21tZW5kwgEgM2VkODdkZGQ3NTM2NWVhNmMxMTBmOWM5OGIwY2M1YzjyAQoIDBIGTm9ybWFs8gEoCAoSJDZlZTA2ODQ3LTViNjQtNDRjOC05MzE0LTQ5OWQxNmYwNWIyZPIBBQgLEgE5ggIAiAL00NTN+jKSAiAzZWQ4N2RkZDc1MzY1ZWE2YzExMGY5Yzk4YjBjYzVjOJoCAMoCFlNob3JJbnRlcmVzdFdlaWdodFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXKAhRDb250ZW50QWdlV2VpZ2h0UnVsZdoCHVRTX1NPVVJDRV9GRUVEX1VTRVJfRVhQRVJUX0NG6AIC+gILTk9STUFMX0ZMT1eKAyA0ODYwOGQ0OTk0YjQ0YjYyODRiZmQ0YjNiMDhmMjdlNJoDDQoCdjIQABoFb3RoZXKoA/PtDdgDAOoDEGFpR3JhcGhFbWJVc2VyQ0b6A04SDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFOi0IAhC4CBjTAiIjdjItODU4MmU1MzExYjNlMDQzMDdmNTIxN2E4ZGVjOTU4NGKABACIBACSBAZOb3JtYWyaBAEyoAQAqAQAsAQAugQGbWFudWFswgQDMTYwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAADAt0eeP4EFAAAAAAAAAACJBYlw+/x4UdI/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBQmQBgCgBjOoBgCSAiYKCTcwMDAwMDMzNhILMzQ0MjE4NjkxODUYBCIKSU1BR0VfVEVYVA==","action_card":false},{"id":"52_1750898911.637","type":"feed","offset":52,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750898911,"updated_time":1750898911,"target":{"id":"1921488782248613041","type":"answer","url":"https://api.zhihu.com/answers/1921488782248613041","author":{"id":"b088efb56057146ec4b124e451b32004","url":"https://api.zhihu.com/people/b088efb56057146ec4b124e451b32004","user_type":"people","url_token":"zhu-zhong-tao","name":"北极星KM","headline":"不断读书，不断忘记","avatar_url":"https://pic1.zhimg.com/50/0f3c3578f_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":108,"is_following":false,"is_followed":false},"created_time":1750898625,"updated_time":1750898625,"voteup_count":0,"thanks_count":0,"comment_count":0,"is_copyable":true,"question":{"id":"536520043","type":"question","url":"https://api.zhihu.com/questions/536520043","author":{"id":"e8c0bf70fe04df6c47968dff69826ae4","url":"https://api.zhihu.com/people/e8c0bf70fe04df6c47968dff69826ae4","user_type":"people","url_token":"hsu-21-72","name":"思考怪-徐先生","headline":"一个思考的怪物，抽丝剥茧，探究本质","avatar_url":"https://picx.zhimg.com/50/v2-057c3e18686eb75767c070a65150bf31_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":25,"is_following":false,"is_followed":false},"title":"人最强的动力来源是什么？","created":1654592182,"answer_count":0,"follower_count":0,"comment_count":0,"bound_topic_ids":[9006,90887,155178],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"做事三分钟热度，计划跑步，装备买好了，一周以后开始吃灰；买了一堆书，发誓一年内让自己脱胎换骨，结果很多书的蒙皮还没撕开就当废品卖掉了。然而现实中总有一些大神，仿佛有不尽的动力一直从事某项事业，他们几十年如一日地跑步、读书、写作、编程等等，他们是如何获得源源不断的动力的？很多人认为他们有着坚定的毅力，他们自律的能力远超常人。我始终认为仅仅靠毅力和自律断然不可能坚持几十年，能够让人长期做一件事情必然…","excerpt_new":"做事三分钟热度，计划跑步，装备买好了，一周以后开始吃灰；买了一堆书，发誓一年内让自己脱胎换骨，结果很多书的蒙皮还没撕开就当废品卖掉了。然而现实中总有一些大神，仿佛有不尽的动力一直从事某项事业，他们几十年如一日地跑步、读书、写作、编程等等，他们是如何获得源源不断的动力的？很多人认为他们有着坚定的毅力，他们自律的能力远超常人。我始终认为仅仅靠毅力和自律断然不可能坚持几十年，能够让人长期做一件事情必然…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"VblSe7ZS\"\u003e做事三分钟热度，计划跑步，装备买好了，一周以后开始吃灰；买了一堆书，发誓一年内让自己脱胎换骨，结果很多书的蒙皮还没撕开就当废品卖掉了。然而现实中总有一些大神，仿佛有不尽的动力一直从事某项事业，他们几十年如一日地跑步、读书、写作、编程等等，他们是如何获得源源不断的动力的？很多人认为他们有着坚定的毅力，他们自律的能力远超常人。我始终认为仅仅靠毅力和自律断然不可能坚持几十年，能够让人长期做一件事情必然有其他原因。是什么原因呢？\u003c/p\u003e\u003cp data-pid=\"vx-op7Sj\"\u003e当对一件事情充满期待时，初始的动力往往很大。我刚刚读研时，我问我的师兄怎样才能学好Linux，他告诉我仔细学完《Unix高级环境编程》这本书肯定能变成Linux高手，我当时很激动，立即买了这本书，以很大的热情去读这本书。但初始的动力，往往是因为幻想，在执行过程中必然会遇到困难、枯燥，难以快速达到自己的期望，这时候就会伴随失望、挫败感、沮丧等负面情绪，这些情绪会削弱前进的动力以至停止，甚至留下心理阴影。那么，如何才能获得持续的动力？\u003c/p\u003e\u003cp data-pid=\"BHWhHdvR\"\u003e当对一件事情充满期待时，最好先给自己泼冷水，郑重提醒自己，任何一件有价值有意义的事情都不是一帆风顺的，必然伴随着挫折、枯燥、无聊，在这个前提下，给这件事赋予意义，以做这件事的意义为自己提供动力。\u003c/p\u003e\u003cp data-pid=\"PxAwASd0\"\u003e以我写作举例，当一个自由职业者是我的理想，当一个自由职业者有诸多好处，有从事自己喜欢的事情的自由，有安排自己时间的自由，有安排自己工作地点的自由，想想这些都激动。但是，我有年近70岁的父母双亲要养，有两个未成年人要养，有房贷要还，我们一家还都在北京生活，这就意味着我这个自由职业的收入要能负担得起这些开销，还要有些盈余以应对突发风险，因此我的写作水平得到top级，这必然是一件非常难的事情，而且我都40岁了，留给我的时间也不多了。但这些困难虽然存在，这并不意味着我要放弃，越是我这个年纪，越需要自由的时间，自由职业的意义对我来说越大，越应该坚定信念、迅速达成目标。\u003c/p\u003e\u003cp data-pid=\"oom8eW2h\"\u003e前面提到了，要想获得成功，必然经历挫折、痛苦、枯燥甚至自我怀疑，如何在面临困境时有继续前行的动力？\u003c/p\u003e\u003cp data-pid=\"lRXkodJf\"\u003e第一、还是要时时提醒自己做这件事情的初心和这件事本身的意义。电影中有很多这样的画面，当一个人在外打拼，遇到困难或险境时，总会拿出自己家人的照片，面露微笑，然后收起照片，以坚毅的目光迅速前行，直面困难和险境。\u003c/p\u003e\u003cp data-pid=\"ilTkZ6wU\"\u003e第二、人还是需要正向的反馈和奖励的。在《刻意练习》这本书中，讲到了正向反馈是做事的动力之一。书中训练记忆数字长度的主人翁史蒂夫说持续的进步是他训练记忆能力的动力之一。《The art of impossible》这本书中说，一个又一个的胜利，会让自己对这件事更加热爱。正向反馈就是可衡量的进步，比如跑步配速提高30秒，数学学会了分数的约分，发表的作品获得了一个点赞等等。\u003c/p\u003e\u003cp data-pid=\"oKRlfnJa\"\u003e第三、专注并获得心流\u003c/p\u003e\u003cp data-pid=\"OWq7JQV4\"\u003e人在专注于当下任务时，往往会获得心流。心流是一种美好的体验，心流状态会产生更多的多巴胺，获得成就感和满足感，这些感觉会让我们走得更远。与之对应的是焦躁、压力、不耐烦，当我们处于这些状态时，往往会丧失继续前行的动力。写作时专注思考和落笔，跑步时专注抬腿和摆臂，读书时专注领会作者表达的意思并写书评…一旦我们沉浸于当前在做的事情，往往会享受其中，便不会那么烦躁、焦虑和不安，我们很有可能走得更远。\u003c/p\u003e\u003cp data-pid=\"GV87kJfp\"\u003e第四、想办法找乐子\u003c/p\u003e\u003cp data-pid=\"Fd59EwTh\"\u003e即便我们做到了以上三个，仍然会有时候面临枯燥、挫折，甚至因长期处于进步停滞状态而焦虑，打击我们继续前进的动力，这时候就要想办法在这些事情中找一些乐子了。记得小时候学的一篇课文，讲述一个人在寒冷的条件下手被冻的皲裂了，便说：“看是风刀子硬还是我的骨头硬！”还有一些人把学习当做打怪升级，给自己设定一个一个关卡，每过一关就给自己奖励。\u003c/p\u003e\u003cp data-pid=\"ykWitS7t\"\u003e其实只要有西天取经的目标，不论取经路上多么艰难险阻，自己总会想办法克服困难，取经路上也会有贵人相助帮我们度过难关，只要有一个清晰、坚定的目标。\u003c/p\u003e\u003cp\u003e\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":1,"favorite_count":0,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1921488782248613041}","attached_info":"CowGCLi+kpC/2NTfiAEQBBoJNzM0MDQ5MDA3IMGv8sIGKAAwAEA0SiQKGVRTX1NPVVJDRV9XQVJNX1VQX05PUk1BTDESATAYACAAOgBKLwokVFNfU09VUkNFX1dBUk1VUF9UV09UT1dFUl9FWFBWMl9URVhUEgEwGAAgADoAWgg4MTUwODMxNGIgNmE1ZjNmZDQ5YjY3NDA4ZTczMzdmZmU5OTM4N2U4MTZyEzE5MjE0ODg3ODIyNDg2MTMwNDGKAQk1MzY1MjAwNDOqAQlyZWNvbW1lbmTCASBiMDg4ZWZiNTYwNTcxNDZlYzRiMTI0ZTQ1MWIzMjAwNPIBCggMEgZOb3JtYWzyASgIChIkMWY2NDg0Y2MtYmI3ZC00MDZmLWI0OGUtNDg4M2EzZjY4MzFl8gEFCAsSATmCAgCIAvTQ1M36MpICIGIwODhlZmI1NjA1NzE0NmVjNGIxMjRlNDUxYjMyMDA0mgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCGFBlcmlvZEludGVyZXN0V2VpZ2h0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZcoCGENvbnRlbnRXYXJtVXBCcmVha0luUnVsZdoCGVRTX1NPVVJDRV9XQVJNX1VQX05PUk1BTDHoAgD6AgtOT1JNQUxfRkxPV4oDIDQ4NjA4ZDQ5OTRiNDRiNjI4NGJmZDRiM2IwOGYyN2U0mgMNCgJ2MhAAGgVvdGhlcqgDAdgDAOoDL2NvbnRlbnRXYXJtdXBUd29Ub3dlclR2cFRleHROb3JtYWxFeHBWMlJlY2FsbGVy+gMfEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERYAEAIgEAJIEBk5vcm1hbKAEAKgEALAEAMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAA4IrwjD+BBQAAAAAAAAAAiQWJcPv8eFHSP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AUJkAYAoAY0qAYBkgIuCgk3MzQwNDkwMDcSEzE5MjE0ODg3ODIyNDg2MTMwNDEYBCIKSU1BR0VfVEVYVA==","action_card":false},{"id":"53_1750898911.254","type":"feed","offset":53,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750898911,"updated_time":1750898911,"target":{"id":"2717281021","type":"answer","url":"https://api.zhihu.com/answers/2717281021","author":{"id":"297d91594f08b1a6a32de8a9fd4189f0","url":"https://api.zhihu.com/people/297d91594f08b1a6a32de8a9fd4189f0","user_type":"people","url_token":"zhouzhirui","name":"爱睡觉的KKY","headline":"llm, kaggle, data scientist","avatar_url":"https://pic1.zhimg.com/50/29206fea5826846fd8450898a3e882b7_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":10543,"is_following":false,"is_followed":false},"created_time":1665885299,"updated_time":1665885900,"voteup_count":6289,"thanks_count":1281,"comment_count":82,"is_copyable":false,"question":{"id":"25097993","type":"question","url":"https://api.zhihu.com/questions/25097993","author":{"id":"cb50a87fb2b8a0d93afac25687aee13e","url":"https://api.zhihu.com/people/cb50a87fb2b8a0d93afac25687aee13e","user_type":"people","url_token":"star-stare","name":"Adam","headline":"业精于勤荒于嬉 行成于思毁于随","avatar_url":"https://picx.zhimg.com/50/dce4e89f4d117369f900652d52cb3606_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":15,"is_following":false,"is_followed":false},"title":"深度学习调参有哪些技巧？","created":1409717698,"answer_count":0,"follower_count":0,"comment_count":2,"bound_topic_ids":[3084,89794],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"分享下调参心得： 先overfit 再trade off，首先保证你的模型capacity能够过拟合，再尝试减小模型，各种正则化方法；lr ，最重要的参数，一般nlp bert类模型在1e-5级别附近，warmup，衰减；cv类模型在1e-3级别附近，衰减；具体需要多尝试一下。batch size 在表示学习，对比学习领域一般越大越好，显存不够上累计梯度，否则模型可能不收敛… 其他领域看情况；dropout，现在大部分任务都需要使用预训练模型，要注意模型内部dropout …","excerpt_new":"分享下调参心得： 先overfit 再trade off，首先保证你的模型capacity能够过拟合，再尝试减小模型，各种正则化方法；lr ，最重要的参数，一般nlp bert类模型在1e-5级别附近，warmup，衰减；cv类模型在1e-3级别附近，衰减；具体需要多尝试一下。batch size 在表示学习，对比学习领域一般越大越好，显存不够上累计梯度，否则模型可能不收敛… 其他领域看情况；dropout，现在大部分任务都需要使用预训练模型，要注意模型内部dropout …","preview_type":"default","preview_text":"","reshipment_settings":"disallowed","content":"\u003cp data-pid=\"GchN4m3g\"\u003e分享下调参心得：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"qX9OnaXK\"\u003e先overfit 再trade off，首先保证你的模型capacity能够过拟合，再尝试减小模型，各种正则化方法；\u003c/li\u003e\u003cli data-pid=\"u06AFyY1\"\u003elr ，最重要的参数，一般nlp bert类模型在1e-5级别附近，warmup，衰减；cv类模型在1e-3级别附近，衰减；具体需要多尝试一下。\u003c/li\u003e\u003cli data-pid=\"WsupRgfa\"\u003ebatch size 在表示学习，对比学习领域一般越大越好，显存不够上累计梯度，否则模型可能不收敛… 其他领域看情况；\u003c/li\u003e\u003cli data-pid=\"HHnBHK3I\"\u003edropout，现在大部分任务都需要使用预训练模型，要注意模型内部dropout ratio是一个很重要的参数，使用默认值不一定最优，有时候dropout reset到0有奇效\u003c/li\u003e\u003cli data-pid=\"RT3tHoFU\"\u003e初始化方法，linear / cnn一般选用kaiming uniform 或者normalize，embedding 一般选择截断 normalize，论文很多，可以去看看。\u003c/li\u003e\u003cli data-pid=\"1zBM-MtW\"\u003e序列输入上LN，非序列上BN\u003c/li\u003e\u003cli data-pid=\"sCQJUgcc\"\u003e基于banckbone 构建层次化的neck 一般都比直接使用最后一层输出要好，reduce function 一般attention 优于简单pooling，多任务需要构建不同的qkv\u003c/li\u003e\u003cli data-pid=\"uE-RgJcP\"\u003e数据增强要结合任务本身来设计\u003c/li\u003e\u003cli data-pid=\"YZql4nG9\"\u003e随机数种子设定好，否则很多对比实验结论不一定准确\u003c/li\u003e\u003cli data-pid=\"E-N1RcQA\"\u003ecross validation方式要结合任务设计，数据标签设计，其中时序数据要避免未来信息泄漏\u003c/li\u003e\u003cli data-pid=\"gAfCwdFJ\"\u003e优化器，nlp，抽象层次较高或目标函数非常不平滑的问题adam优先，其他可以尝试下sgd（一般需要的迭代次数高于sgd）\u003c/li\u003e\u003cli data-pid=\"CC7wCScg\"\u003e不要过早的early stopping，有时候收敛平台在后段，你会错过，参考1. ，先过拟合train set\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"IQ02S0VL\"\u003e收藏的同学点个赞啊….需要点义务劳动的动力\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":284357,"favorite_count":13528,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 2717281021}","attached_info":"Ct4FCLi+kpC/2NTfiAEQBBoJNTI0MTM3ODc1IPPIrZoGKJExMFJANUovCgZJdGVtQ0YSH2RvY190eXBlOiBBbnN3ZXIKaWQ6IDcyMjUyMTQ3MgoYACAAOgBaBzIyMjEyNjBiIDZhNWYzZmQ0OWI2NzQwOGU3MzM3ZmZlOTkzODdlODE2cgoyNzE3MjgxMDIxigEIMjUwOTc5OTOqAQlyZWNvbW1lbmTCASAyOTdkOTE1OTRmMDhiMWE2YTMyZGU4YTlmZDQxODlmMPIBCggMEgZOb3JtYWzyASgIChIkYTNlMjgyZjItNWRhOC00Mzc1LTk4MDMtMmE5MTU3ZDkzNzll8gEFCAsSATmCAgCIAvTQ1M36MpICIDI5N2Q5MTU5NGYwOGIxYTZhMzJkZThhOWZkNDE4OWYwmgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZcoCFENvbnRlbnRBZ2VXZWlnaHRSdWxlygIXVGVzdGVkQW5kV29ya1dlaWdodFJ1bGXKAhxCYXllc0ZpcnN0TGV2ZWxJc29sYXRpb25SdWxl2gIGSXRlbUNG6AID+gILTk9STUFMX0ZMT1eKAyA0ODYwOGQ0OTk0YjQ0YjYyODRiZmQ0YjNiMDhmMjdlNJoDDQoCdjIQABoFb3RoZXKoA8WtEdgDAOoDFXRleHRBbGxTaXRlTXZJdGVtQ0ZWMvoDHxIMVU5LTk9XTl9NT0RFIAAqDU5PX0lNQUdFX01PREWABACIBACSBAZOb3JtYWyaBAEzoAQAqAQAsAQAugQGbWFudWFswgQDMTcwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAADA3lyYP4EFAAAAAAAAAACJBYlw+/x4UdI/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBQmQBgCgBjWoBgCSAiUKCTUyNDEzNzg3NRIKMjcxNzI4MTAyMRgEIgpJTUFHRV9URVhU","action_card":false}],"paging":{"is_end":false,"is_start":false,"next":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=down\u0026ad_interval=-10\u0026after_id=53\u0026desktop=true\u0026end_offset=53\u0026page_number=10\u0026session_token=6a5f3fd49b67408e7337ffe99387e816","previous":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=pull\u0026ad_interval=-10\u0026before_id=53\u0026desktop=true\u0026end_offset=53\u0026page_number=10\u0026session_token=6a5f3fd49b67408e7337ffe99387e816","totals":0},"fresh_text":"推荐已更新"}
