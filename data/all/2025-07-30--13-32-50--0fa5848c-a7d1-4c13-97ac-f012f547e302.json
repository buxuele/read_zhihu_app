{"data":[{"id":"72_1753853588.878","type":"feed","offset":72,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1753853588,"updated_time":1753853588,"target":{"id":"1903437079603545114","type":"article","url":"https://api.zhihu.com/articles/1903437079603545114","author":{"id":"fa919734224a6c78b5b168b5fe586049","url":"https://api.zhihu.com/people/fa919734224a6c78b5b168b5fe586049","user_type":"organization","url_token":"a-li-ji-zhu","name":"阿里云开发者","headline":"阿里的技术创新均在此呈现","avatar_url":"https://pica.zhimg.com/50/v2-1d701f79d418cbcb2d7e991d9862aff6_l.jpg?source=b6762063","is_org":true,"gender":-1,"badge":[{"type":"identity_org","description":"已认证机构号"}],"followers_count":186926,"is_following":false,"is_followed":false},"title":"RAG 2.0 深入解读","comment_permission":"all","created":1746604039,"updated":1746604039,"voteup_count":227,"voting":0,"comment_count":0,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"一、Introduction 过去一年可谓是RAG元年，检索增强生成技术迅速发展与深刻变革，其创新与应用已深刻重塑了大模型落地的 技术范式。站在2025年，RAG不仅突破了早期文本处理的局限，更通过多模态融合、混合检索优化和语义鸿沟跨越等突破，开始在各个行业落地。如果把2024之前的RAG称为RAG 1.0，那目前已进入RAG 2.0时代。一个显着的进步是 长上下文窗口，这一功能引发了争议，但到年中逐渐平息。很多人觉得长上下窗口就够了，传统…","excerpt_new":"一、Introduction 过去一年可谓是RAG元年，检索增强生成技术迅速发展与深刻变革，其创新与应用已深刻重塑了大模型落地的 技术范式。站在2025年，RAG不仅突破了早期文本处理的局限，更通过多模态融合、混合检索优化和语义鸿沟跨越等突破，开始在各个行业落地。如果把2024之前的RAG称为RAG 1.0，那目前已进入RAG 2.0时代。一个显着的进步是 长上下文窗口，这一功能引发了争议，但到年中逐渐平息。很多人觉得长上下窗口就够了，传统…","preview_type":"default","preview_text":"","content":"\u003cp data-pid=\"q_0fxuwC\"\u003e一、Introduction\u003c/p\u003e\u003cp data-pid=\"HBTpwF8m\"\u003e过去一年可谓是RAG元年，检索增强生成技术迅速发展与深刻变革，其创新与应用已深刻重塑了大模型落地的\u003cb\u003e技术范式\u003c/b\u003e。站在2025年，RAG不仅突破了早期文本处理的局限，更通过多模态融合、混合检索优化和语义鸿沟跨越等突破，开始在各个行业落地。如果把2024之前的RAG称为RAG 1.0，那目前已进入RAG 2.0时代。\u003c/p\u003e\u003cp data-pid=\"52Pftxa-\"\u003e一个显着的进步是\u003cb\u003e长上下文窗口\u003c/b\u003e，这一功能引发了争议，但到年中逐渐平息。很多人觉得长上下窗口就够了，传统的检索和RAG会被取代。此外，LLMOps 等架构的成熟使企业和个人能够使用矢量数据库、嵌入/重新排名模型、分块工具、Multimodal技术的快速发展。RAG方面的Paper每周达到几十篇甚至更多。可以说，RAG经历了野蛮快速生长的RAG，从1.0超快速的进入了2.0时代。\u003c/p\u003e\u003cp data-pid=\"XCaNII3s\"\u003eRAG越来越多的应用在企业和生产场景，但是仍面临很多的技术挑战，本文我们从RAG 2.0 面临的主要挑战和部分关键技术来展开叙事。首先快速过一下RAG 2.0的主要问题：\u003c/p\u003e\u003cp data-pid=\"33QqdxDt\"\u003e\u003cb\u003e多模态与复杂任务扩展\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"rqD0R3mU\"\u003e\u003cb\u003e多模态支持不足\u003c/b\u003e：当前的RAG技术主要针对文本数据，但在处理图像、视频等多模态数据时仍面临挑战。例如，如何有效检索和利用多模态信息仍是一个开放性问题。现有 LLMOps 解决方案大多限于纯文本场景。PDF、PPT 或文本与图像结合的文档无法充分发挥其商业潜力。这些类型的文档通常构成企业数据中的大多数。\u003c/li\u003e\u003cli data-pid=\"4a2TyTBB\"\u003e\u003cb\u003e复杂推理任务\u003c/b\u003e：尽管RAG通过检索外部知识增强了模型的推理能力，但在处理多跳推理或复杂逻辑任务时，其性能仍有待提升。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"jg-Gavt_\"\u003e\u003cb\u003e检索质量与噪声问题\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"Pc2YaB33\"\u003e\u003cb\u003e检索精度不足\u003c/b\u003e：RAG的性能高度依赖于检索到的文档质量。如果检索到的文档与查询不相关或包含噪声信息，会导致生成结果不准确甚至错误。\u003c/li\u003e\u003cli data-pid=\"f67RZSzL\"\u003e\u003cb\u003eSemantic GAP\u003c/b\u003e：RAG 的核心在于搜索功能。只有能够根据用户的查询“搜索”答案时，它才能发挥作用。然而，这一先决条件往往无法满足，因为查询模糊或含糊，缺乏明确的意图，或者“多跳”问题需要从多个子问题中综合而来。在这种情况下，提出的问题和检索到的答案之间存在显著的语义差距，这使得传统的搜索方法无效。\u003c/li\u003e\u003cli data-pid=\"Yxtpwgf0\"\u003e\u003cb\u003e噪声数据的影响\u003c/b\u003e：文档中的噪声信息可能混淆模型的推理路径，导致生成内容出现偏差。例如，过时或不准确的信息会误导模型，降低生成结果的可信度。\u003c/li\u003e\u003cli data-pid=\"2sd5ul-p\"\u003e\u003cb\u003e召回率低\u003c/b\u003e：在某些情况下，RAG可能无法检索到所有相关文档，导致生成模型缺乏足够的背景信息来构造完整的答案。比如，纯向量数据库导致召回率和命中率偏低：单纯依赖向量数据库会导致召回率和命中率偏低，阻碍有效的现实问答。这是因为向量表示无法精确地表示准确的信息，并且在检索过程中会造成语义损失。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"H3xfB1cM\"\u003e\u003cb\u003e生成过程中的幻觉与冗余\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"AWxpPP3d\"\u003e\u003cb\u003e幻觉问题\u003c/b\u003e：尽管RAG通过检索外部知识减少了模型生成幻觉的概率，但在检索信息不足或相关性较低时，模型仍可能生成虚构或不准确的内容[6]。\u003c/li\u003e\u003cli data-pid=\"gvf76WJG\"\u003e\u003cb\u003e冗余与重复\u003c/b\u003e：当检索到的文档包含相似信息时，生成内容可能出现冗余或重复，影响回答的质量和简洁性。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"_ah-9OX4\"\u003e\u003cb\u003e计算资源与效率问题\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"1VI3LVV_\"\u003e\u003cb\u003e计算资源消耗\u003c/b\u003e：RAG需要额外的计算资源来支持检索机制和数据库维护，如向量化模型和向量知识库的构建与更新[6]。\u003c/li\u003e\u003cli data-pid=\"ngPuTrc_\"\u003e\u003cb\u003e推理延迟\u003c/b\u003e：由于增加了检索步骤，RAG的推理时间可能比传统LLM更长，尤其是在处理复杂查询时[6]。\u003c/li\u003e\u003cli data-pid=\"v2Ph8bAn\"\u003e\u003cb\u003e实时性要求\u003c/b\u003e：RAG需要实时检索最新信息，但知识库的更新频率和检索效率可能无法满足高实时性需求。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"haPUr0pk\"\u003e\u003cb\u003e安全与隐私问题\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"c9oFScay\"\u003e\u003cb\u003e数据安全\u003c/b\u003e：RAG需要访问外部知识库，这可能涉及敏感数据。如何确保数据的安全性和隐私性是一个重要挑战[8]。\u003c/li\u003e\u003cli data-pid=\"D3F6NIZs\"\u003e\u003cb\u003e对抗性攻击\u003c/b\u003e：RAG系统可能受到对抗性数据注入或上下文冲突等攻击，导致生成内容被操纵或误导\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"w67Hj569\"\u003e\u003cb\u003e奖励函数与训练机制优化\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"Ew83WvT4\"\u003e\u003cb\u003e奖励函数设计\u003c/b\u003e：当前的RAG系统通常采用基于结果的奖励函数，但在复杂任务场景中，这种设计可能无法捕捉细微差异，影响模型性能[1]。\u003c/li\u003e\u003cli data-pid=\"GyYNwq6F\"\u003e\u003cb\u003e训练数据依赖\u003c/b\u003e：RAG的训练需要高质量的交互数据，但获取和标注这些数据可能成本高昂且耗时.\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"LfZ-jzNZ\"\u003e二、技术范式的升级\u003c/p\u003e\u003cp data-pid=\"9Rkp35gA\"\u003eRAG从最初概念诞生到现在，架构经历了三个阶段演化：基础检索生成（Naive RAG）→ 检索全流程优化（Advanced RAG）→ 具备反思能力的模块化系统（Modular RAG）。其中模块化架构通过LLM的递归调用实现动态检索决策，例如让模型自主判断何时触发检索或修正答案，形成类Agent的交互范式。具体可以看下图，细节在此不表，重点关注核心技术。\u003c/p\u003e\u003cp data-pid=\"MQp8Fep1\"\u003e其实不管哪种范式，其本质都是搜索 + LLM的融合，所有核心技术的其实都是搜索和大模型的技术的变革。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-46ea323c00abdf7e62b28b3657a468ba_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"964\" data-rawheight=\"1200\" data-original-token=\"v2-46ea323c00abdf7e62b28b3657a468ba\" class=\"origin_image zh-lightbox-thumb\" width=\"964\" data-original=\"https://pic1.zhimg.com/v2-46ea323c00abdf7e62b28b3657a468ba_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"ai2nXFL_\"\u003e三、关键技术\u003c/p\u003e\u003cp data-pid=\"XuE3adzW\"\u003e\u003cb\u003e3.1 检索技术\u003c/b\u003e\u003c/p\u003e\u003ch2\u003e3.1.1 混合搜索\u003c/h2\u003e\u003cp data-pid=\"l_S4Ux05\"\u003e前面提到过目前RAG的Retrieval存在一些弊端，比如召回率低，准确率低，噪声大，存在冗余查询，效率和鲁棒性差等。因此我们需要Hybrid Search。目前比较通用的混合搜索是三路混合检索：\u003cb\u003e全文搜索 with BM25 + 稠密向量（语义匹配） + 稀疏向量（关键词增强）。\u003c/b\u003e首先我们先简单介绍一下这集中检索方式：\u003c/p\u003e\u003cp data-pid=\"ysnO_bZt\"\u003e\u003cb\u003e全文索引\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"TdJ5HXX8\"\u003e常使用倒排索引（Inverted Index）等技术，将文档中的每个单词映射到包含该单词的文档列表，从而实现高效的查询。查询速度快，适合精确匹配。支持复杂的查询语法（如布尔查询、通配符查询）。缺点是无法理解语义，仅依赖字面匹配。对同义词、语义相似性等处理能力有限，当然这可以通过归一化等预处理来解决。相关性排序\u003cb\u003e，\u003c/b\u003e常用算法为\u003cb\u003eBM25算法\u003c/b\u003e，基于词频、文档长度和逆文档频率的综合评分。\u003c/p\u003e\u003cp data-pid=\"wmnP8P1b\"\u003eBM25（Best Matching 25）是\u003cb\u003e一种基于概率模型的文档相关性评分算法\u003c/b\u003e，广泛用于全文搜索引擎中，用于衡量查询（Query）与文档（Document）之间的匹配程度。它是传统TF-IDF算法的改进版本，尤其在处理文档长度和词频分布上表现更优。BM25通过结合词频、逆文档频率和文档长度归一化，提供了一种高效评估文档与查询相关性的方法，具有高效、灵活和鲁棒的特点。BM25因其简洁性和高效性，至今仍是文本检索的基石技术，尤其在需要快速响应和可解释性的场景中不可替代。\u003c/p\u003e\u003cp data-pid=\"mGcnKOCG\"\u003e\u003cb\u003eSparse vector search \u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"rpauRgOd\"\u003e稀疏检索是一种基于稀疏向量的搜索技术，通常用于传统的信息检索任务。稀疏向量是指向量中大部分元素为零，只有少数元素非零。使用词袋模型（Bag of Words, BoW）或 TF-IDF 等方法将文本表示为稀疏向量，然后通过计算向量之间的相似度（如点积）来检索相关文档。主要使用在传统文本检索（如搜索引擎）。计算效率高，适合大规模数据集，但是无法理解语义。\u003c/p\u003e\u003cp data-pid=\"cVrxlXTM\"\u003e稀疏向量难以替代全文搜索：稀疏向量旨在替代全文搜索，其方法是使用标准预训练模型消除冗余词并添加扩展词，从而得到固定维度（例如 30,000 或 100,000 维）的稀疏向量输出。这种方法在一般查询任务上表现良好；但是，许多用户查询关键字可能不存在于用于生成稀疏向量的预训练模型中，例如特定的机器模型、手册和专业术语。因此，虽然稀疏向量和全文搜索都服务于精确召回的目的，但它们各有千秋，无法互相替代。\u003c/p\u003e\u003cp data-pid=\"f_-Jgziq\"\u003e\u003cb\u003eVector Search\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"OR1AObV1\"\u003eVector search 是一种基于向量空间模型的搜索技术，将数据（如文本、图像、音频）转换为高维向量（通常是稠密向量），并通过计算向量之间的相似度（如余弦相似度或欧氏距离）来找到最相关的结果。利用机器学习模型（如深度学习）将数据映射到向量空间，语义相近的数据在向量空间中距离较近。主要应用场景是语义搜索（Semantic Search）：理解查询的语义，而不仅仅是关键词匹配。能够捕捉语义信息，支持模糊匹配。适合处理非结构化数据（如文本、图像）。但是需要预训练模型生成向量，计算复杂度较高。对硬件资源（如GPU）要求较高。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-a1c7ec353055d85e851e3fe9461c607f_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"591\" data-rawheight=\"285\" data-original-token=\"v2-a1c7ec353055d85e851e3fe9461c607f\" class=\"origin_image zh-lightbox-thumb\" width=\"591\" data-original=\"https://pic2.zhimg.com/v2-a1c7ec353055d85e851e3fe9461c607f_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"56CKXtBJ\"\u003e采用多种召回方法可以为 RAG 带来更好的结果。具体来说，将向量搜索、稀疏向量搜索和全文搜索结合起来可以实现最佳召回率。这很容易理解，因为向量可以表示语义；一个句子甚至整篇文章都可以封装在一个向量中。本质上，向量传达了文本的“含义”，表示其与上下文窗口内其他文本共现的压缩概率。因此，向量无法精确表示查询。例如，如果用户问：“我们公司 2024 年 3 月的财务计划包括哪些组合？”结果可能会返回来自其他时间段的数据或不相关的主题，例如运营计划或营销管理。相比之下，全文搜索和稀疏向量主要表达精确的语义。因此，将这些方法结合起来可以满足我们日常对语义理解和精度的需求。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-5d8fd8c41eb72c6b2a829e0a86d93370_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"695\" data-rawheight=\"587\" data-original-token=\"v2-5d8fd8c41eb72c6b2a829e0a86d93370\" class=\"origin_image zh-lightbox-thumb\" width=\"695\" data-original=\"https://pica.zhimg.com/v2-5d8fd8c41eb72c6b2a829e0a86d93370_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"vdheA83e\"\u003e下图显示了使用 Infinity 在公共基准数据集上进行评估的结果，比较了单向召回方法（向量、稀疏向量、全文搜索）、双向召回和三向召回。纵轴表示排序质量，很明显三向召回取得了最佳结果，充分验证了 BlendedRAG 的效果。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-879bb050803ca6ffdb3bca7ebd04df88_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"692\" data-rawheight=\"340\" data-original-token=\"v2-879bb050803ca6ffdb3bca7ebd04df88\" class=\"origin_image zh-lightbox-thumb\" width=\"692\" data-original=\"https://pic1.zhimg.com/v2-879bb050803ca6ffdb3bca7ebd04df88_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"kZrd81-g\"\u003e目前的混合搜索架构中，不同的数据存储和检索大都是通过异构数据库和存储介质来实现的，这会带来效率和精准度的问题，因此同时支持多种检索的数据库显得尤为重要，但是有较大挑战，目前市面上实现此类功能的数据库有Milvus（支持多模态向量+标量过滤） ， Weaviate（内置混合搜索）。\u003c/p\u003e\u003ch2\u003e3.1.2 DPR（Dense Passage Retrieval）\u003c/h2\u003e\u003cp data-pid=\"6XuCc4rM\"\u003e在RAG（Retrieval-Augmented Generation，检索增强生成）系统中，DPR（Dense Passage Retrieval，稠密段落检索）是检索模块的核心技术之一。DPR通过使用密集向量表示来检索与查询最相关的文档或段落，是RAG系统的重要基础。由 Facebook AI Research 团队在2020年首次提出。\u003c/p\u003e\u003cp data-pid=\"gI8ntZjw\"\u003eDPR是一种基于深度学习的检索方法，专注于将查询（query）和文档（passage）编码为稠密向量，并通过计算向量之间的相似度来检索与查询最相关的文档。DPR是稠密向量检索在段落检索任务中的一个具体实现，它利用深度学习模型将查询和文档编码为稠密向量，并通过相似度计算来检索相关文档。\u003c/p\u003e\u003cp data-pid=\"FiQhso3n\"\u003e\u003cb\u003eDPR的核心功能\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"s8kt8yQm\"\u003e\u003cb\u003e1. 双编码器架构：DPR采用双编码器架构，分别对查询和文档进行编码，将它们映射到高维向量空间中。通过计算查询向量和文档向量之间的相似度（如内积），DPR能够高效地检索出与查询最相关的文档。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"DeaQfJyu\"\u003e\u003cb\u003e2. 语义匹配：与传统的稀疏检索方法（如BM25）不同，DPR能够捕捉查询和文档之间的语义相似性，而不仅仅是关键词匹配。这使得DPR在处理复杂的自然语言查询时表现出色。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"iOc7j-i5\"\u003e\u003cb\u003e3. 高效检索：DPR利用密集向量表示和高效的最近邻搜索算法（如MIPS，Maximum Inner Product Search），能够快速从大规模知识库中检索出相关文档。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"jwxy6dZD\"\u003eDPR作为RAG系统中的检索器，负责从外部知识库中检索与用户查询最相关的文档或段落。这些检索到的文档随后被送至生成模块，生成模块利用这些文档生成高质量、上下文相关的回答。DPR的高效语义检索能力显著提升了RAG系统在开放域问答等任务中的表现。\u003c/p\u003e\u003cp data-pid=\"FDrRaW-U\"\u003e尽管DPR已经取得了显著的成果，但仍有改进空间。例如，DPR训练过程中的知识分散化（decentralization）可以进一步优化，以提高检索的多样性和准确性。此外，研究者们也在探索如何更好地将DPR与预训练语言模型结合，以进一步提升检索和生成的性能。\u003c/p\u003e\u003cp data-pid=\"5zS_Iyj6\"\u003e\u003cb\u003e3.2 重排序 Ranking Models\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"wwbHZYoo\"\u003e我们前面讲过，三路召回（BM25 + 稠密向量 + 稀疏向量）效果最优，但如何高效融合多路结果并重排序（Reranking）仍是难题。\u003c/p\u003e\u003cp data-pid=\"PBaE-ddO\"\u003e排名是任何搜索系统的核心。排名涉及两个组件：一个是用于粗过滤的部分也就是\u003cb\u003e粗排\u003c/b\u003e；另一个是用于微调阶段的重排序模型也叫\u003cb\u003e重排\u003c/b\u003e或者精排。混合检索能够结合不同检索技术的优势获得更好的召回结果，但在不同检索模式下的查询结果需要进行合并和归一化（将数据转换为统一的标准范围或分布，以便更好地进行比较、分析和处理），然后再一起提供给大模型。这时候我们需要引入一个评分系统：重排序模型（Rerank Model）。\u003c/p\u003e\u003cp data-pid=\"dVIJ-48q\"\u003e重排序模型会计算候选文档列表与用户问题的语义匹配度，根据语义匹配度重新进行排序，从而改进语义排序的结果。其原理是计算用户问题与给定的每个候选文档之间的相关性分数，并返回按相关性从高到低排序的文档列表。常见的 Rerank 模型如：Cohere rerank、bge-reranker 等。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-ee62ae410e6ba3ef92b4c105c72add60_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"284\" data-original-token=\"v2-ee62ae410e6ba3ef92b4c105c72add60\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-ee62ae410e6ba3ef92b4c105c72add60_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"tH4jdLWO\"\u003e\u003ci\u003e不过，重排序并不是只适用于不同检索系统的结果合并，即使是在单一检索模式下，引入重排序步骤也能有效帮助改进文档的召回效果，比如我们可以在关键词检索之后加入语义重排序。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"-NMrf900\"\u003e在具体实践过程中，除了将多路查询结果进行归一化之外，在将相关的文本分段交给大模型之前，我们一般会限制传递给大模型的分段个数（即 TopK，可以在重排序模型参数中设置），这样做的原因是大模型的输入窗口存在大小限制（一般为 4K、8K、16K、128K 的 Token 数量），你需要根据选用的模型输入窗口的大小限制，选择合适的分段策略和 TopK 值。\u003c/p\u003e\u003cp data-pid=\"QFnlnxaW\"\u003e需要注意的是，即使模型上下文窗口很足够大，过多的召回分段会可能会引入相关度较低的内容，导致回答的质量降低，所以重排序的 TopK 参数并不是越大越好。\u003c/p\u003e\u003cp data-pid=\"mnzPe90I\"\u003e在RAG（Retrieval-Augmented Generation）系统中，检索完成后进行重排序（reranking）的目的是为了提高最终生成结果的质量和相关性。尽管初始检索阶段已经返回了一组相关文档或段落，但这些结果可能并不完全符合生成模型的需求，或者可能存在排序不合理的情况。重排序可以帮助筛选出最相关、最有用的信息，从而提升生成模型的输出效果。\u003c/p\u003e\u003cp data-pid=\"N-5O4t_U\"\u003e接下来我们重点介绍几种常用的Reranker。\u003c/p\u003e\u003ch2\u003e3.2.1 Cross-Encoder Reranker\u003c/h2\u003e\u003cp data-pid=\"2vtYSNC3\"\u003eCross-Encoder Reranker 是一种基于深度学习的重排序模型，通过\u003cb\u003e联合编码查询-文档对\u003c/b\u003e（将查询和文档拼接后输入模型）直接预测相关性分数，而非生成独立向量。其核心是利用交叉编码器（Cross-Encoder）架构来评估查询（query）和文档（document）对之间的相似度。与双编码器（Bi-Encoder）不同，交叉编码器不是分别对查询和文档进行编码，而是将查询和文档作为一个整体输入到模型中，从而能够更有效地捕获两者之间的交互和关系。这种架构通常由多层神经网络单元组成，例如Transformer或循环神经网络（RNN），能够将输入序列中的信息编码为固定大小的表。比传统向量检索更精准，能捕捉深层次语义关系。它通过端到端分类任务（如二元相关性判断）优化，适合对Top-K候选文档进行精排。代表模型有\u0026lt;font style=\u0026#34;color:rgb(64, 64, 64);\u0026#34;\u0026gt;BAAI/bge-reranker-large\u0026lt;/font\u0026gt;。\u003c/p\u003e\u003cp data-pid=\"JCW-dcXN\"\u003eCross-Encoder可以与延迟交互（Late Interaction）结合，如本文前面提到过的\u003cb\u003eColPali\u003c/b\u003e（多模态RAG场景），通过分解查询-文档交互矩阵为多向量外积，实现高效语义排序，同时保留细粒度交互能力。\u003c/p\u003e\u003cp data-pid=\"8RuZYz5p\"\u003e在效率方面，可以将大型Cross-Encoder（如BERT-large）蒸馏为轻量级模型（如TinyBERT），或采用FP16/INT8量化降低推理延迟。这些都是比较通用的方法，在此不表。\u003c/p\u003e\u003cp data-pid=\"w1inbUfe\"\u003e使用示例：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003eimport numpy\nimport lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\nfrom lancedb.rerankers import CrossEncoderReranker\n\n\nembedder = get_registry().get(\u0026#34;sentence-transformers\u0026#34;).create()\ndb = lancedb.connect(\u0026#34;~/.lancedb\u0026#34;)\n\n\nclass Schema(LanceModel):\n    text: str = embedder.SourceField()\n    vector: Vector(embedder.ndims()) = embedder.VectorField()\n\n\ndata = [\n    {\u0026#34;text\u0026#34;: \u0026#34;hello world\u0026#34;},\n    {\u0026#34;text\u0026#34;: \u0026#34;goodbye world\u0026#34;}\n]\n\n\ntbl = db.create_table(\u0026#34;test\u0026#34;, schema=Schema, mode=\u0026#34;overwrite\u0026#34;)\ntbl.add(data)\n\n\nreranker = CrossEncoderReranker()\n\n\n# Run vector search with a reranker\nresult = tbl.search(\u0026#34;hello\u0026#34;).rerank(reranker=CrossEncoderReranker()).to_list()\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2\u003e3.2.2 Graph-Based Reranking\u003c/h2\u003e\u003cp data-pid=\"JbV6WkM5\"\u003e当前主流RAG系统遵循\u0026#34;检索-排序-生成\u0026#34;的线性流程，其中重排序环节通常采用两类方法：(1) 基于独立编码的交叉注意力模型（如MonoT5），单独评估每个文档与查询的相关性；(2) 基于列表级损失的排序模型（如ListNet），优化整个文档序列的排列。这两种范式都存在根本性局限——它们将文档视为\u003cb\u003e孤立的个体\u003c/b\u003e，完全忽视了文档间丰富的语义关联，导致三个关键问题：\u003c/p\u003e\u003cp data-pid=\"TijruZ-L\"\u003e\u003cb\u003e1. 信息整合失效：\u003c/b\u003e当答案需要综合多篇文档信息时（如对比型问题\u0026#34;比较A与B的优缺点\u0026#34;），独立排序可能将与A、B分别相关但单独评分不高的文档排在后位，而实际上这些文档的组合才最具回答价值[2][3]。\u003c/p\u003e\u003cp data-pid=\"eTI_uXxn\"\u003e\u003cb\u003e2. 冗余放大效应：\u003c/b\u003e高度相似的多篇文档可能因独立评分都较高而同时位居前列，挤占其他重要但独特信息的展示空间。论文图1展示了传统方法在HotpotQA数据集上出现的典型冗余案例，前5篇文档中有3篇内容重叠度超过70%。\u003c/p\u003e\u003cp data-pid=\"AF19d-iW\"\u003e\u003cb\u003e3. 关系认知盲区：\u003c/b\u003e现有系统无法识别文档间的因果、时序、对比等逻辑关系，而这些关系往往是解答复杂问题的关键。例如回答\u0026#34;COVID-19如何导致经济衰退\u0026#34;需要串联病因学文档与经济分析文档，尽管它们的主题相似度可能很低。\u003c/p\u003e\u003cp data-pid=\"rISxcFd6\"\u003e更本质地，这些问题的根源在于传统排序将文档视为\u003cb\u003e独立同分布\u003c/b\u003e样本，而现实中文档间存在复杂的\u003cb\u003e条件依赖\u003c/b\u003e关系。该论文首次提出将文档集合建模为图结构，其中节点表示文档，边表示语义关系，通过图算法挖掘全局结构信息来指导排序决策。\u003c/p\u003e\u003cp data-pid=\"pFBNJ8D2\"\u003e现有RAG系统在处理文档与问题上下文关系时存在挑战，当文档与问题的关联性不明显或仅包含部分信息时，模型可能无法有效利用这些文档。此外，现有方法通常忽视文档之间的连接，导致无法充分利用文档间的语义信息。\u003c/p\u003e\u003cp data-pid=\"YYwakDbm\"\u003e这篇 Paper 《Don\u0026#39;t Forget to Connect! Improving RAG with Graph-based Reranking》该论文提出了一种基于图的重排方法G-RAG，旨在通过利用文档之间的连接信息和语义信息，更有效地识别文档中的有价值信息，从而提高RAG在ODQA中的性能。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-95f91d43d3cb6bd9dd30aad38b460e1c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"583\" data-rawheight=\"279\" data-original-token=\"v2-95f91d43d3cb6bd9dd30aad38b460e1c\" class=\"origin_image zh-lightbox-thumb\" width=\"583\" data-original=\"https://pic1.zhimg.com/v2-95f91d43d3cb6bd9dd30aad38b460e1c_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"BORU41Av\"\u003e\u003cb\u003e关键技术\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"XeWdbZEj\"\u003e\u003cb\u003e1. 图结构构建\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"RJ079jQv\"\u003e将检索到的文档或文本块表示为图中的节点，节点间的边通过以下方式建立：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"Itc1p6Fr\"\u003e\u003cb\u003e语义相似性\u003c/b\u003e（如向量余弦相似度）；\u003c/li\u003e\u003cli data-pid=\"wFXLRxH0\"\u003e\u003cb\u003e实体共现关系\u003c/b\u003e（如命名实体在同一文档中的关联）；\u003c/li\u003e\u003cli data-pid=\"EBqfirw8\"\u003e\u003cb\u003e逻辑依赖\u003c/b\u003e（如文档间的引用或因果链）[2][3]。\u003c/li\u003e\u003c/ul\u003e\u003cli data-pid=\"7prumwG6\"\u003e例如，类似GraphRAG的方法会预生成实体知识图，并通过社区检测划分紧密关联的节点组。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"bhe9tdaZ\"\u003e\u003cb\u003e2. 图神经网络架构\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"PFEF5Joz\"\u003e基于GNN的架构来重排序检索到的文档：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"gzoWv8E4\"\u003e\u003cb\u003e节点特征：\u003c/b\u003e使用预训练的语言模型（如BERT）编码文档文本，并结合AMR图中的最短路径信息来增强这些特征。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"ZHar9vNr\"\u003e框架应用预先训练的语言模型对给定问题 q 的 {p1,p2,⋯,pn} 中所有 n\u003c/p\u003e\u003cp data-pid=\"6JcgmbI_\"\u003e检索到的文档进行编码。文档嵌入表示为\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-1ef9012130878ca78cc94524202e4b76_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"67\" data-rawheight=\"25\" data-original-token=\"v2-1ef9012130878ca78cc94524202e4b76\" class=\"content_image\" width=\"67\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"eioYWqgp\"\u003e，其中 \u003c/p\u003e\u003cp data-pid=\"Gqv49iSu\"\u003ed\u003c/p\u003e\u003cp data-pid=\"aRkeVa3Y\"\u003e 是隐藏维度，\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-8eac0c51d1c1ea31181b5ac0785c890b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"19\" data-rawheight=\"23\" data-original-token=\"v2-8eac0c51d1c1ea31181b5ac0785c890b\" class=\"content_image\" width=\"19\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"jIlVAGmY\"\u003e的每一行由以下公式给出\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-afdac92732193b67806078ed78d3ae5c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"244\" data-rawheight=\"31\" data-original-token=\"v2-afdac92732193b67806078ed78d3ae5c\" class=\"content_image\" width=\"244\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"8CfcSC1y\"\u003e某些负面文档无法与其文本中的问题上下文建立足够的联系。此外，负面文档还会遇到另一种极端情况，即路径包含大量与问题文本相关的信息，但缺乏有价值信息。这种独特的模式提供了有价值的见解，可在编码过程中利用它们来提高重排器的性能。\u003c/p\u003e\u003cp data-pid=\"nAnBxTRw\"\u003e因此，建议的文档嵌入由\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-ee923bf57f8ab4c01a8e78e3532cd2ed_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"67\" data-rawheight=\"22\" data-original-token=\"v2-ee923bf57f8ab4c01a8e78e3532cd2ed\" class=\"content_image\" width=\"67\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"yNy6MmGk\"\u003e给出，并且 \u003c/p\u003e\u003cp data-pid=\"C2wBoqnz\"\u003eX\u003c/p\u003e\u003cp data-pid=\"d_HMwH__\"\u003e的每一行可以由\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-e9f0b715ff962f32a3c25e8086237ef4_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"106\" data-rawheight=\"23\" data-original-token=\"v2-e9f0b715ff962f32a3c25e8086237ef4\" class=\"content_image\" width=\"106\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"PgJBBlIm\"\u003e给出：\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-37ed98d2b33acd94838435a94197f812_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"192\" data-rawheight=\"25\" data-original-token=\"v2-37ed98d2b33acd94838435a94197f812\" class=\"content_image\" width=\"192\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"_SU5EJYa\"\u003e\u003cb\u003e边特征：\u003c/b\u003e利用AMR图中共同节点和边的数量作为边特征。结合了AMR图，不仅捕捉文档的语义信息，还通过图结构增强了文档之间的语义关联。\u003c/li\u003e\u003cli data-pid=\"5TGeeWdQ\"\u003e\u003cb\u003e表示更新：\u003c/b\u003e通过GNN模型更新节点和边的表示，利用消息传递机制传递信息。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"J13rh6Te\"\u003e\u003cb\u003e3. 图算法重排序\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"rCZyZEey\"\u003e采用\u003cb\u003e个性化PageRank\u003c/b\u003e或\u003cb\u003e社区影响力评分\u003c/b\u003e对节点（文档）进行重要性排序，优先选择图中中心性高或与问题节点连接紧密的文档。\u003c/li\u003e\u003cli data-pid=\"8H-ta-dF\"\u003e类似R4框架的图注意力机制，学习文档间的交互关系以优化顺序。\u003c/li\u003e\u003cli data-pid=\"3wLcm-36\"\u003e通过多跳推理挖掘间接关联的文档（如RAE框架的链式检索策略）。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"IN_FhEZh\"\u003e\u003cb\u003e4. 动态响应生成\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"6374rcdD\"\u003e对重排序后的文档集，分两步生成答案：\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"yi5cQIu3\"\u003e\u003cb\u003e1）局部响应生成\u003c/b\u003e：每个高权重文档或社区摘要独立生成部分答案；\u003c/p\u003e\u003cp data-pid=\"i9k3hD6a\"\u003e\u003cb\u003e2）全局整合\u003c/b\u003e：通过LLM对局部响应去冗余并合成最终答案。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"b2PrgAAq\"\u003e类似HippoRAG的神经启发方法，模拟人脑记忆整合机制优化知识融合。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"owFCOFIa\"\u003e\u003cb\u003e5. 端到端优化\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"UtWt1MWl\"\u003e引入强化学习（如R4的奖励机制）或轻量级评估器（如CRAG）联合优化检索与生成模块。\u003c/li\u003e\u003c/ul\u003e\u003ch2\u003e3.2.3 ColBERT Reranker\u003c/h2\u003e\u003cp data-pid=\"4m3aBKFd\"\u003eColBERT（Contextualized Late Interaction over BERT）是一种高效的检索模型，特别适用于大规模文本集合的检索任务。它通过延迟交互机制（late interaction architecture）结合BERT的上下文表示，实现了高效的检索和重排序。这里我们Jina-ColBERT-v2\u003c/p\u003e\u003cp data-pid=\"HzluuJSK\"\u003e\u003cb\u003e1. 延迟交互机制（Late Interaction）：\u003c/b\u003eColBERT引入了一种延迟交互相似性函数，通过分别对查询和文档进行编码，然后在推理时计算查询和文档之间的相似性（MaxSim），从而实现延迟交互。这种方法在保持高效推理的同时，能够捕捉到查询和文档之间的复杂关系。\u003c/p\u003e\u003cp data-pid=\"8EZtpOk-\"\u003e\u003cb\u003e2. 多向量表示：\u003c/b\u003e与传统的单向量检索模型不同，ColBERT为查询和文档中的每个标记生成一个嵌入向量，然后通过聚合这些标记嵌入来计算相关性分数。这种方法能够更细致地捕捉文本的语义信息。\u003c/p\u003e\u003cp data-pid=\"UvGR191I\"\u003e\u003cb\u003e3. 多语言预训练：\u003c/b\u003eJina-ColBERT-v2使用XLM-RoBERTa作为其基础模型，并通过在多种语言的数据上进行预训练，提高了模型的多语言性能。\u003c/p\u003e\u003cp data-pid=\"aZ3AwXAe\"\u003e\u003cb\u003e4. 弱监督学习：\u003c/b\u003e论文提出在大规模的弱监督文本对上进行预训练，以学习文本的一般语义结构。这些文本对包括句子对、问答对和查询-文档对，涵盖了多种语言和领域。\u003c/p\u003e\u003cp data-pid=\"_RmW0YEK\"\u003e\u003cb\u003e5. 三元组训练：\u003c/b\u003e在预训练的基础上，模型进一步在多种语言的检索数据上进行微调，使用标注的三元组数据和硬负样本进行训练，以提高检索性能。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"sHkmrVEK\"\u003e\u003cb\u003e3.3 Multimodal RAG 多模态RAG\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"wW53NoPu\"\u003e目前，多模态检索增强生成（Multimodal RAG） 已成为 RAG 技术中最前沿和流行的方向之一，它通过整合文本、图像、音频、视频等多种模态数据，显著提升了 AI 系统的理解和生成能力。\u003c/p\u003e\u003cp data-pid=\"x9oRDxkm\"\u003e对于多模态文档，传统方法是使用模型将多模态文档转换为文本，然后再进行索引以供检索。另一种方法是直接多模态向量化，比如利用 视觉语言模型 VLM，\u003cb\u003e直接生成向量，绕过复杂的 OCR 过程\u003c/b\u003e。2024 出现的 ColPali。ColPali 将图像视为 1024 个图像块，并为每个块生成嵌入，有效地将单个图像表示为张量。比如：\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-314404eb239634e7e3674d589b514244_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"750\" data-rawheight=\"1012\" data-original-token=\"v2-314404eb239634e7e3674d589b514244\" class=\"origin_image zh-lightbox-thumb\" width=\"750\" data-original=\"https://pic1.zhimg.com/v2-314404eb239634e7e3674d589b514244_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"lpaViJx-\"\u003e这意味着 VLM 对图像的理解更加深入，不再仅仅识别日常物品，而是可以高效识别企业级多模态文档。例如，来自 Google 的开源 3B 模型 PaliGemma，能够将图像块（Image Patches）嵌入到与文本相似的潜在空间中。ColPali 在此基础上扩展，通过投影层将模型输出的高维嵌入降维至 128 维，生成多向量表示（每个图像块对应一个向量），从而保留文档的细粒度视觉信息。借鉴文本检索模型 ColBERT 的“延迟交互”策略，ColPali 在检索阶段计算查询文本的每个 token 向量与文档图像块向量的最大相似度（MaxSim），而非传统的\u003cb\u003e单向量相似度\u003c/b\u003e。这种方法避免了早期交互的计算负担，同时提升了检索精度。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-70c9fb7299e6013227eb0738c0147462_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"603\" data-original-token=\"v2-70c9fb7299e6013227eb0738c0147462\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-70c9fb7299e6013227eb0738c0147462_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"3izqMdM8\"\u003e这种技术的优势非常明显，端到端处理复杂文档\u003cb\u003e，直接输入文档图像（如 PDF 页面），无需传统 OCR、文本提取或布局分析等预处理步骤，显著简化流程并减少错误传播。还可以实现\u003c/b\u003e多模态联合检索，通过视觉和文本嵌入的统一表示，模型能同时理解图表、表格和文本内容。例如，在财务报告或科学论文中，ColPali 可检索出纯文本方法可能遗漏的视觉关键信息。\u003c/p\u003e\u003cp data-pid=\"myRhBMds\"\u003e如果我们可以使用 RAG 根据用户查询在大量 PDF 中查找包含答案的图像和文本，那么我们就可以使用 VLM 生成最终答案。这就是多模态 RAG 的意义所在，它不仅仅是简单的图像搜索。\u003c/p\u003e\u003cp data-pid=\"eSnm_mX9\"\u003e检索过程需要一个 Versatile 的数据库，不仅支持基于张量的重新排序，而且还能在向量检索阶段容纳\u003cb\u003e多向量索引\u003c/b\u003e。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-76974920e29655091dae4dbfba1f2611_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1390\" data-rawheight=\"266\" data-original-token=\"v2-76974920e29655091dae4dbfba1f2611\" class=\"origin_image zh-lightbox-thumb\" width=\"1390\" data-original=\"https://pic2.zhimg.com/v2-76974920e29655091dae4dbfba1f2611_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"1sHQlxPV\"\u003e在这里我们简单介绍一下直接多模态向量化和模态转换。\u003c/p\u003e\u003cp data-pid=\"lOu8mOwf\"\u003e\u003cb\u003e直接多模态向量化\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"XOwWqqO4\"\u003e\u003cb\u003e核心思想：\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"wZ-D50BQ\"\u003e使用多模态模型（如CLIP、Flamingo）直接生成跨模态的向量表示，跳过中间文本转换步骤。\u003c/li\u003e\u003cli data-pid=\"DBUBiopO\"\u003e\u003cb\u003e核心任务：\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"6yf3UG0X\"\u003e通过模型（如CLIP、Flamingo）将不同模态数据（图/文/音）映射到\u003cb\u003e同一向量空间\u003c/b\u003e，确保语义相似的输入（如“狗”的图片和文本“犬”）向量距离相近。\u003c/li\u003e\u003cli data-pid=\"RF6gxlqK\"\u003e\u003cb\u003e关键技术：\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"tvTN_jfZ\"\u003e1）对比学习（Contrastive Learning）：如CLIP的图文对齐训练。\u003c/li\u003e\u003cli data-pid=\"moc38X2T\"\u003e2）共享编码器（Shared Encoder）：同一模型处理多模态输入。\u003c/li\u003e\u003cli data-pid=\"PEh6kn8r\"\u003e\u003cb\u003e输出：\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"6GvJvFLM\"\u003e向量（如512维浮点数组），不直接完成检索任务。\u003c/li\u003e\u003cli data-pid=\"9jAIu9SE\"\u003e\u003cb\u003e流程\u003c/b\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-2515c5b52ff3c268e4f56747d3551b62_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"75\" data-original-token=\"v2-2515c5b52ff3c268e4f56747d3551b62\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pica.zhimg.com/v2-2515c5b52ff3c268e4f56747d3551b62_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"tJhcQY3R\"\u003e\u003cb\u003e模态转换，多模态转文本（Modality-to-Text）\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"f4pBSmB8\"\u003e\u003cb\u003e技术原理：\u003c/b\u003e将非文本模态（如图像、音频）转换为文本描述（如 OCR、ASR、图像描述生成），再使用传统文本 RAG 进行检索和生成。\u003c/li\u003e\u003cli data-pid=\"G4D9cJb2\"\u003e\u003cb\u003e优势：\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"ZQupR5Ib\"\u003e\u003cb\u003e实现简单，兼容现有文本 RAG 架构。\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"Fw3EgPyc\"\u003e\u003cb\u003e适用于结构化数据（如表格、PDF）和语音转文本任务。\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"6nm_6ozw\"\u003e\u003cb\u003e代表工具：\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"w6QbmDqy\"\u003e\u003cb\u003eBLIP-2\u003c/b\u003e（Salesforce）：生成高质量的图像描述。\u003c/li\u003e\u003cli data-pid=\"0znTurJ7\"\u003e\u003cb\u003eWhisper\u003c/b\u003e（OpenAI）：语音转文本（ASR）。\u003c/li\u003e\u003cli data-pid=\"V_Nlbsoo\"\u003e\u003cb\u003e流程\u003c/b\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-7458079ca157cb1a19456fbff84ea244_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"684\" data-rawheight=\"91\" data-original-token=\"v2-7458079ca157cb1a19456fbff84ea244\" class=\"origin_image zh-lightbox-thumb\" width=\"684\" data-original=\"https://pica.zhimg.com/v2-7458079ca157cb1a19456fbff84ea244_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"51XwFjxW\"\u003e多模态转文本（Modality-to-Text）和直接多模态向量化（Direct Multimodal Embedding）对比\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-7fd94411fa40a730da072cf447441bcc_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1386\" data-rawheight=\"860\" data-original-token=\"v2-7fd94411fa40a730da072cf447441bcc\" class=\"origin_image zh-lightbox-thumb\" width=\"1386\" data-original=\"https://pica.zhimg.com/v2-7fd94411fa40a730da072cf447441bcc_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"x_zdhENB\"\u003e当然，现实情况中，我们有多模态融合的scenarios，这个时候我们需要建立一个共享向量空间，使用\u003cb\u003e跨模态模型\u003c/b\u003e（如 OpenAI的CLIP、DeepMind的Flamingo）将不同模态的数据（如图片、文本、音频）映射到同一向量空间，文档中的文本、图像等模态均可检索，通过距离计算匹配用户查询，实现跨模态语义对齐，比如以图搜文，以文搜图等。\u003c/p\u003e\u003cp data-pid=\"MEd-DSG-\"\u003e\u003cb\u003e3.4 强化学习\u003c/b\u003e\u003c/p\u003e\u003ch2\u003e3.4.1 DeepRAG\u003c/h2\u003e\u003cp data-pid=\"fXpyYxYm\"\u003e强化学习（Reinforcement Learning, RL）RAG 中的应用并不鲜见。RL能够优化RAG系统的\u003cb\u003e检索策略\u003c/b\u003e、查询生成和答案推理过程，可以说，强化学习是 RAG 最好的军师。比如 DeepSeek-R1 就是通过基于规则的强化学习 (RL) 成功激发推理能力。\u003c/p\u003e\u003cp data-pid=\"ag6sFnkg\"\u003e这篇 Paper 《DeepRAG: Thinking to Retrieval Step by Step for Large Language Models》提出了DeepRAG，采用马尔可夫决策过程（MDP）建模检索增强推理，动态决定何时检索外部知识。优化了推理精准度，减少不必要检索，提升计算效率。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-68936cab4a0ddc4987e4733cfc2c3a44_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"684\" data-rawheight=\"503\" data-original-token=\"v2-68936cab4a0ddc4987e4733cfc2c3a44\" class=\"origin_image zh-lightbox-thumb\" width=\"684\" data-original=\"https://pic1.zhimg.com/v2-68936cab4a0ddc4987e4733cfc2c3a44_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"GJmEdkPg\"\u003e\u003cb\u003eDeepRAG框架：\u003c/b\u003eDeepRAG将检索增强推理建模为马尔可夫决策过程（MDP），通过迭代分解查询，动态决定在每一步是否检索外部知识或依赖参数推理。\u003cb\u003e奖励函数\u003c/b\u003e根据答案的正确性和检索成本来评估状态，结合答案正确性和检索成本，鼓励高效且准确的推理路径。\u003c/li\u003e\u003cli data-pid=\"LQW13RqG\"\u003e\u003cb\u003e检索叙事（Retrieval Narrative）：\u003c/b\u003e确保结构化和自适应的检索流程，根据先前检索到的信息生成子查询。\u003c/li\u003e\u003cli data-pid=\"RRHUYU23\"\u003e\u003cb\u003e原子决策（Atomic Decisions）：\u003c/b\u003e动态决定每个子查询是否检索外部知识或仅依赖LLMs的参数知识。\u003c/li\u003e\u003cli data-pid=\"sDXDDpDW\"\u003e\u003cb\u003e二叉树搜索（Binary Tree Search）：\u003c/b\u003e为每个子查询构建二叉树，探索基于参数知识或外部知识库的不同回答策略。\u003c/li\u003e\u003cli data-pid=\"9xDEMbUG\"\u003e\u003cb\u003e模仿学习（Imitation Learning）：\u003c/b\u003e通过二叉树搜索合成数据，使模型学习“子查询生成 - 原子决策 - 中间答案”的模式。\u003c/li\u003e\u003cli data-pid=\"-GEFBw7M\"\u003e\u003cb\u003e校准链（Chain of Calibration）：\u003c/b\u003e通过校准每个原子决策来细化模型对其自身知识边界的理解，使其能够更准确地做出检索必要性的决策。\u003c/li\u003e\u003c/ul\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-75e842dda8fa83f88adc034780a2e4cf_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"673\" data-rawheight=\"266\" data-original-token=\"v2-75e842dda8fa83f88adc034780a2e4cf\" class=\"origin_image zh-lightbox-thumb\" width=\"673\" data-original=\"https://picx.zhimg.com/v2-75e842dda8fa83f88adc034780a2e4cf_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"uUK30ZrU\"\u003eDeepRAG 将检索增强推理建模为 MDP，结合二进制树搜索与校准链，实现了动态检索决策。减少冗余检索和不必要的噪声，能够显著提高系统的准确性和效率。但是其训练和推理过程可能需要较高的计算资源，且检索策略和知识边界校准方法有待提高，以泛化到更多的场景。\u003c/p\u003e\u003ch2\u003e3.4.2 CoRAG\u003c/h2\u003e\u003cp data-pid=\"CpSnLVSe\"\u003e传统的RAG方法通常在生成过程之前采用\u003cb\u003e一次性检索\u003c/b\u003e策略，也就是只进行一次检索，但这种方法在处理复杂查询时可能效果有限，因为检索结果可能并不完全准确，做过搜索的同学应该都知道，想要完成一次准确的搜索，需要很多步骤，多路找回，多次检索，合并，粗排，精排等等。这篇Paper 《Chain-of-Retrieval Augmented Generation》提出了CoRAG，核心思想是将检索过程分解为多个步骤，逐步获取和整合外部知识。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-d8cfd76a164b10a2b6306b665723ead0_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"560\" data-rawheight=\"248\" data-original-token=\"v2-d8cfd76a164b10a2b6306b665723ead0\" class=\"origin_image zh-lightbox-thumb\" width=\"560\" data-original=\"https://pica.zhimg.com/v2-d8cfd76a164b10a2b6306b665723ead0_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"Bf-90aUv\"\u003eCoRAG 通过\u003cb\u003e链式检索机制和强化学习\u003c/b\u003e，提升了检索增强生成技术的效率和性能，CoRAG将检索过程分解为多个步骤，实现了逐步检索和动态调整，并且通过强化学习训练检索策略，使模型能够根据任务需求自适应调整检索行为。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-9e69f4631d198e51e9397b6bfaa2228c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"593\" data-rawheight=\"429\" data-original-token=\"v2-9e69f4631d198e51e9397b6bfaa2228c\" class=\"origin_image zh-lightbox-thumb\" width=\"593\" data-original=\"https://pic3.zhimg.com/v2-9e69f4631d198e51e9397b6bfaa2228c_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"iCXYf8ld\"\u003e\u003cb\u003e链式检索机制\u003c/b\u003e\u003cbr/\u003e逐步检索：将检索增强推理建模为\u003cb\u003e多步决策过程，\u003c/b\u003e在生成过程中，模型根据当前生成的内容和任务需求，动态决定是否进行下一步检索。采用\u003cb\u003e自适应检索策略\u003c/b\u003e：若中间答案置信度低，则重新检索；否则依赖已有信息继续生成。检索策略调整：通过强化学习或启发式规则，优化检索策略，确保每次检索都能获取最相关的信息。\u003c/p\u003e\u003cp data-pid=\"O6Dqp-8o\"\u003e大多数 RAG 数据集仅附带查询 Q 以及相应的最终答案 A ，而无需提供中间检索步骤。CoRAG 提出了一种通过拒绝抽样自动生成检索链的方法。\u003c/p\u003e\u003cp data-pid=\"Yi91emRe\"\u003e\u003cb\u003e检索与生成的协同\u003c/b\u003e\u003cbr/\u003e多步检索整合：将每次检索的结果通过注意力机制与生成模型结合，确保生成内容与检索信息的一致性。\u003c/p\u003e\u003cp data-pid=\"Bn4EUqJF\"\u003e动态生成控制：根据检索结果的质量和相关性，动态调整生成策略，避免冗余或无关信息的引入。\u003c/p\u003e\u003cp data-pid=\"1_fwkrNy\"\u003e\u003cb\u003e训练与优化\u003c/b\u003e\u003cbr/\u003e训练数据：使用包含多步检索任务的数据集进行训练。数据集中的每个训练实例都表示为一个元组 (Q,A,Q1:L,A1:L)，并附有查询 Q 和每个子查询的相应前 k 个检索文档。使用多任务学习框架中的标准下一个标记预测目标对增强数据集进行微调。\u003c/p\u003e\u003cp data-pid=\"wZG5u0PM\"\u003e奖励设计：结合任务目标（如答案准确性、文本连贯性）设计奖励函数，引导模型学习最优检索策略。\u003c/p\u003e\u003cp data-pid=\"qUC4rfxw\"\u003e模型架构：基于Transformer架构，扩展了检索决策模块和检索结果整合模块。\u003c/p\u003e\u003cp data-pid=\"sJdDJ9Ec\"\u003e\u003cb\u003e3.5 GNN图神经网络\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"L3KLXPxM\"\u003e传统RAG方法在处理复杂关系和多源知识整合方面存在不足，难以捕捉知识片段之间的复杂关系（如多跳推理任务），如多步检索或基于图的检索面临计算成本高、图结构噪声或不完整、泛化性差等挑战。这篇Paper 《GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation》提出了 GFM-RAG，通过构建图结构来显式建模知识之间的复杂关系，可以提高检索和推理的效率。当然，这些方法仍然受到图结构噪声和不完整性的影响，可能会限制其性能。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-950dd0e8429ce800af875f2d0afe5c47_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"688\" data-rawheight=\"323\" data-original-token=\"v2-950dd0e8429ce800af875f2d0afe5c47\" class=\"origin_image zh-lightbox-thumb\" width=\"688\" data-original=\"https://pic4.zhimg.com/v2-950dd0e8429ce800af875f2d0afe5c47_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"sr4b_Bcx\"\u003e\u003cb\u003eGFM-RAG框架：\u003c/b\u003eGFM-RAG通过构建知识图谱索引（KG-index）和图基础模型（GFM）来增强LLMs的推理能力。KG-index从文档中提取实体和关系，形成一个结构化的知识索引。GFM则利用图神经网络（GNN）来捕捉查询和知识图之间的复杂关系。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-a61089436a6b4fc7de7849e9835702ed_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"836\" data-rawheight=\"732\" data-original-token=\"v2-a61089436a6b4fc7de7849e9835702ed\" class=\"origin_image zh-lightbox-thumb\" width=\"836\" data-original=\"https://pic4.zhimg.com/v2-a61089436a6b4fc7de7849e9835702ed_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"RmBNAYzb\"\u003e包含三个核心组件：\u003c/p\u003e\u003cp data-pid=\"SnrgcYwm\"\u003e\u003cb\u003e1. KG索引构建：从文档中提取实体和关系，构建知识图谱（KG-index），并通过实体解析增强语义连接。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"v3S6KQcX\"\u003e传统的基于嵌入的索引方法将文档编码为单独的向量，但这些方法在对它们之间的关系进行建模方面受到限制。另一方面，知识图谱 (KG) 明确捕捉了数百万个事实之间的关系，可以提供跨多个文档的知识的结构化索引。KG 索引的结构性质与人类海马记忆索引理论非常吻合，其中 KG 索引就像一个人工海马，用于存储知识记忆之间的关联，增强了复杂推理任务对各种知识的整合。\u003c/p\u003e\u003cp data-pid=\"P34UddXJ\"\u003e为了构建 KG 索引，给定一组文档   ，我们首先从文档中提取实体 ℰ 和关系 ℛ 以形成三元组   。然后，构建实体到文档的倒排索引 M∈{0,1}|ℰ|×| | 来记录每个文档中提到的实体。这一过程可以通过现有的开放信息提取 (OpenIE) 工具实现。为了更好地捕捉知识之间的联系，进一步进行实体解析，在具有相似语义的实体之间添加额外边  + ，例如 ( USA ， equivalent ， United States of America )。因此，最终的 KG 索引   构建为 G={(e,r,e′)∈T∪T+}。在实施过程中，利用 LLM 作为 OpenIE 工具，并利用预先训练的密集嵌入模型进行实体解析。\u003c/p\u003e\u003cp data-pid=\"O1Vap-iv\"\u003e\u003cb\u003e2. 图基础模型检索器（GFM Retriever）：\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"wkth92Jp\"\u003e\u003cb\u003e查询依赖的GNN\u003c/b\u003e：动态调整消息传递过程，基于查询语义和KG结构进行多跳推理。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"dAC6ahyL\"\u003e传统的 GNN 遵循消息传递范式，该范式迭代地聚合来自邻居的信息以更新实体表示。这种范式不适用于 GFM 检索器，因为它是特定于图的，并且忽略了查询的相关性。但是 query-dependent GNNs 在捕获查询特定信息和对不可见图的通用性方面表现出良好：\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-8dad584d4f18de2fb040e59826929f90_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"148\" data-rawheight=\"28\" data-original-token=\"v2-8dad584d4f18de2fb040e59826929f90\" class=\"content_image\" width=\"148\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"h-jDSvvm\"\u003e其中\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-bf3447ff3874f25de551fbf7e794c789_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"78\" data-rawheight=\"21\" data-original-token=\"v2-bf3447ff3874f25de551fbf7e794c789\" class=\"content_image\" width=\"78\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"fpBNCQ1l\"\u003e表示初始实体特征， \u003c/p\u003e\u003cp data-pid=\"ZI49Hfkd\"\u003eHqL 表示在经过 L 层依赖于查询的消息传递之后以查询 q 为条件的更新后的实体表示。\u003c/p\u003e\u003cp data-pid=\"ynB0Rh3X\"\u003e查询相关的 GNN 表现出更好的表达能力和逻辑推理能力，作为 GFM 检索器的骨干。它允许 GFM 检索器根据用户查询动态调整消息传递过程，并在图上找到最相关的信息。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"eWz1vN5X\"\u003e\u003cb\u003e两阶段训练\u003c/b\u003e\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"NdOkeW6f\"\u003e无监督KG补全预训练：在大规模KG上学习图推理能力\u003c/li\u003e\u003cli data-pid=\"jdhEiG9Z\"\u003e有监督文档检索微调：优化查询-文档相关性。\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cp data-pid=\"CIX298W3\"\u003e\u003cb\u003eGFM\u003c/b\u003e 检索器的训练目标是最大化与查询相关的实体的可能性，可以通过最小化二元交叉熵 (BCE) 损失来优化：\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-be8e2e15f6be326f5a28ea03fa09714a_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"372\" data-rawheight=\"34\" data-original-token=\"v2-be8e2e15f6be326f5a28ea03fa09714a\" class=\"content_image\" width=\"372\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"eJCvlOKh\"\u003e其中  q 表示与查询 q 相关的目标实体集， ℰ-⊆ℰ∖ q 表示从 KG 中采样的负实体集。然而，由于目标实体的稀疏性，BCE 损失可能遭受梯度消失问题。为了解决这个问题，进一步引入了排名损失， 以最大化正负实体之间的边际：\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-b56d01fc683d7fb3aa75def8cbf0ff3b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"221\" data-rawheight=\"31\" data-original-token=\"v2-b56d01fc683d7fb3aa75def8cbf0ff3b\" class=\"content_image\" width=\"221\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"mevYasTq\"\u003e最终的训练目标是 BCE 损失和排名损失的加权组合：\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-3c75a5668e1bf115cb4bc42615e1a4cd_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"186\" data-rawheight=\"28\" data-original-token=\"v2-3c75a5668e1bf115cb4bc42615e1a4cd\" class=\"content_image\" width=\"186\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"hCzDBamZ\"\u003e\u003cb\u003e3. 文档排序与答案生成：根据实体相关性得分排序文档，输入LLM生成最终答案。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"gVIm2xgW\"\u003e鉴于 GFM 检索器预测的实体相关性得分 Pq∈ℝ|ℰ|×1 ，首先检索相关性得分最高的前 T 个实体 ℰqT ：\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-47dd34460b893d096751ca7fee90c89e_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"255\" data-rawheight=\"32\" data-original-token=\"v2-47dd34460b893d096751ca7fee90c89e\" class=\"content_image\" width=\"255\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"KALyt7bA\"\u003e然后，文档排名器使用这些检索到的实体来获取最终文档。为了减少热门实体的影响，按照实体在文档倒排索引 M∈{0,1}|ℰ|×| | 中被提及的频率的倒数来加权实体，并通过对文档中提及的实体的权重求和来计算最终的文档相关性得分：\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-315bed39384d71cd94bfb807c01607a9_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"200\" data-rawheight=\"86\" data-original-token=\"v2-315bed39384d71cd94bfb807c01607a9\" class=\"content_image\" width=\"200\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"9kVeImBA\"\u003e根据文档相关性得分 Pd 检索排名前 K 的文档，并以检索增强生成的方式输入到 LLMs 的上下文中，以生成最终答案：\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-00ff646b6b3d1346ee97f6ac93a7da33_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"270\" data-rawheight=\"78\" data-original-token=\"v2-00ff646b6b3d1346ee97f6ac93a7da33\" class=\"content_image\" width=\"270\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"GbnTmto1\"\u003e\u003cb\u003e图基础模型（GFM）：\u003c/b\u003eGFM是一个基于查询的GNN，能够根据用户查询动态调整信息传递过程，从而在单步中完成多跳推理。GFM经过两个阶段的训练：无监督的知识图完成预训练和有监督的文档检索微调。模型有8M参数，通过大规模训练（60个KG、14M三元组、700k文档）实现跨数据集零样本泛化。在7个领域数据集上 zero-shot 表现优于HippoRAG 18.9%。\u003c/p\u003e\u003cp data-pid=\"7cB8uzkv\"\u003e关于 Scaling Law，从图中我们看到模型性能随模型参数大小和训练数据大小变化的拟合趋势线。从趋势线中我们可以看到 GFM-RAG 的性能随着模型参数大小和训练数据大小的增加而提高。同时，随着模型参数大小的增大，需要更大的训练数据量才能达到最佳性能。也就是说，同时扩大模型大小和训练数据可以进一步提高 GFM-RAG 的性能。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-a365b7696bfbb5847fbe0694835a7101_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"693\" data-rawheight=\"308\" data-original-token=\"v2-a365b7696bfbb5847fbe0694835a7101\" class=\"origin_image zh-lightbox-thumb\" width=\"693\" data-original=\"https://pic2.zhimg.com/v2-a365b7696bfbb5847fbe0694835a7101_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"hl3FdAdI\"\u003e\u003cb\u003e训练过程\u003c/b\u003e：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"UsFh413L\"\u003e\u003cb\u003e无监督知识图完成预训练：\u003c/b\u003e通过掩码知识图中的实体来创建合成查询，训练GFM预测被掩码的实体。\u003c/li\u003e\u003cli data-pid=\"yLQy1W2B\"\u003e\u003cb\u003e有监督文档检索微调：\u003c/b\u003e使用标注的查询-文档对进行训练，使GFM能够更好地理解用户查询并检索相关文档。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"DAksy9fh\"\u003eGFM-RAG通过图结构建模和图神经网络推理，显著提升了RAG在复杂推理任务中的性能。但还是同样的问题，训练和推理过程可能需要较高的计算资源。如果有更高效的训练策略和更大的模型规模，模型的效率和泛化性将会得到显著提高。\u003c/p\u003e\u003cp data-pid=\"l07unyiN\"\u003e\u003cb\u003e3.6 Agentic RAG\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"1KOrMRDO\"\u003eLLM横行的年代，大多数人言则Agent，事实确实如此，LLM的落地一定是Agent，RAG也不例外。代理和 RAG 之间存在着不可分割的关系，RAG 本身是代理的关键组件，使它们能够访问内部数据；相反，代理可以增强 RAG 功能，从而产生了所谓的 Agentic RAG，例如 Self RAG 和 Adaptive RAG，因此两者实际上你中有我，我中有你的关系。\u003c/p\u003e\u003cp data-pid=\"Qr6f-faL\"\u003e这种高级形式的 RAG 允许以受控的方式在更复杂的场景中进行自适应更改。要实现 Agentic RAG，代理框架必须具备“闭环”功能。在 Andrew Ng 的四种代理设计模式中，这种“闭环”能力被称为反射能力。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-678ba084676364d94085b68e472b48fd_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"713\" data-rawheight=\"367\" data-original-token=\"v2-678ba084676364d94085b68e472b48fd\" class=\"origin_image zh-lightbox-thumb\" width=\"713\" data-original=\"https://pic4.zhimg.com/v2-678ba084676364d94085b68e472b48fd_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"egtk11SN\"\u003eAgentic RAG（基于代理的检索增强生成）代表了RAG技术的最新发展方向，通过将人工智能代理(Agent)的自主规划与决策能力引入传统检索增强生成框架，实现了对复杂查询任务的高效处理。本文将全面解析Agentic RAG的核心概念、技术架构、优势特点以及实际应用场景，帮助读者深入理解这一前沿技术如何通过智能代理的动态编排机制和多跳推理能力，显著提升传统RAG系统在复杂信息处理任务中的表现。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-21851c83683b1cb382f53e55f9ae8cb0_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"375\" data-original-token=\"v2-21851c83683b1cb382f53e55f9ae8cb0\" class=\"origin_image zh-lightbox-thumb\" width=\"700\" data-original=\"https://pic1.zhimg.com/v2-21851c83683b1cb382f53e55f9ae8cb0_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch2\u003e3.6.1 核心概念与产生背景\u003c/h2\u003e\u003cp data-pid=\"JC1VQQLD\"\u003eAgentic RAG（基于代理的检索增强生成）是传统检索增强生成技术的\u003cb\u003e高级演进形式\u003c/b\u003e，它通过\u003cb\u003e引入人工智能代理(Agent)的自主决策能力\u003c/b\u003e，使RAG系统从被动的信息检索-生成管道转变为具有主动规划和反思能力的智能体，本质上是一种融合了Agent能力与RAG架构的混合系统，其核心创新在于将AI智能体的自主规划（如路由、行动步骤、反思等）能力整合到传统的RAG流程中，以适应更加复杂的查询任务。\u003c/p\u003e\u003cp data-pid=\"qqh-40Cy\"\u003eAgentic RAG的\u003cb\u003e产生背景\u003c/b\u003e正是为了解决传统RAG在复杂场景下的这些不足。随着企业知识管理需求的日益复杂化，简单的问答式RAG已不能满足实际业务需求。企业环境中存在大量异构数据源（如结构化数据库、非结构化文档、知识图谱等），用户查询往往需要跨源关联和综合推理。同时，许多高级任务还需要结合外部工具（如计算器、API服务等）才能完整解答。这些挑战促使RAG技术向更智能、更自主的方向发展，从而催生了Agentic RAG这一新兴范式。\u003c/p\u003e\u003cp data-pid=\"VnTS8KpB\"\u003eAI Agent 是具有环境感知、自主决策和行动执行能力的智能体，能够基于目标动态规划行动步骤。将这种能力引入RAG系统后，系统能够自主决定是否需要检索、选择哪种检索策略、评估检索结果质量、决定是否重新检索或改写查询，以及在必要时调用外部工具。这种进化使RAG系统具备了感知，决策和行动能力。\u003c/p\u003e\u003cp data-pid=\"a4ti5yx5\"\u003e从系统构成角度看，Agentic RAG可被视为RAG工具化的Agent框架。在这种视角下，传统的RAG管道（检索器+生成器）被降级为Agent可使用的一种工具，而Agent则负责更高阶的任务规划与协调。这种架构转变带来了设计范式的根本变化：不再是\u0026#34;如何改进RAG管道\u0026#34;，而是\u0026#34;如何让Agent更有效地利用RAG工具\u0026#34;，从而打开了更广阔的设计空间和优化可能性。\u003c/p\u003e\u003cp data-pid=\"KI2GlRjE\"\u003e\u003ci\u003e表：传统RAG与Agentic RAG的核心区别\u003c/i\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-62d70e9cc768482199244fc147d1fea3_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"509\" data-rawheight=\"285\" data-original-token=\"v2-62d70e9cc768482199244fc147d1fea3\" class=\"origin_image zh-lightbox-thumb\" width=\"509\" data-original=\"https://pic2.zhimg.com/v2-62d70e9cc768482199244fc147d1fea3_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch2\u003e3.6.2 技术架构与关键组件\u003c/h2\u003e\u003cp data-pid=\"QWf4uiFd\"\u003eAgentic RAG系统的技术架构呈现出多样化的设计范式，从\u003cb\u003e单Agent控制\u003c/b\u003e到\u003cb\u003e多Agent协同\u003c/b\u003e的不同实现方式。与传统的线性RAG流程不同，Agentic RAG 将检索与生成过程重构为基于智能代理的动态可编排系统，通过引入规划、反思和工具使用等Agent核心能力，显著提升了复杂信息处理任务的解决能力。\u003c/p\u003e\u003cp data-pid=\"oUUnML51\"\u003e\u003cb\u003e单Agent架构模式\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"uigvDKpR\"\u003e单Agent架构是Agentic RAG的\u003cb\u003e基础实现形式\u003c/b\u003e，其核心思想是构建一个具备规划能力的 Master 智能体，将各种RAG管道和外部工具作为该 Agent 可调用的\u0026#34;工具\u0026#34;。在这种架构中，传统RAG的检索器、生成器等组件被工具化，成为 Agent 执行计划时可选择的资源。当用户查询进入系统后，Master Agent 会首先分析查询意图和复杂度，然后动态规划解决方案，可能包括：决定是否需要检索、选择哪种检索策略（如向量检索、关键词检索或混合检索）、确定是否需要进行多步检索以及是否需要调用外部工具等。\u003c/p\u003e\u003cp data-pid=\"Vh7wZJn6\"\u003e单Agent架构中的\u003cb\u003e关键组件\u003c/b\u003e包括：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"BIzj97_1\"\u003e\u003cb\u003e查询分析器：\u003c/b\u003e负责深度理解用户查询，识别隐含意图和所需的信息类型。先进的实现可能采用few-shot学习或思维链(Chain-of-Thought)技术提升意图识别准确率。\u003c/li\u003e\u003cli data-pid=\"4fUbpBEm\"\u003e\u003cb\u003e策略规划器：\u003c/b\u003e基于查询分析结果，制定检索与生成策略。例如，对于\u0026#34;比较X和Y\u0026#34;类的对比查询，规划器可能决定并行检索X和Y的相关信息，然后进行对比生成。\u003c/li\u003e\u003cli data-pid=\"BHXeRSjn\"\u003e\u003cb\u003e工具集：\u003c/b\u003e包括各种专业化RAG管道（如面向事实查询的向量检索、面向摘要任务的文本压缩检索等）和外部工具（如计算器、API接口等）。Agent将这些工具视为可插拔的模块。\u003c/li\u003e\u003cli data-pid=\"4NcyEpnS\"\u003e\u003cb\u003e反思模块：\u003c/b\u003e评估中间结果的质量，决定是否需要调整策略。例如，当首次检索结果不理想时，反思模块可能触发查询改写或更换检索策略。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"hF6zF3NQ\"\u003e单Agent架构的优势在于\u003cb\u003e设计相对简单\u003c/b\u003e和\u003cb\u003e资源需求较低\u003c/b\u003e，适合中等复杂度的应用场景。但当面对企业级复杂知识环境（如跨部门多源异构数据）时，单个Agent可能面临规划负担过重、专业知识不足等挑战，这时就需要考虑更高级的多Agent架构。\u003c/p\u003e\u003cp data-pid=\"usDvn0li\"\u003e\u003cb\u003e多Agent分层架构\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"Idupv1Wo\"\u003e多Agent分层架构是应对\u003cb\u003e企业级复杂场景\u003c/b\u003e的 Agentic RAG 解决方案，通过引入层级化的 Agent 组织，实现关注点分离和专业化分工。典型的双层架构包含一个顶层协调Agent和多个专业领域Agent，每个下层Agent负责特定类型的数据源或任务，而顶层Agent则负责任务分解、协调和结果整合。\u003c/p\u003e\u003cp data-pid=\"penckbUs\"\u003e多Agent架构中的\u003cb\u003e典型角色划分\u003c/b\u003e包括：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"kdm9NYWL\"\u003e\u003cb\u003e顶层协调Agent：\u003c/b\u003e作为系统入口，接收用户查询并进行任务分析和规划。它了解整个系统的能力分布，负责将复杂查询分解为子任务并分配给合适的专业Agent。\u003c/li\u003e\u003cli data-pid=\"_DIhRKJ_\"\u003e\u003cb\u003e领域Agent：\u003c/b\u003e每个Agent专门负责某一类文档或特定领域的数据源。例如，企业环境中可能有财务Agent（处理财报数据）、产品Agent（管理产品文档）和客户Agent（处理CRM数据）等。这些Agent内部可以集成多种RAG工具，如向量检索、SQL查询等，根据子任务特点选择最佳工具。\u003c/li\u003e\u003cli data-pid=\"zy0SgYH5\"\u003e\u003cb\u003e工具Agent：\u003c/b\u003e管理外部工具和API的访问，如网络搜索Agent、计算工具Agent等。当领域Agent需要额外能力时，可以通过顶层Agent协调调用这些工具Agent。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"1jgWLZq2\"\u003e多Agent架构的\u003cb\u003e核心优势\u003c/b\u003e在于其\u003cb\u003e卓越的可扩展性\u003c/b\u003e和\u003cb\u003e专业分工\u003c/b\u003e。新增数据源或工具时，只需添加相应的专业Agent而无需修改核心架构。同时，每个Agent可以专注于特定领域，通过精细化优化提供更专业的服务。腾讯云开发者社区的一篇文章中提到，这种架构\u0026#34;既能准确地解析不同类型的文件，还能利用Agent强大的规划和推理能力，面对用户Query选择最合适的路由策略和处理方法，大幅提升系统面对海量文档、跨文档检索、全局提炼与总结等问题时的处理能力\u0026#34;。\u003c/p\u003e\u003cp data-pid=\"0Uyv_GOV\"\u003e在通信机制的设计上，有中心化通信VS去中心化通信。\u003c/p\u003e\u003cp data-pid=\"58mib4Qk\"\u003e中心化通信（Centralized communication），在中心化通信中，存在一个中心节点，所有智能体都直接与这个中心节点进行通信。中心节点负责协调和集成所有智能体的信息，然后向各个智能体发出指令或反馈。中心节点可以全局地了解所有智能体的状态和信息，有助于做出全局最优的决策。但是容易出现单点故障，中心节点的故障可能导致整个系统的通信瘫痪。\u003c/p\u003e\u003cp data-pid=\"ZtBG3P4o\"\u003e去中心化通信（Decentralized communication），在去中心化通信中，智能体之间直接进行通信，没有中心节点，每个智能体只与它的邻居或部分智能体交换信息。有单点故障的风险，系统的鲁棒性更强，同时可扩展性极强。但是没有全局信息，难以做出全局最优的决策。\u003c/p\u003e\u003cp data-pid=\"NOTTLlp8\"\u003e关于Multi Agent系统的设计，又是另外一个复杂的 Topic 了，不做赘述。\u003c/p\u003e\u003cp data-pid=\"HEBMhLjP\"\u003e四、Challenges and Future Directions in RAG\u003c/p\u003e\u003cp data-pid=\"osoriIOS\"\u003e\u003cb\u003e4.1 统一多模态大模型\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"8sAfGfve\"\u003e通过直接多模态向量化，RAG系统能更自然地处理复杂现实数据，而不仅限于文本世界。实际选型时需权衡计算成本、领域适配性和实时性需求。如GPT-4V、Gemini 1.5的端到端多模态理解。目前的Multimodal 还是处于发展期，远没有成熟，问题包括但不限于：\u003c/p\u003e\u003cp data-pid=\"2vdIBS8t\"\u003e\u003cb\u003e1. 多模态表示与检索的挑战\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"HwthCD23\"\u003e\u003cb\u003e跨模态知识表示：\u003c/b\u003e不同模态的数据（如文本、图像、音频）需要转换为统一的向量表示，以便进行跨模态的高效检索。然而，如何设计一个能够准确捕捉不同模态语义信息的统一表示是一个关键问题。例如，CLIP模型通过学习图像和文本的对齐表示实现了跨模态检索，但其在复杂场景下的泛化能力仍有待提升。\u003c/li\u003e\u003cli data-pid=\"0KtMPuGR\"\u003e\u003cb\u003e检索效率与准确性：\u003c/b\u003e在大规模多模态数据中进行高效检索是一个挑战。向量检索方法虽然能够快速找到相似的模态数据，但可能难以区分语义上的细微差别，导致检索结果不准确。此外，多模态数据的稀疏性也增加了检索难度，尤其是在信息分散于多个文档时。\u003c/li\u003e\u003cli data-pid=\"6EBC0UWZ\"\u003e\u003cb\u003e数据对齐问题：\u003c/b\u003e不同模态的数据在语义上需要对齐，例如一段文本描述了一张图片的内容，如何将这两者在语义上进行有效对齐是一个关键挑战。\u003c/li\u003e\u003cli data-pid=\"mYJZ9HnQ\"\u003e\u003cb\u003e生成内容的质量：\u003c/b\u003e多模态RAG系统需要确保生成内容的准确性和一致性。由于检索到的知识片段可能来自不同的模态和文档，模型需要有效地整合这些信息，比如我们之前讲的如何对多路、多模态Reranker就是一个挑战。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"cKB8O4ks\"\u003e2. 效率与性能\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"Gr-BvW1O\"\u003e\u003cb\u003e计算资源需求：\u003c/b\u003e多模态RAG系统需要处理大量的数据和复杂的模型计算，对计算资源的需求较高。特别是在实时应用中，如何优化检索和生成过程以减少延迟是一个关键问题。\u003c/li\u003e\u003cli data-pid=\"TZOFWDje\"\u003e\u003cb\u003e模型训练与微调：\u003c/b\u003e为了提升多模态RAG系统的性能，需要对模型进行微调。然而，不同模态数据的训练难度不同，且微调过程需要大量的标注数据。\u003c/li\u003e\u003cli data-pid=\"p2rEHFH7\"\u003e\u003cb\u003e鲁棒性与可解释性：\u003c/b\u003e相比于传统的搜索系统，多模态RAG系统在复杂场景下的鲁棒性不足，当然，这不只是RAG的问题。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"QT-a88Xl\"\u003e\u003cb\u003e4.2 安全 (TrustRAG)\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"5qqNcmdu\"\u003e检索外部知识库可能引入敏感信息（如专利、隐私数据），RAG模型可能被滥用于生成虚假信息或恶意内容等等，但是我们这里主要讲恶意攻击和注入。这篇Paper 《TrustRAG: Enhancing Robustness and Trustworthiness in RAG》，提出了一种两阶段防御机制：首先，利用 K-means 聚类识别检索文档中的潜在攻击模式，基于语义嵌入有效隔离可疑内容；其次，通过余弦相似度和 ROUGE 指标检测恶意文档，并通过自我评估过程解决模型内部知识与外部信息之间的差异。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-051ec572e3e5e3ac84fd9bc1b7eaca3b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"827\" data-rawheight=\"451\" data-original-token=\"v2-051ec572e3e5e3ac84fd9bc1b7eaca3b\" class=\"origin_image zh-lightbox-thumb\" width=\"827\" data-original=\"https://pic2.zhimg.com/v2-051ec572e3e5e3ac84fd9bc1b7eaca3b_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"mCKC1VPU\"\u003eTrustRAG 的主要工作流：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"---CTIWb\"\u003e\u003cb\u003e识别恶意文档：\u003c/b\u003e利用 K-means 聚类分析文档的语义嵌入分布，识别出潜在的恶意文档簇。\u003c/li\u003e\u003cli data-pid=\"gZbtNNd-\"\u003e\u003cb\u003e过滤恶意内容：\u003c/b\u003e根据嵌入分布过滤掉恶意文档，保留干净文档。\u003c/li\u003e\u003cli data-pid=\"1ylZwJ8h\"\u003e\u003cb\u003e提取内部知识：\u003c/b\u003e利用 LLM 的内部知识生成准确的推理结果。\u003c/li\u003e\u003cli data-pid=\"VZtWDMGx\"\u003e\u003cb\u003e解决冲突：\u003c/b\u003e通过整合内部和外部知识，解决知识冲突，去除不相关或矛盾的文档。\u003c/li\u003e\u003cli data-pid=\"Z8puy9if\"\u003e\u003cb\u003e生成可靠答案：\u003c/b\u003e基于精炼后的文档生成最终的可靠回答\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"1mArokuT\"\u003e其实关于安全这一块，是一个非常重要的课题，可以确定的是，LLM一定会超过单个碳基生命的智慧。如何做好安全防护，一定是使用者首先要关注的，比如Deep Mind就有一个Red Team团队专门研究大模型安全的课题，这里我们不做过多介绍，后续可以单独作为一个研究的 Topic。\u003c/p\u003e\u003ch2\u003eReference\u003c/h2\u003e\u003cul\u003e\u003cli data-pid=\"WIfDONS5\"\u003eAdvanced AI and Retrieval-Augmented Generation for Code Development in High-Performance Computing | NVIDIA Technical Blog：\u003ca href=\"https://link.zhihu.com/?target=https%3A//developer.nvidia.com/blog/advanced-ai-and-retrieval-augmented-generation-for-code-development-in-high-performance-computing/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003edeveloper.nvidia.com/bl\u003c/span\u003e\u003cspan class=\"invisible\"\u003eog/advanced-ai-and-retrieval-augmented-generation-for-code-development-in-high-performance-computing/\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"PDNJOc-O\"\u003eLLM as HPC Expert: Extending RAG Architecture for HPC Data：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2501.14733\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2501.1473\u003c/span\u003e\u003cspan class=\"invisible\"\u003e3\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"L6blPE1Y\"\u003eBlended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2404.07220\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2404.0722\u003c/span\u003e\u003cspan class=\"invisible\"\u003e0\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"IV4VoBaQ\"\u003eColPali: Efficient Document Retrieval with Vision Language Models：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2407.01449\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2407.0144\u003c/span\u003e\u003cspan class=\"invisible\"\u003e9\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"tlFWtKhn\"\u003eRAG-Reward: Optimizing RAG with Reward Modeling and RLHF：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2501.13264\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2501.1326\u003c/span\u003e\u003cspan class=\"invisible\"\u003e4\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"3bFyboyi\"\u003eGFM-RAG: Graph Foundation Model for Retrieval Augmented Generation：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2502.01113\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2502.0111\u003c/span\u003e\u003cspan class=\"invisible\"\u003e3\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"5eRxXc9j\"\u003eTrustRAG: Enhancing Robustness and Trustworthiness in RAG：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2501.00879\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2501.0087\u003c/span\u003e\u003cspan class=\"invisible\"\u003e9\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"UtmAOyk-\"\u003eChain-of-Retrieval Augmented Generation：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2501.14342\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2501.1434\u003c/span\u003e\u003cspan class=\"invisible\"\u003e2\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"Rr0KjVs8\"\u003eVideoRAG: Retrieval-Augmented Generation over Video Corpus：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2501.05874\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2501.0587\u003c/span\u003e\u003cspan class=\"invisible\"\u003e4\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"Ji405xqv\"\u003eThe Power of Noise: Redefining Retrieval for RAG Systems：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2401.14887\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2401.1488\u003c/span\u003e\u003cspan class=\"invisible\"\u003e7\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"tCfdmGSK\"\u003eDon’t Forget to Connect! Improving RAG with Graph-based Reranking：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2405.18414\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2405.1841\u003c/span\u003e\u003cspan class=\"invisible\"\u003e4\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"xQyloHct\"\u003eAgentic Retrieval-Augmented Generation: A Survey on Agentic RAG：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2501.09136\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2501.0913\u003c/span\u003e\u003cspan class=\"invisible\"\u003e6\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"frp5ad4x\"\u003eImproving Retrieval-Augmented Generation through Multi-Agent Reinforcement Learning：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2501.15228\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2501.1522\u003c/span\u003e\u003cspan class=\"invisible\"\u003e8\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"8alLA4wB\"\u003eDense Passage Retrieval for Open-Domain Question Answering：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2004.04906\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2004.0490\u003c/span\u003e\u003cspan class=\"invisible\"\u003e6\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"64o4Sc1I\"\u003eDeepRAG: Thinking to Retrieval Step by Step for Large Language Models：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2502.01142\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2502.0114\u003c/span\u003e\u003cspan class=\"invisible\"\u003e2\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"iOClasdt\"\u003eApplication of Multi-Way Recall Fusion Reranking Based on Tensor and ColBERT in RAG：\u003ca href=\"https://link.zhihu.com/?target=https%3A//ieeexplore.ieee.org/document/10761558\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003eieeexplore.ieee.org/doc\u003c/span\u003e\u003cspan class=\"invisible\"\u003eument/10761558\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"ltJxF7fP\"\u003eMultimodal Embedding Models | Weaviate：\u003ca href=\"https://link.zhihu.com/?target=https%3A//weaviate.io/blog/multimodal-models\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003eweaviate.io/blog/multim\u003c/span\u003e\u003cspan class=\"invisible\"\u003eodal-models\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"1u90RBJ7\"\u003eR1/o1的风又吹到了RAG，微软CoRAG高达93%的复杂推理效果~：\u003ca href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/9Pu6wijQ9BLbH6nrP6YBTA\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003emp.weixin.qq.com/s/9Pu6\u003c/span\u003e\u003cspan class=\"invisible\"\u003ewijQ9BLbH6nrP6YBTA\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"gz5Xk7WT\"\u003eThe Rise and Evolution of RAG in 2024 A Year in Review | RAGFlow：\u003ca href=\"https://link.zhihu.com/?target=https%3A//ragflow.io/blog/the-rise-and-evolution-of-rag-in-2024-a-year-in-review\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003eragflow.io/blog/the-ris\u003c/span\u003e\u003cspan class=\"invisible\"\u003ee-and-evolution-of-rag-in-2024-a-year-in-review\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"vfT9GKUW\"\u003eAdvanced RAG Techniques | Weaviate：\u003ca href=\"https://link.zhihu.com/?target=https%3A//weaviate.io/blog/advanced-rag\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003eweaviate.io/blog/advanc\u003c/span\u003e\u003cspan class=\"invisible\"\u003eed-rag\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"x6PNRpvJ\"\u003eJina-ColBERT-v2: A General-Purpose Multilingual Late Interaction Retriever：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2408.16672\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/pdf/2408.1667\u003c/span\u003e\u003cspan class=\"invisible\"\u003e2\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"F6XlB_qB\"\u003eLLMs的推理之路：从链式思维到强化学习，迈向大型推理模型：\u003ca href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/tesV5lAsLXVBdP2WqUCrmw\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003emp.weixin.qq.com/s/tesV\u003c/span\u003e\u003cspan class=\"invisible\"\u003e5lAsLXVBdP2WqUCrmw\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"q1WP5bpe\"\u003eFrom RAG to Memory: Non-Parametric Continual Learning for Large Language Models：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2502.14802\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/pdf/2502.1480\u003c/span\u003e\u003cspan class=\"invisible\"\u003e2\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"A5I4_0Iu\"\u003eRAG vs. GraphRAG: A Systematic Evaluation and Key Insights：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2502.11371\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/pdf/2502.1137\u003c/span\u003e\u003cspan class=\"invisible\"\u003e1\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"1QXpTXDM\"\u003eColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2004.12832\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/abs/2004.1283\u003c/span\u003e\u003cspan class=\"invisible\"\u003e2\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003cli data-pid=\"Ts2qAI2O\"\u003eSafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2501.18636\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003earxiv.org/pdf/2501.1863\u003c/span\u003e\u003cspan class=\"invisible\"\u003e6\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"yOpLQz_C\"\u003e\u003cb\u003e实时与AI智能体进行语音通话\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"4zFd8ETO\"\u003eAI实时语音互动是一种旨在帮助企业快速构建AI与用户之间的语音通话应用的解决方案。用户只需通过白屏化的界面操作，即可快速构建一个专属的AI智能体，并通过视频云ARTC网络与终端用户进行实时交互。    \u003c/p\u003e\u003cp data-pid=\"7XYs3WVJ\"\u003e点击\u003ca href=\"https://link.zhihu.com/?target=https%3A//www.aliyun.com/solution/tech-solution/real-time-interaction%3Futm_content%3Dg_1000399268\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e阅读原文\u003c/a\u003e查看详情。\u003c/p\u003e\u003cp\u003e\u003c/p\u003e","is_labeled":false,"visited_count":8826,"thumbnails":["https://picx.zhimg.com/50/v2-7748a2a68f437ed03d6d6b70ef338a3e_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-37426cdd400a00c29e2d06934e29af5d_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-b373030d8079df406d25e091bf5438f9_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-fc0fafb0102576d3c2a19b9087c4d503_720w.jpg?source=b6762063"],"favorite_count":703,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1903437079603545114}","attached_info":"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","action_card":false},{"id":"73_1753853588.548","type":"feed","offset":73,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1753853588,"updated_time":1753853588,"target":{"id":"1931103948233742053","type":"answer","url":"https://api.zhihu.com/answers/1931103948233742053","author":{"id":"60a8e85f9d49d3d507b529b2e876aa5b","url":"https://api.zhihu.com/people/60a8e85f9d49d3d507b529b2e876aa5b","user_type":"people","url_token":"you-shi-huan-xi-xia-wu-cha","name":"游世欢喜下午茶","headline":"一花一世界","avatar_url":"https://pic1.zhimg.com/50/v2-cdf29e9174293b3e0d106dc45b09e9a7_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":23,"is_following":false,"is_followed":false},"created_time":1753191059,"updated_time":1753191059,"voteup_count":6,"thanks_count":0,"comment_count":0,"is_copyable":true,"question":{"id":"1895408695459962900","type":"question","url":"https://api.zhihu.com/questions/1895408695459962900","author":{"id":"e7b982a0104555cf8c76ca597f123be5","url":"https://api.zhihu.com/people/e7b982a0104555cf8c76ca597f123be5","user_type":"people","url_token":"qiao-bian-hong-yao-miss","name":"桥边红药miss","headline":"当看尽潮起潮落，你会记得我。","avatar_url":"https://picx.zhimg.com/50/v2-8e1ef9b413f7eb97122bb8ff0c9b37e1_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":659,"is_following":false,"is_followed":false},"title":"文艺复兴时期的代表人物有哪些？","created":1744680647,"answer_count":0,"follower_count":0,"comment_count":0,"bound_topic_ids":[15628,117733,338297],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"thumbnail":"https://pic1.zhimg.com/50/v2-4cd7ecb261647305119d05bd277a52a6_720w.jpg?source=b6762063","excerpt":"文艺复兴美术史四个主要阶段： 1、预备期：13th-14th摆脱中世纪僵硬单纯的美术程式，突破中世纪拜占庭绘画偶像化的束缚，完美的叙事同现实主义的直接感受结合，写实风格和明暗远近法结合，使宗教的抽象概念成为栩栩如生的具象，突出的造型表现力创造出真实形象与真实空间 ，开创了人文主义思想和写实主义表现。 有人说：“绘画在文艺复兴早期人文主义没抬头的时候其实就是对宗教统治权威表忠心歌功颂德的极度阿谀......” 开创了…","excerpt_new":"文艺复兴美术史四个主要阶段： 1、预备期：13th-14th摆脱中世纪僵硬单纯的美术程式，突破中世纪拜占庭绘画偶像化的束缚，完美的叙事同现实主义的直接感受结合，写实风格和明暗远近法结合，使宗教的抽象概念成为栩栩如生的具象，突出的造型表现力创造出真实形象与真实空间 ，开创了人文主义思想和写实主义表现。 有人说：“绘画在文艺复兴早期人文主义没抬头的时候其实就是对宗教统治权威表忠心歌功颂德的极度阿谀......” 开创了…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cblockquote data-pid=\"axQdXxBD\"\u003e\u003cb\u003e文艺复兴美术史四个主要阶段：\u003c/b\u003e\u003c/blockquote\u003e\u003cp data-pid=\"e4wq6qNT\"\u003e\u003cb\u003e1、预备期：13th-14th\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"eR08lSwm\"\u003e摆脱中世纪僵硬单纯的美术程式，突破中世纪拜占庭绘画偶像化的束缚，完美的叙事同现实主义的直接感受结合，写实风格和明暗远近法结合，使宗教的抽象概念成为栩栩如生的具象，突出的造型表现力创造出真实形象与真实空间 ，开创了人文主义思想和写实主义表现。\u003c/p\u003e\u003cp data-pid=\"vdjCGOE6\"\u003e有人说：“绘画在文艺复兴早期人文主义没抬头的时候其实就是对宗教统治权威表忠心歌功颂德的极度阿谀......”\u003c/p\u003e\u003cp data-pid=\"9yf5jSPc\"\u003e开创了平面绘画中的透视法则和明暗技术 ，巧妙强调人物质感与明暗关系。开启了透视法与光线对人体的体积感， 刻画人物的体积感和表现自然的空间感。\u003c/p\u003e\u003cp data-pid=\"wBbTtb2J\"\u003e对油画艺术技巧的纵深发展做出了奠基。\u003c/p\u003e\u003cblockquote data-pid=\"1Ih_VIK-\"\u003e\u003cb\u003e代表人物：乔托（Giotto di bondone ，1266－1337）、马萨乔（Massaccio,1401-1428）、扬·凡·艾克（ Jan Van Eyck，1385-1441）。\u003c/b\u003e\u003c/blockquote\u003e\u003cp data-pid=\"cvQ1iEqV\"\u003e\u003cb\u003e乔托《最后的审判》，c.1306年，1000cm × 840cm，湿壁画，意大利帕多瓦斯克罗威尼礼拜堂，这幅湿壁画是礼拜堂西墙壁画，是礼拜堂系列画作故事的结尾。\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-9a1baaf6d52f0bedfd09d47afa3df10c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1100\" data-rawheight=\"1318\" data-original-token=\"v2-72e1e963e67d80100f94c0e1f9bdf52c\" data-default-watermark-src=\"https://pic3.zhimg.com/v2-1913255dc18ff274c0cb2dd9fc8d4fba_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1100\" data-original=\"https://pic3.zhimg.com/v2-9a1baaf6d52f0bedfd09d47afa3df10c_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"4XLTccZ7\"\u003e\u003cbr/\u003eLast Judgment \u003c/p\u003e\u003cblockquote data-pid=\"ry-kkRNo\"\u003e\u003cb\u003eGIOTTO di Bondone\u003c/b\u003e\u003cbr/\u003e\u003ci\u003eLast Judgment \u003c/i\u003e\u003cbr/\u003e1306\u003cbr/\u003eFresco\u003cbr/\u003eCappella Scrovegni (Arena Chapel), Padua\u003c/blockquote\u003e\u003cp data-pid=\"cFyU5rsI\"\u003e\u003cb\u003e马萨乔《纳税银》，c.1425年，247cm × 597cm，湿壁画。佛罗伦萨卡尔米内圣母大殿的布兰卡契小礼拜堂。\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-dcf598c650b8508ca59fc4bade07307f_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1139\" data-rawheight=\"500\" data-original-token=\"v2-2ceac17b79a74b3bff5e4df9bc1bb735\" data-default-watermark-src=\"https://pic4.zhimg.com/v2-1838a1a74d3100d3922a14520fc78f2d_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1139\" data-original=\"https://picx.zhimg.com/v2-dcf598c650b8508ca59fc4bade07307f_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"bnfVs6e6\"\u003e\u003cbr/\u003eThe Tribute Money\u003c/p\u003e\u003cblockquote data-pid=\"y9_bVDSE\"\u003e\u003cb\u003eMasaccio\u003c/b\u003e\u003cbr/\u003e\u003ci\u003eThe Tribute Money\u003c/i\u003e\u003cbr/\u003ec.1425\u003cbr/\u003eFresco，247 cm× 597cm\u003cbr/\u003e Cappella  dei Brancacci (left view)，Santa Maria del Carmine, Florence, Italy\u003c/blockquote\u003e\u003cp data-pid=\"R02UP41-\"\u003e\u003cb\u003e扬 · 凡 · 艾克《阿尔诺芬妮夫妇像》，c.1434年，83.7 x 57 cm，油画。是风俗画的开山之作，也是油画材料和绘画方法革新后的代表性作品。现收藏于英国伦敦国家画廊。\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-b07463c3e09cec69342e7676080e00a7_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1035\" data-rawheight=\"1400\" data-original-token=\"v2-fc06aa21e4333053d34197d3c58a7ffd\" data-default-watermark-src=\"https://pic1.zhimg.com/v2-da94a56b0c23c05d1893648b18364728_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1035\" data-original=\"https://pic2.zhimg.com/v2-b07463c3e09cec69342e7676080e00a7_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"L3cKZzjN\"\u003e\u003cbr/\u003eThe Portrait of Giovanni Arnolfini \u003c/p\u003e\u003cblockquote data-pid=\"2u-OAD4w\"\u003e\u003cb\u003eJan van Eyck\u003c/b\u003e\u003cbr/\u003e\u003ci\u003eThe Portrait of Giovanni Arnolfini （The Arnolfini Wedding）\u003c/i\u003e\u003cbr/\u003ec.1434，oil/panel，83.7 x 57 cm\u003cbr/\u003eThe National Gallery\u003c/blockquote\u003e\u003cp data-pid=\"EfSrNh4v\"\u003e日本女作家Nanami Shiono（盐野七生）在她的著作中提出：文艺复兴第一人，并不是我们认为的但丁、乔托等，而是一位神职人员，他叫圣方济各（St.Francis）。\u003c/p\u003e\u003cp data-pid=\"LBYtJ5qV\"\u003e方济各会的宗教激进主义提倡放弃正统宗教的经院哲学，颂扬自然之美和人类的精神实质和价值。\u003c/p\u003e\u003cp data-pid=\"hxiMLWje\"\u003e中世纪的教义是文艺复兴坚实的土壤。\u003c/p\u003e\u003cp data-pid=\"zXwcjDJ1\"\u003e\u003cb\u003e2、发展期：14th-15th\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"KZuHsfuV\"\u003e文艺复兴初期，画家们并不能从神灵控制下完全摆脱出来，大场面宗教内容的绘画，成就了文艺复兴的崇高代表。画法上更强调轮廓线来表现人体造型，作品发挥了强大写实造型功夫，人物表情更加细致入微，同时出现最早裸体女神描绘，成为文艺复兴正式开始的标志性作品，对打破中世纪传统和宗教禁力作出了贡献。\u003c/p\u003e\u003cblockquote data-pid=\"eFSidyVx\"\u003e\u003cb\u003e代表人物：波提切利（ Botticelli ，1445-1510）。\u003c/b\u003e\u003c/blockquote\u003e\u003cp data-pid=\"WPrRqHj2\"\u003e\u003cb\u003e但丁神曲插图，是 Sandro Botticelli 为 Lorenzo di Pierfrancesco de\u0026#39; Medici 委托的手稿插图，为书籍插图艺术的颠峰。\u003c/b\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-f0ea04cb5bd967c6b96d0bca41f476f4_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1059\" data-rawheight=\"700\" data-original-token=\"v2-c424bd39f7dc8ea4b680369983423e03\" data-default-watermark-src=\"https://pic1.zhimg.com/v2-35daa7836cbce5046a4df4371fae4e52_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1059\" data-original=\"https://pic1.zhimg.com/v2-f0ea04cb5bd967c6b96d0bca41f476f4_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"lX8wG9xJ\"\u003e\u003cbr/\u003e但丁神曲第十八章地狱的插图\u003c/p\u003e\u003cblockquote data-pid=\"6xr9ed1E\"\u003e\u003cb\u003eBOTTICELLI, Sandro\u003c/b\u003e\u003cbr/\u003e\u003ci\u003eDante: Divina Commedia\u003c/i\u003e\u003cbr/\u003e1480s\u003cbr/\u003eManuscript (Ms. Hamilton 201), 320 x 470 mm\u003cbr/\u003eStaatliche Museen, Berlin\u003c/blockquote\u003e\u003cp data-pid=\"Kjs6Gkrp\"\u003e\u003ci\u003eThis almost completely coloured silverpoint drawing gives us an impression of the magnificent way in which all the miniatures were to be produced. It is an illustration to the Inferno, canto XVIII. The main figures, Dante and Virgil, are emphasized by their vibrantly shining robes.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"Omfg3eqv\"\u003e\u003ci\u003eSeveral remarkable illustrated Dante manuscripts exist. Certainly the most famous illustrations of the Divina Commedia are the superb drawings Sandro Botticelli planned for a de luxe manuscript commissioned by Lorenzo di Pierfrancesco de\u0026#39; Medici.\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"oRK-58qn\"\u003e几乎完全彩色的银尖笔画\u003ci\u003e（coloured silverpoint drawing）\u003c/i\u003e是第十八章地狱的插图， 主要人物但丁和维吉尔在地狱的沟渠中旅行时，遇到了被魔鬼折磨的皮条客和勾引者的灵魂以及马屁精和妓女的灵魂，他们在痛苦中受苦。\u003c/p\u003e\u003cp data-pid=\"FdeLb4p-\"\u003e\u003cb\u003e\u003ci\u003eThe Birth of Venus\u003c/i\u003e（维纳斯的诞生，意：\u003ci\u003eLa Nascita di Venere \u003c/i\u003e)，1485年，蛋彩画， 173 x 279 cm，收藏于Galleria degli Uffizi, Florence（佛罗伦萨乌菲齐美术馆）。它是意大利文艺复兴绘画的标志，也被称为文艺复兴真正意义上的开山之作。\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-46340cf53b94d75c18195e6df4677f24_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1200\" data-rawheight=\"705\" data-original-token=\"v2-7cb71accba96b44b2fb48d09155bbd1b\" data-default-watermark-src=\"https://picx.zhimg.com/v2-7fd57ecb883cf4d72fd0d1033f396b6f_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1200\" data-original=\"https://pic3.zhimg.com/v2-46340cf53b94d75c18195e6df4677f24_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"Ahl9qiWh\"\u003e\u003cbr/\u003eThe Birth of Venus\u003c/p\u003e\u003cblockquote data-pid=\"fcAqkFCx\"\u003e\u003cb\u003eBOTTICELLI, Sandro\u003c/b\u003e\u003cbr/\u003e\u003ci\u003eThe Birth of Venus\u003c/i\u003e\u003cbr/\u003ec. 1485\u003cbr/\u003eTempera on canvas, 173 x 279 cm\u003cbr/\u003eGalleria degli Uffizi, Florence\u003c/blockquote\u003e\u003cp data-pid=\"U0XOAakW\"\u003e\u003cb\u003e3、鼎盛期：从15th-16th\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"pBgXCm7q\"\u003e从乔托、马萨乔开始，人物虽然开始写实立体，但是形象是僵硬的。无论是扬凡艾克精细的描摹细节，还是波提切利突出人物的长发衣物线条，都没有完全解决这个问题。\u003c/p\u003e\u003cp data-pid=\"ZswQb7_4\"\u003e而鼎盛期的画家们以反映世俗生活为已任，解剖学、透视画法等科学与艺术结合，大胆的艺术改革，抛弃中世纪艺术传统，新的创作方法和技巧层出。文艺复兴的重心转向了罗马。\u003c/p\u003e\u003cblockquote data-pid=\"Dgz-Vxqz\"\u003e\u003cb\u003e代表人物：达·芬奇（da Vinci ，1452-1519）、米开朗基罗（Michelangelo Buonarroti，1471-1564）、拉斐尔（Raphael Sanzio， 1483-1520）。\u003c/b\u003e\u003c/blockquote\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-1407b185a9f95fa03b14e9db18e81a09_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1400\" data-rawheight=\"1353\" data-original-token=\"v2-210d3dad7e166675eff6bf32191d717c\" data-default-watermark-src=\"https://pica.zhimg.com/v2-1c968d71e7d981984347fdab879ecbae_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1400\" data-original=\"https://pic2.zhimg.com/v2-1407b185a9f95fa03b14e9db18e81a09_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"Xi3KHmQM\"\u003e\u003cbr/\u003e达芬奇 《三博士朝圣》（未完成）\u003c/p\u003e\u003cblockquote data-pid=\"gKpuh4Oa\"\u003e\u003cb\u003eLEONARDO da Vinci\u003c/b\u003e\u003cbr/\u003e\u003ci\u003eAdoration of the Magi\u003c/i\u003e\u003cbr/\u003e1481-82\u003cbr/\u003eCharcoal, watercolour, ink and oil on wood, 244 x 240 cm\u003cbr/\u003eGalleria degli Uffizi, Florence\u003c/blockquote\u003e\u003cp data-pid=\"5sQ1pklo\"\u003e\u003cb\u003e4、末期（16th-17th）\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"fkZc0AnT\"\u003e这个时期。艺术形式百花齐放，喷涌而出，多家画派崛起。富有艺术感和想象力，强调色彩和素描的表现力的威尼斯画派的崛起，北欧的德国、佛兰德斯和尼德兰等地的创作崛起、那不勒斯画派崭露头角。\u003c/p\u003e\u003cp data-pid=\"BICw72sG\"\u003e作品上开始采用了明暗造型法及晕涂法。带着古典主义色彩，形象动感热烈，色彩富丽奇幻，作品构图新颖，造型柔和，层次丰富，色彩富丽奇幻，涌现大量杰出的现实主义画家，革命性地追求光线效果，并将宗教人物去神话化，以戏剧般的写实手法画出平民生活的世界。\u003c/p\u003e\u003cblockquote data-pid=\"bmgKkQXR\"\u003e\u003cb\u003e代表人物：乔尔乔内（Giorgione1477—1510）、提香（Tiziano Vecellio 1490-1576）、丁托列托（Tintoretto 1518-1594）、委罗内塞（Paolo Veronese，1528－1588）、卡拉瓦乔(Michelangelo Merisi da Caravaggio，1571-1610)、委拉斯开兹（ Velazquez 1599-1660）。\u003c/b\u003e\u003c/blockquote\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-cc3be9dfd64af9d207f4e870ef9b129f_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1300\" data-rawheight=\"1047\" data-original-token=\"v2-437973b17879a5638eb0af81917437d7\" data-default-watermark-src=\"https://pic1.zhimg.com/v2-c14387898f22ac33d7d5e72fc28a3d16_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1300\" data-original=\"https://picx.zhimg.com/v2-cc3be9dfd64af9d207f4e870ef9b129f_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"JcuCF7nv\"\u003e\u003cbr/\u003e乔尔乔内乡村派对\u003c/p\u003e\u003cblockquote data-pid=\"gFNra_xZ\"\u003e\u003cb\u003eGIORGIONE\u003c/b\u003e\u003cbr/\u003ePastoral Concert (Fête champêtre)\u003cbr/\u003e1508-09\u003cbr/\u003eOil on canvas, 110 x 138 cm\u003cbr/\u003eMusée du Louvre, Paris\u003c/blockquote\u003e\u003cp\u003e\u003cbr/\u003e \u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":287,"thumbnails":["https://picx.zhimg.com/50/v2-4cd7ecb261647305119d05bd277a52a6_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-366679191d8406deca9dea3126945ae0_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-f9d9728cd4dd71e9703d2886b34e5aa4_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-38964701a008b3eeb08ed8b60f086da1_720w.jpg?source=b6762063","https://pica.zhimg.com/50/v2-4468223941ab22784ced12a22168b707_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-0a55e389dfba13abcd90225a2833bbcb_720w.jpg?source=b6762063"],"favorite_count":13,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1931103948233742053}","attached_info":"CogJCIrkppqf7/7pugEQBBoJNzM4MzM3MTUxIJOl/sMGKAYwAEBJSkIKLVRTX1NPVVJDRV9UV09UT1dFUl9NVUxUSV9TQ0VORV9WMV9SRUNBTExfVEVYVBIBMBgAIAA6CnsicmF3IjoiIn1KQgotVFNfU09VUkNFX1RXT1RPV0VSX01VTFRJX1NDRU5FX1YxX1JFQ0FMTF9URVhUEgEwGAAgADoKeyJyYXciOiIifVoJMTE0NTA0MTE1YiBhYTdkMjI0ZTA2ZDRiMzFiNzRmNjRkMDgwZDliN2Y1NnITMTkzMTEwMzk0ODIzMzc0MjA1M4oBEzE4OTU0MDg2OTU0NTk5NjI5MDCqAQlyZWNvbW1lbmTCASA2MGE4ZTg1ZjlkNDlkM2Q1MDdiNTI5YjJlODc2YWE1YvIBCggMEgZOb3JtYWzyASgIChIkNGIzNDE4ZTYtZDIyYi00YTNmLWIyYjItMTgzYjkxNzBjNTFj8gEGCAsSAjEzggIAiALu48fOhTOSAiA2MGE4ZTg1ZjlkNDlkM2Q1MDdiNTI5YjJlODc2YWE1YpoCAMoCFlNob3JJbnRlcmVzdFdlaWdodFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXKAhRDb250ZW50QWdlV2VpZ2h0UnVsZdoCLVRTX1NPVVJDRV9UV09UT1dFUl9NVUxUSV9TQ0VORV9WMV9SRUNBTExfVEVYVOgCA/oCC05PUk1BTF9GTE9XigMgMDkwMThiZDM2NmQwNGQwNWE2ZTE3NzFjNjNiMGFlY2KaAw0KAnYyEAAaBW90aGVyqAOfAtgDAOoDH3RleHRGZWVkVHdvVG93ZXJXYXJtdXBTdWNjZXNzVjH6A+gCEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERTotCAQQzAgYpgoiI3YyLTcyZTFlOTYzZTY3ZDgwMTAwZjk0YzBlMWY5YmRmNTJjOi0IAxDzCBj0AyIjdjItMmNlYWMxN2I3OWE3NGIzYmZmNWU0ZGY5YmMxYmI3MzU6LQgDEIsIGPgKIiN2Mi1mYzA2YWEyMWU0MzMzMDUzZDM0MTk3ZDNjNThhN2ZmZDotCAMQowgYvAUiI3YyLWM0MjRiZDM5ZjdkYzhlYTRiNjgwMzY5OTgzNDIzZTAzOi0IBRCwCRjBBSIjdjItN2NiNzFhY2NiYTk2YjQ0YjJmYjQ4ZDA5MTU1YmJkMWI6LQgDEPgKGMkKIiN2Mi0yMTBkM2RhZDdlMTY2Njc1ZWZmNmJmMzIxOTFkNzE3YzotCAMQlAoYlwgiI3YyLTQzNzk3M2IxNzg3OWE1NjM4ZWIwYWY4MTkxNzQzN2Q3gAQAiAQAkgQGTm9ybWFsmgQBM6AEAKgEALAEALoEAmFpwgQDNDAwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAABA3PiTP4EFAAAAAAAAAACJBQOJhAWjadM/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBQ2QBgCgBkmoBgOSAi4KCTczODMzNzE1MRITMTkzMTEwMzk0ODIzMzc0MjA1MxgEIgpJTUFHRV9URVhU","action_card":false},{"id":"74_1753853588.401","type":"feed","offset":74,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1753853588,"updated_time":1753853588,"target":{"id":"1904201445634474778","type":"answer","url":"https://api.zhihu.com/answers/1904201445634474778","author":{"id":"be4996643b04fda8ddc2ec09480a7d55","url":"https://api.zhihu.com/people/be4996643b04fda8ddc2ec09480a7d55","user_type":"people","url_token":"chen-ying-nong","name":"枫冷慕诗","headline":"公众号：枫冷慕诗，资本论是我团队的号。","avatar_url":"https://pica.zhimg.com/50/v2-44eb83371add65028eca8d2be4a77405_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":291647,"is_following":false,"is_followed":false},"created_time":1746777003,"updated_time":1746777003,"voteup_count":4382,"thanks_count":91,"comment_count":570,"is_copyable":false,"question":{"id":"1891394428519835413","type":"question","url":"https://api.zhihu.com/questions/1891394428519835413","author":{"id":"791d04adea6c858b8845aab7cae981f2","url":"https://api.zhihu.com/people/791d04adea6c858b8845aab7cae981f2","user_type":"people","url_token":"gu-li-te-96","name":"职场大咖","headline":"职业经理人","avatar_url":"https://picx.zhimg.com/50/v2-58a9a92c5a268b1095a94f602b6b204a_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":5,"is_following":false,"is_followed":false},"title":"胖东来为什么没有走快速扩张路线？","created":1743723572,"answer_count":0,"follower_count":0,"comment_count":23,"bound_topic_ids":[16788,18459],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"因为走不出去，想弄他们的人太多了，去个郑州都困难无比，真全国扩张了，于东来估计会出大问题，不信你看最近的情况。 5月3日，胖东来的创始人于东来在自己的个人账号里发布了最后一条内容：如果不对随意污蔑伤害他人的行为进行处罚，我会主动关闭或者永远离开胖东来这个企业！ 随后，于东来清空了自己的所有视频，并把自己的私人账号设置成了私密状态，看到这种情况，网友们大为吃惊，他们惊呼：于东来这是要退网了吗？胖东来到…","excerpt_new":"因为走不出去，想弄他们的人太多了，去个郑州都困难无比，真全国扩张了，于东来估计会出大问题，不信你看最近的情况。 5月3日，胖东来的创始人于东来在自己的个人账号里发布了最后一条内容：如果不对随意污蔑伤害他人的行为进行处罚，我会主动关闭或者永远离开胖东来这个企业！ 随后，于东来清空了自己的所有视频，并把自己的私人账号设置成了私密状态，看到这种情况，网友们大为吃惊，他们惊呼：于东来这是要退网了吗？胖东来到…","preview_type":"default","preview_text":"","reshipment_settings":"disallowed","content":"\u003cp data-pid=\"kvWz0bvJ\"\u003e因为走不出去，想弄他们的人太多了，去个郑州都困难无比，真全国扩张了，于东来估计会出大问题，不信你看最近的情况。\u003c/p\u003e\u003cp data-pid=\"OzDMcq6E\"\u003e5月3日，胖东来的创始人于东来在自己的个人账号里发布了最后一条内容：如果不对随意污蔑伤害他人的行为进行处罚，我会主动关闭或者永远离开胖东来这个企业！\u003c/p\u003e\u003cp data-pid=\"HuXxy1KJ\"\u003e随后，于东来清空了自己的所有视频，并把自己的私人账号设置成了私密状态，看到这种情况，网友们大为吃惊，他们惊呼：于东来这是要退网了吗？胖东来到底发生了什么事情？\u003c/p\u003e\u003cp data-pid=\"fphDzTMO\"\u003e其实，于东来之所以会这么愤怒，是因为最近有一场围猎胖东来的运动已经开始，有某些特殊群体他们正联合起来围剿胖东来。\u003c/p\u003e\u003cp data-pid=\"wNX1xdib\"\u003e不信我们看看最近发生的事情。\u003c/p\u003e\u003cp data-pid=\"K91k5RiL\"\u003e2025年4月初，一个拥有28万粉丝的小网红柴怼怼在网上公开抨击胖东来，他说胖东来销售的和田玉存在严重的质量问题，几百块钱的东西卖出了好几万元人民币，甚至为了增强说服力，他还晒出了一个所谓的内部报价单，以此来证明胖东来一直在割消费者的韭菜。\u003c/p\u003e\u003cp data-pid=\"FjX07rN9\"\u003e消息传出之后，舆论沸腾，大量不明真相的网友跑去质问于东来，甚至有人还对于东来和胖东来的员工进行人身攻击。\u003c/p\u003e\u003cp data-pid=\"ljEFolqf\"\u003e看到汹涌奔腾的民意，于东来先是连续两次发布声明，公开了自己的定价标准，然后又找专业的鉴定机构出具证明，论证自己的玉石质量没问题。\u003c/p\u003e\u003cp data-pid=\"v1ICx8uk\"\u003e可即便如此，网络上还是有大量攻击抹黑胖东来的声音，看到误解的声音不断传出，于东来感到备受委屈，所以一怒之下直接选择了清空所有视频，并把自己的账号设置成了私密。\u003c/p\u003e\u003cp data-pid=\"_C9fHvho\"\u003e最后经过市场监管部门的证明，胖东来销售的玉石没有问题，柴怼怼的批评纯粹就是子虚乌有，甚至网友还惊讶的发现，这个柴怼怼没有任何的专业资质，之前还多次销售祛湿茶和假酒来大肆圈钱，更离谱的是，他自己来打假胖东来，结果却被网友扒出，他销售的玉石连证书都是伪造的。\u003c/p\u003e\u003cp data-pid=\"G1Q0WiMi\"\u003e也就是说，这纯粹就是针对胖东来的一次恶意碰瓷。\u003c/p\u003e\u003cp data-pid=\"sQqPOoYr\"\u003e而且这已经不是今年的第一次碰瓷事件了，在今年过年的时候，一个叫小段的网红就跳出来攻击胖东来，她说，自己在胖东来买了一条内裤，结果穿了没几次，内裤不仅掉色，还让她的皮肤出现了过敏。\u003c/p\u003e\u003cp data-pid=\"BD_u6S1k\"\u003e听闻消息，大年初五的胖东来立马给出了回应，他们先是和这位网红电话确认，然后派出了他们内衣部的经理带网红去医院检查，并给出了500块钱的现金赔偿。\u003c/p\u003e\u003cp data-pid=\"Qza_7n0L\"\u003e可没想到了，这位网红大发脾气。\u003c/p\u003e\u003cp data-pid=\"w1VCntBC\"\u003e她先是说胖东来不尊重自己，带自己去检查竟然打车过来，连车都不开一辆，没有一点诚意。\u003c/p\u003e\u003cp data-pid=\"x8F8YAM3\"\u003e然后又说自己的皮肤越来越严重了，500块钱就想打发自己。\u003c/p\u003e\u003cp data-pid=\"1MY80vrR\"\u003e她在视频里痛哭流涕，引起了无数人的同情，大量的人跑去质问胖东来，为什么要欺负一个女孩子？\u003c/p\u003e\u003cp data-pid=\"4XQoW6Ck\"\u003e眼看舆论不受控制，被逼到墙脚的于东来只能选择正面回应，他先是下架了这批内裤，然后找了三家机构进行检测，出具了长达53页的鉴定报告，最后结果显示，胖东来的内裤没有问题，过敏可能是顾客的个人原因。\u003c/p\u003e\u003cp data-pid=\"XGf44j58\"\u003e听闻消息，网友们恍然大悟，然后大家转身去挖这位网红的底细，结果发现这位网红是“过敏爱好者”，她在很短的时间内投诉过十几个不同品牌，每次都是过敏问题。\u003c/p\u003e\u003cp data-pid=\"Z6397ijn\"\u003e更搞笑的是，在这位网红的家里，网友还发现了胖东来的购物车，连车都被她给顺回家了，她竟然还死咬着胖东来碰瓷，这件事实在是过于离谱。\u003c/p\u003e\u003cp data-pid=\"-HSO8xaK\"\u003e而且更魔幻的是，不仅是网红在碰瓷胖东来，还有某些超市，也在刻意的抹黑和碰瓷胖东来，比如说浙江嘉兴的胖都来，它从商场的名称到品牌的配色，再到经营范围，全都在碰瓷胖东来，但是它的服务和质量却没有向胖东来看齐，他靠着擦边的方式博取流量，损害了胖东来多年累积的信誉，很多顾客去消费之后直呼上当，还因此怪到了胖东来头上。\u003c/p\u003e\u003cp data-pid=\"7lpHjO3z\"\u003e看到这种纯纯的碰瓷行径，于东来气愤的走上了法律维权之路。\u003c/p\u003e\u003cp data-pid=\"l5I1r5QP\"\u003e而且我说的这些都只是冰山一角，自从爆火出圈之后，胖东来就一直被某些势力恶意攻击。\u003c/p\u003e\u003cp data-pid=\"EjnCHPcS\"\u003e有经济学家说胖东来福利太高，分钱太多，扰乱了市场秩序，缺乏社会价值。\u003c/p\u003e\u003cp data-pid=\"xo9i9IGP\"\u003e有企业家说胖东来帮扶同行是为了进行商业扩张，全部都是为了赚钱。\u003c/p\u003e\u003cp data-pid=\"heXhX1My\"\u003e还有网友批评胖东来爹味太浓，管彩礼管桌席，简直就是大家长作风。\u003c/p\u003e\u003cp data-pid=\"oec7Ft-Z\"\u003e总之，在某些人眼里，胖东来就是万恶之源，他们早就想对他群起而攻之了。\u003c/p\u003e\u003cp data-pid=\"0vfLkf5n\"\u003e为什么他们会这么愤怒？据我看来，应该是因为胖东来有五大罪状。\u003c/p\u003e\u003cp data-pid=\"qByAsUhn\"\u003e第一大罪状，给员工分钱太多，严重扰乱了市场秩序。\u003c/p\u003e\u003cp data-pid=\"CP3TKGNR\"\u003e现在中国绝大多数小城市的超市，员工的工资都只有三四千，甚至某些小县城，员工的工资还停留在2000多块钱，就这么点收入，连生活都举步维艰，有什么幸福感可言？可你知道胖东来的员工工资有多高吗？\u003c/p\u003e\u003cp data-pid=\"Hw9nhh2i\"\u003e普通员工，月薪9800人民币，班长，一个月12000，课长19000，处长31000，店长更是达到了惊人的78000一个月的收入，可以毫不夸张的说，就胖东来这收入，放眼全球的超市，都算绝对的高收入群体。\u003c/p\u003e\u003cp data-pid=\"CB7HQv79\"\u003e之所以胖东来的员工能拿这么多钱，是因为于东来这么多年坚持把利润的95%都分给员工，自己永远只拿5%，所以才能撑起员工的高福利。\u003c/p\u003e\u003cp data-pid=\"5vE3qSqw\"\u003e对胖东来的员工而言，于东来就是衣食父母，是大恩人，可是对其他企业的老板而言，于东来就显得有点可恶了，因为他的存在，让其他的老板显得毫无格局，所以他们才会不停的对他进行攻击。\u003c/p\u003e\u003cp data-pid=\"Q9cPwlND\"\u003e第二大罪状，给员工的休息时间太长。\u003c/p\u003e\u003cp data-pid=\"R0p20ay4\"\u003e根据统计，胖东来的员工每年有假期150多天，部分管理人员甚至能达到180多天，基本相当于一年有一半左右的时间都在休息。\u003c/p\u003e\u003cp data-pid=\"sRF47ALr\"\u003e而且胖东来还严格执行的是五天八小时工作制，每周二必须强制闭店，有再多的钱也不赚，坚持要让员工养好身体。\u003c/p\u003e\u003cp data-pid=\"pEooAaUk\"\u003e更浮夸的是，胖东来竟然还有10天的不开心假，就是说如果你最新心情不好，比如说失恋了，自己喜欢的球队输球了，你可以直接向领导申请，休息十天再来上班，这个假期领导必须批准，否则于东来就会追责到底。\u003c/p\u003e\u003cp data-pid=\"1G00GO35\"\u003e之所以会给员工这么多的休息时间，于东来自己说得很清楚，他说：加班就是在占用别人成长的机会，剥夺别人的时间，是不道德的，人生不只是挣钱，还有生活，享受和娱乐。\u003c/p\u003e\u003cp data-pid=\"QjQgGRZG\"\u003e基于这个经营理念，哪怕胖东来再忙，于东来也要给员工充足的休息时间，因为他非常清楚，钱是赚不完的，如果一个企业眼里只有赚钱，那365天每天24小时待岗，你干到累死，老板都不会满足，因为人的贪欲是无穷无尽的。\u003c/p\u003e\u003cp data-pid=\"H3KV306d\"\u003e所以与其这样，倒还不如让员工好好休养，以更好的精神状态去工作。\u003c/p\u003e\u003cp data-pid=\"ro8MZ615\"\u003e于东来本身自己是个好心，但在其他老板看来，就不是那么多回事了，他们会说，你一年休180多天，你开个超市还搞五天八小时双休，那我这种996、007的公司算什么？这不纯纯就是小丑了，所以他们必须要针对胖东来。\u003c/p\u003e\u003cp data-pid=\"SwsoMnaG\"\u003e第三大罪状，对顾客太好。\u003c/p\u003e\u003cp data-pid=\"BsxjTNG2\"\u003e对于国内的很多老板来说，顾客是什么？答案是一个数字，是钞票，是行走的人民币，他们永远只关心如何让顾客心安理得的掏钱，所以所有的商业模式都是围绕这个核心目在进行的。\u003c/p\u003e\u003cp data-pid=\"mULFhd8q\"\u003e但是胖东来不一样，他是真的把顾客当家人，他给排队的顾客免费发水，用雨衣为顾客的电动车遮雨，他的橙子旁边会放着剥皮器，电子秤称重前是负数，连塑料袋都要去皮，绝对不占顾客一点便宜。\u003c/p\u003e\u003cp data-pid=\"lMSK220N\"\u003e还有胖东来的货架旁边，一定会有老花镜，就是为了方便老年人看清说明书。\u003c/p\u003e\u003cp data-pid=\"L-37mthk\"\u003e更离谱的是，在胖东来买榴莲，开肉太少还能直接换货，一直换到你满意为止，甚至就连看完电影不满意，都能退掉一半的票钱。\u003c/p\u003e\u003cp data-pid=\"OuGC0k-z\"\u003e最夸张的是之前的擀面皮事件，就因为有顾客反馈胖东来擀面皮的地方不够卫生，胖东来就直接赔偿了833.3万元人民币。\u003c/p\u003e\u003cp data-pid=\"2F1-yeCR\"\u003e用于东来自己的话说：他不想让顾客觉得自己没有良心。\u003c/p\u003e\u003cp data-pid=\"IS9DwLbv\"\u003e第四大罪状，胖东来不合群。\u003c/p\u003e\u003cp data-pid=\"BgP1LKfi\"\u003e今年于东来去参加一个会议，某家超市的高管说自己一个月可以赚200万的利润，听完这句话，于东来直接反问：月赚 200 万为什么不给员工涨工资？\u003cbr/\u003e听到这句话现场尴尬不已，因为不给员工涨工资的老板到处都是，你这样讲，是不是只会让自己格格不入？\u003c/p\u003e\u003cp data-pid=\"STqrN-N8\"\u003e第五大罪状，胖东来不上市。\u003c/p\u003e\u003cp data-pid=\"ysg1jjwG\"\u003e大家都知道，胖东来现在很赚钱，有很多资本都想入股分一比，可是于东来坚持不上市，不接受入股要求，时间久了，就会引起某些群体的怨恨。\u003c/p\u003e\u003cp data-pid=\"OS_jeWHN\"\u003e就是因为这“五大罪状”，所以才会有那么多的人一直想要整垮胖东来，因为只要胖东来倒下了，那以后所有人都是一样的工资水平，一样的工作时间了，没有了胖东来的对比，所有人都可以心安理得的走以前的老路，这就是为什么他们会发起围剿行动攻击胖东来的真正原因。\u003c/p\u003e\u003cp\u003e\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":259576,"favorite_count":808,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1904201445634474778}","attached_info":"CoIGCIrkppqf7/7pugEQBBoJNzI2NTg0MTUwIKvn9sAGKJ4iMLoEQEpKOAotVFNfU09VUkNFX0lOVEVSRVNUX1dPUkRfQ09OVEVOVF9WQUxVRV9MRVZFTF9DEgEwGAAgADoAWgkxMTQzMjI5NjdiIGFhN2QyMjRlMDZkNGIzMWI3NGY2NGQwODBkOWI3ZjU2chMxOTA0MjAxNDQ1NjM0NDc0Nzc4igETMTg5MTM5NDQyODUxOTgzNTQxM6oBCXJlY29tbWVuZMIBIGJlNDk5NjY0M2IwNGZkYThkZGMyZWMwOTQ4MGE3ZDU18gEKCAwSBk5vcm1hbPIBKAgKEiQ3ZGUwYTdmYS1mMTFjLTRiNWYtODMxMi1lZDU1YzdmNmNhMWLyAQYICxICMTOCAgCIAu7jx86FM5ICIGJlNDk5NjY0M2IwNGZkYThkZGMyZWMwOTQ4MGE3ZDU1mgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZcoCFENvbnRlbnRBZ2VXZWlnaHRSdWxl2gItVFNfU09VUkNFX0lOVEVSRVNUX1dPUkRfQ09OVEVOVF9WQUxVRV9MRVZFTF9D6AID+gILTk9STUFMX0ZMT1eKAyAwOTAxOGJkMzY2ZDA0ZDA1YTZlMTc3MWM2M2IwYWVjYpoDDQoCdjIQABoFb3RoZXKoA/jrD9gDAOoDKkludGVyZXN0V29yZENvbnRlbnRWYWx1ZUxldmVsQ1Bvb2xSZWNhbGxlcvoDHxIMVU5LTk9XTl9NT0RFIAAqDU5PX0lNQUdFX01PREWABACIBACSBAZOb3JtYWyaBAEzoAQAqAQAsAQAugQGbWFudWFswgQDMTYwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAACAp2+xP4EFAAAAAAAAAACJBQOJhAWjadM/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBQ2QBgCgBkqoBgCSAi4KCTcyNjU4NDE1MBITMTkwNDIwMTQ0NTYzNDQ3NDc3OBgEIgpJTUFHRV9URVhU","action_card":false},{"id":"75_1753853588.738","type":"feed","offset":75,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1753853588,"updated_time":1753853588,"target":{"id":"1892639264770073107","type":"answer","url":"https://api.zhihu.com/answers/1892639264770073107","author":{"id":"7d8f2efa2333945fd59972033e3e7495","url":"https://api.zhihu.com/people/7d8f2efa2333945fd59972033e3e7495","user_type":"people","url_token":"mike-fen-xing-ji-he-xue-xi-fa","name":"Mike-私域运营","headline":"专注于自创分形几何学习法、私域流量运营案例与实战分析","avatar_url":"https://picx.zhimg.com/50/v2-f3ce7016f2e03150ef89a637fe5f1020_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":182,"is_following":false,"is_followed":false},"created_time":1744020364,"updated_time":1744020364,"voteup_count":63,"thanks_count":4,"comment_count":0,"is_copyable":true,"question":{"id":"644741472","type":"question","url":"https://api.zhihu.com/questions/644741472","author":{"id":"60342b664bb6ee9927f5f17e64d57b97","url":"https://api.zhihu.com/people/60342b664bb6ee9927f5f17e64d57b97","user_type":"people","url_token":"9-72-84-39","name":"四点点雨","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-16ab40c35fc6bf3b7db4139edbefe964_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":81,"is_following":false,"is_followed":false},"title":"如何建立一个有效的知识库？","created":1708237379,"answer_count":0,"follower_count":0,"comment_count":1,"bound_topic_ids":[120,949,13349],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"thumbnail":"https://picx.zhimg.com/50/v2-7b0efa8f2af8796747acbb3438e867e4_720w.jpg?source=b6762063","excerpt":"一、对于知识库「有效性」的理解：建立有效的知识库，核心在于“有效”。 而「有效」我分为两种理解：一种是知识库对于「自身学习」的有效，二是知识库针对「自身工作」的有效。 前者主要是put in（输入），通过对外部学习资料的整理和吸收，而提高自身认知；   后者主要是put out（输出），通过对实际项目遇到的问题的解决，而获取相应收益。   二、针对知识库有效性的几个重要认知：1、资料的整理≠知识库曾经在很长一段时间，我将…","excerpt_new":"一、对于知识库「有效性」的理解：建立有效的知识库，核心在于“有效”。 而「有效」我分为两种理解：一种是知识库对于「自身学习」的有效，二是知识库针对「自身工作」的有效。 前者主要是put in（输入），通过对外部学习资料的整理和吸收，而提高自身认知；   后者主要是put out（输出），通过对实际项目遇到的问题的解决，而获取相应收益。   二、针对知识库有效性的几个重要认知：1、资料的整理≠知识库曾经在很长一段时间，我将…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp\u003e\u003c/p\u003e\u003ch2\u003e一\u003cb\u003e、对于知识库「有效性」的理解：\u003c/b\u003e\u003c/h2\u003e\u003cp data-pid=\"9JoTx8vb\"\u003e建立有效的知识库，核心在于“有效”。\u003c/p\u003e\u003cp data-pid=\"BghSUBuF\"\u003e而「有效」我分为两种理解：一种是知识库对于「自身学习」的有效，二是知识库针对「自身工作」的有效。\u003c/p\u003e\u003cp data-pid=\"MItF6NnJ\"\u003e前者主要是put in（输入），通过对外部学习资料的整理和吸收，而提高自身认知；\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-85046f9f2fa8170779995de1e5a0b9aa_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2868\" data-rawheight=\"1458\" data-original-token=\"v2-e52106329530208aae687493458d9b03\" data-default-watermark-src=\"https://pic1.zhimg.com/v2-f7f19fb1e9a6601fecb8dd112e8a1772_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"2868\" data-original=\"https://pica.zhimg.com/v2-85046f9f2fa8170779995de1e5a0b9aa_r.jpg\"/\u003e\u003cfigcaption\u003e元认知｜知识晶体的代表性知识类型\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"-wbkrq2P\"\u003e后者主要是put out（输出），通过对实际项目遇到的问题的解决，而获取相应收益。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-c7688cb56642dec50794cdb8350d7ffc_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2868\" data-rawheight=\"1494\" data-original-token=\"v2-ea77555b47dfe404e0ab78322dc9d1c1\" data-default-watermark-src=\"https://pic3.zhimg.com/v2-18df4b3852b7e0a3f86b7f44aa913aae_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"2868\" data-original=\"https://pic3.zhimg.com/v2-c7688cb56642dec50794cdb8350d7ffc_r.jpg\"/\u003e\u003cfigcaption\u003e让学员先见到收益（有效），然后再产生学习兴趣\u003c/figcaption\u003e\u003c/figure\u003e\u003chr/\u003e\u003ch2\u003e\u003cb\u003e二、针对知识库有效性的几个重要认知：\u003c/b\u003e\u003c/h2\u003e\u003ch3\u003e\u003cb\u003e1、资料的整理≠知识库\u003c/b\u003e\u003c/h3\u003e\u003cp data-pid=\"b8YjKjHh\"\u003e曾经在很长一段时间，我将知识或者信息错误地理解成了知识库，陷入到资料囤积的一种循环里，这样的信息大概整理过100T，但其中有95%以上的资料在整理好了以后，根本用不上，同时浪费了大量的时间和精力。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-8c74ed3b59d7f06b61e41f6820d51656_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1398\" data-rawheight=\"1080\" data-original-token=\"v2-788324c1dd82d2eb1253775fcdc8309d\" data-default-watermark-src=\"https://pica.zhimg.com/v2-4c1815a115e6ff1574562c7363a036dc_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1398\" data-original=\"https://pic3.zhimg.com/v2-8c74ed3b59d7f06b61e41f6820d51656_r.jpg\"/\u003e\u003cfigcaption\u003e整理资料走过的弯路\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3\u003e\u003cb\u003e2、刷题的数量≠公式的掌握\u003c/b\u003e\u003c/h3\u003e\u003cp data-pid=\"XuYXSQsM\"\u003e数字化资料的唾手可得以及人工智能的兴起，使得资料的获取由原来的以G为单位，变成了以T为变单位，但对于知识库的有效性的理解不对，整理再多的资料都是无用的，只是用勤奋的战术掩盖了战略上的懒惰。所以，知识库的有效性应该是秉持一份“万能公式”，而不是捧着“三年高考五年模拟”而不断刷题，\u003cb\u003e因为每个人的时间和精力是有限的，而且是极其有限。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e\u003cb\u003e3、工具的先进性≠知识库的有效性\u003c/b\u003e\u003c/h3\u003e\u003cp data-pid=\"EK8Tuz_r\"\u003e工具的先进性在某种程度上来说是提高了资料与知识的整理的效率，但效率的提升，会造成一种错误的结果：即整理了更多低效或者错误的资料。\u003c/p\u003e\u003cp data-pid=\"ar9ebVU-\"\u003e首先，方向的正确性是第一要务，其次才是工具所带来效率的提升，如果方向不对，效率越高，损失越大。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-9a0c2ada4915ce7d9a5bcd25a41426cb_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2278\" data-rawheight=\"1306\" data-original-token=\"v2-c17a8dac2ba80babb2c540031c409e7b\" data-default-watermark-src=\"https://picx.zhimg.com/v2-a469bddf249ee5f80757833c3b3131d5_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"2278\" data-original=\"https://picx.zhimg.com/v2-9a0c2ada4915ce7d9a5bcd25a41426cb_r.jpg\"/\u003e\u003cfigcaption\u003e方向不对，效率越高，伤害越大\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3\u003e\u003cb\u003e4、方法越简单，知识库越有效\u003c/b\u003e\u003c/h3\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-ed646bf54523d83d4f7f6bc108f7c25c_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1546\" data-rawheight=\"590\" data-original-token=\"v2-0a19f375b02e87da3f6bac0a6be66ed5\" data-default-watermark-src=\"https://pic2.zhimg.com/v2-431fe8b04a5705bb533679342ff487ab_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1546\" data-original=\"https://pic3.zhimg.com/v2-ed646bf54523d83d4f7f6bc108f7c25c_r.jpg\"/\u003e\u003cfigcaption\u003e对于简单规则的认知\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"IpIlbhCg\"\u003e曾经在很长一段时间，我花费巨资以及浏览于各类知识付费平台，学习了各种理论以及方法论，但是每当遇到实际的问题却很难找到对应的模型和知识能够完全“适配”，也通过各种工具以及软件来去代替自己的思路，忽略了对自身认知和项目的理解深度，直到经过长期的思考之后，我在分形几何中探索出了一套“分形几何学习法”，用数学与逻辑推理的能力去拆解遇到的问题，发现除非必要，绝大部分的问题都可以通过对于简单规则的多次重复而解决。\u003c/p\u003e\u003cp data-pid=\"1Ws60gGi\"\u003e因为简单，所以更容易形成标准化，因为简单，所以随着时间的推进与人员的增长，也可以做到执行不走样。\u003c/p\u003e\u003cp data-pid=\"PWi6YxsW\"\u003e\u003cb\u003e抛弃对于复杂工具的依赖以及对于人工智能的迷信，用简单的规则的重复，是知识库有效性无限增长的必要条件。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e\u003cb\u003e5、以人为本，以终为始\u003c/b\u003e\u003c/h3\u003e\u003cp data-pid=\"CqCRF_oG\"\u003e所有的文件以及产业、项目的发展最终都会回归到“以人为本”的核心理念，同样的，知识库的有效性必须建立在“满足人的需求”的基础之上，本人在以往的公司合营以及项目合作过程中，都有一个习惯，就是站在旁观者的角度去审视对方的需求，而不是将自己的产品与服务销售给对方，世间存在万能公式，但是万能公式的使用需要在特定的条件内进行。\u003c/p\u003e\u003cp data-pid=\"bgNFijJg\"\u003e针对此次知识库的建立，我分为五步来进行设计：\u003c/p\u003e\u003cp data-pid=\"8RXaXTTS\"\u003e\u003cb\u003e（1）首先，要明确合作与建立知识库的人属于哪一类？\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"Wf748z2a\"\u003e针对合作的超级个体，知识库的建立我认为合作的人和项目一般分为三类人群：专才、全才、通才。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-837d5cd3c7f7d12747fc2f33dbf60a6e_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2856\" data-rawheight=\"1534\" data-original-token=\"v2-7d9abb6b8bc0a59f284645a3bf6a67f7\" data-default-watermark-src=\"https://pic2.zhimg.com/v2-fd7e367466d58d67b6a4f9993f9d98eb_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"2856\" data-original=\"https://pic1.zhimg.com/v2-837d5cd3c7f7d12747fc2f33dbf60a6e_r.jpg\"/\u003e\u003cfigcaption\u003e分形几何学习法中三类超级个体的“结构”与特征\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"ARje6VFx\"\u003e\u003cb\u003e（2）其次， 建立基于真实需求基础上的「专属资源（料）库」\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"viuKV5jj\"\u003e为每一个合作伙伴建立专属的资料库，保持所有人员的知识库的“边界性”。这个是避免知识库混淆的一个基本条件。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-e9ba27436f1ce767b27cf78907246429_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1702\" data-rawheight=\"1098\" data-original-token=\"v2-0732e494b5ee54020057af60632e7db7\" data-default-watermark-src=\"https://pica.zhimg.com/v2-fea686b29099d34afa7816da8bb46ccc_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1702\" data-original=\"https://pic2.zhimg.com/v2-e9ba27436f1ce767b27cf78907246429_r.jpg\"/\u003e\u003cfigcaption\u003e已有71名合伙伙伴或学员专属「资料库」\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"PLS9ZI5W\"\u003e\u003cb\u003e（3）创建知识库的「骨架」，确保现有知识库的有效，且可复用「已有先人」的知识库沉淀。\u003c/b\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-e34d403f85d674403b76508d059234c2_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2866\" data-rawheight=\"1510\" data-original-token=\"v2-74f87e93af610e143c97cb164491ba0c\" data-default-watermark-src=\"https://pic3.zhimg.com/v2-4916a65e3016f11d2b2be551d1999d52_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"2866\" data-original=\"https://pic3.zhimg.com/v2-e34d403f85d674403b76508d059234c2_r.jpg\"/\u003e\u003cfigcaption\u003e前、中、后ERM管理架构\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-c7d583607a60ffff2849c87d490b9849_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2120\" data-rawheight=\"600\" data-original-token=\"v2-d8cc1389edee8c730d61317f91fae17a\" data-default-watermark-src=\"https://pica.zhimg.com/v2-526679af3092462862a03e193b3e8ee2_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"2120\" data-original=\"https://picx.zhimg.com/v2-c7d583607a60ffff2849c87d490b9849_r.jpg\"/\u003e\u003cfigcaption\u003e将「知识模块化」具象化\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"VNQ_gilQ\"\u003e有了骨架以后，将相应知识模块具象化，然后针对个人实际情况，不断填充相应知识，逐步实现知识库的内容。\u003c/p\u003e\u003cp data-pid=\"RT8rll42\"\u003e\u003cb\u003e（4）针对现实情况进行填充资料的「筛选」与「填充」。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"v06gqpZI\"\u003e针对put in（输入）的资料填充，我在结合了上百个实操项目经验之后，做了两步：一是知识的分类，只分为三类，三类知识特征如下所示。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-f67ff3f789f5a7457dac76c7b49aa3d1_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2862\" data-rawheight=\"1490\" data-original-token=\"v2-705ce90ede0e5f620c33680f986888b7\" data-default-watermark-src=\"https://pica.zhimg.com/v2-bc0f473bfab194fc4030b28957dd3396_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"2862\" data-original=\"https://pic2.zhimg.com/v2-f67ff3f789f5a7457dac76c7b49aa3d1_r.jpg\"/\u003e\u003cfigcaption\u003e显性知识、隐性知识与默会知识特征与表现\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"7pezJOA4\"\u003e二是针对各类信息与知识，做了一个基于实战需要下的分层与分级。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-53fcf3c20953f2160dea257ae3195f11_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2878\" data-rawheight=\"1524\" data-original-token=\"v2-2a10aad315ffe357ef56488eefaada99\" data-default-watermark-src=\"https://pica.zhimg.com/v2-f3a0bb255e367612c7e9efbfb486910c_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"2878\" data-original=\"https://pic2.zhimg.com/v2-53fcf3c20953f2160dea257ae3195f11_r.jpg\"/\u003e\u003cfigcaption\u003e知识类型应用于实战时所需要进行的决策与遵循梯度\u003c/figcaption\u003e\u003c/figure\u003e\u003chr/\u003e\u003ch2\u003e\u003cb\u003e三、基于实战与项目需要，知识库所产生的指数级价值与增长\u003c/b\u003e\u003c/h2\u003e\u003cp data-pid=\"DLmSGae8\"\u003e在明确的基本的知识库「骨架」与资源积累后，会建立基于实战的公司组织架构与团队成员模式，以上ERM管理中台为例，针对互联网各类服务，创建了相应的308个互联网团队。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-46a86d76e56225546d1b854b4ac231db_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1936\" data-rawheight=\"1272\" data-original-token=\"v2-35c6a8bb3d58b1fb000724d929c72a05\" data-default-watermark-src=\"https://pic3.zhimg.com/v2-a68767bb126099e6331af3137b98c714_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1936\" data-original=\"https://pic4.zhimg.com/v2-46a86d76e56225546d1b854b4ac231db_r.jpg\"/\u003e\u003cfigcaption\u003e互联网+服务商资料库\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"DIs0I-3J\"\u003e将这308个服务商团队进行统计后，可形成完成以下互联网服务清单。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-994e2d597b0dd5fe450c4639c5795042_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1500\" data-rawheight=\"1220\" data-original-token=\"v2-a1eddaa07daf3b7d3240f8947b21d5ef\" data-default-watermark-src=\"https://pic3.zhimg.com/v2-bb06c00183751d7a348840c01ca4c2c2_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1500\" data-original=\"https://pic3.zhimg.com/v2-994e2d597b0dd5fe450c4639c5795042_r.jpg\"/\u003e\u003cfigcaption\u003e服务商相应服务清单\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"YWwvS-wR\"\u003e而这些即是「供给」，因为有了「供给」才能满足「需求」，只有这样的「知识库」我认为有是有效的，当我从大学毕业的第一天开始，我就认为，\u003cb\u003e凡是不能产生商业价值的知识库都是无效的知识库。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"pt_zwTGF\"\u003e\u003cb\u003e同理可得，基于医疗服务的一个学员知识库我是这样建立的。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e\u003cb\u003e1、建立ERM中台；\u003c/b\u003e\u003c/h3\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-a8b0aba7330898478a7fb0eec0ef9858_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1076\" data-rawheight=\"684\" data-original-token=\"v2-86575b05afd2054c5d614aa07643e5af\" data-default-watermark-src=\"https://pic4.zhimg.com/v2-4a3d74f07e2aaad0cd28b23871ecb5e3_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1076\" data-original=\"https://pic1.zhimg.com/v2-a8b0aba7330898478a7fb0eec0ef9858_r.jpg\"/\u003e\u003cfigcaption\u003e同一模型下的知识模块分解文件夹\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-446cc50317844e8a651a62ff1aa320d6_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1420\" data-rawheight=\"984\" data-original-token=\"v2-b9cbaf7f5619d1b757497dd9416cdd49\" data-default-watermark-src=\"https://pic2.zhimg.com/v2-bce7fb2e176f0a7c476ae2239f294417_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1420\" data-original=\"https://pic1.zhimg.com/v2-446cc50317844e8a651a62ff1aa320d6_r.jpg\"/\u003e\u003cfigcaption\u003e服务商两大类，第1-100为医疗服务商，101-200是保险类服务商\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"TwrnSaWc\"\u003e其中，以上服务商统一隶属模块「12｜4-1、合作服务商库」；\u003c/p\u003e\u003ch3\u003e\u003cb\u003e2、建立公司组织形式下的「主体」；\u003c/b\u003e\u003c/h3\u003e\u003cp data-pid=\"licxVAtk\"\u003e这一块主要以公司形式存在。\u003c/p\u003e\u003ch3\u003e\u003cb\u003e3、建立线上沟通平台，完成需求匹配与服务的交付，赚取相应利润；\u003c/b\u003e\u003c/h3\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-75a453b325f11d02d44207f3e8eedb5f_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2120\" data-rawheight=\"736\" data-original-token=\"v2-aa7642d77c352767e3e4d971036c969c\" data-default-watermark-src=\"https://pic4.zhimg.com/v2-bd37c1bf963b6916cc0291f7b7864fe9_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"2120\" data-original=\"https://pic2.zhimg.com/v2-75a453b325f11d02d44207f3e8eedb5f_r.jpg\"/\u003e\u003cfigcaption\u003e公司架构下的社交化媒体建立架构\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-a8a74db4d77914c547e0e07192a156d6_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"630\" data-rawheight=\"1044\" data-original-token=\"v2-2701a406632a6d33e3870e6a3246c77f\" data-default-watermark-src=\"https://pica.zhimg.com/v2-d61556adb106861760cc44d381c8fa7c_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"630\" data-original=\"https://pica.zhimg.com/v2-a8a74db4d77914c547e0e07192a156d6_r.jpg\"/\u003e\u003cfigcaption\u003e相应服务商所在管理群显示效果\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"E-LpQkZY\"\u003e编号原则：「12」隶属服务商所在知识模块编号，「-n」隶属相应服务商库相应编号。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-f861603af1949228b5b50c6d4e7bff33_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"502\" data-rawheight=\"958\" data-original-token=\"v2-a3566530f24972045da378c0268600b8\" data-default-watermark-src=\"https://pic1.zhimg.com/v2-e624d0b9e81e6f146af5f294fa975876_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"502\" data-original=\"https://picx.zhimg.com/v2-f861603af1949228b5b50c6d4e7bff33_r.jpg\"/\u003e\u003cfigcaption\u003e会员所在「服务」群以及显示效果\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"rYrbQNLT\"\u003e\u003cb\u003e而针对「知识库」与企业经营的联动的创建原则，我总结了4个：\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"diijYNTN\"\u003e原则1:从阻力最小的角度切入；\u003c/p\u003e\u003cp data-pid=\"aGGLsgqF\"\u003e原则2:从最能契合项目发展的资源切入；\u003c/p\u003e\u003cp data-pid=\"fcaJO_5H\"\u003e原则3:从有过成交经历的客户合作开始；\u003c/p\u003e\u003cp data-pid=\"CDyXO4x4\"\u003e原则4:从小体量的成交开始合作；\u003c/p\u003e\u003cp data-pid=\"KOk-cW5h\"\u003e总结，从容易的先开展合作；\u003c/p\u003e\u003cp data-pid=\"MEM_ynAA\"\u003e\u003cb\u003e其次，也总结从「知识库建立」→「有效变现」的四个原则：\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"wkSdy9MX\"\u003e原则1:不要为了学习而学习；\u003c/p\u003e\u003cp data-pid=\"Mw8EJSru\"\u003e原则2:不要为了整理资料而整理资料；\u003c/p\u003e\u003cp data-pid=\"nvjoeXKq\"\u003e原则3:不要贪大求全；\u003c/p\u003e\u003cp data-pid=\"x3RWqodq\"\u003e原则4:干中学。\u003c/p\u003e\u003chr/\u003e\u003ch2\u003e四、万能公式的普遍适用性\u003c/h2\u003e\u003ch3\u003e1、已操盘或从事的行业经验\u003c/h3\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-13841f78f59b552ada546d46e91ffe63_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2844\" data-rawheight=\"1528\" data-original-token=\"v2-327bbd3b8ef4043a566040dd838ca63c\" data-default-watermark-src=\"https://pic4.zhimg.com/v2-3bda0159c54e3625f80a7d35fae38427_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"2844\" data-original=\"https://picx.zhimg.com/v2-13841f78f59b552ada546d46e91ffe63_r.jpg\"/\u003e\u003cfigcaption\u003e已从事行业或项目\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3\u003e2、基于分形几何学习法所建立的平台与项目的双反馈机制\u003c/h3\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-38951f3f30a94ea3f45a8716b4bb1efc_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2848\" data-rawheight=\"1472\" data-original-token=\"v2-94920986febe4c018e96e9944cfbfaac\" data-default-watermark-src=\"https://pic4.zhimg.com/v2-a90dd05fb9245757334953badd9ff3a5_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"2848\" data-original=\"https://pic3.zhimg.com/v2-38951f3f30a94ea3f45a8716b4bb1efc_r.jpg\"/\u003e\u003cfigcaption\u003e双平台互反馈机制\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"WcLNfaMS\"\u003e更多的分享可跳转至本人专栏进行学习，有想要获取「模块」化文件夹的也可以交流。\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":true,"visited_count":3230,"thumbnails":["https://pic1.zhimg.com/50/v2-7b0efa8f2af8796747acbb3438e867e4_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-ae76cd46126e299232dcdcf43f2c97d8_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-4d02c20a32dd33da0917b0e047ec64d0_720w.jpg?source=b6762063","https://pica.zhimg.com/50/v2-899c6421db6a77bfb273904909b04998_720w.jpg?source=b6762063","https://pica.zhimg.com/50/v2-d1df8d34ea5927b1faf15a638da6a8fc_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-7a1553c758522d42e5168a874faca8db_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-69409dac58b6da29d7c73a970f6550a3_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-fed1b351fc443779fdcbfcae8bbfa64c_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-1696b462a61c88ff6d25957b91c88bfd_720w.jpg?source=b6762063","https://pica.zhimg.com/50/v2-a94413a176af3469945b602ec145781c_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-d939c58e0b4e426cb18d17ba274253e7_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-b71f38a6995632dd53a65b1fabe1bab1_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-da7942a4522d3a6132b6847a310b163f_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-fd9d80471e6189f35db5b2056a810811_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-16d63c7b6ba9d5c973fd1fbc96b2e5e4_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-25a61509fc324e3d8dffac8d82c1f080_720w.jpg?source=b6762063"],"favorite_count":287,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1892639264770073107}","attached_info":"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","action_card":false},{"id":"76_1753853588.381","type":"feed","offset":76,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1753853588,"updated_time":1753853588,"target":{"id":"1933851430164345242","type":"answer","url":"https://api.zhihu.com/answers/1933851430164345242","author":{"id":"61f33bd2ae8d851010223580eab4f738","url":"https://api.zhihu.com/people/61f33bd2ae8d851010223580eab4f738","user_type":"people","url_token":"bytearch","name":"智能笔尖","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-9ab04abf354ae2f316c3879e281ede36_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":141,"is_following":false,"is_followed":false},"created_time":1753846110,"updated_time":1753846110,"voteup_count":0,"thanks_count":0,"comment_count":0,"is_copyable":true,"question":{"id":"22613456","type":"question","url":"https://api.zhihu.com/questions/22613456","author":{"id":"2f79578de0aaa50e44899ee4e7f17b2a","url":"https://api.zhihu.com/people/2f79578de0aaa50e44899ee4e7f17b2a","user_type":"people","url_token":"xu-fei-2-94","name":"三只眼睛","headline":"","avatar_url":"https://pic1.zhimg.com/50/2ecc6c745_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":1069,"is_following":false,"is_followed":false},"title":"如何通过写作赚钱？","created":1390796478,"answer_count":0,"follower_count":0,"comment_count":13,"bound_topic_ids":[18531,566823,637154],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"见字如面，我是墨云。 昨天有位粉丝朋友发消息问我： \"墨云，为什么我的公众号写了半年，还是没什么起色？\" 她说自己每天都在坚持更新，也学了很多课程，但阅读量就是上不去。 我让她把号发给我看了看。 头像模糊，名字随意，内容东拼西凑... 一眼看过去，完全不知道这是做什么的号。 这就是90%新手的通病。今天这篇文章，我要把一个在鹅厂工作的朋友，私下分享给我的公众号涨粉密码全部告诉你。 这套方法，我用在3月8号注册的新…","excerpt_new":"见字如面，我是墨云。 昨天有位粉丝朋友发消息问我： \"墨云，为什么我的公众号写了半年，还是没什么起色？\" 她说自己每天都在坚持更新，也学了很多课程，但阅读量就是上不去。 我让她把号发给我看了看。 头像模糊，名字随意，内容东拼西凑... 一眼看过去，完全不知道这是做什么的号。 这就是90%新手的通病。今天这篇文章，我要把一个在鹅厂工作的朋友，私下分享给我的公众号涨粉密码全部告诉你。 这套方法，我用在3月8号注册的新…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"txm1MFRY\"\u003e见字如面，我是墨云。\u003c/p\u003e\u003cp data-pid=\"_LrYv6uW\"\u003e昨天有位粉丝朋友发消息问我：\u003c/p\u003e\u003cp data-pid=\"T0H_vgOz\"\u003e\u0026#34;墨云，为什么我的公众号写了半年，还是没什么起色？\u0026#34;\u003c/p\u003e\u003cp data-pid=\"mu8VrFPv\"\u003e她说自己每天都在坚持更新，也学了很多课程，但阅读量就是上不去。\u003c/p\u003e\u003cp data-pid=\"17Cry74R\"\u003e我让她把号发给我看了看。\u003c/p\u003e\u003cp data-pid=\"GddOKlw_\"\u003e头像模糊，名字随意，内容东拼西凑...\u003c/p\u003e\u003cp data-pid=\"kFG5CPBc\"\u003e一眼看过去，完全不知道这是做什么的号。\u003c/p\u003e\u003cp data-pid=\"chR9vbTu\"\u003e\u003cb\u003e这就是90%新手的通病。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"jVBATrTK\"\u003e今天这篇文章，我要把一个在鹅厂工作的朋友，私下分享给我的公众号涨粉密码全部告诉你。\u003c/p\u003e\u003cp data-pid=\"kYou8ojN\"\u003e这套方法，我用在3月8号注册的新号上，从零粉丝做到现在每篇20万阅读。\u003c/p\u003e\u003cp data-pid=\"66aVhhuA\"\u003e\u003cb\u003e没有任何外部推广，没有刷粉，纯靠系统推荐。\u003c/b\u003e\u003c/p\u003e\u003ch2\u003e一、框架思维，90%的人第一步就错了\u003c/h2\u003e\u003cp data-pid=\"UgAudRk0\"\u003e做公众号最致命的错误是什么？\u003c/p\u003e\u003cp data-pid=\"c6Cuikvu\"\u003e\u003cb\u003e没有框架思维。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"Ek1bYYXs\"\u003e很多人一上来就急着写文章，头像随便找一个，名字想到什么写什么，介绍也是敷衍了事。\u003c/p\u003e\u003cp data-pid=\"xYyGycmE\"\u003e这就像你开了个店，门头破破烂烂，招牌看不清，顾客路过都不知道你是卖什么的。\u003c/p\u003e\u003cp data-pid=\"dP9XXk-q\"\u003e\u003cb\u003e腾讯的算法第一眼看的就是你的框架。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"4rU9uoUb\"\u003e我那个朋友告诉我，腾讯内部有个说法：\u003c/p\u003e\u003cp data-pid=\"o_UbCjdg\"\u003e\u0026#34;框架不对，神仙难救。\u0026#34;\u003c/p\u003e\u003cp data-pid=\"7dNr2a4r\"\u003e什么叫框架？\u003c/p\u003e\u003cp data-pid=\"uYmy6_1Y\"\u003e\u003cb\u003e头像 + 名称 + 介绍 + 内容 = 统一的IP形象\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"uBQn61Pf\"\u003e这四个要素必须高度一致，缺一不可。\u003c/p\u003e\u003cp data-pid=\"JezHz-XO\"\u003e你看九图老师的号，一眼就知道是做酒类内容的。\u003c/p\u003e\u003cp data-pid=\"QzHSbXc4\"\u003e你看一姐的号，定位清晰，专业感十足。\u003c/p\u003e\u003cp data-pid=\"LOLmZ6-8\"\u003e\u003cb\u003e这就是框架的力量。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"f5WdVe2G\"\u003e但很多人做不到统一。\u003c/p\u003e\u003cp data-pid=\"DaQqyqy8\"\u003e头像是风景照，名字叫\u0026#34;爱哭的猫\u0026#34;，内容写的是职场干货...\u003c/p\u003e\u003cp data-pid=\"wmpMGPig\"\u003e平台都迷路了，不知道把你推给谁。\u003c/p\u003e\u003cp data-pid=\"-0m1jSMW\"\u003e\u003cb\u003e记住这个公式：\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"STchkgwQ\"\u003e专业头像 + 真实姓名艺名 + 精准定位 + 垂直内容 = 高权重账号\u003c/p\u003e\u003ch3\u003e取名的学问\u003c/h3\u003e\u003cp data-pid=\"Lgp-liRE\"\u003e很多人喜欢取\u0026#34;小仙女\u0026#34;、\u0026#34;可爱的狗\u0026#34;这种网名。\u003c/p\u003e\u003cp data-pid=\"Kn-JI5Ps\"\u003e\u003cb\u003e一看就不专业。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"BGzUBPvb\"\u003e正确的取名方式：\u003c/p\u003e\u003cp data-pid=\"PF30cYGt\"\u003e\u003cb\u003e姓氏 + 知性名字\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"KCkPPwmz\"\u003e比如：李知秋、王雅文、张慧心...\u003c/p\u003e\u003cp data-pid=\"Ag7ZaeQt\"\u003e让别人觉得你是公司请来的专业写手。\u003c/p\u003e\u003cp data-pid=\"RSvxP9Oh\"\u003e\u003cb\u003e这是体现专业性的第一步。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e人设的威力\u003c/h3\u003e\u003cp data-pid=\"vz0LT-CL\"\u003e你不只是在写文章，你是在塑造一个人。\u003c/p\u003e\u003cp data-pid=\"P3jw6bUv\"\u003e\u003cb\u003e每次读者看到你的名字，都在加深对你的印象。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"9Ws40prJ\"\u003e所以每篇文章开头，都要强化你的人设：\u003c/p\u003e\u003cp data-pid=\"uSeSeZCI\"\u003e\u0026#34;大家好，我是李知秋，一个专注职场成长10年的资深HR。\u0026#34;\u003c/p\u003e\u003cp data-pid=\"DlWTbXqF\"\u003e\u003cb\u003e重复，重复，再重复。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"v-2cht2p\"\u003e直到读者闭着眼睛都能想起你是谁。\u003c/p\u003e\u003ch2\u003e二、平台属性，破解流量分发密码\u003c/h2\u003e\u003cp data-pid=\"a0Us0dFt\"\u003e很多人不理解一个现象：\u003c/p\u003e\u003cp data-pid=\"ukq7ROn2\"\u003e为什么这篇文章突然爆了，下一篇又跌回谷底？\u003c/p\u003e\u003cp data-pid=\"e9gMH-Rl\"\u003e\u003cb\u003e答案很简单：你不懂平台属性。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"gKTE55a0\"\u003e腾讯现在要和小红书、今日头条抢高端用户。\u003c/p\u003e\u003cp data-pid=\"FPvfwfaK\"\u003e注意，是高端用户。\u003c/p\u003e\u003cp data-pid=\"Nu-RJylF\"\u003e\u003cb\u003e低端流量，他们不要。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"vmoc0tQi\"\u003e所以平台制定了三大评判标准：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"SY9y5xFQ\"\u003e\u003cb\u003e头像要符合名称\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"AnGyp5-4\"\u003e\u003cb\u003e名称要符合内容\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"zEOph5c4\"\u003e\u003cb\u003e内容要保持垂直\u003c/b\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"670pXe5h\"\u003e这三点必须高度一致。\u003c/p\u003e\u003cp data-pid=\"PBCph4NP\"\u003e如果你是美容博主，就要在文章中经常出现\u0026#34;美容\u0026#34;、\u0026#34;护肤\u0026#34;、\u0026#34;保养\u0026#34;这些关键词。\u003c/p\u003e\u003cp data-pid=\"c_xe9xGw\"\u003e\u003cb\u003e不是在标签里打，是在正文里写。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"HpKUyOi9\"\u003e因为1000万阅读量以下的账号，都是机器人在审核。\u003c/p\u003e\u003cp data-pid=\"Rv2zeL5G\"\u003e机器人靠什么判断你的内容？\u003c/p\u003e\u003cp data-pid=\"L2noP_5H\"\u003e\u003cb\u003e靠关键词频率。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"UXyqXOrJ\"\u003e你在文章中反复提到\u0026#34;美容\u0026#34;，机器人就会给你打上美容标签。\u003c/p\u003e\u003cp data-pid=\"JXiy09J5\"\u003e然后把你推荐给同样关注美容的用户。\u003c/p\u003e\u003cp data-pid=\"doX46y8f\"\u003e\u003cb\u003e这就是获得精准流量的核心机制。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e隐形限流的真相\u003c/h3\u003e\u003cp data-pid=\"DuSfOhHQ\"\u003e很多人会遇到隐形限流，自己还不知道。\u003c/p\u003e\u003cp data-pid=\"jRm4Oc_l\"\u003e腾讯不会通知你，但会悄悄降低你的推荐权重。\u003c/p\u003e\u003cp data-pid=\"QAHb06Lu\"\u003e\u003cb\u003e隐形限流的四大原因：\u003c/b\u003e\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"Ta5-aRFO\"\u003e\u003cb\u003e伪原创被识别\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"23S-Ujhg\"\u003e\u003cb\u003e被用户举报\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"nWNsnjJu\"\u003e\u003cb\u003e框架不一致\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"b_aVDamz\"\u003e\u003cb\u003e标题与内容不匹配\u003c/b\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"coM6hy9L\"\u003e最要命的是第一点。\u003c/p\u003e\u003cp data-pid=\"NrnIINPu\"\u003e现在很多人写文章，都是东拼西凑。\u003c/p\u003e\u003cp data-pid=\"M5JRk-cs\"\u003e从这个号抄一段，从那个号抄一段，以为改几个字就是原创了。\u003c/p\u003e\u003cp data-pid=\"vCT6bYMy\"\u003e\u003cb\u003e大错特错。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"owXrCjie\"\u003e腾讯的算法已经进化到可以识别编码。\u003c/p\u003e\u003cp data-pid=\"uJCHfbHM\"\u003e如果你直接从其他公众号复制内容，哪怕改了文字，编码还是会被识别。\u003c/p\u003e\u003cp data-pid=\"Du53KNfY\"\u003e\u003cb\u003e正确的做法是：\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"_yC9zgEg\"\u003e先把内容复制到微信，再发给自己，然后从微信复制到编辑器。\u003c/p\u003e\u003cp data-pid=\"GNYLMz3n\"\u003e这样可以清除原有编码，避免被识别为抄袭。\u003c/p\u003e\u003ch3\u003e千万不要人工干预\u003c/h3\u003e\u003cp data-pid=\"_1gWhC10\"\u003e很多新手有个坏习惯：\u003c/p\u003e\u003cp data-pid=\"6gQOmVEO\"\u003e文章发出去没人看，就找朋友帮忙分享。\u003c/p\u003e\u003cp data-pid=\"CkQC3f11\"\u003e\u003cb\u003e这是最蠢的做法。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"430Rg6U_\"\u003e现在的公众号已经不是靠人工传播的时代了。\u003c/p\u003e\u003cp data-pid=\"a9v75BD5\"\u003e\u003cb\u003e它是流量池机制。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"Y0NLAMG0\"\u003e如果你的文章是通过朋友分享获得阅读量，平台会判定为人工传播。\u003c/p\u003e\u003cp data-pid=\"Os0W2IYs\"\u003e\u003cb\u003e结果就是永远进不了推荐池。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"UYk1WVem\"\u003e正确的做法是：\u003c/p\u003e\u003cp data-pid=\"n0J7NTuZ\"\u003e让文章自然跑，哪怕刚开始只有几十个阅读也没关系。\u003c/p\u003e\u003cp data-pid=\"Z1KliAOe\"\u003e\u003cb\u003e只要质量过关，平台一定会给你流量。\u003c/b\u003e\u003c/p\u003e\u003ch2\u003e三、标题密码，流量推荐的入场券\u003c/h2\u003e\u003cp data-pid=\"3kRoNZcc\"\u003e再好的内容，没有好标题也白搭。\u003c/p\u003e\u003cp data-pid=\"QrHQU3Y0\"\u003e\u003cb\u003e标题就是平台流量推荐的入场券。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"Qmn9KvJ0\"\u003e大部分人死在这一关。\u003c/p\u003e\u003cp data-pid=\"Ym_48qZS\"\u003e我总结了一个标题公式，屡试不爽：\u003c/p\u003e\u003cp data-pid=\"vSbdxsAT\"\u003e\u003cb\u003e为什么 + 原来这样 + 哦我懂了\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e为什么句式\u003c/h3\u003e\u003cp data-pid=\"S8u_u8-j\"\u003e人天生对\u0026#34;为什么\u0026#34;好奇。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"OfBLCC5f\"\u003e为什么茅台的香能抓住大部分人的嗅觉？\u003c/li\u003e\u003cli data-pid=\"bRnYBQNg\"\u003e为什么美女在骨不在皮？\u003c/li\u003e\u003cli data-pid=\"nDzskwwP\"\u003e为什么真丝会缩水，但还有那么多人买？\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"jGkB6JQj\"\u003e\u003cb\u003e\u0026#34;为什么\u0026#34;三个字，就是好奇心的钩子。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e原来这样句式\u003c/h3\u003e\u003cp data-pid=\"HptQf1Bh\"\u003e给人一种你知道答案的感觉。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"noBfOOvz\"\u003e真丝缩水问题，原来这样可以快速解决\u003c/li\u003e\u003cli data-pid=\"e0Rh6R98\"\u003e茅台为什么这么香？原来是因为这个工艺\u003c/li\u003e\u003cli data-pid=\"m5JNegEe\"\u003e职场晋升的秘密，原来高手都在用这招\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"Ddtiu-i9\"\u003e\u003cb\u003e\u0026#34;原来\u0026#34;二字，暗示你有独特见解。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e哦我懂了句式\u003c/h3\u003e\u003cp data-pid=\"Uqi1a0bL\"\u003e让读者产生恍然大悟的感觉。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"tEVAU0_T\"\u003e哦我懂了，为什么茅台能做到人人都爱\u003c/li\u003e\u003cli data-pid=\"ODJbMO4P\"\u003e哦我懂了，原来职场高手都是这样思考的\u003c/li\u003e\u003cli data-pid=\"3mJUQ1s6\"\u003e哦我懂了，这就是顶级销售的底层逻辑\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"HUXhMxvc\"\u003e\u003cb\u003e这三个句式可以组合使用，威力翻倍。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"0Y4SkWh9\"\u003e但记住一点：\u003c/p\u003e\u003cp data-pid=\"0xVvVB15\"\u003e\u003cb\u003e标题必须和你的定位匹配。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"uNfj6eeG\"\u003e你是美容博主，就不要写理财标题。\u003c/p\u003e\u003cp data-pid=\"pJXVD8ls\"\u003e你是职场号，就不要蹭娱乐热点。\u003c/p\u003e\u003cp data-pid=\"6v8gOcJ0\"\u003e\u003cb\u003e垂直，垂直，还是垂直。\u003c/b\u003e\u003c/p\u003e\u003ch2\u003e四、内容为王，情绪价值才是核心\u003c/h2\u003e\u003cp data-pid=\"V1_8o4kr\"\u003e什么样的文章容易爆？\u003c/p\u003e\u003cp data-pid=\"F1iolweI\"\u003e\u003cb\u003e能提供情绪价值的文章。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"4NKxA14t\"\u003e不是你的观点有多深刻，不是你的逻辑有多严密。\u003c/p\u003e\u003cp data-pid=\"M_Wignii\"\u003e\u003cb\u003e而是能否引起读者的情绪共鸣。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"Ry3HTnJ3\"\u003e可能是认同，可能是愤怒，可能是感动，也可能是争议。\u003c/p\u003e\u003cp data-pid=\"JrP2GM7u\"\u003e\u003cb\u003e只要有情绪波动，就有传播价值。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"9nUEU2EJ\"\u003e我之前写过一篇《为什么太平公主的女生很多男人不喜欢，但国际模特都需要平胸女孩》\u003c/p\u003e\u003cp data-pid=\"2_yJQfob\"\u003e两天63万阅读，全是男性读者。\u003c/p\u003e\u003cp data-pid=\"jb4Dh3_B\"\u003e\u003cb\u003e因为它戳中了一个群体的情绪点。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e垂直领域的选择\u003c/h3\u003e\u003cp data-pid=\"9hsI-cb7\"\u003e如果你是女性，我推荐三个最容易出爆文的方向：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"bXRUdzkb\"\u003e\u003cb\u003e情感类\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"BgZpex23\"\u003e\u003cb\u003e夫妻关系类\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"UBTI74SP\"\u003e\u003cb\u003e疗愈类\u003c/b\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"dIDNTjMB\"\u003e这三个方向，不爆则已，一爆就是几万甚至几十万阅读。\u003c/p\u003e\u003cp data-pid=\"aIMVBTeL\"\u003e\u003cb\u003e因为现在的社会太浮躁了，大家都需要情绪出口。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"3mK1m_Dd\"\u003e如果你是男性，建议写男性视角的内容。\u003c/p\u003e\u003cp data-pid=\"SSsJivVN\"\u003e\u003cb\u003e市场上专门写男性内容的号太少了，竞争小，需求大。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"lyTyqTvf\"\u003e但不管选什么方向，记住一点：\u003c/p\u003e\u003cp data-pid=\"p3yUsES8\"\u003e\u003cb\u003e一定要选你内心真正想做的方向。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"rI8MD-pO\"\u003e很多人被别人的建议绕晕了，今天写这个，明天写那个。\u003c/p\u003e\u003cp data-pid=\"fIadrNTC\"\u003e\u003cb\u003e往往你最初的想法，就是最适合你的。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"Ng3rbxDg\"\u003e因为那是你内心的真实需求，也能让你持续输出有价值的内容。\u003c/p\u003e\u003ch3\u003e偷师学艺的艺术\u003c/h3\u003e\u003cp data-pid=\"lFBg2lJd\"\u003e\u003cb\u003e任何行业最快的成长方式，都是偷师学艺。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"qZeo-aUD\"\u003e找到5-10个对标账号，不要管他们是大号还是小号。\u003c/p\u003e\u003cp data-pid=\"3avmaU-1\"\u003e\u003cb\u003e只要坚持更新的，都有学习价值。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"coQAZDxF\"\u003e因为他们能坚持更新，说明找到了自己的节奏。\u003c/p\u003e\u003cp data-pid=\"mPuimJpz\"\u003e你要学习的不是他们的具体内容，而是：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"iwYVFtoA\"\u003e文章结构怎么搭建？\u003c/li\u003e\u003cli data-pid=\"kJQuJ3cM\"\u003e开头怎么吸引人？\u003c/li\u003e\u003cli data-pid=\"8F-Am6SK\"\u003e结尾怎么引导关注？\u003c/li\u003e\u003cli data-pid=\"nLcNSEfu\"\u003e排版怎么让人舒服？\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"I6b8MGlP\"\u003e\u003cb\u003e学会这些套路，你就能快速上手。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"N4y4SpSd\"\u003e别人用半年摸索的经验，你一个月就能掌握。\u003c/p\u003e\u003cp data-pid=\"Dt3yox4h\"\u003e这不是抄袭，这是学习。\u003c/p\u003e\u003cp data-pid=\"IpH4w7Nx\"\u003e\u003cb\u003e三人行，必有我师。\u003c/b\u003e\u003c/p\u003e\u003ch2\u003e五、发布策略，时间点里的流量密码\u003c/h2\u003e\u003cp data-pid=\"HF_08bOg\"\u003e什么时候发文章最好？\u003c/p\u003e\u003cp data-pid=\"EgrDjrOg\"\u003e\u003cb\u003e这是个伪命题。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"IvBgkCpD\"\u003e传统思维是分析用户习惯：\u003c/p\u003e\u003cp data-pid=\"mEQHBN4B\"\u003e上班族8点坐地铁可以看手机，宝妈9点哄娃睡觉有空刷手机...\u003c/p\u003e\u003cp data-pid=\"jB51fURF\"\u003e\u003cb\u003e但现在完全不是这个逻辑了。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"hVG6z7o_\"\u003e现在的公众号是24小时流量池机制。\u003c/p\u003e\u003cp data-pid=\"Bxo35Rmh\"\u003e\u003cb\u003e每个号的最佳发布时间都不一样。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"_sgvzqVd\"\u003e我的新号测试了一个月，发现早上发布效果最好。\u003c/p\u003e\u003cp data-pid=\"5_lAAk2d\"\u003e中午发基本没流量，晚上发也不行。\u003c/p\u003e\u003cp data-pid=\"K8nn2wPf\"\u003e\u003cb\u003e但这只适用于我的号。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"LPLP6MD0\"\u003e你需要用一个月时间，测试出你这个号的最佳发布时间。\u003c/p\u003e\u003ch3\u003e发布方式的小技巧\u003c/h3\u003e\u003cp data-pid=\"bRFqJNpw\"\u003e手机发布和电脑发布，效果是不一样的。\u003c/p\u003e\u003cp data-pid=\"c9WsVFxu\"\u003e\u003cb\u003e建议都试试。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"xqOMrNr0\"\u003e有时候手机发布更容易进推荐池，有时候电脑发布效果更好。\u003c/p\u003e\u003cp data-pid=\"6JIdJ1sd\"\u003e\u003cb\u003e没有标准答案，只能靠测试。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"2BOeVRVj\"\u003e还有个细节很多人忽略：\u003c/p\u003e\u003cp data-pid=\"rA7f86w7\"\u003e\u003cb\u003e定时发布和手动发布，权重也不同。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"CvD1DV1z\"\u003e定时发布是机器行为，手动发布是人工行为。\u003c/p\u003e\u003cp data-pid=\"8974PaGV\"\u003e\u003cb\u003e平台更喜欢人工行为。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"XPa_XD-r\"\u003e所以建议写好文章保存在草稿箱，到时间手动发布。\u003c/p\u003e\u003ch3\u003e更新频率的平衡\u003c/h3\u003e\u003cp data-pid=\"jO1frwzj\"\u003e很多课程强调日更的重要性。\u003c/p\u003e\u003cp data-pid=\"PnkFm1HG\"\u003e\u003cb\u003e但我更认同质量大于数量。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"f-1Qm7kJ\"\u003e如果你能保证每天都出高质量内容，当然最好。\u003c/p\u003e\u003cp data-pid=\"PdbDnnZU\"\u003e\u003cb\u003e但如果做不到，宁可降低频率，也要保证质量。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"Z2VVjX80\"\u003e我见过太多号，为了日更而日更，质量越来越差，最后把号做死了。\u003c/p\u003e\u003cp data-pid=\"nU2GWNtu\"\u003e\u003cb\u003e记住：平台要的是优质内容，不是垃圾信息。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"Um982rVk\"\u003e宁可两天更新一次高质量文章，也不要每天发一篇应付了事的内容。\u003c/p\u003e\u003cp data-pid=\"MYcAed8f\"\u003e\u003cb\u003e一篇爆文的价值，超过100篇普通文章。\u003c/b\u003e\u003c/p\u003e\u003ch2\u003e六、权重提升，新号快速起飞的秘密\u003c/h2\u003e\u003cp data-pid=\"DBARHNVJ\"\u003e很多人不理解权重的概念。\u003c/p\u003e\u003cp data-pid=\"Kz2KMgd3\"\u003e\u003cb\u003e权重就是平台对你的信任度。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"4PoJ61GJ\"\u003e权重越高，获得推荐的机会越大。\u003c/p\u003e\u003cp data-pid=\"sfqvYgJR\"\u003e新号权重为零，所以要想办法快速提升权重。\u003c/p\u003e\u003ch3\u003e编码清洁的重要性\u003c/h3\u003e\u003cp data-pid=\"3C9_4UA2\"\u003e前面提到过，复制粘贴会带来编码问题。\u003c/p\u003e\u003cp data-pid=\"dxKXPE2U\"\u003e\u003cb\u003e这里再详细说说如何避免。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"uFeKPDhr\"\u003e如果你要参考其他文章：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"8kQuWYzL\"\u003e先复制到微信，发给自己\u003c/li\u003e\u003cli data-pid=\"ulz4oOvW\"\u003e在微信里修改内容\u003c/li\u003e\u003cli data-pid=\"KNHf8SCN\"\u003e再从微信复制到编辑器\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"JbfLJ_GL\"\u003e\u003cb\u003e这样可以彻底清除原有编码。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"rzBVol3I\"\u003e还有个方法是复制到Word，再从Word复制到编辑器。\u003c/p\u003e\u003cp data-pid=\"-VixyCTJ\"\u003e\u003cb\u003e总之，不要直接从公众号复制到公众号。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e图片原创的技巧\u003c/h3\u003e\u003cp data-pid=\"m-pnVULq\"\u003e很多人忽略了图片原创的重要性。\u003c/p\u003e\u003cp data-pid=\"6SRrCPSD\"\u003e直接用网上的图片，会被识别为非原创内容。\u003c/p\u003e\u003cp data-pid=\"jvjL9PnX\"\u003e\u003cb\u003e简单的解决方法：\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"fthkOBKk\"\u003e把图片四周裁剪掉一点点，产生图片原创。\u003c/p\u003e\u003cp data-pid=\"2p2KhD6F\"\u003e\u003cb\u003e这样平台就会认为是你的原创图片。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"bWRCH3LX\"\u003e虽然听起来像是在\u0026#34;欺骗\u0026#34;平台，但这是合理的技术手段。\u003c/p\u003e\u003cp data-pid=\"8HL5Dabu\"\u003e\u003cb\u003e毕竟我们是在用心做内容，只是借用了一些素材。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e标签策略的运用\u003c/h3\u003e\u003cp data-pid=\"A9jic_Cz\"\u003e很多人不会用合集标签功能。\u003c/p\u003e\u003cp data-pid=\"m62XzqXC\"\u003e\u003cb\u003e这个功能很重要，可以帮你蹭到大号的流量。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"G9kAJm8Z\"\u003e具体操作：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"H9zNKkH8\"\u003e找到你对标的大号\u003c/li\u003e\u003cli data-pid=\"-ml4PVUM\"\u003e看他们经常用什么标签\u003c/li\u003e\u003cli data-pid=\"0_V96N1D\"\u003e复制他们的标签设置\u003c/li\u003e\u003cli data-pid=\"qi_890em\"\u003e每次发文章都用这些标签\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"lvZ5_A4s\"\u003e\u003cb\u003e时间久了，你的文章就会出现在他们文章的推荐位置。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"O4RT7zlD\"\u003e这就是\u0026#34;搭顺风车\u0026#34;的技巧。\u003c/p\u003e\u003ch3\u003e避免买粉刷量\u003c/h3\u003e\u003cp data-pid=\"225V93jm\"\u003e\u003cb\u003e千万不要买粉丝，千万不要刷阅读量。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"EeK7EoWw\"\u003e这是百害而无一利的行为。\u003c/p\u003e\u003cp data-pid=\"OJdYc5vK\"\u003e不仅浪费钱，还会损害账号权重。\u003c/p\u003e\u003cp data-pid=\"tt_MIOok\"\u003e\u003cb\u003e腾讯的算法比你想象的聪明。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"sNX_IYXE\"\u003e真实的粉丝增长是有规律的，虚假的粉丝很容易被识别。\u003c/p\u003e\u003cp data-pid=\"PsA6PAXl\"\u003e\u003cb\u003e一旦被发现，就是隐形限流的开始。\u003c/b\u003e\u003c/p\u003e\u003ch2\u003e七、变现思维，IP价值的最大化\u003c/h2\u003e\u003cp data-pid=\"W44BiRJn\"\u003e很多人做公众号只想着流量主收益。\u003c/p\u003e\u003cp data-pid=\"roYQV513\"\u003e\u003cb\u003e格局太小了。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"5reY3Wcx\"\u003e公众号的真正价值在于个人IP的打造。\u003c/p\u003e\u003cp data-pid=\"7VPRcID1\"\u003e\u003cb\u003eIP做好了，变现渠道无穷无尽。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e精准粉丝的威力\u003c/h3\u003e\u003cp data-pid=\"5jCdw_Sh\"\u003e1个精准粉丝 = 50个泛粉丝\u003c/p\u003e\u003cp data-pid=\"Z5zKhddW\"\u003e\u003cb\u003e这不是夸张，是真实数据。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"duVyoSJw\"\u003e我做服装的时候，随便发一条产品广告，当天就能卖出一两百万。\u003c/p\u003e\u003cp data-pid=\"PoFZED8Y\"\u003e\u003cb\u003e因为关注我的都是真正对服装感兴趣的人。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"Vx_3CrFs\"\u003e精准粉丝的购买意愿和购买能力，都远超泛粉丝。\u003c/p\u003e\u003cp data-pid=\"YV2xDR-2\"\u003e所以不要追求粉丝数量，要追求粉丝质量。\u003c/p\u003e\u003cp data-pid=\"IGU4IuTj\"\u003e\u003cb\u003e100个精准粉丝，胜过10000个僵尸粉。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e多元化变现路径\u003c/h3\u003e\u003cp data-pid=\"7fDZCalu\"\u003e除了流量主，公众号还有很多变现方式：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"jsN6aTx7\"\u003e\u003cb\u003e产品销售\u003c/b\u003e：卖自己的产品或服务\u003c/li\u003e\u003cli data-pid=\"X4InGp2b\"\u003e\u003cb\u003e知识付费\u003c/b\u003e：课程、咨询、训练营\u003c/li\u003e\u003cli data-pid=\"MXhhd4us\"\u003e\u003cb\u003e广告合作\u003c/b\u003e：品牌软文、产品推广\u003c/li\u003e\u003cli data-pid=\"ROy-a-Db\"\u003e\u003cb\u003e社群运营\u003c/b\u003e：付费社群、会员制度\u003c/li\u003e\u003cli data-pid=\"rzTG14Az\"\u003e\u003cb\u003e线下活动\u003c/b\u003e：讲座、培训、聚会\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"YUTTnEEJ\"\u003e\u003cb\u003e每一个渠道的收益，都可能超过流量主。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"-3__45QF\"\u003e关键是你要有清晰的变现思路，而不是盲目追求流量。\u003c/p\u003e\u003ch3\u003eIP的长期价值\u003c/h3\u003e\u003cp data-pid=\"7NVttUme\"\u003e一个成功的IP，价值可以延续很多年。\u003c/p\u003e\u003cp data-pid=\"tOe-Ot7u\"\u003e\u003cb\u003e它不只是一个公众号，而是你的个人品牌。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"FsqHNj3K\"\u003e有了个人品牌，你可以：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"DJ0eK-uR\"\u003e出书\u003c/li\u003e\u003cli data-pid=\"v_UUrE3S\"\u003e做培训\u003c/li\u003e\u003cli data-pid=\"iKza9K4v\"\u003e当顾问\u003c/li\u003e\u003cli data-pid=\"a8Ru5JxK\"\u003e开公司\u003c/li\u003e\u003cli data-pid=\"Nhd5QnLi\"\u003e做投资\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"MD0hpawe\"\u003e\u003cb\u003e这些机会的价值，远超你在公众号上赚到的钱。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"haU0bZcc\"\u003e所以做公众号，一定要有长远眼光。\u003c/p\u003e\u003cp data-pid=\"nvIFwNv4\"\u003e\u003cb\u003e不要只看眼前的收益，要看长期的价值。\u003c/b\u003e\u003c/p\u003e\u003ch2\u003e八、心态管理，持续创作的心理建设\u003c/h2\u003e\u003cp data-pid=\"SYNvXu8g\"\u003e做公众号最难的不是技巧，而是坚持。\u003c/p\u003e\u003cp data-pid=\"X5AuY4z_\"\u003e\u003cb\u003e90%的人都死在了半路上。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e克服新手焦虑\u003c/h3\u003e\u003cp data-pid=\"AA03ZeKI\"\u003e很多新手有个通病：太着急了。\u003c/p\u003e\u003cp data-pid=\"A5sTBQT2\"\u003e今天发了文章没人看，就开始怀疑自己的方向。\u003c/p\u003e\u003cp data-pid=\"A8wKBS5g\"\u003e明天看到别人爆文，又想改变策略。\u003c/p\u003e\u003cp data-pid=\"okDLeWDu\"\u003e\u003cb\u003e这种心态要不得。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"-WYDRtLl\"\u003e任何成功的账号，都有一个默默无闻的积累期。\u003c/p\u003e\u003cp data-pid=\"-SmZr1lO\"\u003e\u003cb\u003e你看到的是别人的成功，看不到别人的坚持。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"Lg14Af3X\"\u003e我的新号也是从每天几十个阅读开始的，坚持了一个多月才有起色。\u003c/p\u003e\u003cp data-pid=\"IWQPzCCC\"\u003e\u003cb\u003e现在回头看，那段时间的积累最宝贵。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e保持创作热情\u003c/h3\u003e\u003cp data-pid=\"4gkKJluj\"\u003e写久了容易疲倦，这很正常。\u003c/p\u003e\u003cp data-pid=\"5T0YEtTC\"\u003e\u003cb\u003e关键是要找到持续创作的动力。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"3uqu6DeD\"\u003e我的方法是：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"eDO0Vuth\"\u003e\u003cb\u003e记录进步\u003c/b\u003e：每天记录数据变化，看到成长轨迹\u003c/li\u003e\u003cli data-pid=\"ompj2sO5\"\u003e\u003cb\u003e读者反馈\u003c/b\u003e：关注读者留言，感受自己的价值\u003c/li\u003e\u003cli data-pid=\"OLVKnSHh\"\u003e\u003cb\u003e学习充电\u003c/b\u003e：定期学习新知识，保持输入\u003c/li\u003e\u003cli data-pid=\"ivQmXKAo\"\u003e\u003cb\u003e休息调整\u003c/b\u003e：累了就休息，不要硬撑\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"CMz3lbRo\"\u003e\u003cb\u003e创作是马拉松，不是百米冲刺。\u003c/b\u003e\u003c/p\u003e\u003ch3\u003e面对挫折的心态\u003c/h3\u003e\u003cp data-pid=\"PnrXgUAu\"\u003e做公众号一定会遇到挫折：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"KUjoxSMD\"\u003e文章突然没流量了\u003c/li\u003e\u003cli data-pid=\"gV6fDh0j\"\u003e辛苦写的文章没人看\u003c/li\u003e\u003cli data-pid=\"rVMn4mXo\"\u003e被读者误解或批评\u003c/li\u003e\u003cli data-pid=\"a_U2xhSe\"\u003e同行超越了自己\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"SspQOTfP\"\u003e\u003cb\u003e这些都是正常现象。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"Bsa6avEK\"\u003e我的建议是：\u003c/p\u003e\u003cp data-pid=\"HHN26fmt\"\u003e\u003cb\u003e把挫折当成成长的机会。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"-njNditx\"\u003e没流量了，就反思内容是否偏离了定位。\u003c/p\u003e\u003cp data-pid=\"6ZbZ9zmw\"\u003e没人看，就分析标题和开头是否有吸引力。\u003c/p\u003e\u003cp data-pid=\"QPtsg2xI\"\u003e被批评，就看看是否有改进的空间。\u003c/p\u003e\u003cp data-pid=\"MIrsZHZm\"\u003e\u003cb\u003e每一次挫折，都是优化的契机。\u003c/b\u003e\u003c/p\u003e\u003ch2\u003e结语：从零到一的跃迁\u003c/h2\u003e\u003cp data-pid=\"LHC749e2\"\u003e写到这里，我想起一句话：\u003c/p\u003e\u003cp data-pid=\"Zbme9U3E\"\u003e\u003cb\u003e\u0026#34;再小的个体，也有自己的品牌。\u0026#34;\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"FdLMD_e7\"\u003e这是公众号最初的slogan，也是它给我们最大的礼物。\u003c/p\u003e\u003cp data-pid=\"JVU-ASag\"\u003e在这个时代，每个人都有机会成为自己的品牌。\u003c/p\u003e\u003cp data-pid=\"6g-2VlV0\"\u003e\u003cb\u003e但机会只留给有准备的人。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"HCKczrzR\"\u003e这篇文章分享的所有方法，都是我和朋友们实战验证的。\u003c/p\u003e\u003cp data-pid=\"W7atrs-i\"\u003e\u003cb\u003e没有理论空谈，只有实操干货。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"W8hF3klX\"\u003e但记住一点：\u003c/p\u003e\u003cp data-pid=\"mG8qPztT\"\u003e\u003cb\u003e方法只是工具，关键是执行。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"LwsipvDO\"\u003e很多人看了很多干货，学了很多课程，但就是不行动。\u003c/p\u003e\u003cp data-pid=\"VGTPK0v6\"\u003e\u003cb\u003e知道和做到之间，隔着一万八千里。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"0erBHzNc\"\u003e如果你真的想在公众号上有所成就，就从今天开始：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"oTO_29Og\"\u003e\u003cb\u003e明确定位，搭建框架\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"nqqXF3bA\"\u003e\u003cb\u003e找到对标账号，开始学习\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"lL9poxKg\"\u003e\u003cb\u003e写第一篇文章，开始积累\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"CSp2iec2\"\u003e\u003cb\u003e测试发布时间，优化策略\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"1FysOtkj\"\u003e\u003cb\u003e坚持更新，保持质量\u003c/b\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"oKjN-VFH\"\u003e\u003cb\u003e一步一个脚印，踏踏实实往前走。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"R2KgNOWi\"\u003e半年后，你会发现一个不一样的自己。\u003c/p\u003e\u003cp data-pid=\"o6Fwpt2O\"\u003e一年后，你可能已经实现了财务自由。\u003c/p\u003e\u003cp data-pid=\"x_iszNYf\"\u003e\u003cb\u003e这不是鸡汤，这是现实。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"OPXTDqe1\"\u003e在公众号这个平台上，每天都有人从零开始，实现人生逆袭。\u003c/p\u003e\u003cp data-pid=\"AOuB4Lvm\"\u003e\u003cb\u003e下一个，为什么不能是你？\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"D0wnbUNN\"\u003e\u003cb\u003e如果觉得文章不错，麻烦点个小心心支持作者持续创作，感谢老铁！\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"C_wHd1oj\"\u003e@\u003cb\u003e墨云：vx:  inkroam\u003c/b\u003e\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":1,"favorite_count":1,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1933851430164345242}","attached_info":"CtwFCIrkppqf7/7pugEQBBoJNzM5NTc5NzI0IN6ipsQGKAAwAEBMSiQKGVRTX1NPVVJDRV9XQVJNX1VQX05PUk1BTDESATAYACAAOgBKKAodVFNfU09VUkNFX1dBUk1VUF9QUkVUUkFJTl9JMkkSATAYACAAOgBaBzEyMjYwNDBiIGFhN2QyMjRlMDZkNGIzMWI3NGY2NGQwODBkOWI3ZjU2chMxOTMzODUxNDMwMTY0MzQ1MjQyigEIMjI2MTM0NTaqAQlyZWNvbW1lbmTCASA2MWYzM2JkMmFlOGQ4NTEwMTAyMjM1ODBlYWI0ZjczOPIBCggMEgZOb3JtYWzyASgIChIkMDAyYTg4NTAtMWIyMC00ODZmLTg0MzEtOGQ5ZGM4ZTNkMDli8gEGCAsSAjEzggIAiALu48fOhTOSAiA2MWYzM2JkMmFlOGQ4NTEwMTAyMjM1ODBlYWI0ZjczOJoCAMoCFlNob3JJbnRlcmVzdFdlaWdodFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXKAhhDb250ZW50V2FybVVwQnJlYWtJblJ1bGXaAhlUU19TT1VSQ0VfV0FSTV9VUF9OT1JNQUwx6AID+gILTk9STUFMX0ZMT1eKAyAwOTAxOGJkMzY2ZDA0ZDA1YTZlMTc3MWM2M2IwYWVjYpoDDQoCdjIQABoFb3RoZXKoAwHYAwDqAxNwcmV0cmFpbl9pMmlfcmVjYWxs+gMfEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERYAEAIgEAJIEBk5vcm1hbJoEATOgBACoBACwBAC6BAJhacIEAzQwMMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAACMFhT+BBQAAAAAAAAAAiQUDiYQFo2nTP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AUNkAYAoAZMqAYBkgIuCgk3Mzk1Nzk3MjQSEzE5MzM4NTE0MzAxNjQzNDUyNDIYBCIKSU1BR0VfVEVYVA==","action_card":false},{"id":"77_1753853588.576","type":"feed","offset":77,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1753853588,"updated_time":1753853588,"target":{"id":"1889972768910595282","type":"article","url":"https://api.zhihu.com/articles/1889972768910595282","author":{"id":"c6403435f349ba3ddef6b113dd31610f","url":"https://api.zhihu.com/people/c6403435f349ba3ddef6b113dd31610f","user_type":"people","url_token":"wind-35-80","name":"wind","headline":"十多年编程经验，现任大厂架构师，全力探索AI前沿技术","avatar_url":"https://pic1.zhimg.com/50/v2-28fadfaa80dd729296878baac5d90d1d_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":1948,"is_following":false,"is_followed":false},"title":"JAVA线上故障排查全套路","comment_permission":"all","created":1743472241,"updated":1743472241,"voteup_count":162,"voting":0,"comment_count":9,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"JAVA线上故障排查全套路线上故障主要会包括 cpu、磁盘、内存以及网络问题，而大多数故障可能会包含不止一个层面的问题，所以进行排查时候尽量四个方面依次排查一遍。同时例如 jstack、jmap 等工具也是不囿于一个方面的问题的，基本上出问题就是 df、free、top 三连，然后依次 jstack、jmap 伺候，具体问题具体分析即可。 CPU一般来讲我们首先会排查 cpu 方面的问题。cpu 异常往往还是比较好定位的。原因包括业务逻辑问题(死循环)…","excerpt_new":"JAVA线上故障排查全套路线上故障主要会包括 cpu、磁盘、内存以及网络问题，而大多数故障可能会包含不止一个层面的问题，所以进行排查时候尽量四个方面依次排查一遍。同时例如 jstack、jmap 等工具也是不囿于一个方面的问题的，基本上出问题就是 df、free、top 三连，然后依次 jstack、jmap 伺候，具体问题具体分析即可。 CPU一般来讲我们首先会排查 cpu 方面的问题。cpu 异常往往还是比较好定位的。原因包括业务逻辑问题(死循环)…","preview_type":"default","preview_text":"","content":"\u003ch2\u003eJAVA线上故障排查全套路\u003c/h2\u003e\u003cp data-pid=\"67KOcwAz\"\u003e线上故障主要会包括 cpu、磁盘、内存以及网络问题，而大多数故障可能会包含不止一个层面的问题，所以进行排查时候尽量四个方面依次排查一遍。同时例如 jstack、jmap 等工具也是不囿于一个方面的问题的，基本上出问题就是 df、free、top 三连，然后依次 jstack、jmap 伺候，具体问题具体分析即可。\u003c/p\u003e\u003ch2\u003eCPU\u003c/h2\u003e\u003cp data-pid=\"w-63YK1Z\"\u003e一般来讲我们首先会排查 cpu 方面的问题。cpu 异常往往还是比较好定位的。原因包括业务逻辑问题(死循环)、频繁 gc 以及上下文切换过多。而最常见的往往是业务逻辑(或者框架逻辑)导致的，可以使用 jstack 来分析对应的堆栈情况。\u003c/p\u003e\u003ch3\u003e使用 jstack 分析 cpu 问题\u003c/h3\u003e\u003cp data-pid=\"cYxKdlj1\"\u003e我们先用ps命令找到对应进程的pid(如果你有好几个目标进程，可以先用top看一下哪个占用比较高)。 接着用\u003ccode\u003etop -H -p pid\u003c/code\u003e来找到cpu使用率比较高的一些线程 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-373ed9d9b598ef08cb1409b2008a658c_1440w.jpg\" data-rawwidth=\"1346\" data-rawheight=\"476\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-91174ed68fb8d3224130e981fbcef205\" class=\"origin_image zh-lightbox-thumb\" width=\"1346\" data-original=\"https://pic3.zhimg.com/v2-373ed9d9b598ef08cb1409b2008a658c_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"KNkoyIRP\"\u003e然后将占用最高的pid转换为16进制\u003ccode\u003eprintf \u0026#39;%x\\n\u0026#39; pid\u003c/code\u003e得到nid\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-b571a2b7c9a68e37eb5872a784542f10_1440w.jpg\" data-rawwidth=\"510\" data-rawheight=\"76\" data-size=\"normal\" data-original-token=\"v2-b571a2b7c9a68e37eb5872a784542f10\" class=\"origin_image zh-lightbox-thumb\" width=\"510\" data-original=\"https://pica.zhimg.com/v2-b571a2b7c9a68e37eb5872a784542f10_r.jpg\"/\u003e\u003cfigcaption\u003eimg\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"xXOnzAQy\"\u003e接着直接在 jstack 中找到相应的堆栈信息\u003ccode\u003ejstack pid |grep \u0026#39;nid\u0026#39; -C5 –color\u003c/code\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-4b37b60d1bf1f7879c8bb0f624869ea5_1440w.jpg\" data-rawwidth=\"1790\" data-rawheight=\"436\" data-size=\"normal\" data-original-token=\"v2-e5a8ee59202a51a8ea44dd0be524b712\" class=\"origin_image zh-lightbox-thumb\" width=\"1790\" data-original=\"https://picx.zhimg.com/v2-4b37b60d1bf1f7879c8bb0f624869ea5_r.jpg\"/\u003e\u003cfigcaption\u003eimg\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"-pdCsxqg\"\u003e可以看到我们已经找到了nid为0x42的堆栈信息，接着只要仔细分析一番即可。\u003c/p\u003e\u003cp data-pid=\"5RzLAKbm\"\u003e当然更常见的是我们对整个 jstack 文件进行分析，通常我们会比较关注 \u003cb\u003eWAITING\u003c/b\u003e 和 \u003cb\u003eTIMED_WAITING\u003c/b\u003e 的部分，BLOCKED 就不用说了。我们可以使用命令 \u003ccode\u003ecat jstack.log | grep \u0026#34;java.lang.Thread.State\u0026#34; | sort -nr | uniq -c\u003c/code\u003e来对 jstack 的状态有一个整体的把握，如果 WAITING 之类的特别多，那么多半是有问题啦。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-ffa1f2abe34c73b388cc40f3f96d9fde_1440w.jpg\" data-rawwidth=\"1266\" data-rawheight=\"258\" data-size=\"normal\" data-original-token=\"v2-2c115548293db23235918a6f4fd716e1\" class=\"origin_image zh-lightbox-thumb\" width=\"1266\" data-original=\"https://pica.zhimg.com/v2-ffa1f2abe34c73b388cc40f3f96d9fde_r.jpg\"/\u003e\u003cfigcaption\u003eimg\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3\u003e频繁 gc\u003c/h3\u003e\u003cp data-pid=\"i2yQdW6W\"\u003e当然我们还是会使用 jstack 来分析问题，但有时候我们可以先确定下 gc 是不是太频繁，使用 \u003ccode\u003ejstat -gc pid 1000\u003c/code\u003e 命令来对 gc 分代变化情况进行观察，1000 表示采样间隔(ms)，S0C/S1C、S0U/S1U、EC/EU、OC/OU、MC/MU 分别代表两个 Survivor 区、Eden 区、老年代、元数据区的容量和使用量。YGC/YGT、FGC/FGCT、GCT则代表 YoungGc、FullGc 的耗时和次数以及总耗时。如果看到 gc 比较频繁，再针对 gc 方面做进一步分析。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-4e98d8de93de39dc06f9ffb0eb31ca90_1440w.jpg\" data-rawwidth=\"2288\" data-rawheight=\"258\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-4e98d8de93de39dc06f9ffb0eb31ca90\" class=\"origin_image zh-lightbox-thumb\" width=\"2288\" data-original=\"https://pic3.zhimg.com/v2-4e98d8de93de39dc06f9ffb0eb31ca90_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003e上下文切换\u003c/h3\u003e\u003cp data-pid=\"zf53r0xG\"\u003e针对频繁上下文问题，我们可以使用 \u003ccode\u003evmstat\u003c/code\u003e 命令来进行查看 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-32b92418a9e9e83dff9eef723706fb15_1440w.jpg\" data-rawwidth=\"1348\" data-rawheight=\"300\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-4b33b491caa42e8ed1d9a504d9f33377\" class=\"origin_image zh-lightbox-thumb\" width=\"1348\" data-original=\"https://picx.zhimg.com/v2-32b92418a9e9e83dff9eef723706fb15_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"8VnqixE1\"\u003e cs(context switch)一列则代表了上下文切换的次数。 如果我们希望对特定的pid进行监控那么可以使用 \u003ccode\u003epidstat -w pid\u003c/code\u003e命令，cswch和nvcswch表示自愿及非自愿切换。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-76dbd738bab29801484c968cea305f0a_1440w.jpg\" data-rawwidth=\"922\" data-rawheight=\"432\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-de9fe262bfa5d4def0b066a086f76e99\" class=\"origin_image zh-lightbox-thumb\" width=\"922\" data-original=\"https://pic1.zhimg.com/v2-76dbd738bab29801484c968cea305f0a_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch2\u003e磁盘\u003c/h2\u003e\u003cp data-pid=\"IbKHkjc2\"\u003e磁盘问题和 cpu 一样是属于比较基础的。首先是磁盘空间方面，我们直接使用 \u003ccode\u003edf -hl\u003c/code\u003e 来查看文件系统状态 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-0aa4c0d725afb4afe6193b693db075f0_1440w.jpg\" data-rawwidth=\"1452\" data-rawheight=\"184\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-0aa4c0d725afb4afe6193b693db075f0\" class=\"origin_image zh-lightbox-thumb\" width=\"1452\" data-original=\"https://pic1.zhimg.com/v2-0aa4c0d725afb4afe6193b693db075f0_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"zLqT5TpS\"\u003e更多时候，磁盘问题还是性能上的问题。我们可以通过 iostat： \u003ccode\u003eiostat -d -k -x\u003c/code\u003e 来进行分析 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-58ff9b2f82607ca4f0c499ad8d976f31_1440w.jpg\" data-rawwidth=\"1952\" data-rawheight=\"436\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-0760f14993b5aa662560b37b86de9c07\" class=\"origin_image zh-lightbox-thumb\" width=\"1952\" data-original=\"https://picx.zhimg.com/v2-58ff9b2f82607ca4f0c499ad8d976f31_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"gs6N_3UM\"\u003e 最后一列\u003ccode\u003e%util\u003c/code\u003e可以看到每块磁盘写入的程度，而\u003ccode\u003errqpm/s\u003c/code\u003e以及\u003ccode\u003ewrqm/s\u003c/code\u003e分别表示读写速度，一般就能帮助定位到具体哪块磁盘出现问题了。\u003c/p\u003e\u003cp data-pid=\"jaZshQ8S\"\u003e另外我们还需要知道是哪个进程在进行读写，一般来说开发自己心里有数，或者用iotop命令来进行定位文件读写的来源。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-0837c11a25cb8c4557f389ea231d4d7c_1440w.jpg\" data-rawwidth=\"2560\" data-rawheight=\"648\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-0cd65beca0cc0c751c58dc3ad62c97e6\" class=\"origin_image zh-lightbox-thumb\" width=\"2560\" data-original=\"https://pica.zhimg.com/v2-0837c11a25cb8c4557f389ea231d4d7c_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"RL7Evwih\"\u003e 不过这边拿到的是tid，我们要转换成pid，可以通过readlink来找到pid\u003ccode\u003ereadlink -f /proc/*/task/tid/../..\u003c/code\u003e。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-379b5bc32975d90980e638f38b65d0ef_1440w.jpg\" data-rawwidth=\"944\" data-rawheight=\"84\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-379b5bc32975d90980e638f38b65d0ef\" class=\"origin_image zh-lightbox-thumb\" width=\"944\" data-original=\"https://picx.zhimg.com/v2-379b5bc32975d90980e638f38b65d0ef_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"G593KgaT\"\u003e 找到pid之后就可以看这个进程具体的读写情况\u003ccode\u003ecat /proc/pid/io\u003c/code\u003e \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-4670e1487ab85034df0166fb619747bd_1440w.jpg\" data-rawwidth=\"660\" data-rawheight=\"282\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-337e3b80cdc0db5c71dc68fe5e79967d\" class=\"origin_image zh-lightbox-thumb\" width=\"660\" data-original=\"https://pic4.zhimg.com/v2-4670e1487ab85034df0166fb619747bd_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"RUA71cy9\"\u003e 我们还可以通过lsof命令来确定具体的文件读写情况\u003ccode\u003elsof -p pid\u003c/code\u003e \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-1024a0f1f183e6a1268a8688de6a2769_1440w.jpg\" data-rawwidth=\"2158\" data-rawheight=\"1226\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-d61a91f6598291e45c512ddba76bfbb0\" class=\"origin_image zh-lightbox-thumb\" width=\"2158\" data-original=\"https://pic2.zhimg.com/v2-1024a0f1f183e6a1268a8688de6a2769_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch2\u003e内存\u003c/h2\u003e\u003cp data-pid=\"iFCHk4gp\"\u003e内存问题排查起来相对比 CPU 麻烦一些，场景也比较多。主要包括 OOM、GC 问题和堆外内存。一般来讲，我们会先用\u003ccode\u003efree\u003c/code\u003e命令先来检查一发内存的各种情况。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-d42f87a16e07115b5df10ed7428b6948_1440w.jpg\" data-rawwidth=\"1314\" data-rawheight=\"152\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-d42f87a16e07115b5df10ed7428b6948\" class=\"origin_image zh-lightbox-thumb\" width=\"1314\" data-original=\"https://pic3.zhimg.com/v2-d42f87a16e07115b5df10ed7428b6948_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003e堆内内存\u003c/h3\u003e\u003cp data-pid=\"sN2lexPf\"\u003e内存问题大多还都是堆内内存问题。表象上主要分为 OOM 和 StackOverflow。\u003c/p\u003e\u003ch3\u003eOOM\u003c/h3\u003e\u003cp data-pid=\"_D8PyAM1\"\u003eJMV 中的内存不足，OOM 大致可以分为以下几种：\u003c/p\u003e\u003cp data-pid=\"-jXWH4v2\"\u003e\u003cb\u003eException in thread \u0026#34;main\u0026#34; java.lang.OutOfMemoryError: unable to create new native thread\u003c/b\u003e 这个意思是没有足够的内存空间给线程分配java栈，基本上还是线程池代码写的有问题，比如说忘记shutdown，所以说应该首先从代码层面来寻找问题，使用jstack或者jmap。如果一切都正常，JVM方面可以通过指定\u003ccode\u003eXss\u003c/code\u003e来减少单个 thread stack 的大小。另外也可以在系统层面，可以通过修改\u003ccode\u003e/etc/security/limits.conf\u003c/code\u003enofile和nproc来增大os对线程的限制 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-d3e9f583034b7783d2c99964365fb18d_1440w.jpg\" data-rawwidth=\"326\" data-rawheight=\"152\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-e30ea376ebfba6e73f55ab520361f1ed\" class=\"content_image\" width=\"326\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"q1D-ZozG\"\u003e\u003cb\u003eException in thread \u0026#34;main\u0026#34; java.lang.OutOfMemoryError: Java heap space\u003c/b\u003e 这个意思是堆的内存占用已经达到-Xmx设置的最大值，应该是最常见的OOM错误了。解决思路仍然是先应该在代码中找，怀疑存在内存泄漏，通过jstack和jmap去定位问题。如果说一切都正常，才需要通过调整\u003ccode\u003eXmx\u003c/code\u003e的值来扩大内存。\u003c/p\u003e\u003cp data-pid=\"JuawMuXG\"\u003e\u003cb\u003eCaused by: java.lang.OutOfMemoryError: Meta space\u003c/b\u003e 这个意思是元数据区的内存占用已经达到\u003ccode\u003eXX:MaxMetaspaceSize\u003c/code\u003e设置的最大值，排查思路和上面的一致，参数方面可以通过\u003ccode\u003eXX:MaxPermSize\u003c/code\u003e来进行调整(这里就不说1.8以前的永久代了)。\u003c/p\u003e\u003ch3\u003eStack Overflow\u003c/h3\u003e\u003cp data-pid=\"DoGzsK7S\"\u003e栈内存溢出，这个大家见到也比较多。 \u003cb\u003eException in thread \u0026#34;main\u0026#34; java.lang.StackOverflowError\u003c/b\u003e 表示线程栈需要的内存大于Xss值，同样也是先进行排查，参数方面通过\u003ccode\u003eXss\u003c/code\u003e来调整，但调整的太大可能又会引起OOM。\u003c/p\u003e\u003ch3\u003e使用JMAP定位代码内存泄漏\u003c/h3\u003e\u003cp data-pid=\"6Ixs-O3c\"\u003e上述关于OOM和StackOverflow的代码排查方面，我们一般使用JMAP\u003ccode\u003ejmap -dump:format=b,file=filename pid\u003c/code\u003e来导出dump文件 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-3e6731c3e8501ad6b23a7edd900c805e_1440w.jpg\" data-rawwidth=\"742\" data-rawheight=\"114\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-3e6731c3e8501ad6b23a7edd900c805e\" class=\"origin_image zh-lightbox-thumb\" width=\"742\" data-original=\"https://pic1.zhimg.com/v2-3e6731c3e8501ad6b23a7edd900c805e_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"VvPTFczl\"\u003e 通过mat(Eclipse Memory Analysis Tools)导入dump文件进行分析，内存泄漏问题一般我们直接选Leak Suspects即可，mat给出了内存泄漏的建议。另外也可以选择Top Consumers来查看最大对象报告。和线程相关的问题可以选择thread overview进行分析。除此之外就是选择Histogram类概览来自己慢慢分析，大家可以搜搜mat的相关教程。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-e9f6e70c3264d4ec9bd69a8d6d5c99e5_1440w.jpg\" data-rawwidth=\"1768\" data-rawheight=\"1364\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-fb570cb3bf9d281c053ca814fbf4bb29\" class=\"origin_image zh-lightbox-thumb\" width=\"1768\" data-original=\"https://pic2.zhimg.com/v2-e9f6e70c3264d4ec9bd69a8d6d5c99e5_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"WkRueC40\"\u003e日常开发中，代码产生内存泄漏是比较常见的事，并且比较隐蔽，需要开发者更加关注细节。比如说每次请求都new对象，导致大量重复创建对象；进行文件流操作但未正确关闭；手动不当触发gc；ByteBuffer缓存分配不合理等都会造成代码OOM。\u003c/p\u003e\u003cp data-pid=\"6oz4P2Wu\"\u003e另一方面，我们可以在启动参数中指定\u003ccode\u003e-XX:+HeapDumpOnOutOfMemoryError\u003c/code\u003e来保存OOM时的dump文件。\u003c/p\u003e\u003ch3\u003egc问题和线程\u003c/h3\u003e\u003cp data-pid=\"ML6vZ9l8\"\u003egc问题除了影响cpu也会影响内存，排查思路也是一致的。一般先使用jstat来查看分代变化情况，比如youngGC或者fullGC次数是不是太多呀；EU、OU等指标增长是不是异常呀等。 线程的话太多而且不被及时gc也会引发oom，大部分就是之前说的\u003ccode\u003eunable to create new native thread\u003c/code\u003e。除了jstack细细分析dump文件外，我们一般先会看下总体线程，通过\u003ccode\u003epstreee -p pid |wc -l\u003c/code\u003e。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-7aeda19334d1de41a203d69ce29cf944_1440w.jpg\" data-rawwidth=\"454\" data-rawheight=\"72\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-7aeda19334d1de41a203d69ce29cf944\" class=\"origin_image zh-lightbox-thumb\" width=\"454\" data-original=\"https://pic3.zhimg.com/v2-7aeda19334d1de41a203d69ce29cf944_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"tgbOOXje\"\u003e 或者直接通过查看\u003ccode\u003e/proc/pid/task\u003c/code\u003e的数量即为线程数量。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-13e8f8517780a9ba86179e9602409cb8_1440w.jpg\" data-rawwidth=\"518\" data-rawheight=\"66\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-13e8f8517780a9ba86179e9602409cb8\" class=\"origin_image zh-lightbox-thumb\" width=\"518\" data-original=\"https://pica.zhimg.com/v2-13e8f8517780a9ba86179e9602409cb8_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003e堆外内存\u003c/h3\u003e\u003cp data-pid=\"UXSdfo2V\"\u003e如果碰到堆外内存溢出，那可真是太不幸了。首先堆外内存溢出表现就是物理常驻内存增长快，报错的话视使用方式都不确定，如果由于使用Netty导致的，那错误日志里可能会出现\u003ccode\u003eOutOfDirectMemoryError\u003c/code\u003e错误，如果直接是DirectByteBuffer，那会报\u003ccode\u003eOutOfMemoryError: Direct buffer memory\u003c/code\u003e。\u003c/p\u003e\u003cp data-pid=\"z-Ipncfk\"\u003e堆外内存溢出往往是和NIO的使用相关，一般我们先通过pmap来查看下进程占用的内存情况\u003ccode\u003epmap -x pid | sort -rn -k3 | head -30\u003c/code\u003e，这段意思是查看对应pid倒序前30大的内存段。这边可以再一段时间后再跑一次命令看看内存增长情况，或者和正常机器比较可疑的内存段在哪里。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-dc39fc53b5c0136ed0eefb043a392513_1440w.jpg\" data-rawwidth=\"1022\" data-rawheight=\"1126\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-2180a5cc7ff74d483959b82654874f7b\" class=\"origin_image zh-lightbox-thumb\" width=\"1022\" data-original=\"https://picx.zhimg.com/v2-dc39fc53b5c0136ed0eefb043a392513_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"KIjEj4nw\"\u003e 我们如果确定有可疑的内存端，需要通过gdb来分析\u003ccode\u003egdb --batch --pid {pid} -ex \u0026#34;dump memory filename.dump {内存起始地址} {内存起始地址+内存块大小}\u0026#34;\u003c/code\u003e \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-cc7cced3d6fd53db0dafd197ec7332e3_1440w.jpg\" data-rawwidth=\"1398\" data-rawheight=\"46\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-cc7cced3d6fd53db0dafd197ec7332e3\" class=\"origin_image zh-lightbox-thumb\" width=\"1398\" data-original=\"https://pic2.zhimg.com/v2-cc7cced3d6fd53db0dafd197ec7332e3_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"VRZBZrm6\"\u003e 获取dump文件后可用heaxdump进行查看\u003ccode\u003ehexdump -C filename | less\u003c/code\u003e，不过大多数看到的都是二进制乱码。\u003c/p\u003e\u003cp data-pid=\"PiLLTJ8T\"\u003eNMT是Java7U40引入的HotSpot新特性，配合jcmd命令我们就可以看到具体内存组成了。需要在启动参数中加入 \u003ccode\u003e-XX:NativeMemoryTracking=summary\u003c/code\u003e 或者 \u003ccode\u003e-XX:NativeMemoryTracking=detail\u003c/code\u003e，会有略微性能损耗。\u003c/p\u003e\u003cp data-pid=\"4UZnk5Gb\"\u003e一般对于堆外内存缓慢增长直到爆炸的情况来说，可以先设一个基线\u003ccode\u003ejcmd pid VM.native_memory baseline\u003c/code\u003e。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-e1a085000e224b1d11a83e5c73d14798_1440w.jpg\" data-rawwidth=\"690\" data-rawheight=\"114\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-e1a085000e224b1d11a83e5c73d14798\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-e1a085000e224b1d11a83e5c73d14798_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"pGUZbTCk\"\u003e 然后等放一段时间后再去看看内存增长的情况，通过\u003ccode\u003ejcmd pid VM.native_memory detail.diff(summary.diff)\u003c/code\u003e做一下summary或者detail级别的diff。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-5baf0c7cd5a60c1458ebfb38746c3509_1440w.jpg\" data-rawwidth=\"638\" data-rawheight=\"50\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-5baf0c7cd5a60c1458ebfb38746c3509\" class=\"origin_image zh-lightbox-thumb\" width=\"638\" data-original=\"https://picx.zhimg.com/v2-5baf0c7cd5a60c1458ebfb38746c3509_r.jpg\"/\u003e\u003c/figure\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-f73b2a6e9e1fbe45cc19f1c10706cd52_1440w.jpg\" data-rawwidth=\"1496\" data-rawheight=\"1558\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-367b9338b635c0b76e15e2f3dfe5f736\" class=\"origin_image zh-lightbox-thumb\" width=\"1496\" data-original=\"https://pic3.zhimg.com/v2-f73b2a6e9e1fbe45cc19f1c10706cd52_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"1XYa2sxJ\"\u003e 可以看到jcmd分析出来的内存十分详细，包括堆内、线程以及gc(所以上述其他内存异常其实都可以用nmt来分析)，这边堆外内存我们重点关注Internal的内存增长，如果增长十分明显的话那就是有问题了。 detail级别的话还会有具体内存段的增长情况，如下图。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-32f9bac8d651186f6564815965eb953f_1440w.jpg\" data-rawwidth=\"1158\" data-rawheight=\"148\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-32f9bac8d651186f6564815965eb953f\" class=\"origin_image zh-lightbox-thumb\" width=\"1158\" data-original=\"https://pic2.zhimg.com/v2-32f9bac8d651186f6564815965eb953f_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"jwam-zLY\"\u003e此外在系统层面，我们还可以使用strace命令来监控内存分配 \u003ccode\u003estrace -f -e \u0026#34;brk,mmap,munmap\u0026#34; -p pid\u003c/code\u003e 这边内存分配信息主要包括了pid和内存地址。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-6b150dab7ebbc5ba2fd87432d32145a4_1440w.jpg\" data-rawwidth=\"1482\" data-rawheight=\"444\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-a3377344de825549177feeaa872a89b3\" class=\"origin_image zh-lightbox-thumb\" width=\"1482\" data-original=\"https://pic1.zhimg.com/v2-6b150dab7ebbc5ba2fd87432d32145a4_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"d_PpnZw_\"\u003e不过其实上面那些操作也很难定位到具体的问题点，关键还是要看错误日志栈，找到可疑的对象，搞清楚它的回收机制，然后去分析对应的对象。比如DirectByteBuffer分配内存的话，是需要full GC或者手动system.gc来进行回收的(所以最好不要使用\u003ccode\u003e-XX:+DisableExplicitGC\u003c/code\u003e)。那么其实我们可以跟踪一下DirectByteBuffer对象的内存情况，通过\u003ccode\u003ejmap -histo:live pid\u003c/code\u003e手动触发fullGC来看看堆外内存有没有被回收。如果被回收了，那么大概率是堆外内存本身分配的太小了，通过\u003ccode\u003e-XX:MaxDirectMemorySize\u003c/code\u003e进行调整。如果没有什么变化，那就要使用jmap去分析那些不能被gc的对象，以及和DirectByteBuffer之间的引用关系了。\u003c/p\u003e\u003ch2\u003eGC问题\u003c/h2\u003e\u003cp data-pid=\"riGBglvx\"\u003e堆内内存泄漏总是和GC异常相伴。不过GC问题不只是和内存问题相关，还有可能引起CPU负载、网络问题等系列并发症，只是相对来说和内存联系紧密些，所以我们在此单独总结一下GC相关问题。\u003c/p\u003e\u003cp data-pid=\"QA6LcmUs\"\u003e我们在cpu章介绍了使用jstat来获取当前GC分代变化信息。而更多时候，我们是通过GC日志来排查问题的，在启动参数中加上\u003ccode\u003e-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps\u003c/code\u003e来开启GC日志。 常见的Young GC、Full GC日志含义在此就不做赘述了。\u003c/p\u003e\u003cp data-pid=\"h1wsnADD\"\u003e针对gc日志，我们就能大致推断出youngGC与fullGC是否过于频繁或者耗时过长，从而对症下药。我们下面将对G1垃圾收集器来做分析，这边也建议大家使用G1\u003ccode\u003e-XX:+UseG1GC\u003c/code\u003e。\u003c/p\u003e\u003cp data-pid=\"oWCkIBoW\"\u003e\u003cb\u003eyoungGC过频繁\u003c/b\u003e youngGC频繁一般是短周期小对象较多，先考虑是不是Eden区/新生代设置的太小了，看能否通过调整-Xmn、-XX:SurvivorRatio等参数设置来解决问题。如果参数正常，但是young gc频率还是太高，就需要使用Jmap和MAT对dump文件进行进一步排查了。\u003c/p\u003e\u003cp data-pid=\"EoihBVDQ\"\u003e\u003cb\u003eyoungGC耗时过长\u003c/b\u003e 耗时过长问题就要看GC日志里耗时耗在哪一块了。以G1日志为例，可以关注Root Scanning、Object Copy、Ref Proc等阶段。Ref Proc耗时长，就要注意引用相关的对象。Root Scanning耗时长，就要注意线程数、跨代引用。Object Copy则需要关注对象生存周期。而且耗时分析它需要横向比较，就是和其他项目或者正常时间段的耗时比较。比如说图中的Root Scanning和正常时间段比增长较多，那就是起的线程太多了。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-b7a13c185873ecc4f890e4f55fda6378_1440w.jpg\" data-rawwidth=\"1564\" data-rawheight=\"1144\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-97e757922512571120995bde86cb9b9e\" class=\"origin_image zh-lightbox-thumb\" width=\"1564\" data-original=\"https://pica.zhimg.com/v2-b7a13c185873ecc4f890e4f55fda6378_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"o5YAsCWr\"\u003e\u003cb\u003e触发fullGC\u003c/b\u003e G1中更多的还是mixedGC，但mixedGC可以和youngGC思路一样去排查。触发fullGC了一般都会有问题，G1会退化使用Serial收集器来完成垃圾的清理工作，暂停时长达到秒级别，可以说是半跪了。 fullGC的原因可能包括以下这些，以及参数调整方面的一些思路：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"S_7NsanD\"\u003e并发阶段失败：在并发标记阶段，MixGC之前老年代就被填满了，那么这时候G1就会放弃标记周期。这种情况，可能就需要增加堆大小，或者调整并发标记线程数\u003ccode\u003e-XX:ConcGCThreads\u003c/code\u003e。\u003c/li\u003e\u003cli data-pid=\"oiIwseUY\"\u003e晋升失败：在GC的时候没有足够的内存供存活/晋升对象使用，所以触发了Full GC。这时候可以通过\u003ccode\u003e-XX:G1ReservePercent\u003c/code\u003e来增加预留内存百分比，减少\u003ccode\u003e-XX:InitiatingHeapOccupancyPercent\u003c/code\u003e来提前启动标记，\u003ccode\u003e-XX:ConcGCThreads\u003c/code\u003e来增加标记线程数也是可以的。\u003c/li\u003e\u003cli data-pid=\"ldiGmPtw\"\u003e大对象分配失败：大对象找不到合适的region空间进行分配，就会进行fullGC，这种情况下可以增大内存或者增大\u003ccode\u003e-XX:G1HeapRegionSize\u003c/code\u003e。\u003c/li\u003e\u003cli data-pid=\"HSIqHY5P\"\u003e程序主动执行System.gc()：不要随便写就对了。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"u4vK3xNX\"\u003e另外，我们可以在启动参数中配置\u003ccode\u003e-XX:HeapDumpPath=/xxx/dump.hprof\u003c/code\u003e来dump fullGC相关的文件，并通过jinfo来进行gc前后的dump\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003ejinfo -flag +HeapDumpBeforeFullGC pid \njinfo -flag +HeapDumpAfterFullGC pid\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"mJCsavd_\"\u003e这样得到2份dump文件，对比后主要关注被gc掉的问题对象来定位问题。\u003c/p\u003e\u003ch2\u003e网络\u003c/h2\u003e\u003cp data-pid=\"nd60vp81\"\u003e涉及到网络层面的问题一般都比较复杂，场景多，定位难，成为了大多数开发的噩梦，应该是最复杂的了。这里会举一些例子，并从tcp层、应用层以及工具的使用等方面进行阐述。\u003c/p\u003e\u003ch3\u003e超时\u003c/h3\u003e\u003cp data-pid=\"E1sLhmIu\"\u003e超时错误大部分处在应用层面，所以这块着重理解概念。超时大体可以分为连接超时和读写超时，某些使用连接池的客户端框架还会存在获取连接超时和空闲连接清理超时。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"YsTL6UB8\"\u003e读写超时。readTimeout/writeTimeout，有些框架叫做so_timeout或者socketTimeout，均指的是数据读写超时。注意这边的超时大部分是指逻辑上的超时。soa的超时指的也是读超时。读写超时一般都只针对客户端设置。\u003c/li\u003e\u003cli data-pid=\"3ntmJdGy\"\u003e连接超时。connectionTimeout，客户端通常指与服务端建立连接的最大时间。服务端这边connectionTimeout就有些五花八门了，jetty中表示空闲连接清理时间，tomcat则表示连接维持的最大时间。\u003c/li\u003e\u003cli data-pid=\"HvrjoPdu\"\u003e其他。包括连接获取超时connectionAcquireTimeout和空闲连接清理超时idleConnectionTimeout。多用于使用连接池或队列的客户端或服务端框架。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"M88i75UE\"\u003e我们在设置各种超时时间中，需要确认的是尽量保持客户端的超时小于服务端的超时，以保证连接正常结束。\u003c/p\u003e\u003cp data-pid=\"QHnpeNtQ\"\u003e在实际开发中，我们关心最多的应该是接口的读写超时了。\u003c/p\u003e\u003cp data-pid=\"FUZ7jcGR\"\u003e如何设置合理的接口超时是一个问题。如果接口超时设置的过长，那么有可能会过多地占用服务端的tcp连接。而如果接口设置的过短，那么接口超时就会非常频繁。\u003c/p\u003e\u003cp data-pid=\"ac0Y6NwS\"\u003e服务端接口明明rt降低，但客户端仍然一直超时又是另一个问题。这个问题其实很简单，客户端到服务端的链路包括网络传输、排队以及服务处理等，每一个环节都可能是耗时的原因。\u003c/p\u003e\u003ch3\u003eTCP队列溢出\u003c/h3\u003e\u003cp data-pid=\"C3B5TuAw\"\u003etcp队列溢出是个相对底层的错误，它可能会造成超时、rst等更表层的错误。因此错误也更隐蔽，所以我们单独说一说。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-289c20c451ddf84900d1f4a6cf7309fc_1440w.jpg\" data-rawwidth=\"1153\" data-rawheight=\"745\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-b63c2ffc7cb9bbc38cebc8ba04625abb\" class=\"origin_image zh-lightbox-thumb\" width=\"1153\" data-original=\"https://pic1.zhimg.com/v2-289c20c451ddf84900d1f4a6cf7309fc_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"kXKzdxnA\"\u003e如上图所示，这里有两个队列：syns queue(半连接队列）、accept queue（全连接队列）。三次握手，在server收到client的syn后，把消息放到syns queue，回复syn+ack给client，server收到client的ack，如果这时accept queue没满，那就从syns queue拿出暂存的信息放入accept queue中，否则按tcp_abort_on_overflow指示的执行。\u003c/p\u003e\u003cp data-pid=\"25QFnHkh\"\u003etcp_abort_on_overflow 0表示如果三次握手第三步的时候accept queue满了那么server扔掉client发过来的ack。tcp_abort_on_overflow 1则表示第三步的时候如果全连接队列满了，server发送一个rst包给client，表示废掉这个握手过程和这个连接，意味着日志里可能会有很多\u003ccode\u003econnection reset / connection reset by peer\u003c/code\u003e。\u003c/p\u003e\u003cp data-pid=\"qf9SS3CS\"\u003e那么在实际开发中，我们怎么能快速定位到tcp队列溢出呢？\u003c/p\u003e\u003cp data-pid=\"YvBsaTsS\"\u003e\u003cb\u003enetstat命令，执行netstat -s | egrep \u0026#34;listen|LISTEN\u0026#34;\u003c/b\u003e \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-83733a82b2961b9578aaea08f6073424_1440w.jpg\" data-rawwidth=\"1214\" data-rawheight=\"132\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-83733a82b2961b9578aaea08f6073424\" class=\"origin_image zh-lightbox-thumb\" width=\"1214\" data-original=\"https://pic3.zhimg.com/v2-83733a82b2961b9578aaea08f6073424_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"z1kPWfIa\"\u003e 如上图所示，overflowed表示全连接队列溢出的次数，sockets dropped表示半连接队列溢出的次数。\u003c/p\u003e\u003cp data-pid=\"aZ3qkp9S\"\u003e\u003cb\u003ess命令，执行ss -lnt\u003c/b\u003e \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-1d54ee672b91f702cc2c94bc08bb111a_1440w.jpg\" data-rawwidth=\"1228\" data-rawheight=\"106\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-1d54ee672b91f702cc2c94bc08bb111a\" class=\"origin_image zh-lightbox-thumb\" width=\"1228\" data-original=\"https://pic1.zhimg.com/v2-1d54ee672b91f702cc2c94bc08bb111a_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"261N1VAa\"\u003e 上面看到Send-Q 表示第三列的listen端口上的全连接队列最大为5，第一列Recv-Q为全连接队列当前使用了多少。\u003c/p\u003e\u003cp data-pid=\"UbfOC_vr\"\u003e接着我们看看怎么设置全连接、半连接队列大小吧：\u003c/p\u003e\u003cp data-pid=\"9GTTDNKz\"\u003e全连接队列的大小取决于min(backlog, somaxconn)。backlog是在socket创建的时候传入的，somaxconn是一个os级别的系统参数。而半连接队列的大小取决于max(64, /proc/sys/net/ipv4/tcp_max_syn_backlog)。\u003c/p\u003e\u003cp data-pid=\"mldxp-b7\"\u003e在日常开发中，我们往往使用servlet容器作为服务端，所以我们有时候也需要关注容器的连接队列大小。在tomcat中backlog叫做\u003ccode\u003eacceptCount\u003c/code\u003e，在jetty里面则是\u003ccode\u003eacceptQueueSize\u003c/code\u003e。\u003c/p\u003e\u003ch3\u003eRST异常\u003c/h3\u003e\u003cp data-pid=\"RRLk7-3N\"\u003eRST包表示连接重置，用于关闭一些无用的连接，通常表示异常关闭，区别于四次挥手。\u003c/p\u003e\u003cp data-pid=\"9b0K4Po7\"\u003e在实际开发中，我们往往会看到\u003ccode\u003econnection reset / connection reset by peer\u003c/code\u003e错误，这种情况就是RST包导致的。\u003c/p\u003e\u003cp data-pid=\"y1kbpnz3\"\u003e\u003cb\u003e端口不存在\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"ILL91qFG\"\u003e如果像不存在的端口发出建立连接SYN请求，那么服务端发现自己并没有这个端口则会直接返回一个RST报文，用于中断连接。\u003c/p\u003e\u003cp data-pid=\"PzIcMmBn\"\u003e\u003cb\u003e主动代替FIN终止连接\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"J7czK8lm\"\u003e一般来说，正常的连接关闭都是需要通过FIN报文实现，然而我们也可以用RST报文来代替FIN，表示直接终止连接。实际开发中，可设置SO_LINGER数值来控制，这种往往是故意的，来跳过TIMED_WAIT，提供交互效率，不闲就慎用。\u003c/p\u003e\u003cp data-pid=\"vbGdc-ge\"\u003e\u003cb\u003e客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"MwmoTd2J\"\u003e我们上面讲的tcp队列溢出发送RST包其实也是属于这一种。这种往往是由于某些原因，一方无法再能正常处理请求连接了(比如程序崩了，队列满了)，从而告知另一方关闭连接。\u003c/p\u003e\u003cp data-pid=\"ZsNVtZZp\"\u003e\u003cb\u003e接收到的TCP报文不在已知的TCP连接内\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"rglW6KcV\"\u003e比如，一方机器由于网络实在太差TCP报文失踪了，另一方关闭了该连接，然后过了许久收到了之前失踪的TCP报文，但由于对应的TCP连接已不存在，那么会直接发一个RST包以便开启新的连接。\u003c/p\u003e\u003cp data-pid=\"PFySt-Uh\"\u003e\u003cb\u003e一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"yRAZbgkd\"\u003e这种大多也和网络环境相关了，网络环境差可能会导致更多的RST报文。\u003c/p\u003e\u003cp data-pid=\"D8GTtHS5\"\u003e之前说过RST报文多会导致程序报错，在一个已关闭的连接上读操作会报\u003ccode\u003econnection reset\u003c/code\u003e，而在一个已关闭的连接上写操作则会报\u003ccode\u003econnection reset by peer\u003c/code\u003e。通常我们可能还会看到\u003ccode\u003ebroken pipe\u003c/code\u003e错误，这是管道层面的错误，表示对已关闭的管道进行读写，往往是在收到RST，报出\u003ccode\u003econnection reset\u003c/code\u003e错后继续读写数据报的错，这个在glibc源码注释中也有介绍。\u003c/p\u003e\u003cp data-pid=\"S8FandIv\"\u003e我们在排查故障时候怎么确定有RST包的存在呢？当然是使用tcpdump命令进行抓包，并使用wireshark进行简单分析了。\u003ccode\u003etcpdump -i en0 tcp -w xxx.cap\u003c/code\u003e，en0表示监听的网卡。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-1bee5c73806eff9c4ab3865e0ccafe35_1440w.jpg\" data-rawwidth=\"1386\" data-rawheight=\"88\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-1bee5c73806eff9c4ab3865e0ccafe35\" class=\"origin_image zh-lightbox-thumb\" width=\"1386\" data-original=\"https://picx.zhimg.com/v2-1bee5c73806eff9c4ab3865e0ccafe35_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"NyF02J4N\"\u003e接下来我们通过wireshark打开抓到的包，可能就能看到如下图所示，红色的就表示RST包了。 \u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-c66a1a6f0980872955154f5b56115aad_1440w.jpg\" data-rawwidth=\"1260\" data-rawheight=\"262\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-d59feaf6149a6d2da127c1c2e6ef097c\" class=\"origin_image zh-lightbox-thumb\" width=\"1260\" data-original=\"https://pic4.zhimg.com/v2-c66a1a6f0980872955154f5b56115aad_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eTIME_WAIT和CLOSE_WAIT\u003c/h3\u003e\u003cp data-pid=\"gJNfPTgv\"\u003eTIME_WAIT和CLOSE_WAIT是啥意思相信大家都知道。 在线上时，我们可以直接用命令\u003ccode\u003enetstat -n | awk \u0026#39;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}\u0026#39;\u003c/code\u003e来查看time-wait和close_wait的数量\u003c/p\u003e\u003cp data-pid=\"ns2-_rop\"\u003e用ss命令会更快\u003ccode\u003ess -ant | awk \u0026#39;{++S[$1]} END {for(a in S) print a, S[a]}\u0026#39;\u003c/code\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-5dcc6f7924aaca763ebc8058397611d1_1440w.jpg\" data-rawwidth=\"1204\" data-rawheight=\"146\" data-size=\"normal\" data-original-token=\"v2-5dcc6f7924aaca763ebc8058397611d1\" class=\"origin_image zh-lightbox-thumb\" width=\"1204\" data-original=\"https://pic2.zhimg.com/v2-5dcc6f7924aaca763ebc8058397611d1_r.jpg\"/\u003e\u003cfigcaption\u003eimg\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3\u003eTIME_WAIT\u003c/h3\u003e\u003cp data-pid=\"go6-5M8a\"\u003etime_wait的存在一是为了丢失的数据包被后面连接复用，二是为了在2MSL的时间范围内正常关闭连接。它的存在其实会大大减少RST包的出现。\u003c/p\u003e\u003cp data-pid=\"R6_jJMuo\"\u003e过多的time_wait在短连接频繁的场景比较容易出现。这种情况可以在服务端做一些内核参数调优:\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭\nnet.ipv4.tcp_tw_reuse = 1\n#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭\nnet.ipv4.tcp_tw_recycle = 1\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"V-WG3gQu\"\u003e当然我们不要忘记在NAT环境下因为时间戳错乱导致数据包被拒绝的坑了，另外的办法就是改小\u003ccode\u003etcp_max_tw_buckets\u003c/code\u003e，超过这个数的time_wait都会被干掉，不过这也会导致报\u003ccode\u003etime wait bucket table overflow\u003c/code\u003e的错。\u003c/p\u003e\u003ch3\u003eCLOSE_WAIT\u003c/h3\u003e\u003cp data-pid=\"F0RLMF4g\"\u003eclose_wait 往往都是因为应用程序写的有问题，没有在 ACK 后再次发起 FIN 报文。close_wait 出现的概率甚至比time_wait要更高，后果也更严重。往往是由于某个地方阻塞住了，没有正常关闭连接，从而渐渐地消耗完所有的线程。\u003c/p\u003e\u003cp data-pid=\"CSoWTE-i\"\u003e想要定位这类问题，最好是通过jstack来分析线程堆栈来排查问题，具体可参考上述章节。这里仅举一个例子。\u003c/p\u003e\u003cp data-pid=\"NT1tEafy\"\u003e开发同学说应用上线后CLOSE_WAIT就一直增多，直到挂掉为止，jstack后找到比较可疑的堆栈是大部分线程都卡在了\u003ccode\u003ecountdownlatch.await\u003c/code\u003e方法，找开发同学了解后得知使用了多线程但是确没有catch异常，修改后发现异常仅仅是最简单的升级sdk后常出现的\u003ccode\u003eclass not found\u003c/code\u003e。\u003c/p\u003e\u003cp data-pid=\"Yh9vNCE9\"\u003e获取更多干货内容，记得关注我哦。\u003c/p\u003e","is_labeled":false,"visited_count":7762,"thumbnails":["https://pica.zhimg.com/50/v2-676093d4dbb1d8a8b3a8fac7eefb3e39_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-b395132078e0367b8c39bec64c917867_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-2144f24cf9d7ce93fa8c43255c6d4ab0_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-16f6fdb6c43067ac8ee899dab60411da_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-5cea0eecd609c9548358687f51ee2d75_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-97f0f99ed4afc93c7905814fd9f087e4_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-58a741215521d5393aa0708491fc7cdb_720w.jpg?source=b6762063"],"favorite_count":1007,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1889972768910595282}","attached_info":"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","action_card":false}],"paging":{"is_end":false,"is_start":false,"next":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=down\u0026ad_interval=-10\u0026after_id=77\u0026desktop=true\u0026end_offset=77\u0026page_number=14\u0026session_token=aa7d224e06d4b31b74f64d080d9b7f56","previous":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=pull\u0026ad_interval=-10\u0026before_id=77\u0026desktop=true\u0026end_offset=77\u0026page_number=14\u0026session_token=aa7d224e06d4b31b74f64d080d9b7f56","totals":0},"fresh_text":"推荐已更新"}
