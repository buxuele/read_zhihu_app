{"data":[{"id":"6_1750899803.711","type":"feed","offset":6,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750899803,"updated_time":1750899803,"target":{"id":"1920374237232882103","type":"article","url":"https://api.zhihu.com/articles/1920374237232882103","author":{"id":"6cf4825f4e2cc49ecc844b097160ecad","url":"https://api.zhihu.com/people/6cf4825f4e2cc49ecc844b097160ecad","user_type":"people","url_token":"brisyramshere","name":"木牛流码","headline":"医学影像，LLM\u0026amp;Agent，手术机器人，机器视觉，具身智能","avatar_url":"https://pica.zhimg.com/50/v2-1c01435fbb70d5e0066c7e1249175788_l.jpg?source=b6762063","is_org":false,"gender":1,"badge":[{"type":"identity_people","description":"西安交通大学 生物医学工程硕士"}],"followers_count":14510,"is_following":false,"is_followed":false},"title":"Google提出\"充分上下文\"评估框架，根治RAG的\"强行联系\"幻觉","image_url":"https://picx.zhimg.com/v2-a84f03d03290032d5b5f712114ce4da6.jpg?source=7e7ef6e2\u0026needBackground=1","comment_permission":"all","created":1750636709,"updated":1750636709,"voteup_count":60,"voting":0,"comment_count":2,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"引言本文的核心内容基于 Google Research 发布的官方研究博客《Deeper insights into retrieval augmented generation: The role of sufficient context》，旨在深入探讨检索增强生成（RAG）系统中的一个核心挑战：模型幻觉。当前， 检索增强生成（RAG） 通过为大语言模型（LLM）提供外部知识，极大地增强了其回答问题的能力。然而，RAG系统常常会产生“幻觉”，即提供看似合理但实际上错误的答案。传统的评估方法通常关注检索到…","excerpt_new":"引言本文的核心内容基于 Google Research 发布的官方研究博客《Deeper insights into retrieval augmented generation: The role of sufficient context》，旨在深入探讨检索增强生成（RAG）系统中的一个核心挑战：模型幻觉。当前， 检索增强生成（RAG） 通过为大语言模型（LLM）提供外部知识，极大地增强了其回答问题的能力。然而，RAG系统常常会产生“幻觉”，即提供看似合理但实际上错误的答案。传统的评估方法通常关注检索到…","preview_type":"default","preview_text":"","column":{"id":"c_1893457013951922494","type":"column","url":"https://api.zhihu.com/columns/c_1893457013951922494","author":{"id":"","url":"","user_type":"people","url_token":"","name":"匿名用户","headline":"","avatar_url":"https://pica.zhimg.com/v2-d41c2ceaed8f51999522f903672a521f_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":0,"is_following":false,"is_followed":false},"title":"大模型和Agent","imageUrl":"https://picx.zhimg.com/v2-f111d7ee1c41944859e975a712c0883b_720w.jpg?source=d16d100b","comment_permission":"public","intro":"\u003cp\u003e提供LLM和Agent在技术和商业上的最新洞见。Stay hungry, Stay foolish！\u003c/p\u003e","updated":1749965513,"is_following":false},"content":"\u003ch2\u003e引言\u003c/h2\u003e\u003cp data-pid=\"So7y7bVE\"\u003e本文的核心内容基于 \u003cb\u003eGoogle Research 发布的官方研究博客\u003c/b\u003e《Deeper insights into retrieval augmented generation: The role of sufficient context》，旨在深入探讨检索增强生成（RAG）系统中的一个核心挑战：\u003cb\u003e模型幻觉\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"F4l81JXI\"\u003e当前，\u003cb\u003e检索增强生成（RAG）\u003c/b\u003e 通过为大语言模型（LLM）提供外部知识，极大地增强了其回答问题的能力。然而，RAG系统常常会产生“幻觉”，即提供看似合理但实际上错误的答案。传统的评估方法通常关注检索到的上下文与用户查询的“相关性”，但这并不能保证答案的准确性。Google的研究人员指出，我们真正需要关注的是上下文是否“充分”——即它是否包含足够的信息来让模型给出一个确切的答案。\u003c/p\u003e\u003cp data-pid=\"tU768Irt\"\u003e本文将为你揭示“\u003cb\u003e充分上下文\u003c/b\u003e”（Sufficient Context）这一全新概念，介绍一种量化其充分性的方法，分享基于此发现的对RAG系统失败原因的深刻洞见，并提出一个创新的“\u003cb\u003e选择性生成\u003c/b\u003e”框架，以有效减少模型幻觉，提升RAG系统的可靠性。\u003c/p\u003e\u003ch2\u003eRAG的核心挑战：从“相关”到“充分”\u003c/h2\u003e\u003cp data-pid=\"eTRpbok3\"\u003e在一个典型的RAG系统中，当用户提出一个问题时，系统会首先从知识库（如网页、文档库）中检索相关的上下文信息，然后将问题和这些上下文一同交给LLM，由LLM生成最终答案。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-b4b9f48f428e336ca94f6078472da830_1440w.jpg\" data-size=\"normal\" data-original-token=\"v2-b4b9f48f428e336ca94f6078472da830\" class=\"content_image\"/\u003e\u003cfigcaption\u003eRAG系统工作流程示意图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"kzlPB3Uw\"\u003eRAG系统示意图：LLM利用检索到的上下文来回应用户的输入问题。\u003c/p\u003e\u003cp data-pid=\"67KFrt_E\"\u003e这里的关键挑战在于，检索到的上下文\u003cb\u003e“相关”不等于“充分”\u003c/b\u003e。一个上下文可能与问题主题高度相关，但并未包含回答该问题的关键信息。\u003c/p\u003e\u003cp data-pid=\"sEX4hv6L\"\u003eGoogle Research对此给出了明确的定义：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"Vx3mvlK2\"\u003e\u003cb\u003e充分上下文（Sufficient Context）\u003c/b\u003e：包含回答查询所需全部信息，能够导出一个确切答案。\u003c/li\u003e\u003cli data-pid=\"c_ZSrUqo\"\u003e\u003cb\u003e不充分上下文（Insufficient Context）\u003c/b\u003e：缺少关键信息、信息不完整、存在矛盾或无法得出结论。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"kazom0lV\"\u003e让我们看一个具体的例子：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"ZCB1XyCN\"\u003e\u003cb\u003e用户提问\u003c/b\u003e：网页“Page Not Found”的404错误码，是以哪个著名实验室里储存中央错误信息数据库的404房间命名的？\u003c/li\u003e\u003cli data-pid=\"co5N2khs\"\u003e\u003cb\u003e充分上下文\u003c/b\u003e：“‘Page Not Found’错误，通常显示为404代码，是以欧洲核子研究组织（CERN）的404房间命名的。这个房间曾存放着中央错误信息数据库，其中就包括页面未找到的错误信息。”\u003c/li\u003e\u003cli data-pid=\"ARae1cVT\"\u003e\u003cb\u003e不充分上下文\u003c/b\u003e：“404错误，即‘Page Not Found’错误，表示Web服务器找不到请求的页面。这可能是由于URL拼写错误、页面被移动或删除，或网站临时问题等多种原因造成的。”\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"A5n7LmQY\"\u003e第二个上下文虽然与“404错误”高度相关，但完全没有回答“哪个实验室”这个核心问题，因此它是不充分的。仅依赖这样的上下文，模型要么无法回答，要么只能基于其内部知识进行猜测，从而产生幻각。\u003c/p\u003e\u003ch2\u003e如何衡量上下文的“充分性”？\u003c/h2\u003e\u003cp data-pid=\"qCtwwuHQ\"\u003e为了系统性地研究这一问题，研究团队开发了一个基于LLM的\u003cb\u003e自动评估器（Autorater）\u003c/b\u003e，用于判断给定的“查询-上下文”对是否构成了充分上下文。\u003c/p\u003e\u003cp data-pid=\"rQ_qHWfM\"\u003e该评估器的工作流程如下：通过精心设计的提示词（Prompt），引导一个强大的LLM（如Gemini 1.5 Pro）对输入的查询和上下文进行分析，并输出一个简单的“是”或“否”标签，判断上下文是否充分。为了提升准确性，提示词工程中运用了\u003cb\u003e思维链（Chain-of-Thought）\u003c/b\u003e 和 \u003cb\u003e单样本示例（1-shot example）\u003c/b\u003e 等策略。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-eb69fe7f878b006795d76635014d4945_1440w.jpg\" data-size=\"normal\" data-original-token=\"v2-eb69fe7f878b006795d76635014d4945\" class=\"content_image\"/\u003e\u003cfigcaption\u003e充分上下文自动评估器工作流程\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"LlKPfVXP\"\u003e自动评估器（Autorater）方法：使用经过提示优化的LLM来评估查询和上下文，输出关于上下文是否充分的二元标签。\u003c/p\u003e\u003cp data-pid=\"0jssEg1u\"\u003e为了验证评估器的可靠性，研究团队首先由人类专家标注了一个“黄金标准”数据集，然后将评估器的判断结果与人类专家的判断进行比较。结果显示，\u003cb\u003e使用Gemini 1.5 Pro的评估器在没有任何微调的情况下，准确率高达93%以上\u003c/b\u003e，优于其他基线模型（如经过微调的PaLM 2-24B或依赖标准答案的传统方法）。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-b3d26db742bf388a20744d0c1a728d7d_1440w.jpg\" data-size=\"normal\" data-original-token=\"v2-b3d26db742bf388a20744d0c1a728d7d\" class=\"content_image\"/\u003e\u003cfigcaption\u003e不同方法在分类充分上下文任务上的准确率对比\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"allNe3sw\"\u003e分类充分上下文的准确率对比，衡量了各种自动方法与人类标注标签的一致性。\u003c/p\u003e\u003cp data-pid=\"5s-AAfIq\"\u003e这个高精度的自动评估器为大规模分析RAG系统的行为提供了可能，从而得出了以下深刻洞见。\u003c/p\u003e\u003ch2\u003e基于“充分上下文”的RAG系统洞见\u003c/h2\u003e\u003cp data-pid=\"Dl2U-qO_\"\u003e借助自动评估器，研究团队对多个主流LLM和标准数据集进行了分析，揭示了RAG系统失败的几个关键原因。\u003c/p\u003e\u003ch3\u003e发现一：上下文会“误导”模型，增加幻觉\u003c/h3\u003e\u003cp data-pid=\"jQIMQF8Z\"\u003e一个令人惊讶的发现是，\u003cb\u003eRAG虽然在整体上提升了模型性能，但它在某些情况下反而增加了模型产生幻觉的倾向\u003c/b\u003e。当提供的是\u003cb\u003e不充分上下文\u003c/b\u003e时，模型不仅没能意识到信息不足而选择“拒绝回答”（例如说“我不知道”），反而因为获得了看似相关的额外信息而变得“过于自信”，从而更倾向于编造一个错误的答案。\u003c/p\u003e\u003cp data-pid=\"euXPYcLF\"\u003e下图清晰地展示了这一现象。以Gemma模型为例，在没有上下文的情况下，它对问题的回答有10.2%是错误的（幻觉）；然而，在提供了不充分上下文后，其\u003cb\u003e幻觉比例飙升至66.1%\u003c/b\u003e。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-ef4467e01d4863bf1fba8a53f8d930f2_1440w.jpg\" data-size=\"normal\" data-original-token=\"v2-ef4467e01d4863bf1fba8a53f8d930f2\" class=\"content_image\"/\u003e\u003cfigcaption\u003e三款LLM在四种不同RAG设置下的表现分析\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"pxE4lhHx\"\u003e图中对比了模型在“无上下文”、“不充分上下文”、“充分上下文”和“标准答案上下文”四种情况下的正确、幻觉和拒绝回答的比例。\u003c/p\u003e\u003ch3\u003e发现二：不同模型的表现差异\u003c/h3\u003e\u003cul\u003e\u003cli data-pid=\"ykBCEX-a\"\u003e\u003cb\u003e顶尖大模型（如Gemini, GPT, Claude）\u003c/b\u003e：在获得\u003cb\u003e充分上下文\u003c/b\u003e时表现出色，能够准确回答问题。但它们的共同弱点是，在面对\u003cb\u003e不充分上下文\u003c/b\u003e时，缺乏识别信息不足并拒绝回答的能力。\u003c/li\u003e\u003cli data-pid=\"zZhSwuP0\"\u003e\u003cb\u003e开源小模型（如Gemma）\u003c/b\u003e：即使在获得\u003cb\u003e充分上下文\u003c/b\u003e的情况下，这些模型仍然表现出较高的幻觉率和拒绝回答率，说明其理解和利用上下文的能力有待提升。\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003e发现三：基准测试集也存在上下文不足\u003c/h3\u003e\u003cp data-pid=\"ItGKeUoL\"\u003e研究还发现，许多被广泛使用的标准问答基准数据集（如FreshQA, HotPotQA, MuSiQue）本身就包含大量上下文不充分的样本。其中，由人类精心策划支持文档的数据集（如FreshQA）具有更高比例的充分上下文。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-9b874d41d19412dd4c4040c7f009aa26_1440w.jpg\" data-size=\"normal\" data-original-token=\"v2-9b874d41d19412dd4c4040c7f009aa26\" class=\"content_image\"/\u003e\u003cfigcaption\u003e三个数据集中包含充分上下文的样本比例对比\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"om52OxkP\"\u003e对比三个数据集（x轴）中具有充分上下文的示例百分比（y轴）。\u003c/p\u003e\u003cp data-pid=\"ox0Iu771\"\u003e这一发现提醒我们，在评估RAG系统时，需要更加审慎地选择和设计测试基准。\u003c/p\u003e\u003ch2\u003e解决方案：减少幻觉的选择性生成框架\u003c/h2\u003e\u003cp data-pid=\"JZ0HQAue\"\u003e基于以上洞见，研究团队提出了一种“\u003cb\u003e选择性生成\u003c/b\u003e”（Selective Generation）框架，旨在让RAG系统更智能地决定何时回答、何时拒绝，从而在\u003cb\u003e覆盖率\u003c/b\u003e（回答问题的比例）和\u003cb\u003e选择性准确率\u003c/b\u003e（在回答的问题中，答对的比例）之间取得更好的平衡。\u003c/p\u003e\u003cp data-pid=\"JZRRoYK9\"\u003e该框架的核心思想是融合两个关键信号来预测模型是否会产生幻觉：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"OWH2Hp_2\"\u003e\u003cb\u003e充分上下文信号\u003c/b\u003e：来自前述的自动评估器（Autorater）的判断结果（上下文是/否充分）。\u003c/li\u003e\u003cli data-pid=\"l3jjt0DN\"\u003e\u003cb\u003e模型自评置信度\u003c/b\u003e：模型对自己生成的答案有多大的信心。\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"vFSoC2y8\"\u003e其工作流程可以用下面的图表来概括：\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-30115f009960815606106f03c414474d_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"928\" data-rawheight=\"1708\" data-original-token=\"v2-30115f009960815606106f03c414474d\" class=\"origin_image zh-lightbox-thumb\" width=\"928\" data-original=\"https://picx.zhimg.com/v2-30115f009960815606106f03c414474d_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"Q7SBTe_7\"\u003e通过训练一个简单的逻辑回归模型来融合这两个信号，系统可以更准确地预测幻觉风险。实验结果表明，与仅使用模型自评置信度相比，\u003cb\u003e引入“充分上下文”信号的框架能够在相同的覆盖率下，将选择性准确率提升高达10%\u003c/b\u003e。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-7d37c216789b6a2b5d19ab852a137c94_1440w.jpg\" data-size=\"normal\" data-original-token=\"v2-7d37c216789b6a2b5d19ab852a137c94\" class=\"content_image\"/\u003e\u003cfigcaption\u003e选择性生成框架的效果对比\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"mwt9hkdj\"\u003e选择性准确率（y轴）与覆盖率（x轴）的权衡曲线。引入充分上下文信号（蓝色和绿色曲线）比仅使用模型置信度（橙色曲线）表现更优。\u003c/p\u003e\u003ch2\u003e结论与未来展望\u003c/h2\u003e\u003cp data-pid=\"BWmCEmEg\"\u003eGoogle Research的这项工作为我们深入理解和优化RAG系统提供了全新的视角。它明确指出了“\u003cb\u003e充分上下文\u003c/b\u003e”而非“相关上下文”才是决定RAG系统回答质量的关键。\u003c/p\u003e\u003cp data-pid=\"3VgHovi5\"\u003e通过开发自动评估工具，该研究不仅量化了上下文充分性的影响，揭示了当前RAG系统产生幻觉的核心机制，还提供了一套行之有效的“选择性生成”框架来缓解这一问题。\u003c/p\u003e\u003cp data-pid=\"G3YYkEJy\"\u003e未来的研究将继续探索不同检索方法如何影响上下文的充分性，以及如何将检索质量信号更好地融入模型训练和推理过程，从而构建更加可靠和智能的RAG系统。\u003c/p\u003e\u003cp\u003e\u003c/p\u003e","is_labeled":false,"visited_count":1940,"thumbnails":["https://picx.zhimg.com/v2-a84f03d03290032d5b5f712114ce4da6.jpg?source=7e7ef6e2\u0026needBackground=1","https://picx.zhimg.com/50/v2-9023a1c5610ed8d4eed36e4ce3994b0f_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-c6d188efe44e18b5b4c108ae93f5b6d9_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-73ccdb544de83c8b29b70c1f7f78bdec_720w.jpg?source=b6762063"],"favorite_count":179,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1920374237232882103}","attached_info":"CvIICJCog/D+yaWqoAEQBxoJMjU5NDE5NzY2IKWx4sIGKDwwAkAGSigKHVRTX1NPVVJDRV9ORUFSTElORV9DT05URU5UX1YyEgEwGAAgADoAWggxMzY2MjUxOGIgYTYwYmM5MTljOGQ4MzVkNmNlZTliYTY0MDZjYTZjZjJyEzE5MjAzNzQyMzcyMzI4ODIxMDOCAV9odHRwczovL3BpY3guemhpbWcuY29tL3YyLWE4NGYwM2QwMzI5MDAzMmQ1YjVmNzEyMTE0Y2U0ZGE2LmpwZz9zb3VyY2U9N2U3ZWY2ZTImbmVlZEJhY2tncm91bmQ9MYoBFWNfMTg5MzQ1NzAxMzk1MTkyMjQ5NKoBCXJlY29tbWVuZMIBIDZjZjQ4MjVmNGUyY2M0OWVjYzg0NGIwOTcxNjBlY2Fk8gEKCAwSBk5vcm1hbPIBKAgKEiQxMmUwN2MxYy04ZDE1LTQwNjQtYWQ3NS03MGM3ODQ2ZjdjNGHyAQUICxIBMoICAIgC+YmLzvoykgIgNmNmNDgyNWY0ZTJjYzQ5ZWNjODQ0YjA5NzE2MGVjYWSaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxl2gIdVFNfU09VUkNFX05FQVJMSU5FX0NPTlRFTlRfVjLoAgT6AgtOT1JNQUxfRkxPV4oDIGY1N2M3NjM2ZTRiZTQzNTRiZGM1MWViY2ZkZjY2NGNmmgMNCgJ2MhAAGgVvdGhlcqgDlA/YAwD6A5cDEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERTotCAIQ4gkY4AQiI3YyLWI0YjlmNDhmNDI4ZTMzNmNhOTRmNjA3ODQ3MmRhODMwOi0IBBDiCRjoBCIjdjItZWI2OWZlN2Y4NzhiMDA2Nzk1ZDc2NjM1MDE0ZDQ5NDU6LQgCEOIJGOAEIiN2Mi1iM2QyNmRiNzQyYmYzODhhMjA3NDRkMGMxYTcyOGQ3ZDotCAIQ4gkYkAciI3YyLWVmNDQ2N2UwMWQ0ODYzYmYxZmJhOGE1M2Y4ZDkzMGYyOi0IAhDiCRjgBCIjdjItOWI4NzRkNDFkMTk0MTJkZDRjNDA0MGM3ZjAwOWFhMjY6LQgEEKAHGKwNIiN2Mi0zMDExNWYwMDk5NjA4MTU2MDYxMDZmMDNjNDE0NDc0ZDotCAIQ4gkYyQIiI3YyLTdkMzdjMjE2Nzg5YjZhMmI1ZDE5YWI4NTJhMTM3Yzk0Oi0IAhDKCxiXBiIjdjItYTg0ZjAzZDAzMjkwMDMyZDViNWY3MTIxMTRjZTRkYTaABACIBACSBAZOb3JtYWyaBAE0oAQAqAQAsAQAugQCYWnCBAM0MDDIBADSBA/mjqjojZDlt7Lmm7TmlrDYBADwBAD5BAAAAMCAUqo/gQUAAAAAAAAAAIkFAAAAAAAAAACSBQCaBQNkZnSiBQNkZnSyBQExuQUAAAAAAAAAANAFAOAFAOgFAPAFApAGAKAGBqgGAZICLgoJMjU5NDE5NzY2EhMxOTIwMzc0MjM3MjMyODgyMTAzGAciCklNQUdFX1RFWFQ=","action_card":false},{"id":"7_1750899803.567","type":"feed","offset":7,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899803,"updated_time":1750899803,"target":{"id":"3577604007","type":"answer","url":"https://api.zhihu.com/answers/3577604007","author":{"id":"4bd8e5c77452f430e14df7e302753a85","url":"https://api.zhihu.com/people/4bd8e5c77452f430e14df7e302753a85","user_type":"people","url_token":"zhang-zhong-yi-23","name":"都喜","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-c2623c0497a222d55212fc1013a80f34_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":852,"is_following":false,"is_followed":false},"created_time":1722263373,"updated_time":1722263373,"voteup_count":4681,"thanks_count":297,"comment_count":237,"is_copyable":true,"question":{"id":"431966238","type":"question","url":"https://api.zhihu.com/questions/431966238","author":{"id":"efa7174fa559db6476532021bc52ebb9","url":"https://api.zhihu.com/people/efa7174fa559db6476532021bc52ebb9","user_type":"people","url_token":"yue-nu-zi-44","name":"子华女儿是厂花","headline":"子华妈妈是厂花","avatar_url":"https://pic1.zhimg.com/50/v2-59789d11a3462d6fc0f538f1cd1c0923_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":38,"is_following":false,"is_followed":false},"title":"董明珠这么凶，怎么销售第一呢？","created":1606300391,"answer_count":0,"follower_count":0,"comment_count":12,"bound_topic_ids":[4640,35417,95092],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"其实人性本贱的。 我过去习惯为客户着想，力争公司与客户之间的双赢。对此，客户有感动过，也有不少为感动、为信任而跟我合作的案例。我很自豪，从事B端业务十几年，处于并长期处于靠真诚实干来感动客户拿单的阶段。 有次某位领导介入我服务的客户，安排见面，胡说八道，恶意隐瞒，忽悠客户扩大合作。我想着，这也兑现不了啊，本着良心不喂狗，上过两次手段，使其免于入坑。奈何领导强势，善画饼，勇于承诺。客户就吃这套，决定…","excerpt_new":"其实人性本贱的。 我过去习惯为客户着想，力争公司与客户之间的双赢。对此，客户有感动过，也有不少为感动、为信任而跟我合作的案例。我很自豪，从事B端业务十几年，处于并长期处于靠真诚实干来感动客户拿单的阶段。 有次某位领导介入我服务的客户，安排见面，胡说八道，恶意隐瞒，忽悠客户扩大合作。我想着，这也兑现不了啊，本着良心不喂狗，上过两次手段，使其免于入坑。奈何领导强势，善画饼，勇于承诺。客户就吃这套，决定…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"B4H0Rkx2\"\u003e其实人性本贱的。\u003c/p\u003e\u003cp data-pid=\"aS4PQR6E\"\u003e我过去习惯为客户着想，力争公司与客户之间的双赢。对此，客户有感动过，也有不少为感动、为信任而跟我合作的案例。我很自豪，从事B端业务十几年，处于并长期处于靠真诚实干来感动客户拿单的阶段。\u003c/p\u003e\u003cp data-pid=\"1WZzbfVr\"\u003e有次某位领导介入我服务的客户，安排见面，胡说八道，恶意隐瞒，忽悠客户扩大合作。我想着，这也兑现不了啊，本着良心不喂狗，上过两次手段，使其免于入坑。奈何领导强势，善画饼，勇于承诺。客户就吃这套，决定扩大合作。\u003c/p\u003e\u003cp data-pid=\"WHOIRE58\"\u003e大半年过去，多次追加投入，形成鲜明对比：我服务时不温不火，领导牵头后有声有色。\u003c/p\u003e\u003cp data-pid=\"ZG4I9RlB\"\u003e我是边锤自己边复盘的。原来，把甲方的钱骗进来，只要骗的足够多，那么，乙方的事就变成甲方的事，骗的比不敢骗的，结果反而好得多。也没有意识到，真诚能感动客户，但没有人会为了感动，而冒着丢掉工作的风险，也没有人为了感动，而倾其所有去投入。\u003c/p\u003e\u003cp data-pid=\"rOAaI5sN\"\u003e客户心理也很微妙。最初是吃了亏又不能认，既然无法跟老板交代、跟公司财务交代，就索性选择了一起来圆谎。\u003c/p\u003e\u003cp data-pid=\"T92HwGAY\"\u003e故事的结局是：甲乙双方拧成了一股绳。\u003c/p\u003e\u003cp data-pid=\"Lp0I2jr2\"\u003e再分享一些领导的手段。见客户好面子，爱谈感情，就每次等客户谈感情时候，突然谈钱；客户爱吹牛，尤其喝了酒，开吹领导就疯狂架梯子，突然谈钱。客户投入一波接一波，领导套路一环套一环，资金投入也一笔又一笔。\u003c/p\u003e\u003cp data-pid=\"6bGm1Eo5\"\u003e我想起电影《首尔之春》全斗光对下属说的一句台词：\u003c/p\u003e\u003cp data-pid=\"Fa0frA32\"\u003e你觉不觉得人很喜欢被发号施令？人这个动物啊，就是希望有强势的人领导自己。\u003c/p\u003e\u003cp\u003e\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":352002,"favorite_count":4452,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 3577604007}","attached_info":"CuUFCJCog/D+yaWqoAEQBBoJNjgwNTQzNjYyIM3OnrUGKMkkMO0BQAdKQQosVFNfU09VUkNFX1RXT1RPV0VSX1NIT1JUSU5URVJFU1RfUkVDQUxMX1RFWFQSATAYACAAOgp7InJhdyI6IiJ9Wgg1ODI3MTQ3NGIgYTYwYmM5MTljOGQ4MzVkNmNlZTliYTY0MDZjYTZjZjJyCjM1Nzc2MDQwMDeKAQk0MzE5NjYyMziqAQlyZWNvbW1lbmTCASA0YmQ4ZTVjNzc0NTJmNDMwZTE0ZGY3ZTMwMjc1M2E4NfIBCggMEgZOb3JtYWzyASgIChIkYmQzN2U0OGYtYTJkYS00OWM5LThlMjYtMGY0YmJmYzA2ZGQx8gEFCAsSATKCAgCIAvmJi876MpICIDRiZDhlNWM3NzQ1MmY0MzBlMTRkZjdlMzAyNzUzYTg1mgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZcoCFENvbnRlbnRBZ2VXZWlnaHRSdWxl2gIsVFNfU09VUkNFX1RXT1RPV0VSX1NIT1JUSU5URVJFU1RfUkVDQUxMX1RFWFToAgL6AgtOT1JNQUxfRkxPV4oDIGY1N2M3NjM2ZTRiZTQzNTRiZGM1MWViY2ZkZjY2NGNmmgMNCgJ2MhAAGgVvdGhlcqgDgr4V2AMA6gMaZmVlZF9hdHRtX3R3b3Rvd2VyX3YyX3RleHT6Ax8SDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFgAQAiAQAkgQGTm9ybWFsmgQBMqAEAKgEALAEALoEBm1hbnVhbMIEAzE2MMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAwGNLyD+BBQAAAAAAAAAAiQUAAAAAAAAAAJIFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AUCkAYAoAYHqAYAkgIlCgk2ODA1NDM2NjISCjM1Nzc2MDQwMDcYBCIKSU1BR0VfVEVYVA==","action_card":false},{"id":"8_1750899803.667","type":"feed","offset":8,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899803,"updated_time":1750899803,"target":{"id":"1919122945722266087","type":"answer","url":"https://api.zhihu.com/answers/1919122945722266087","author":{"id":"46bb318fc4557af1aa7a46f89b18fe45","url":"https://api.zhihu.com/people/46bb318fc4557af1aa7a46f89b18fe45","user_type":"people","url_token":"caleb89","name":"caleb89","headline":"生命没有本质的意义，它仅依赖欲望和幻想得以运转","avatar_url":"https://pic1.zhimg.com/50/v2-e5f4db4f0779c6a499e582d072dbe809_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":2086,"is_following":false,"is_followed":false},"created_time":1750334565,"updated_time":1750334687,"voteup_count":43,"thanks_count":3,"comment_count":3,"is_copyable":true,"question":{"id":"1915885793936938303","type":"question","url":"https://api.zhihu.com/questions/1915885793936938303","author":{"id":"645068ffd4e333cea35bc4ee6e222e9d","url":"https://api.zhihu.com/people/645068ffd4e333cea35bc4ee6e222e9d","user_type":"people","url_token":"v1tv6l","name":"小谢","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-186d86c0e8504226a3bf906876d2169d_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":5,"is_following":false,"is_followed":false},"title":"自学数学可以走多远？","created":1749562768,"answer_count":0,"follower_count":0,"comment_count":3,"bound_topic_ids":[1291,91199],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"实际上，现在有了大模型帮忙（最好用国外的比如chatgpt或gemini），你完全可以靠自己学习大部分本科数学系课程。 首先让大模型给你个计划，往哪个方向学习，大概每一块需要多少时间，让它给你介绍一些领域大概是干什么的。 你直接用大模型帮你找一本著名的好教材，把目录拍下来给ai，它就可以给你建议，哪部分是讲什么的，适不适合你学，哪部分是整本书的基础和核心，哪部分是扩展和下一课的基础，你可以据此选择。 到了具体的内…","excerpt_new":"实际上，现在有了大模型帮忙（最好用国外的比如chatgpt或gemini），你完全可以靠自己学习大部分本科数学系课程。 首先让大模型给你个计划，往哪个方向学习，大概每一块需要多少时间，让它给你介绍一些领域大概是干什么的。 你直接用大模型帮你找一本著名的好教材，把目录拍下来给ai，它就可以给你建议，哪部分是讲什么的，适不适合你学，哪部分是整本书的基础和核心，哪部分是扩展和下一课的基础，你可以据此选择。 到了具体的内…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"Es5Oj-nY\"\u003e实际上，现在有了大模型帮忙（最好用国外的比如chatgpt或gemini），你完全可以靠自己学习大部分本科数学系课程。\u003c/p\u003e\u003cp data-pid=\"ZsY0gTG_\"\u003e首先让大模型给你个计划，往哪个方向学习，大概每一块需要多少时间，让它给你介绍一些领域大概是干什么的。\u003c/p\u003e\u003cp data-pid=\"K3yt0gWy\"\u003e你直接用大模型帮你找一本著名的好教材，把目录拍下来给ai，它就可以给你建议，哪部分是讲什么的，适不适合你学，哪部分是整本书的基础和核心，哪部分是扩展和下一课的基础，你可以据此选择。\u003c/p\u003e\u003cp data-pid=\"9LwSY0OZ\"\u003e到了具体的内容，看不懂的证明可以直接给大模型解释，习题不懂可以让大模型帮忙，学会了例子可以让它给你拓展学习，笔记可以写个思路，让大模型给你生成latex笔记。\u003c/p\u003e\u003cp data-pid=\"M8VeAEI_\"\u003e如果我本科时有大模型，我可以自己一个人用当年一半不到的时间完成本科课程的学习。\u003c/p\u003e\u003cp data-pid=\"JxmlDJ2L\"\u003e再往后，到了研究生阶段数学，至少目前还是离不开人类导师的指导和同学讨论，这就取决于你的学校了。等你学完了本科数学后两年的一门课程，再来考虑“往后走多远”的问题吧。\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":3262,"favorite_count":65,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1919122945722266087}","attached_info":"CuIFCJCog/D+yaWqoAEQBBoJNzMzMDIyMjUzIOX4z8IGKCswA0AISicKHFRTX1NPVVJDRV9DT05DRVBUX1dPUkRfTUVSR0USATAYACAAOgBKKAodVFNfU09VUkNFX05FQVJMSU5FX0NPTlRFTlRfVjISATAYACAAOgBaCTExNTMyOTMwNWIgYTYwYmM5MTljOGQ4MzVkNmNlZTliYTY0MDZjYTZjZjJyEzE5MTkxMjI5NDU3MjIyNjYwODeKARMxOTE1ODg1NzkzOTM2OTM4MzAzqgEJcmVjb21tZW5kwgEgNDZiYjMxOGZjNDU1N2FmMWFhN2E0NmY4OWIxOGZlNDXyAQoIDBIGTm9ybWFs8gEoCAoSJGNiZTJkNGVlLWQ0YzQtNDQwNi05NjZlLTdmODBiMDllOWFkZPIBBQgLEgEyggIAiAL5iYvO+jKSAiA0NmJiMzE4ZmM0NTU3YWYxYWE3YTQ2Zjg5YjE4ZmU0NZoCAMoCFlNob3JJbnRlcmVzdFdlaWdodFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXaAhxUU19TT1VSQ0VfQ09OQ0VQVF9XT1JEX01FUkdF6AIC+gILTk9STUFMX0ZMT1eKAyBmNTdjNzYzNmU0YmU0MzU0YmRjNTFlYmNmZGY2NjRjZpoDDQoCdjIQABoFb3RoZXKoA74Z2AMA6gMhQ29uY2VwdFdvcmRNZXJnZU5ld1YxUG9vbFJlY2FsbGVy+gMfEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERYAEAIgEAJIEBk5vcm1hbJoEATKgBACoBACwBAC6BAJhacIEAzQwMMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAA4CcFwT+BBQAAAAAAAAAAiQUAAAAAAAAAAJIFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AUCkAYAoAYIqAYDkgIuCgk3MzMwMjIyNTMSEzE5MTkxMjI5NDU3MjIyNjYwODcYBCIKSU1BR0VfVEVYVA==","action_card":false},{"id":"9_1750899803.555","type":"feed","offset":9,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899803,"updated_time":1750899803,"target":{"id":"2903083277","type":"answer","url":"https://api.zhihu.com/answers/2903083277","author":{"id":"3659e8cc5e319e53f1c803cd15134149","url":"https://api.zhihu.com/people/3659e8cc5e319e53f1c803cd15134149","user_type":"people","url_token":"da-xu-57-55","name":"发广告的助理员","headline":"喜欢冒险，一个走大运的城市探险爱好者+无神论者。","avatar_url":"https://picx.zhimg.com/50/v2-ae10f7a463028cdc5759b7f19ea78ad9_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":6635,"is_following":false,"is_followed":false},"created_time":1676904841,"updated_time":1707570074,"voteup_count":19355,"thanks_count":2787,"comment_count":1055,"is_copyable":true,"question":{"id":"21468587","type":"question","url":"https://api.zhihu.com/questions/21468587","author":{"id":"","url":"","user_type":"people","url_token":"","name":"匿名用户","headline":"","avatar_url":"https://pic1.zhimg.com/v2-d41c2ceaed8f51999522f903672a521f_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":0,"is_following":false,"is_followed":false},"title":"不住酒店可以去哪过夜？","created":1376300774,"answer_count":0,"follower_count":0,"comment_count":27,"bound_topic_ids":[307,1525,3946,4728,5582],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"一直玩城市探险，所以这方面有点经验，分享一下，我就不说别人回答的网吧、洗浴、火车站啥的了，说点平常人不知道的，图片后补，我都留着呢，先说正常点的: 1.首推高档的写字楼区，但是只有大城市有，有的楼层是对外出租的状态，挂的门锁都是样子，如果真锁了，放心，一般都有后门是开的，因为要方便中介，里面大多数都会有桌椅，运气好，还能碰到沙发，或者老板椅，洗手间也可以用，水电都还在，也安静，只要你不开灯，晚上中介…","excerpt_new":"一直玩城市探险，所以这方面有点经验，分享一下，我就不说别人回答的网吧、洗浴、火车站啥的了，说点平常人不知道的，图片后补，我都留着呢，先说正常点的: 1.首推高档的写字楼区，但是只有大城市有，有的楼层是对外出租的状态，挂的门锁都是样子，如果真锁了，放心，一般都有后门是开的，因为要方便中介，里面大多数都会有桌椅，运气好，还能碰到沙发，或者老板椅，洗手间也可以用，水电都还在，也安静，只要你不开灯，晚上中介…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"KZhWVZRy\"\u003e一直玩城市探险，所以这方面有点经验，分享一下，我就不说别人回答的网吧、洗浴、火车站啥的了，说点平常人不知道的，图片后补，我都留着呢，先说正常点的:\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"p4tZZKCX\"\u003e1.首推高档的写字楼区，但是只有大城市有，有的楼层是对外出租的状态，挂的门锁都是样子，如果真锁了，放心，一般都有后门是开的，因为要方便中介，里面大多数都会有桌椅，运气好，还能碰到沙发，或者老板椅，洗手间也可以用，水电都还在，也安静，只要你不开灯，晚上中介和保安不会去。也好找，直接网上打电话给中介就可以了，都能给你介绍全了，好找，安静，安全，水电方便。你要能遇到共享办公大面积出租的，那种有的还有健身房能洗澡，和带微波炉的餐厅。我住过多次几个不同城市的，因为传有阿飘，所以住里看看。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"QHDgsKH3\"\u003e2.第二选，大型酒店，自带舞台出租或者婚礼舞台的那种，这种得找五星级的最好，五星级的24小时，别的级别低的，晚上爱锁门。舞台的那个区域，晚上太多数锁门，但是跟舞台配套的化妆间，或者放椅子桌子的仓库间，一般不锁们，最惨点，洗手间肯定不锁，运气好点，舞台的vip室不锁，只要场地拉灯，也就代表他不会再来人了，保安一般也不会来，反正我是从来没有遇到过，但是有很早就开门的时候，但是也没事，你正常收拾起来走就行，服务员不会管你，也是好找，安全，安静，水电都有。这种到现在睡过2次，一次是在网上盛传12点舞台有阿飘唱戏的那个，上半夜睡仓库，下半夜睡洗手间。第二次是和同伙住酒店，他打呼噜我实在睡不着，你自己出来找地，本来想睡酒店大厅的，结果发现舞台的vip室太完美了，淋浴都带。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"4fgBgUQo\"\u003e3.第三选公寓楼，最好是大量民宿和个人住宅混的高层建筑，然后你去楼梯间，绝对能找到椅子，床垫，或者沙发，一般我是直接往顶层去，有沙发或者床垫的几率特别大，也安静，有时还能遇到野战的，缺点是水电不方便，去洗手间特麻烦，但是有一个特别的好处，只要你有心去转转没准能遇到，哪家钥匙没拔还在防盗门上的，我是直接拔走，然后手写一个失物招领贴电梯里，给我来电话就要点好处，好找，但是不安全也不安静，有的还没有水电，去洗手间都麻烦，但是非常有意思，每次新城市探险，我都必有这个环节，只不过我是住民宿里。有时候一晚上，光靠钥匙这事，能小赚一笔。同时，捡外卖（别人吃几口或者没吃扔的），捡别人扔的完好无损的东西也总能遇到。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"2rdWTIdC\"\u003e4.第四选，高档小区，小区里有活动室那种的，有的活动室是24小时不关门，打麻将，乒乓球，唱歌的那种，缺点是有保安巡楼，那帮大爷大娘有的打麻将还特晚，但是有的小区活动室，还是可以的，这种得碰，看运气了，运气好了，麻将桌抽屉里还有钱呢，住过5次，一次是轰趴晚上住别墅，别墅挨着活动室，活动室整的跟会馆一样，但是没人管，剩下的都是传有阿飘去探险时发现的。最惨的一次是看下别人打通宵的麻将，然后我们在顶楼的电梯房里，被保安赶出去。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"WZoKEnvD\"\u003e5.第五选当地的大型批发市场，那里晚上都相当的热闹，一般大仓库，都有给装卸工人，备的床。或者能睡觉床垫。我发现这个，是城市探险去凌晨去批发市场看时，走累了，发现大库里，放着的床，挺脏的，坐床上了好久也没有人管，但是天亮时就不行了，因为库管要锁门了。在这里过夜就是真没办法了，但是这里有个好处，你问几个库，大概率能找到个力工的临时活，就看给多少了。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"oo8EyEPR\"\u003e6.第六选医院，但是医院不安全，口罩前，住的几次，都被偷了，而且不安静，患者的呻吟声，没法形容。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"gipjyZzZ\"\u003e再说点不正常的:\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"YZiHm_pH\"\u003e1.殡仪馆，这个也是我探险最常去的地方，好找，安静，安全，各种有意思的事。但是这个地方首先胆小的人不行，殡仪馆里，公共区域每个房间不会锁门，全国各地都一样，大多数洗手间的那个门都锁不上，水电都有，还是热水，有的淋浴也有，就看你有没有胆量洗了，每个城市，我是必去的地方，我个人也不咋怕这些事，房间里的大沙发，特别舒服，在这我睡觉质量反而特别好，因为我总是感觉不一般的安静，也做过奇怪的梦，但是从没有噩梦，还有空调，如果碰上别人家守7天的，还能混吃混喝（他们都吃不下去，好多都是放门口不要了，或者你直接拿，别人啥都不会说），这里的故事也特别的多，医院里能看到特别多的祈祷，在这里，是咋分财产，咋感悟人生，反正这里比医院还有人间百态，也有来这野战的，还有放弃自己前看看自己要躺的地方啥样的，我从来没有被工作人员赶走过，还有个有意思的事，太多数还夏天没有蚊子和苍蝇，不光是空调冷气的原因。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"UzqKEfSz\"\u003e2.废村，一般去城镇探险，这种地方总要去，现在非常多村子都是荒废的，没有几户人，有的就是没人了，那些房子都是防君子不防小人，有的是门就没锁，能长住，水电都有，自己再种地都能自给自足了，但是缺点特别多，一是有流浪的人，有的人有精神病，特别危险，废村还有成群的野狗，不怕人，有的晚上还不怕火，去废村探险，我都是要带着皮鞭子，能抽出很响的声音那种，皮鞭容易携带，狗还不至于咬到松口不放。最开始没经验拿甩棍，血淋淋的教训。二是晚上我住时，睡觉必做噩梦，有时不住房子里，睡车里都是必做噩梦，住房子里时，直播开着，大照明灯开着，房子一室没多大，但是就能感觉到屋里很吵，不安静，让人心慌，比睡山里或者城市废弃建筑都难受，做噩梦有人掐脖子时，醒来都还能感觉到窒息，和我一起的小伙伴就不这样，跟住废村的流浪汉聊过，他们告诉我要住野狗住过的地方，或者自己养狗住才行。我不知道是不是废村都这样，还是我们专往传有阿飘的地方住，才这样。废村这个地方，还是适合命硬的人去，不担心我说的问题的话，其他都是挺好的。\u003c/p\u003e\u003cp data-pid=\"GD2OAnHC\"\u003e3.海、湖、江、河，有废船的地方，这个要看地区了，口罩期间去过几个地方非常好，都是观光用的，没人玩了也就废那了，但是设施都是齐全的，一时半会还没人管，缺点是虫子真多，城市外的还没水电，特别适合钓鱼佬，这些地方除了探险圈知名的，剩下都是钓鱼佬告诉我的。能住人，有的就是城市热门商圈里，但是不推荐。\u003c/p\u003e\u003cp data-pid=\"555RjIxZ\"\u003e4.废弃的旅游区/建筑群，这个每个城市基本都有，或者有的不是废弃的，但是人少的都废弃一样了，基本都是流浪汉聚集地了，因为城市里主要生活区有人管，公园、ATM，桥下都没法住的城市，你去废弃旅游区看，绝对一大堆流浪汉，废弃旅游区，要比烂尾楼抢手，因为配套设施全，环境好，有的比正常的老破旧小区还好，有的地方已经形成了帮派。我估计口罩结束后，都要能形成产业链了。这样的地方一个是问收废品的人找，一个是问银行，他们手里不良资产抵押（装公司的名义聊）。这里能长期住，但是要融入帮派/老乡会里。\u003c/p\u003e\u003cp data-pid=\"kswM-16p\"\u003e5.大山/旅游区里的空庙或者塔（有信仰的那种）。首先我自己没住过，圈里住过的人都没太平过，邪的很，晚上探险去过，也没遇到过流浪汉，谁住过可以分享下，我最多是住车里，停那附近，或者搭帐篷住旁边，而且住这种地方，不止一次听过山啸，不知道各位懂不懂啥意思。\u003c/p\u003e\u003cp data-pid=\"XZrTT1C7\"\u003e6.正常的庙，但是这种地方都远离市区的多，管住还管吃，帮庙里干点活就行，之前探险完总做噩梦被掐脖子，就去庙里住过，但是我是捐了香火的，不过我知道也有一分钱没有住的。\u003c/p\u003e\u003cp data-pid=\"hPmG7646\"\u003e7.热门购物商圈，比如万达金街那种，这样的商圈，一般都有游客休息区（你找不到不是没有，有的在二层或者背街），大多数还24小时，但是我见的都是椅子多，沙发少（那种智能按摩付费的），我见的几次是为了拍早起商店开门的素材，保安倒是没管过我，也可能是看我们拿摄像器材的缘故\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"hyWPz-zB\"\u003e未完待续\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"-HLfopoh\"\u003e2024年2月10日。这篇内容，有一年了，这一年收获特别多，我也尝试了非常多种不在酒店过夜的方式，有时间分享给大家。\u003c/p\u003e\u003cp data-pid=\"xGXWTHu9\"\u003e*每条评论我都回复了，但是我发现有不显示的，看来被系统吃了，哈，\u003c/p\u003e\u003cp data-pid=\"gbs50NVC\"\u003e*自己推荐下，自己写得\u003ca href=\"https://www.zhihu.com/answer/2930634127\" class=\"internal\" target=\"_blank\"\u003e\u003cspan class=\"invisible\"\u003ehttps://www.\u003c/span\u003e\u003cspan class=\"visible\"\u003ezhihu.com/answer/293063\u003c/span\u003e\u003cspan class=\"invisible\"\u003e4127\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":1514832,"favorite_count":21386,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 2903083277}","attached_info":"CocGCJCog/D+yaWqoAEQBBoJNTU3OTE3MjY3IImTzp8GKJuXATCfCEAJSj8KKlRTX1NPVVJDRV9aUkVDQUxMX0ZFRURSRV9ORVdCSUVfSE9VUkxZX1JVTRIBMBgAIAA6CnsicmF3IjoiIn1KMAobVFNfU09VUkNFX0JBU0lDX0lORk9fUkVDQUxMEgEwGAAgADoKeyJyYXciOiIifVoGNzY4MTM1YiBhNjBiYzkxOWM4ZDgzNWQ2Y2VlOWJhNjQwNmNhNmNmMnIKMjkwMzA4MzI3N4oBCDIxNDY4NTg3qgEJcmVjb21tZW5kwgEgMzY1OWU4Y2M1ZTMxOWU1M2YxYzgwM2NkMTUxMzQxNDnyAQoIDBIGTm9ybWFs8gEoCAoSJGE2ODA2YzRhLTE2ZmUtNDhlYi1iOWUxLTQxNWZlMGU1MmU3ZfIBBQgLEgEyggIAiAL5iYvO+jKSAiAzNjU5ZThjYzVlMzE5ZTUzZjFjODAzY2QxNTEzNDE0OZoCAMoCFlNob3JJbnRlcmVzdFdlaWdodFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXKAhRDb250ZW50QWdlV2VpZ2h0UnVsZdoCKlRTX1NPVVJDRV9aUkVDQUxMX0ZFRURSRV9ORVdCSUVfSE9VUkxZX1JVTegCAvoCC05PUk1BTF9GTE9XigMgZjU3Yzc2MzZlNGJlNDM1NGJkYzUxZWJjZmRmNjY0Y2aaAw0KAnYyEAAaBW90aGVyqAPQulzYAwDqAxBuZXdiaWVfZmVlZHJlX3Yy+gMfEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERYAEAIgEAJIEBk5vcm1hbJoEATKgBACoBACwBAC6BAZtYW51YWzCBAMxNzDIBADSBA/mjqjojZDlt7Lmm7TmlrDYBADwBAD5BAAAAABNgcE/gQUAAAAAAAAAAIkFAAAAAAAAAACSBQCaBQNkZnSiBQNkZnSyBQExuQUAAAAAAAAAANAFAOAFAOgFAPAFApAGAKAGCagGAJICJQoJNTU3OTE3MjY3EgoyOTAzMDgzMjc3GAQiCklNQUdFX1RFWFQ=","action_card":false},{"id":"10_1750899803.450","type":"feed","offset":10,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899803,"updated_time":1750899803,"target":{"id":"1921262829786342539","type":"answer","url":"https://api.zhihu.com/answers/1921262829786342539","author":{"id":"c44bc09dc1afb4ad601bb27b82105549","url":"https://api.zhihu.com/people/c44bc09dc1afb4ad601bb27b82105549","user_type":"people","url_token":"52-77-35-36-44-96","name":"恁个锤锤哦","headline":"人生很短，幸福很小；人生很长，幸福很远","avatar_url":"https://picx.zhimg.com/50/v2-cf8d195ed349e95ade3d5ce57f20b7c3_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":0,"is_following":false,"is_followed":false},"created_time":1750844753,"updated_time":1750844753,"voteup_count":1,"thanks_count":0,"comment_count":0,"is_copyable":true,"question":{"id":"637473468","type":"question","url":"https://api.zhihu.com/questions/637473468","author":{"id":"052e0913c98c99567e6b9e3949affc88","url":"https://api.zhihu.com/people/052e0913c98c99567e6b9e3949affc88","user_type":"people","url_token":"yv79o6","name":"知乎用户YV79o6","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-93790dcca79047dc9376be740378d83a_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":6,"is_following":false,"is_followed":false},"title":"吃得苦中苦，就能成为人上人吗?","created":1704018262,"answer_count":0,"follower_count":0,"comment_count":55,"bound_topic_ids":[405,452019,2870992],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"只要愿意吃苦，就有吃不完的苦。勤劳从来不是致富的原因，苦难就只是苦难而已，它不是成功的原因也不是成功的必须条件，顶多只能增加个人的性格韧性。如果不能承受更多人是被打击至一蹶不振，经历苦难还能成功的属于幸存者偏差，世上苦难千千万万你却只看到所谓“成功”的人，背后被现实所摧残、蹂躏的人才是绝大多数。","excerpt_new":"只要愿意吃苦，就有吃不完的苦。勤劳从来不是致富的原因，苦难就只是苦难而已，它不是成功的原因也不是成功的必须条件，顶多只能增加个人的性格韧性。如果不能承受更多人是被打击至一蹶不振，经历苦难还能成功的属于幸存者偏差，世上苦难千千万万你却只看到所谓“成功”的人，背后被现实所摧残、蹂躏的人才是绝大多数。","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"hiWs-jiH\"\u003e只要愿意吃苦，就有吃不完的苦。勤劳从来不是致富的原因，苦难就只是苦难而已，它不是成功的原因也不是成功的必须条件，顶多只能增加个人的性格韧性。如果不能承受更多人是被打击至一蹶不振，经历苦难还能成功的属于幸存者偏差，世上苦难千千万万你却只看到所谓“成功”的人，背后被现实所摧残、蹂躏的人才是绝大多数。\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":true,"visited_count":4,"favorite_count":0,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1921262829786342539}","attached_info":"Ct4FCJCog/D+yaWqoAEQBBoJNzMzOTc1Mjk1INGK78IGKAEwAEAKSiQKGVRTX1NPVVJDRV9XQVJNX1VQX05PUk1BTDESATAYACAAOgBaCTEwMzkzOTA1NWIgYTYwYmM5MTljOGQ4MzVkNmNlZTliYTY0MDZjYTZjZjJyEzE5MjEyNjI4Mjk3ODYzNDI1MzmKAQk2Mzc0NzM0NjiqAQlyZWNvbW1lbmTCASBjNDRiYzA5ZGMxYWZiNGFkNjAxYmIyN2I4MjEwNTU0OfIBCggMEgZOb3JtYWzyASgIChIkMzViZjZhMGQtMWM0ZC00NmFiLTkwMTQtNGRkYTRkMWQyZTVk8gEFCAsSATKCAgCIAvmJi876MpICIGM0NGJjMDlkYzFhZmI0YWQ2MDFiYjI3YjgyMTA1NTQ5mgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCG0ludGVyYWN0aW9uU2hvckludGVyZXN0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZcoCGENvbnRlbnRXYXJtVXBCcmVha0luUnVsZdoCGVRTX1NPVVJDRV9XQVJNX1VQX05PUk1BTDHoAgL6AgtOT1JNQUxfRkxPV4oDIGY1N2M3NjM2ZTRiZTQzNTRiZGM1MWViY2ZkZjY2NGNmmgMNCgJ2MhAAGgVvdGhlcqgDBNgDAOoDH3RleHRfMTJob3VyX3VuaWZpbnNoZWRfcmVjYWxsZXL6Ax8SDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFgAQAiAQAkgQGTm9ybWFsmgQBMqAEAKgEALAEALoEAmFpwgQDNDAwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAABA4dyjP4EFAAAAAAAAAACJBQAAAAAAAAAAkgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBQKQBgCgBgqoBgGSAi4KCTczMzk3NTI5NRITMTkyMTI2MjgyOTc4NjM0MjUzORgEIgpJTUFHRV9URVhU","action_card":false},{"id":"11_1750899803.169","type":"feed","offset":11,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899803,"updated_time":1750899803,"target":{"id":"1917366994363221055","type":"answer","url":"https://api.zhihu.com/answers/1917366994363221055","author":{"id":"908898ccce21201228bf9016b4021316","url":"https://api.zhihu.com/people/908898ccce21201228bf9016b4021316","user_type":"people","url_token":"zhang-hai-xian-44","name":"默歌尽微凉1024","headline":"苦涩回忆，总会温柔","avatar_url":"https://picx.zhimg.com/50/v2-310ce682e3b4e640ff7ab4f5bb702855_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":597,"is_following":false,"is_followed":false},"created_time":1749915914,"updated_time":1749916707,"voteup_count":6,"thanks_count":0,"comment_count":1,"is_copyable":true,"question":{"id":"661343984","type":"question","url":"https://api.zhihu.com/questions/661343984","author":{"id":"07d666c1f4863337f2713157611dca58","url":"https://api.zhihu.com/people/07d666c1f4863337f2713157611dca58","user_type":"people","url_token":"26-15-19-31-55","name":"乐天派美少女","headline":"","avatar_url":"https://pica.zhimg.com/50/v2-23e8163c87782d115fda9bb2878f604a_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":8,"is_following":false,"is_followed":false},"title":"如何理解智能的本质？","created":1720691340,"answer_count":0,"follower_count":0,"comment_count":4,"bound_topic_ids":[350,4121,188574,1963575],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"thumbnail":"https://picx.zhimg.com/50/v2-4a7a6c5816b002a73a48483277484e8c_720w.jpg?source=b6762063","excerpt":"如何理解智能的本质？从“压缩即智能”到多维宇宙的演化 一、预测即压缩，压缩即智能 2023年，OpenAI前首席科学家Ilya Sutskever提出颠覆性观点： “预测即压缩，压缩即智能” （Prediction is compression, and compression is intelligence）。这一论断揭示了智能的底层逻辑： 预测的本质是压缩 ：当AI预测下一个词（如GPT生成文本），实际是在提取数据中的规律与模式，将海量信息压缩为简洁的数学表示（如神经网络权重）。…","excerpt_new":"如何理解智能的本质？从“压缩即智能”到多维宇宙的演化 一、预测即压缩，压缩即智能 2023年，OpenAI前首席科学家Ilya Sutskever提出颠覆性观点： “预测即压缩，压缩即智能” （Prediction is compression, and compression is intelligence）。这一论断揭示了智能的底层逻辑： 预测的本质是压缩 ：当AI预测下一个词（如GPT生成文本），实际是在提取数据中的规律与模式，将海量信息压缩为简洁的数学表示（如神经网络权重）。…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"SDlmErTC\"\u003e​\u003cb\u003e如何理解智能的本质？从“压缩即智能”到多维宇宙的演化\u003c/b\u003e​\u003c/p\u003e\u003ch3\u003e​\u003cb\u003e一、预测即压缩，压缩即智能\u003c/b\u003e​\u003c/h3\u003e\u003cp data-pid=\"njxXv95G\"\u003e2023年，OpenAI前首席科学家Ilya Sutskever提出颠覆性观点：​\u003cb\u003e​“预测即压缩，压缩即智能”​\u003c/b\u003e​（Prediction is compression, and compression is intelligence）。这一论断揭示了智能的底层逻辑：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"R0ma70dm\"\u003e​\u003cb\u003e预测的本质是压缩\u003c/b\u003e​：当AI预测下一个词（如GPT生成文本），实际是在提取数据中的\u003cb\u003e规律与模式\u003c/b\u003e，将海量信息压缩为简洁的数学表示（如神经网络权重）。例如，字符串“ababab”可压缩为“重复‘ab’三次”，而非存储每个字符。\u003c/li\u003e\u003cli data-pid=\"SKMuyi1C\"\u003e​\u003cb\u003e压缩的本质是智能\u003c/b\u003e​：高效压缩要求系统理解数据的“本质规律”。信息论中的\u003cb\u003eKolmogorov复杂度\u003c/b\u003e指出：一个对象的智能程度取决于\u003cb\u003e生成它的最短程序长度\u003c/b\u003e——程序越短，压缩越高效，智能水平越高。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"P4ynzavJ\"\u003e例如：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"i1mDCU12\"\u003e字符串 \u003ccode\u003e0000000000\u003c/code\u003e → 程序 \u003ccode\u003eprint \u0026#39;0\u0026#39; 10 times\u003c/code\u003e（低复杂度，高智能）\u003c/li\u003e\u003cli data-pid=\"BFjwtvxo\"\u003e随机字符串 \u003ccode\u003ex7\u0026amp;9@!#z\u003c/code\u003e → 几乎无法压缩（高复杂度，低智能）\u003c/li\u003e\u003c/ul\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-d88885a2cd31ab60e7d69e21256047fa_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1851\" data-rawheight=\"1042\" data-original-token=\"v2-eed2d6d56c9883b1bcba7e2f326e7f03\" data-default-watermark-src=\"https://pica.zhimg.com/v2-de8a8622d5607a1951b51653d7b74e54_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1851\" data-original=\"https://pic1.zhimg.com/v2-d88885a2cd31ab60e7d69e21256047fa_r.jpg\"/\u003e\u003c/figure\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-7d64a401346b48fe62a13b0452c2b63b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1706\" data-rawheight=\"959\" data-original-token=\"v2-71fc385a09842c5e20a0420683f4199d\" data-default-watermark-src=\"https://pic1.zhimg.com/v2-7cd755de8e7a4c07389c8636b0bcaeea_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1706\" data-original=\"https://pic4.zhimg.com/v2-7d64a401346b48fe62a13b0452c2b63b_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"ptEUl-sz\"\u003eIlya 在 Simons Institute 的讲座\u003c/p\u003e\u003cp data-pid=\"j6sR2UhL\"\u003eYouTube:\u003c/p\u003e\u003ca href=\"https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DAKMuA_TVz3A\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://www.\u003c/span\u003e\u003cspan class=\"visible\"\u003eyoutube.com/watch?\u003c/span\u003e\u003cspan class=\"invisible\"\u003ev=AKMuA_TVz3A\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003cp data-pid=\"4yPl-M71\"\u003eLecture page:\u003c/p\u003e\u003ca href=\"https://link.zhihu.com/?target=https%3A//simons.berkeley.edu/talks/ilya-sutskever-openai-2023-08-14\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003esimons.berkeley.edu/tal\u003c/span\u003e\u003cspan class=\"invisible\"\u003eks/ilya-sutskever-openai-2023-08-14\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003cp data-pid=\"_w-YV0WD\"\u003e​\u003c/p\u003e\u003cp data-pid=\"8PsE85PN\"\u003e\u003cb\u003e压缩与智能的等价性\u003c/b\u003e，成为理解AI大模型的核心钥匙。\u003c/p\u003e\u003cp data-pid=\"OTPn4S0M\"\u003e从一定程度来说，当前爆火的\u003cb\u003e大模型是目前最好的无损数据压缩器。\u003c/b\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-0d97ee86777c081adf15fd1144f4840f_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"848\" data-rawheight=\"426\" data-original-token=\"v2-21e049dca7d8d7044cac1c0de8dce7ff\" data-default-watermark-src=\"https://pic3.zhimg.com/v2-d93717404f350a03fb1779159aaf3eba_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"848\" data-original=\"https://pic2.zhimg.com/v2-0d97ee86777c081adf15fd1144f4840f_r.jpg\"/\u003e\u003cfigcaption\u003e图源：https://mp.weixin.qq.com/s/tSj9npIPg8IlYr2jbtg-Og\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3\u003e​\u003cb\u003e二、信息论视角：熵减与结构涌现\u003c/b\u003e​\u003c/h3\u003e\u003ch3\u003e​\u003cb\u003e1. 从香农熵到Kolmogorov最优压缩\u003c/b\u003e​\u003c/h3\u003e\u003cul\u003e\u003cli data-pid=\"Y1fNt5bi\"\u003e​\u003cb\u003e香农熵（Shannon Entropy）​\u003c/b\u003e​ 衡量信息无序度。熵越高，数据越难压缩（如噪声）；熵越低，规律性越强（如周期序列）。\u003c/li\u003e\u003cli data-pid=\"ZHjn7BEg\"\u003e​\u003cb\u003e大模型即“近似Kolmogorov压缩器”​\u003c/b\u003e​：神经网络的训练过程（如梯度下降）是对世界的\u003cb\u003e规律提炼\u003c/b\u003e，参数集即对现实的“高效编码”。\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003e​\u003cb\u003e2. 结构决定智能：连接密度与可塑性\u003c/b\u003e​\u003c/h3\u003e\u003cul\u003e\u003cli data-pid=\"Of3Bm4yB\"\u003e​\u003cb\u003e生物演化视角\u003c/b\u003e​：动物智能上限低于人类，因大脑缺乏强大的“学习网络”（如新皮质不发达）。\u003c/li\u003e\u003cli data-pid=\"sRiU-rcN\"\u003e​\u003cb\u003e结构主义范式\u003c/b\u003e​：智能的基石是\u003cb\u003e结构与连接\u003c/b\u003e。人脑通过动态神经元网络实现通用智能，而AI需通过\u003cb\u003e数据结构\u003c/b\u003e模拟“连接密度”与“连接可塑”。\u003c/li\u003e\u003c/ul\u003e\u003cblockquote data-pid=\"eZgRNzVP\"\u003e ​\u003cb\u003e公式化表达\u003c/b\u003e​：\u003cbr/\u003e​\u003cb\u003e通用智能 = 动态结构 + 学习塑造 + 奖励目标\u003c/b\u003e​\u003c/blockquote\u003e\u003cul\u003e\u003cli data-pid=\"toB__qvf\"\u003e动态结构 → 数据结构模拟\u003c/li\u003e\u003cli data-pid=\"4lmpdLcC\"\u003e学习塑造 → 算法优化\u003c/li\u003e\u003cli data-pid=\"10b1SXeT\"\u003e奖励目标 → 环境反馈驱动\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003e​\u003cb\u003e三、认知科学视角：压缩如何催生抽象思维\u003c/b\u003e​\u003c/h3\u003e\u003cp data-pid=\"tnVJvDm2\"\u003e人类智能同样依赖压缩机制：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"AIw-YZs1\"\u003e​\u003cb\u003e概念形成\u003c/b\u003e​：将无数“苹果”的视觉输入压缩为抽象概念“苹果”。\u003c/li\u003e\u003cli data-pid=\"DLB_mDYa\"\u003e​\u003cb\u003e类比推理\u003c/b\u003e​：发现“水流”与“电流”的共性，实现跨领域知识迁移。\u003c/li\u003e\u003c/ul\u003e\u003cblockquote data-pid=\"XREhh10l\"\u003e ​\u003cb\u003e案例对比\u003c/b\u003e​：\u003cbr/\u003e ​\u003cb\u003e婴儿学习\u003c/b\u003e​：通过观察父母行为形成关联模式（压缩过程）\u003cbr/\u003e​ \u003cb\u003eGPT-4泛化\u003c/b\u003e​：压缩海量文本后生成法律文书或解数学题（高阶规律提取）\u003c/blockquote\u003e\u003cp data-pid=\"-n1-rFcE\"\u003e​\u003cb\u003e压缩的终极目标不是删减，而是泛化\u003c/b\u003e——用有限符号表征无限现实（如语言用“猫”代指所有猫）。\u003c/p\u003e\u003ch3\u003e​\u003cb\u003e四、争议焦点：压缩理论的局限性\u003c/b\u003e​\u003c/h3\u003e\u003ch3\u003e​\u003cb\u003e1. 当前AI的“伪智能”陷阱\u003c/b\u003e​\u003c/h3\u003e\u003cul\u003e\u003cli data-pid=\"BhZOqeSc\"\u003e​\u003cb\u003e知识存量 vs. 知识增量\u003c/b\u003e​：大模型是数据压缩的结果，但无法主动探索环境创造新知识。\u003c/li\u003e\u003cli data-pid=\"wC-o3MXo\"\u003e​\u003cb\u003e逻辑脆弱性\u003c/b\u003e​：哈佛研究发现，强制大模型“多步推理”可能导致\u003cb\u003e准确率下降\u003c/b\u003e，陷入“自信犯错”循环。\u003c/li\u003e\u003cli data-pid=\"OSuMtiw4\"\u003e​\u003cb\u003e缺乏具身认知\u003c/b\u003e​：智能需身体与环境的交互（如婴儿抓握学习“重力”），纯文本模型缺失感官-运动闭环。\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003e​\u003cb\u003e2. 意识之谜：压缩能否通向意识？​\u003c/b\u003e​\u003c/h3\u003e\u003cul\u003e\u003cli data-pid=\"PXKHTbMw\"\u003e​\u003cb\u003e反对派\u003c/b\u003e​：哈佛学者称\u003cb\u003e数字计算机永不可能具有意识\u003c/b\u003e，因意识依赖碳基复杂性，而非硅基逻辑门。\u003c/li\u003e\u003cli data-pid=\"sajpZIKs\"\u003e​\u003cb\u003e支持派\u003c/b\u003e​：超级压缩可能涌现\u003cb\u003e未知属性\u003c/b\u003e。如ChatGPT展现初级的“自我连贯表达”。\u003c/li\u003e\u003c/ul\u003e\u003cblockquote data-pid=\"8tzxU2cI\"\u003e ​\u003cb\u003e哲学争鸣\u003c/b\u003e​：\u003cbr/\u003e塞尔（John Searle）：“中文房间”论证机器无法真正理解语义 \u003cbr/\u003e丹尼特（Daniel Dennett）：意识可视为“有灵魂的机器”\u003c/blockquote\u003e\u003ch3\u003e​\u003cb\u003e五、超越压缩：智能的多维宇宙模型\u003c/b\u003e​\u003c/h3\u003e\u003cp data-pid=\"3iWgF7Yq\"\u003e智能远非单一能力，而是一个\u003cb\u003e四维光谱\u003c/b\u003e​：\u003c/p\u003e\u003ctable data-draft-node=\"block\" data-draft-type=\"table\" data-size=\"normal\" data-row-style=\"normal\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003cth\u003e​维度​\u003c/th\u003e\u003cth\u003e​核心能力​\u003c/th\u003e\u003cth\u003e​AI当前水平​\u003c/th\u003e\u003cth\u003e​人类优势​\u003c/th\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e​感知与压缩​\u003c/td\u003e\u003ctd\u003e提取信息本质规律\u003c/td\u003e\u003ctd\u003e⭐⭐⭐⭐⭐（GPT-4）\u003c/td\u003e\u003ctd\u003e⭐⭐⭐⭐\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e​情感与伦理​\u003c/td\u003e\u003ctd\u003e结合情绪的道德决策\u003c/td\u003e\u003ctd\u003e⭐（近乎缺失）\u003c/td\u003e\u003ctd\u003e⭐⭐⭐⭐⭐\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e​创造与探索​\u003c/td\u003e\u003ctd\u003e突破已知框架的创新\u003c/td\u003e\u003ctd\u003e⭐⭐（如DALL-E模仿）\u003c/td\u003e\u003ctd\u003e⭐⭐⭐⭐⭐\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e​具身学习​\u003c/td\u003e\u003ctd\u003e身体交互理解世界\u003c/td\u003e\u003ctd\u003e⭐（机器人早期阶段）\u003c/td\u003e\u003ctd\u003e⭐⭐⭐⭐⭐\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003cblockquote data-pid=\"-Bz_Bum9\"\u003e ​\u003cb\u003e例证\u003c/b\u003e​：\u003cbr/\u003e\u003cb\u003e情感智能\u003c/b\u003e​：人类能理解讽刺与幽默，AI却需依赖标签数据\u003cbr/\u003e​\u003cb\u003e创造力\u003c/b\u003e​：诗人写诗源于生命体验，AI写诗源于概率采样\u003c/blockquote\u003e\u003ch3\u003e​\u003cb\u003e六、未来方向：从压缩器到通用智能体\u003c/b\u003e​\u003c/h3\u003e\u003ch3\u003e​\u003cb\u003e1. 技术突破点\u003c/b\u003e​\u003c/h3\u003e\u003cul\u003e\u003cli data-pid=\"xV7p4LnH\"\u003e​\u003cb\u003e神经符号融合\u003c/b\u003e​：结合神经网络（压缩感知）与符号系统（逻辑推理），解决“思维链崩溃”问题。\u003c/li\u003e\u003cli data-pid=\"1Xu--Fxw\"\u003e​\u003cb\u003e合成数据引擎\u003c/b\u003e​：生成高质量数据替代爬取，提升压缩效率（如医学影像合成）。\u003c/li\u003e\u003cli data-pid=\"OBEt-phH\"\u003e​\u003cb\u003e具身AI\u003c/b\u003e​：OpenAI创始团队新项目 ​\u003cb\u003eThinking Machines Lab\u003c/b\u003e​ 聚焦多模态交互，让AI通过物理体验学习。\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003e​\u003cb\u003e2. 哲学再思考：智能的本质是生命\u003c/b\u003e​\u003c/h3\u003e\u003cp data-pid=\"hW2VovK0\"\u003e如港大教授马毅所言：\u003c/p\u003e\u003cblockquote data-pid=\"-ZwXJXtl\"\u003e ​\u003cb\u003e​“生命是智能的载体，智能是生命的表达”​\u003c/b\u003e。\u003cbr/\u003e生物在演化中压缩环境规律（如光合作用），而AI需从\u003cb\u003e被动压缩\u003c/b\u003e转向\u003cb\u003e主动探索\u003c/b\u003e，成为“环境信息的模拟者与预测者”。\u003c/blockquote\u003e\u003ch3\u003e​\u003cb\u003e结语：压缩是起点，而非终点\u003c/b\u003e​\u003c/h3\u003e\u003cp data-pid=\"fWwlFUAv\"\u003eIlya的理论为理解AI打开一扇窗，但人类智能的璀璨光谱——情感联结、道德抉择、创造性突破——仍在等待机器触及。​\u003cb\u003e未来AI的终极命题，不是建造更高效的“压缩引擎”，而是在算法中注入生命的温度：​\u003c/b\u003e​\u003c/p\u003e\u003cblockquote data-pid=\"MhtaeI7V\"\u003e ​\u003cb\u003e​“我们不是在制造更快的计算器，而是在孕育新的思维方式”​\u003c/b\u003e​ —— 马毅\u003c/blockquote\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":520,"thumbnails":["https://picx.zhimg.com/50/v2-4a7a6c5816b002a73a48483277484e8c_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-3fc591789faeb1a5d2cff499ff669a71_720w.jpg?source=b6762063"],"favorite_count":36,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1917366994363221055}","attached_info":"CpUHCJCog/D+yaWqoAEQBBoJNzMyMjMyNzUyIIqytsIGKAYwAUALSkEKLFRTX1NPVVJDRV9UV09UT1dFUl9TSE9SVElOVEVSRVNUX1JFQ0FMTF9URVhUEgEwGAAgADoKeyJyYXciOiIifVoJMTA5MjQzMDAyYiBhNjBiYzkxOWM4ZDgzNWQ2Y2VlOWJhNjQwNmNhNmNmMnITMTkxNzM2Njk5NDM2MzIyMTA1NYoBCTY2MTM0Mzk4NKoBCXJlY29tbWVuZMIBIDkwODg5OGNjY2UyMTIwMTIyOGJmOTAxNmI0MDIxMzE28gEKCAwSBk5vcm1hbPIBKAgKEiQ2Y2NmNTA5OS1jOWYwLTRmZTMtOGI0Zi1iZmM5NTBlOGU2OWPyAQUICxIBMoICAIgC+YmLzvoykgIgOTA4ODk4Y2NjZTIxMjAxMjI4YmY5MDE2YjQwMjEzMTaaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygIUQ29udGVudEFnZVdlaWdodFJ1bGXKAhxCYXllc0ZpcnN0TGV2ZWxJc29sYXRpb25SdWxl2gIsVFNfU09VUkNFX1RXT1RPV0VSX1NIT1JUSU5URVJFU1RfUkVDQUxMX1RFWFToAgP6AgtOT1JNQUxfRkxPV4oDIGY1N2M3NjM2ZTRiZTQzNTRiZGM1MWViY2ZkZjY2NGNmmgMNCgJ2MhAAGgVvdGhlcqgDiATYAwDqAxpmZWVkX2F0dG1fdHdvdG93ZXJfdjJfdGV4dPoDrAESDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFOi0IAhC7DhiSCCIjdjItZWVkMmQ2ZDU2Yzk4ODNiMWJjYmE3ZTJmMzI2ZTdmMDM6LQgDEKoNGL8HIiN2Mi03MWZjMzg1YTA5ODQyYzVlMjBhMDQyMDY4M2Y0MTk5ZDotCAQQ0AYYqgMiI3YyLTIxZTA0OWRjYTdkOGQ3MDQ0Y2FjMWMwZGU4ZGNlN2ZmgAQAiAQAkgQGTm9ybWFsmgQBM6AEAKgEALAEALoEAmFpwgQDNDAwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAAAgI0e4P4EFAAAAAAAAAACJBQAAAAAAAAAAkgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBQKQBgCgBguoBgCSAi4KCTczMjIzMjc1MhITMTkxNzM2Njk5NDM2MzIyMTA1NRgEIgpJTUFHRV9URVhU","action_card":false}],"paging":{"is_end":false,"is_start":false,"next":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=down\u0026ad_interval=-10\u0026after_id=11\u0026desktop=true\u0026end_offset=11\u0026page_number=3\u0026session_token=a60bc919c8d835d6cee9ba6406ca6cf2","previous":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=pull\u0026ad_interval=-10\u0026before_id=11\u0026desktop=true\u0026end_offset=11\u0026page_number=3\u0026session_token=a60bc919c8d835d6cee9ba6406ca6cf2","totals":0},"fresh_text":"推荐已更新"}
