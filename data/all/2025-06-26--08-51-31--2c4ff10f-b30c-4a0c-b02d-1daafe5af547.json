{"data":[{"id":"78_1750899137.4","type":"feed","offset":78,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750899137,"updated_time":1750899137,"target":{"id":"1920170086523724487","type":"article","url":"https://api.zhihu.com/articles/1920170086523724487","author":{"id":"99e2674fdd6437820d96374cf6f5162e","url":"https://api.zhihu.com/people/99e2674fdd6437820d96374cf6f5162e","user_type":"people","url_token":"24-61-39-63-7","name":"饭饭科技视频博客","headline":" 分享YouTube / B站优质科技视频，供学习交流   ","avatar_url":"https://picx.zhimg.com/50/v2-8ad3d9f84724cb020a297138fcc89e82_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":94,"is_following":false,"is_followed":false},"title":"用了 ClaudeCode 开发后，我再也不想碰 Cursor 了","comment_permission":"all","created":1750585834,"updated":1750820286,"voteup_count":26,"voting":0,"comment_count":12,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"我在B站看到一篇非常的内容，想给大家分享一下   大家好，我是来自LegacyLands开发团队的灵溪，主要负责框架设计与后端开发。   在这支视频中，我将分享使用 ClaudeCode的经验，探讨它如何显著提升团队开发效率，以及与Cursor相比的优势。目前关于ClaudeCode的中文内容较少，很高兴能结合自身使用体验为大家提供参考。此外，我将演示PromptX的增强系统，它能有效解决包括ClaudeCode在内的部分AI工具在实际开发中的痛点问题。首先简要…","excerpt_new":"我在B站看到一篇非常的内容，想给大家分享一下   大家好，我是来自LegacyLands开发团队的灵溪，主要负责框架设计与后端开发。   在这支视频中，我将分享使用 ClaudeCode的经验，探讨它如何显著提升团队开发效率，以及与Cursor相比的优势。目前关于ClaudeCode的中文内容较少，很高兴能结合自身使用体验为大家提供参考。此外，我将演示PromptX的增强系统，它能有效解决包括ClaudeCode在内的部分AI工具在实际开发中的痛点问题。首先简要…","preview_type":"default","preview_text":"","content":"\u003ch2\u003e我在B站看到一篇非常的内容，想给大家分享一下\u003c/h2\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-8068912c012d508355f85900b679fcf1_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-8068912c012d508355f85900b679fcf1\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pic2.zhimg.com/v2-8068912c012d508355f85900b679fcf1_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"O9pVi633\"\u003e大家好，我是来自LegacyLands开发团队的灵溪，主要负责框架设计与后端开发。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-61406ffd1693d4b0f231fcc449e494f3_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-61406ffd1693d4b0f231fcc449e494f3\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://picx.zhimg.com/v2-61406ffd1693d4b0f231fcc449e494f3_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"CtMLQ4Z3\"\u003e在这支视频中，我将分享使用\u003cb\u003eClaudeCode\u003c/b\u003e的经验，探讨它如何显著提升团队开发效率，以及与\u003cb\u003eCursor\u003c/b\u003e相比的优势。目前关于ClaudeCode的中文内容较少，很高兴能结合自身使用体验为大家提供参考。此外，我将演示\u003cb\u003ePromptX\u003c/b\u003e的增强系统，它能有效解决包括ClaudeCode在内的部分AI工具在实际开发中的痛点问题。\u003c/p\u003e\u003cp data-pid=\"qdWMsoPv\"\u003e首先简要介绍ClaudeCode的安装环境。安装过程非常简单，但目前仅支持\u003cb\u003eLinux\u003c/b\u003e和\u003cb\u003eMacOS\u003c/b\u003e系统。Windows用户需借助\u003cb\u003eWSL\u003c/b\u003e或虚拟机运行。安装只需在终端运行命令即可。部分用户可能遇到网络连接问题，这源于某些不可抗力因素。除了使用全局代理如\u003cb\u003eTerm Mode\u003c/b\u003e外，我会通过修改ClaudeCode的配置文件来强制代理流量，这样会更加稳定。接下来将演示这一方法：在配置文件中添加代理地址（如10808）后即可正常使用。\u003c/p\u003e\u003cp data-pid=\"iLjCY3U1\"\u003e最后谈谈定价结构，我们仅关注个人使用场景。个人用户有两个可选计划。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-0eafdd21a1087d93c88301da1f7e0bad_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-0eafdd21a1087d93c88301da1f7e0bad\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pic4.zhimg.com/v2-0eafdd21a1087d93c88301da1f7e0bad_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"z_zNnEZv\"\u003e\u003cb\u003ePro计划\u003c/b\u003e每月17美元，\u003cb\u003eMax计划\u003c/b\u003e起价100美元。我目前使用的是Max计划。\u003c/p\u003e\u003cp data-pid=\"atir9G3r\"\u003ePro计划适合非全职开发者或非每日使用的用户。理论上，Pro和Max计划均支持无限使用，但官方会根据使用频率和资源负载设置\u003cb\u003e软性限制\u003c/b\u003e，通常每5小时重置一次额度，月使用上限为50次。\u003c/p\u003e\u003cp data-pid=\"Bgyjq6Gp\"\u003e具体限制可能有所浮动，但根据我的个人经验，正常使用Max计划几乎不会触及额度限制，除非频繁调用\u003cb\u003eAlpas模型\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"N-fJXRN_\"\u003e\u003cb\u003eClaude Code\u003c/b\u003e目前支持Claude4 Sonnet和Claude4 Alpas两种模型。虽然不像Cursor等AI IDE提供多种模型选择，但在开发场景下，这些模型已足够强大。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-ce6f72df56a14f895578987cf378d909_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-ce6f72df56a14f895578987cf378d909\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pic4.zhimg.com/v2-ce6f72df56a14f895578987cf378d909_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"rcbv6g8b\"\u003e那么，究竟是什么原因促使我从\u003cb\u003eCursor\u003c/b\u003e转向\u003cb\u003eCloud Code\u003c/b\u003e呢？在过去的几天里，我们团队的大部分成员都已从Cursor迁移至Cloud Code。主要原因在于，Cloud Code在各方面表现都显著优于Cursor。即便使用相同的模型，Cloud Code的响应速度更快，网络连接更稳定，错误率更低，且上下文窗口更大。此外，它不会像Cursor那样频繁出现压缩上下文的情况。可以说，Cloud Code提供了一个更简洁、高效且可靠的开发环境。\u003c/p\u003e\u003cp data-pid=\"L5nvRSbz\"\u003e尽管Cloud Code对不熟悉终端操作的开发者不够友好，且订阅价格较高，但其带来的\u003cb\u003e生产力提升\u003c/b\u003e足以覆盖这部分成本。因此，我们团队愿意为其付费，这确实是一种开发效率的飞跃。\u003c/p\u003e\u003cp data-pid=\"ZYmL9OdJ\"\u003e接下来，我将完整演示如何使用Cloud Code辅助开发，包括如何上手新项目、发现潜在问题、提出修改建议，以及让Cloud Code协助修复或重构代码。希望这个演示能对大家有所帮助。\u003c/p\u003e\u003cp data-pid=\"fVkqqCcg\"\u003e我的系统是\u003cb\u003eUbuntu\u003c/b\u003e。首先打开终端，进入工作目录：Distop/Developer/Java/LexilasLibrary。随后直接启动Cloud Code。由于已安装并配置好代理，这里我们选择\u003cb\u003e英国节点\u003c/b\u003e启动——在实际测试中，其他地区的节点可能出现问题，而英国节点最为稳定。\u003c/p\u003e\u003cp data-pid=\"gWmOiIYk\"\u003e成功启动Cloud Code后，打开IDE并通过Cloud Code绑定。当IDE成功连接后，我们可以复制代码片段进行交互。例如复制某个文件内容粘贴进去，右下角会显示”Wireline Selected”表示选中行。发送这段代码时，会连同所在类一起传递。根据\u003cb\u003eJetBrains IDEA\u003c/b\u003e的反馈，它能够识别所选类并提供相应帮助。\u003c/p\u003e\u003cp data-pid=\"oMDptVn_\"\u003e接下来我们需要分析这个项目。由于刚接触该项目，可能对某些部分不太熟悉。\u003cb\u003e老板要求我们优化Player模块，并对其进行评估\u003c/b\u003e。现在切换到Claude Code，这里使用\u003cb\u003ePromptX\u003c/b\u003e作为辅助框架。PromptX能显著提升Claude Code的上下文理解能力，使其能够记住重要信息，如项目结构和最佳实践，避免每次都要重新分析。此外，它还提供多种角色选择功能来增强Claude Code的专业能力。\u003c/p\u003e\u003cp data-pid=\"4nF9ZUXS\"\u003e我们可以询问预设角色。系统显示Claude Code的官方3LM已加载，PromptX也已成功加载。PromptX提供以下角色：Java后端开发者、产品经理智能助手、测试角色等。我们选择\u003cb\u003eJava后端开发者角色\u003c/b\u003e（输入3即可激活）。\u003c/p\u003e\u003cp data-pid=\"q5w8q0gH\"\u003e在查看MCP时，可以看到已连接JetBrains的MCP。这意味着系统能够通过MCP访问所有项目文件和相关警告信息。接下来让系统熟悉Player模块：我们直接复制粘贴Player模块的路径，要求其阅读源码并进行评估。\u003c/p\u003e\u003cp data-pid=\"6GTwXuPf\"\u003e需要注意的是，Claude是一个\u003cb\u003e混合模型\u003c/b\u003e。对于复杂任务，必须明确指示其进行深度思考，否则可能不会主动分析。现在系统已开始思考（显示Thinking状态）。放大终端窗口后，系统识别出这是一个标准的Java项目，从目录结构判断属于玩家数据管理模块，并进行了详细的内容分析。\u003c/p\u003e\u003cp data-pid=\"PvFiJDrI\"\u003e可以看到，他表示需要先探索项目结构，阅读源码并理解模块功能，从\u003cb\u003e架构设计\u003c/b\u003e、\u003cb\u003e代码质量\u003c/b\u003e和\u003cb\u003e设计模式\u003c/b\u003e等专业角度进行评估。在实际使用Claude Code时，相比Cursor有一个显著优势：它会主动进行思考，并创建有用的待办事项清单来规划目标，从而更快地满足我们的需求。仅通过阅读部分源码，它就能提供这些分析。\u003c/p\u003e\u003cp data-pid=\"yov45jit\"\u003e接下来，我们需要指示它继续逐行阅读代码，并评估整个项目。从已读取的内容来看，它查看了配置文件（误认为是Mainware文件）、测试类、工厂类、RedditStream接收器，以及主要服务类、数据类和主类。基于这些文件，它已完成了初步评估，涵盖架构设计、代码质量、\u003cb\u003e性能优化\u003c/b\u003e、\u003cb\u003e容错机制\u003c/b\u003e、\u003cb\u003e测试覆盖\u003c/b\u003e、\u003cb\u003e生产就绪度\u003c/b\u003e和\u003cb\u003e可维护性\u003c/b\u003e等方面。\u003c/p\u003e\u003cp data-pid=\"0GdijP22\"\u003e在检查过程中，发现存在代码重复问题。例如ParaLauncher模块中的RomDebugTest方法，与其他模块的测试代码高度重复。我们可以将这段代码复制到Claude Code中，它会自动标注代码来源。然后，我们要求它不要立即修改代码，而是先在GitHub上提交Issue。具体操作是使用已配置好的\u003cb\u003eGitHub CLI工具\u003c/b\u003e，参照最近的Issue格式来提交问题报告。\u003c/p\u003e\u003cp data-pid=\"VzyBYIvK\"\u003e因此，他使用了一些命令来查看最近的\u003cb\u003eIssue\u003c/b\u003e。现在，他提出要创建一个\u003cb\u003eIssue\u003c/b\u003e来解决RomDebugTest方法的重复问题。我们打开浏览器，查看他是否提交了这个Issue。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-0bfb43dcbc40e786240af5177484e847_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-0bfb43dcbc40e786240af5177484e847\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pic2.zhimg.com/v2-0bfb43dcbc40e786240af5177484e847_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"lFbL9SGp\"\u003e他酝酿许久，终于提交了一个Issue。他甚至花了五分钟才完成这个Issue的提交。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-89b4d69d90bcb1dd65185a7beebc29ca_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-89b4d69d90bcb1dd65185a7beebc29ca\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pic1.zhimg.com/v2-89b4d69d90bcb1dd65185a7beebc29ca_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"o7NJn6NH\"\u003e让我们评估这个Issue的质量。可以看出他的描述相当详细，我们可以通过翻译来进一步了解。这是一个适合新手处理且需要加强的Issue，\u003cb\u003e优先级为中等\u003c/b\u003e。主要内容是将通用测试逻辑提取到基础模块中。目前每个模块启动器都实现了几乎相同的RomDebugTest方法，存在代码重复问题。他以PlayerLauncher为例，指出了代码重复和维护挑战，并提供了解决方案建议，包括模块解耦方案。\u003c/p\u003e\u003cp data-pid=\"ekdA1i-v\"\u003e技术实现部分详细说明了分阶段实施计划： - 第一阶段的任务 - 第二阶段的任务 - 功能增强方案 - 需要修改的文件列表\u003c/p\u003e\u003cp data-pid=\"a85Ovjbd\"\u003e此外，还阐述了改进后的预期收益，整体方案较为完善。\u003c/p\u003e\u003cp data-pid=\"5MuTay4u\"\u003e接下来，他创建了一个Ticket来分析模块中现有的测试基础设施。完成Ticket创建后，他计划开发一个工具类和必要的接口。我们直接授权他执行这些修改，无需再征询确认。此时系统已开启\u003cb\u003e自动接收模式\u003c/b\u003e，可以自动采纳所有更改。\u003c/p\u003e\u003cp data-pid=\"Y4LS3AAT\"\u003e界面右下角显示当前上下文压缩率仅为30%。这是因为刚才让他分析了整个项目并提交了Issue，消耗了大量上下文资源。接下来，我们将使用\u003cb\u003ePromptX\u003c/b\u003e来演示如何优雅地解决上下文占用问题。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-7df8b2a60e157d9ff27b07ce1d0d6551_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-7df8b2a60e157d9ff27b07ce1d0d6551\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pic4.zhimg.com/v2-7df8b2a60e157d9ff27b07ce1d0d6551_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"l_dqQjua\"\u003e可以看到，他已经完成了大部分工作，并在\u003cb\u003eFoundation模块\u003c/b\u003e中添加了基础测试基础设施。随后，他使用Gradle进行构建。在日常使用Claude Code时，我们建议指导Claude Code自行完成构建，这有助于发现项目中的所有错误并逐一修复。\u003c/p\u003e\u003cp data-pid=\"UjFilETQ\"\u003e在构建过程中，他发现了若干错误并逐步修复。目前，他已成功修复Foundation模块中的错误，并测试Player模块能否正常构建。编译成功后，他开始对比重构前后的代码行数差异，并创建测试用例来验证新编写的工具类。\u003c/p\u003e\u003cp data-pid=\"ILINzsoe\"\u003e接下来，他准备更新Gradle Hub Issue，但我们建议暂缓此操作以便自行检查。可以看到他的代码编写非常详细且工整。这里包含一个\u003cb\u003e接口定义\u003c/b\u003e、工具类实现以及测试代码。虽然测试代码因缺少依赖而报错，但这并非重点。编译已通过，总代码量为283行。\u003c/p\u003e\u003cp data-pid=\"5Xyjz9Ii\"\u003e测试结果显示所有用例均已通过，格式符合预期。测试报告包含通过数量、总测试数及耗时等信息。需要注意的是，这些测试不包含压力测试，且当前报错是由于分布式环境下的锁竞争性能测试所致。\u003c/p\u003e\u003cp data-pid=\"koWgfvyP\"\u003e在提交代码前，我们需要进行人工审核。发现部分代码风格与习惯不符，已手动调整。确认接口定义无误后，重新格式化代码。现在所有工作均已完成，可以提交更改并关闭相关任务。\u003c/p\u003e\u003cp data-pid=\"KT9fMqGx\"\u003eClaude Code还有一个非常实用的功能。\u003c/p\u003e\u003cp data-pid=\"FA1xJKHV\"\u003e当你让它自行提交更改时，它会自动添加自己的署名。这里可以看到它先检查了\u003cb\u003e差异\u003c/b\u003e，然后将所有更改添加进去。虽然它署上了自己的名字，但这并无大碍。\u003c/p\u003e\u003cp data-pid=\"zyKChJOa\"\u003e它发现\u003cb\u003e医学分支\u003c/b\u003e虽已关闭，但命令中存在一些错误，随后进行了提交。现在我们来检查医学分支是否确实已关闭，并分析刚才出现的错误原因。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-17fa29c541b71866e7fdd020a2da4da2_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-17fa29c541b71866e7fdd020a2da4da2\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pic1.zhimg.com/v2-17fa29c541b71866e7fdd020a2da4da2_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"zBiVQh0_\"\u003e代码可能存在一些问题，但目前已修复完成。我们可以进一步调整。\u003c/p\u003e\u003cp data-pid=\"izyxVJVq\"\u003e\u003cb\u003e当前衣袖关闭功能的信息存在错误\u003c/b\u003e，请修复。系统自动添加了一条更正评论来解决该问题。随后，系统在下方补充了修正内容，我们将其删除。现在系统确认衣袖关闭信息已完整。\u003c/p\u003e\u003cp data-pid=\"JEx0w6pI\"\u003e系统指出之前的评论存在格式问题，并提供了更正后的信息。\u003cb\u003e实现代码已精简\u003c/b\u003e，新增了技术组件和技术模块的API方法。效果良好，系统已按指示提交了署名信息。\u003c/p\u003e\u003cp data-pid=\"0aq_jL4l\"\u003e查看提交记录显示：\u003cb\u003e重构通用测试执行逻辑并提取至基础模块\u003c/b\u003e，共计修改200行代码。虽然问题较为简单，但仍存在一些细微问题需要完善。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-7595cf854351f092e825a89a819227c2_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-7595cf854351f092e825a89a819227c2\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pica.zhimg.com/v2-7595cf854351f092e825a89a819227c2_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"ZTbWaOT7\"\u003e我们刚刚发现不仅是\u003cb\u003e配合模块\u003c/b\u003e存在重复代码，该模块本身也有重复。因此需要明确指出复制粘贴的问题。不仅仅是配合模块，\u003cb\u003eannotation模块\u003c/b\u003e也存在类似情况。\u003c/p\u003e\u003cp data-pid=\"RU4xvgDe\"\u003e各位如果仔细观察，会发现我在编写Javadoc时习惯仅使用一个标签，而不会特意添加结束标签。AI在编写Javadoc时很好地模仿了我的风格，比如这里没有使用句号，也没有结束标签，完全符合我的写作习惯。\u003c/p\u003e\u003cp data-pid=\"WR_1SiQ0\"\u003e接着AI自动进行了\u003cb\u003eupdate\u003c/b\u003e和\u003cb\u003ededuce\u003c/b\u003e检查，确认了模块间的依赖关系。可以看到上下文即将超载，因此我们暂停操作，要求AI保存当前经验记忆，并说明已完成的工作、发现的新问题以及后续任务。AI还详细说明了技术要点和重构模式。\u003c/p\u003e\u003cp data-pid=\"0PLQZEcT\"\u003e由于上下文即将超载，我们使用\u003cb\u003eclear命令\u003c/b\u003e清除上下文。然后指示AI切换到\u003cb\u003eJava后端开发者角色\u003c/b\u003e，回忆之前的工作。\u003cb\u003ePromptX\u003c/b\u003e的配置文件将保存在项目目录下。由于当前PromptX存在一些小问题，需要手动指定记忆文件路径让其读取，以便继续未完成的任务并进行深度思考。\u003c/p\u003e\u003cp data-pid=\"dy1oN8g_\"\u003e值得一提的是，此前我们只让AI深度思考过一次，即在读取整个项目时。即便如此，AI的表现依然非常出色，这一点与\u003cb\u003eCursor\u003c/b\u003e相比差异明显。\u003c/p\u003e\u003cp data-pid=\"v1wOOre_\"\u003e现在AI已成功切换到Java后端开发者角色，并读取了记忆文件。虽然记忆系统显示暂存内容存在一些小bug（开发者后续会修复，我已就此在GitHub提交了\u003cb\u003eissue\u003c/b\u003e），但所有\u003cb\u003elaunch操作\u003c/b\u003e都已完成。AI正在更新构建状态并验证编译是否通过，它已自动调用了\u003cb\u003emaven命令\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"2NxpZnAe\"\u003e应使用 \u003cb\u003eGradle\u003c/b\u003e 的 \u003cb\u003eshadowJar\u003c/b\u003e 进行编译。Ubuntu系统提示home目录磁盘空间不足，建议清空回收站。在编译过程中，可查看home目录的空间使用情况。当前home空间已占用97%，仅剩2.6%，主要占用来自桌面文件和当前录制的视频文件，共计11GB。\u003c/p\u003e\u003cp data-pid=\"36HWVrHz\"\u003e重构完成后，提交所有更改并关闭相关issue。目前已经同时运行了两个 \u003cb\u003eClaudeCode\u003c/b\u003e 实例，这表明可以并行运行多个AI代理，分别负责前端开发、后端开发、测试和运维工作。\u003c/p\u003e\u003cp data-pid=\"-UDoDLEd\"\u003e系统已完成宝贵记忆的传承，并展示了深度思考的能力。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-1e6b871d598294cf1994b2dd5b2f6f1c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-1e6b871d598294cf1994b2dd5b2f6f1c\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pica.zhimg.com/v2-1e6b871d598294cf1994b2dd5b2f6f1c_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"3AtgslZ3\"\u003e本次提交是否包含ClaudeCode？我确认存在。此外，当前仅提交了代码但尚未推送。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-62f82265c70a7e22c216b4efc55b5f03_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-62f82265c70a7e22c216b4efc55b5f03\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pic2.zhimg.com/v2-62f82265c70a7e22c216b4efc55b5f03_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"vKAcFszo\"\u003e对吧。我们推送一下。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-1c017318a7a34b4368a0ff3decf3d782_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-1c017318a7a34b4368a0ff3decf3d782\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pic1.zhimg.com/v2-1c017318a7a34b4368a0ff3decf3d782_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"alMttebD\"\u003e确实如此。在此过程中，我们成功完成了从熟悉项目、发现问题、提出issue，到最终解决问题并关闭issue的完整流程。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-4c25bd6b47e3fd205deead8f5f2ae1ef_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-original-token=\"v2-4c25bd6b47e3fd205deead8f5f2ae1ef\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pic4.zhimg.com/v2-4c25bd6b47e3fd205deead8f5f2ae1ef_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"c-WqUx8n\"\u003e整个流程的所有任务均已完成。当前代码库更加简洁、一致且易于维护。\u003c/p\u003e\u003cp data-pid=\"6mm7GO69\"\u003e本期关于Cloud Code的讲解到此结束。后续我们还将介绍一些其他功能，例如直接复制图片以及Cloud对图片的识别等。希望本视频对您有所帮助。感谢观看。\u003c/p\u003e","is_labeled":false,"visited_count":4371,"thumbnails":["https://pic1.zhimg.com/50/v2-4ce02105c3739e85414067b51492bc4f_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-780b124c5ec6bcb443afdd2d7a26ba26_720w.jpg?source=b6762063","https://pica.zhimg.com/50/v2-b3596ef9ca11aa89bebf04be5ae7a2d5_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-ead33c53aba633826600da37a29fde76_720w.jpg?source=b6762063","https://pica.zhimg.com/50/v2-98c454a1b39fc3be5b9609b152c76c68_720w.jpg?source=b6762063","https://pica.zhimg.com/50/v2-97ac32d1a82a85cb4aeea1c1f8619b67_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-e4860cff95c6de08502186acb6c03bd2_720w.jpg?source=b6762063","https://pica.zhimg.com/50/v2-95bd2d9ed7e3bac84c7aad6232bd2d98_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-60b24486c6ba9e251d6724b95f222911_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-495356bf49ac5b74d7647063ceb43f5e_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-61495778121bb523abbcf5c10ba70cb2_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-544c64dca272b8951b6cb36711c6f9b2_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-d98feca39efc8b0154d4d758b3244b9d_720w.jpg?source=b6762063"],"favorite_count":60,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1920170086523724487}","attached_info":"CpkLCOD5laeW9LTCsgEQBxoJMjU5NDA3MjA1IOqj38IGKBowDEBOSkkKH1RTX1NPVVJDRV9aUkVDQUxMX0lURU1DRl9VUFZPVEUSIGRvY190eXBlOiBBcnRpY2xlCmlkOiAyNTkxNDYxNTkKGAAgADoASigKHVRTX1NPVVJDRV9ORUFSTElORV9DT05URU5UX1YyEgEwGAAgADoAYiBhODQ1YjU3Y2VhZDM0MDdiOWM4YTk4Y2EzMjJjNDcxYnITMTkyMDE3MDA4NjUyMzcyNDQ4N6oBCXJlY29tbWVuZMIBIDk5ZTI2NzRmZGQ2NDM3ODIwZDk2Mzc0Y2Y2ZjUxNjJl8gEKCAwSBk5vcm1hbPIBKAgKEiQ0NTA1NTFhNy01MzhjLTQyNjUtOTM1ZC05ZmI5MWMwZTZhNzPyAQYICxICMTSCAgCIAuC04s36MpICIDk5ZTI2NzRmZGQ2NDM3ODIwZDk2Mzc0Y2Y2ZjUxNjJlmgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCFkFjdGlvblNob3JJbnRlcmVzdFJ1bGXKAhtJbnRlcmFjdGlvblNob3JJbnRlcmVzdFJ1bGXKAhhQZXJpb2RJbnRlcmVzdFdlaWdodFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXaAh9UU19TT1VSQ0VfWlJFQ0FMTF9JVEVNQ0ZfVVBWT1RF6AID+gILTk9STUFMX0ZMT1eKAyBkNGE0ODVmNzY2MWQ0MGVhYWZiYThjMTFmODg3YjgzN5oDDQoCdjIQABoFb3RoZXKoA5Mi2AMA6gMZdGV4dEFsbFNpdGVBY3Rpb25JdGVtQ0ZWMvoDggUSDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFOi0IAhCAChjQBSIjdjItODA2ODkxMmMwMTJkNTA4MzU1Zjg1OTAwYjY3OWZjZjE6LQgCEIAKGNAFIiN2Mi02MTQwNmZmZDE2OTNkNGIwZjIzMWZjYzQ0OWU0OTRmMzotCAIQgAoY0AUiI3YyLTBlYWZkZDIxYTEwODdkOTNjODgzMDFkYTFmN2UwYmFkOi0IAhCAChjQBSIjdjItY2U2ZjcyZGY1NmExNGY4OTU1Nzg5ODdjZjM3OGQ5MDk6LQgCEIAKGNAFIiN2Mi0wYmZiNDNkY2JjNDBlNzg2MjQwYWY1MTc3NDg0ZTg0NzotCAIQgAoY0AUiI3YyLTg5YjRkNjlkOTBiY2IxZGQ2NTE4NWE3YmVlYmMyOWNhOi0IAhCAChjQBSIjdjItN2RmOGIyYTYwZTE1N2Q5ZmYyN2IwN2NlMWQwZDY1NTE6LQgCEIAKGNAFIiN2Mi0xN2ZhMjljNTQxYjcxODY2ZTdmZGQwMjBhMmRhNGRhMjotCAMQgAoY0AUiI3YyLTc1OTVjZjg1NDM1MWYwOTJlODI1YTg5YTgxOTIyN2MyOi0IAhCAChjQBSIjdjItMWU2Yjg3MWQ1OTgyOTRjZjE5OTRiMmRkNWIyZjZmMWM6LQgDEIAKGNAFIiN2Mi02MmY4MjI2NWM3MGE3ZTIyYzIxNmI0ZWZjNTViNWYwMzotCAIQgAoY0AUiI3YyLTFjMDE3MzE4YTdhMzRiNDM2OGEwZmYzZGVjZjNkNzgyOi0IAhCAChjQBSIjdjItNGMyNWJkNmI0N2UzZmQyMDVkZWVhZDhmNWYyYWUxZWaABACIBACSBAZOb3JtYWyaBAEzoAQAqAQAsAQAugQGbWFudWFswgQDMTcwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAADAbrO9P4EFAAAAAAAAAACJBQsD4WCPftI/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBQ6QBgCgBk+oBgGSAi4KCTI1OTQwNzIwNRITMTkyMDE3MDA4NjUyMzcyNDQ4NxgHIgpJTUFHRV9URVhU","action_card":false},{"id":"79_1750899137.238","type":"feed","offset":79,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899137,"updated_time":1750899137,"target":{"id":"1921243255661627166","type":"answer","url":"https://api.zhihu.com/answers/1921243255661627166","author":{"id":"770ac5d857436394529bed656ea1f7c8","url":"https://api.zhihu.com/people/770ac5d857436394529bed656ea1f7c8","user_type":"people","url_token":"bai-zhan-gui-lai-zai-du-shu-23","name":"阿凯财富论","headline":"创业， 始于梦想， 死于常识。\n\n公号：【阿凯财富论】\n\n","avatar_url":"https://pic1.zhimg.com/50/v2-8adc0731233f4ab02311a283b214a61e_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":2266,"is_following":false,"is_followed":false},"created_time":1750840087,"updated_time":1750840087,"voteup_count":4,"thanks_count":0,"comment_count":0,"is_copyable":true,"question":{"id":"1905035744277427833","type":"question","url":"https://api.zhihu.com/questions/1905035744277427833","author":{"id":"eb90c5c250ea7fad7bd9b937f944de4c","url":"https://api.zhihu.com/people/eb90c5c250ea7fad7bd9b937f944de4c","user_type":"people","url_token":"--50-20-81-1","name":"江湖浪子.","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-5940db3a24bd5262f61fd961cc7f9b8a_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":3,"is_following":false,"is_followed":false},"title":"现在就想搞钱，有靠谱路子吗?","created":1746975915,"answer_count":0,"follower_count":0,"comment_count":6,"bound_topic_ids":[1344163,2067530],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"一个饿得快要死的人， 冲进一家餐厅， 抓住老板的衣领， 嘶吼道： “快！ 给我吃的！ 什么都行！ 我现在就要！”老板被他吓了一跳， 但还是好心地， 从厨房里， 端出了一碗， 热气腾腾的， 白米饭。 说： “兄弟， 别急， 先吃这个， 垫垫肚子。”这个人， 一把推开那碗饭， 眼睛血红地， 盯着菜单上， 最贵的那道菜——“佛跳墙”。 他指着图片， 对老板说： “不！ 我就要吃这个！ 我听说， 吃了这个， 就能立刻， 满血复活！…","excerpt_new":"一个饿得快要死的人， 冲进一家餐厅， 抓住老板的衣领， 嘶吼道： “快！ 给我吃的！ 什么都行！ 我现在就要！”老板被他吓了一跳， 但还是好心地， 从厨房里， 端出了一碗， 热气腾腾的， 白米饭。 说： “兄弟， 别急， 先吃这个， 垫垫肚子。”这个人， 一把推开那碗饭， 眼睛血红地， 盯着菜单上， 最贵的那道菜——“佛跳墙”。 他指着图片， 对老板说： “不！ 我就要吃这个！ 我听说， 吃了这个， 就能立刻， 满血复活！…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"EKZ6xZXF\"\u003e一个饿得快要死的人，\u003cbr/\u003e冲进一家餐厅，\u003cbr/\u003e抓住老板的衣领，\u003cbr/\u003e嘶吼道：\u003cbr/\u003e“快！\u003cbr/\u003e给我吃的！\u003cbr/\u003e什么都行！\u003cbr/\u003e我现在就要！”\u003c/p\u003e\u003cp data-pid=\"-jV4E4dz\"\u003e老板被他吓了一跳，\u003cbr/\u003e但还是好心地，\u003cbr/\u003e从厨房里，\u003cbr/\u003e端出了一碗，\u003cbr/\u003e热气腾腾的，\u003cbr/\u003e白米饭。\u003cbr/\u003e说：\u003cbr/\u003e“兄弟，\u003cbr/\u003e别急，\u003cbr/\u003e先吃这个，\u003cbr/\u003e垫垫肚子。”\u003c/p\u003e\u003cp data-pid=\"xTRS9rQV\"\u003e这个人，\u003cbr/\u003e一把推开那碗饭，\u003cbr/\u003e眼睛血红地，\u003cbr/\u003e盯着菜单上，\u003cbr/\u003e最贵的那道菜——“佛跳墙”。\u003cbr/\u003e他指着图片，\u003cbr/\u003e对老板说：\u003cbr/\u003e“不！\u003cbr/\u003e我就要吃这个！\u003cbr/\u003e我听说，\u003cbr/\u003e吃了这个，\u003cbr/\u003e就能立刻，\u003cbr/\u003e满血复活！”\u003c/p\u003e\u003cp data-pid=\"l59PgNCr\"\u003e老板叹了口气，\u003cbr/\u003e说：\u003cbr/\u003e“兄弟，\u003cbr/\u003e你现在的肠胃，\u003cbr/\u003e根本受不了这么油腻的东西。\u003cbr/\u003e你现在最需要的，\u003cbr/\u003e不是山珍海味，\u003cbr/\u003e就是这碗，\u003cbr/\u003e能救你命的，\u003cbr/\u003e白米饭。”\u003c/p\u003e\u003cp data-pid=\"_J8a_mab\"\u003e你那句“现在就想搞钱”，\u003cbr/\u003e就是那个饿死鬼，\u003cbr/\u003e在嘶吼。\u003cbr/\u003e在这种极度渴求，\u003cbr/\u003e又极度虚弱的状态下，\u003cbr/\u003e任何看起来能“一口回血”的“佛跳墙”（暴富项目），\u003cbr/\u003e都是能让你，\u003cbr/\u003e直接进ICU的毒药。\u003cbr/\u003e你现在唯一需要的，\u003cbr/\u003e就是那碗，\u003cbr/\u003e最朴素，\u003cbr/\u003e最难吃，\u003cbr/\u003e但却能救你命的，\u003cbr/\u003e“白米饭”。\u003c/p\u003e\u003chr/\u003e\u003cp data-pid=\"arACYkHF\"\u003e\u003cb\u003e\u003cu\u003e第一口饭：去“垃圾堆”里，捡“信息差”\u003c/u\u003e\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"3RPju4Sc\"\u003e这是你能立刻上手，\u003cbr/\u003e最原始，\u003cbr/\u003e也最有效的搞钱方式。\u003cbr/\u003e别一听“垃圾堆”就觉得low。\u003cbr/\u003e我说的“垃圾堆”，\u003cbr/\u003e是指那些被大多数“聪明人”所忽略的，\u003cbr/\u003e信息不对称的洼地。\u003c/p\u003e\u003cp data-pid=\"b4yDEd_R\"\u003e搞钱，\u003cbr/\u003e最快的法门，\u003cbr/\u003e永远是“信息差”。\u003cbr/\u003e就是“你知道，但他不知道”。\u003cbr/\u003e在今天这个信息爆炸的时代，\u003cbr/\u003e信息差不但没有消失，\u003cbr/\u003e反而以一种更隐蔽的方式，\u003cbr/\u003e遍地都是。\u003cbr/\u003e因为信息太多，\u003cbr/\u003e等于没有信息。\u003cbr/\u003e在信息的海洋里，\u003cbr/\u003e帮别人“筛选”和“搬运”有用的信息，\u003cbr/\u003e本身就是一种极具价值的服务。\u003c/p\u003e\u003cp data-pid=\"dZ-0J7Rn\"\u003e你现在立刻就能去的，\u003cbr/\u003e最大的“信息垃圾堆”，\u003cbr/\u003e有两个：\u003cbr/\u003e\u003cb\u003e一个是“国内”与“国外”的墙；\u003c/b\u003e\u003cbr/\u003e\u003cb\u003e另一个是“付费”与“免费”的墙。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"onqrO8u7\"\u003e怎么捡“国内国外”的信息差？\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"kKy6-SQo\"\u003e\u003cb\u003e搬运工具：\u003c/b\u003e\u003cbr/\u003e国外有很多极其牛逼的，\u003cbr/\u003e免费的或有试用期的AI工具、设计软件、效率神器。\u003cbr/\u003e大部分国内用户不知道，\u003cbr/\u003e或者不会用。\u003cbr/\u003e你不需要懂技术。\u003cbr/\u003e你只需要花时间去YouTube上，\u003cbr/\u003e看那些老外是怎么用这些工具的。\u003cbr/\u003e然后，\u003cbr/\u003e把他们的使用教程“翻译”过来，\u003cbr/\u003e录成一个中文版的保姆级教程。\u003cbr/\u003e再然后，\u003cbr/\u003e把这个工具的安装包和你的教程打包在一起，\u003cbr/\u003e放到闲鱼、淘宝上，\u003cbr/\u003e卖个9块9，\u003cbr/\u003e或者29块9。\u003cbr/\u003e你赚的，\u003cbr/\u003e就是信息差和你的“翻译”辛苦费。\u003c/li\u003e\u003cli data-pid=\"Lz2GnCW-\"\u003e\u003cb\u003e搬运内容：\u003c/b\u003e\u003cbr/\u003e去TikTok上找那些点赞几百万的，\u003cbr/\u003e最火的宠物搞笑视频，\u003cbr/\u003e或者生活小技巧视频。\u003cbr/\u003e把它们下载下来，\u003cbr/\u003e用剪映简单地去个水印，\u003cbr/\u003e换个背景音乐。\u003cbr/\u003e然后，\u003cbr/\u003e发布到你自己的抖音、快手、视频号上。\u003cbr/\u003e这叫“内容搬运”。\u003cbr/\u003e虽然平台不鼓励，\u003cbr/\u003e但只要你做得巧妙，\u003cbr/\u003e依然有巨大的流量空间。\u003cbr/\u003e有了流量，\u003cbr/\u003e你就可以接广告，\u003cbr/\u003e或者在主页挂上商品链接，\u003cbr/\u003e赚取佣金。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"krAaaOlV\"\u003e怎么捡“付费免费”的信息差？\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"dfHwxE16\"\u003e\u003cb\u003e搬运报告和资料：\u003c/b\u003e\u003cbr/\u003e有很多专业的行业网站或付费数据库，\u003cbr/\u003e会定期发布非常有价值的行业研究报告。\u003cbr/\u003e这些东西对于普通人来说，\u003cbr/\u003e要么找不到，\u003cbr/\u003e要么太贵了。\u003cbr/\u003e你可以想办法通过各种渠道搞到这些资料。\u003cbr/\u003e然后，\u003cbr/\u003e把这些资料拆分成不同的主题，\u003cbr/\u003e比如《2024年中国咖啡行业发展白皮书》。\u003cbr/\u003e再把它们挂到闲鱼，\u003cbr/\u003e或者专门的文档交易网站上，\u003cbr/\u003e卖个几块钱一份。\u003cbr/\u003e你赚的，\u003cbr/\u003e是信息渠道的差价。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"BQK0xymW\"\u003e这个“捡垃圾”的过程，\u003cbr/\u003e看起来技术含量很低，\u003cbr/\u003e甚至有点“不道德”。\u003cbr/\u003e但你必须明白，\u003cbr/\u003e\u003cb\u003e在你快要饿死的时候，生存，就是最大的道德。\u003c/b\u003e\u003cbr/\u003e你通过这些“搬运”，\u003cbr/\u003e赚到的不仅仅是你的第一笔救命钱。\u003cbr/\u003e更重要的，\u003cbr/\u003e是你在这个过程中，\u003cbr/\u003e亲手完成了一次最完整的商业闭环：\u003cbr/\u003e\u003cb\u003e发现信息差 -\u0026gt; 获取信息 -\u0026gt; 加工信息 -\u0026gt; 找到目标用户 -\u0026gt; 完成交易。\u003c/b\u003e\u003cbr/\u003e这个经验，\u003cbr/\u003e比任何商业理论都宝贵一万倍。\u003c/p\u003e\u003chr/\u003e\u003cp data-pid=\"uN_cqum6\"\u003e\u003cb\u003e\u003cu\u003e第二口饭：在“窄巷子”里，卖“确定性”\u003c/u\u003e\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"CXa44o_C\"\u003e当你通过“捡垃圾”，\u003cbr/\u003e吃上了第一口饭，\u003cbr/\u003e不再为生存发愁的时候。\u003cbr/\u003e你就要开始吃第二口饭了。\u003cbr/\u003e这口饭，\u003cbr/\u003e能让你从“活下去”，\u003cbr/\u003e走向“活得好”。\u003cbr/\u003e这口饭，\u003cbr/\u003e叫**“卖确定性”**。\u003c/p\u003e\u003cp data-pid=\"tobjpz0i\"\u003e这个世界充满了“不确定性”。\u003cbr/\u003e而人们愿意花大价钱去购买“确定性”。\u003cbr/\u003e“我这样做，\u003cbr/\u003e就一定能瘦下来吗？”\u003cbr/\u003e“我买这个，\u003cbr/\u003e就一定能解决我的问题吗？”\u003cbr/\u003e“我跟着你干，\u003cbr/\u003e就一定能赚到钱吗？”\u003cbr/\u003e谁能提供一个更“确定”的答案，\u003cbr/\u003e谁就能收到钱。\u003c/p\u003e\u003cp data-pid=\"7UZCighb\"\u003e对于一个刚起步的普通人，\u003cbr/\u003e你不可能在宽阔的大马路上，\u003cbr/\u003e去跟那些大公司、大品牌拼“确定性”。\u003cbr/\u003e你唯一的活路，\u003cbr/\u003e是找到一条极其狭窄的，\u003cbr/\u003e没人看得上的“窄巷子”。\u003cbr/\u003e然后，\u003cbr/\u003e在这条巷子里，\u003cbr/\u003e成为那个能提供最强“确定性”的专家。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"tgB2FhWU\"\u003e\u003cb\u003e不要做“英语培训”，\u003c/b\u003e\u003cbr/\u003e那条路太宽了，\u003cbr/\u003e挤满了巨头。\u003cbr/\u003e\u003cb\u003e你可以做“只针对程序员的，面试英语口语陪练”。\u003c/b\u003e\u003cbr/\u003e你的目标用户，\u003cbr/\u003e极其精准。\u003cbr/\u003e他们的痛点，\u003cbr/\u003e极其明确。\u003cbr/\u003e你提供的“确定性”就是：\u003cbr/\u003e“跟我练一个月，\u003cbr/\u003e保证你能流利地，\u003cbr/\u003e回答外企面试官的，\u003cbr/\u003e那10个最高频的技术问题。”\u003c/li\u003e\u003cli data-pid=\"B64L-JAG\"\u003e\u003cb\u003e不要做“PPT美化”，\u003c/b\u003e\u003cbr/\u003e这个服务太泛滥了。\u003cbr/\u003e\u003cb\u003e你可以做“只针对医药代表的，学术会议PPT美化”。\u003c/b\u003e\u003cbr/\u003e你深入研究这个行业的审美和规范，\u003cbr/\u003e你提供的“确定性”就是：\u003cbr/\u003e“把你的PPT交给我，\u003cbr/\u003e保证做出来的效果，\u003cbr/\u003e比你们公司，\u003cbr/\u003e所有同事的都专业，\u003cbr/\u003e让你的老板和客户，\u003cbr/\u003e眼前一亮。”\u003c/li\u003e\u003cli data-pid=\"Bv8dDlhw\"\u003e\u003cb\u003e不要做“个人形象顾问”，\u003c/b\u003e\u003cbr/\u003e这个概念太虚了。\u003cbr/\u003e\u003cb\u003e你可以做“只针对大龄单身男性的，第一次约会形象改造”。\u003c/b\u003e\u003cbr/\u003e你提供的“确定性”就是：\u003cbr/\u003e“给我3个小时，\u003cbr/\u003e我带你去搞定发型、服装、配饰，\u003cbr/\u003e保证让你在约会时，\u003cbr/\u003e看起来像个，\u003cbr/\u003e干净、体面、有品位的正常人。”\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"We_LKHk2\"\u003e\u003cb\u003e在“窄巷子”里，你就是王。\u003c/b\u003e\u003cbr/\u003e因为你的竞争对手，\u003cbr/\u003e几乎为零。\u003cbr/\u003e你可以把一个极小的需求，\u003cbr/\u003e做得极深，\u003cbr/\u003e极透。\u003cbr/\u003e然后，\u003cbr/\u003e定一个，\u003cbr/\u003e让你自己都觉得有点心虚的，\u003cbr/\u003e高价。\u003cbr/\u003e因为，\u003cbr/\u003e“确定性”，\u003cbr/\u003e本身就是最贵的奢侈品。\u003c/p\u003e\u003chr/\u003e\u003cp data-pid=\"tcmoWs7V\"\u003e\u003cb\u003e\u003cu\u003e第三口饭：别想“万无一失”，先求“一枪开出”\u003c/u\u003e\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"m03vY1Hl\"\u003e你那句“现在就想”，\u003cbr/\u003e还藏着一个巨大的敌人，\u003cbr/\u003e叫**“完美主义”**。\u003cbr/\u003e你越是渴望，\u003cbr/\u003e就越是害怕失败。\u003cbr/\u003e你总想，\u003cbr/\u003e找到一个“万无一失”的，\u003cbr/\u003e“绝对靠谱”的路子，\u003cbr/\u003e然后，\u003cbr/\u003e再开始行动。\u003cbr/\u003e结果就是，\u003cbr/\u003e你永远都在“准备”，\u003cbr/\u003e永远都在“观望”，\u003cbr/\u003e永远都在“等待下一个”。\u003c/p\u003e\u003cp data-pid=\"7OOZ48IE\"\u003e\u003cb\u003e对于一个饿着肚子的人来说，最愚蠢的行为，就是挑剔食物。\u003c/b\u003e\u003cbr/\u003e你现在要做的，\u003cbr/\u003e不是去写一份完美的商业计划书。\u003cbr/\u003e而是，\u003cbr/\u003e\u003cb\u003e立刻，马上，现在，去完成你的第一个“交易闭环”。\u003c/b\u003e\u003cbr/\u003e哪怕，\u003cbr/\u003e只赚一块钱。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"wh1SzAej\"\u003e\u003cb\u003e别再分析哪个AI工具更有前景了。\u003c/b\u003e\u003cbr/\u003e现在就去闲鱼上，\u003cbr/\u003e发布一个服务：\u003cbr/\u003e“10元，用AI帮你写一篇200字的检讨书”。\u003cbr/\u003e看看会不会有人买。\u003c/li\u003e\u003cli data-pid=\"g-lxPESt\"\u003e\u003cb\u003e别再研究哪个短视频平台流量更大了。\u003c/b\u003e\u003cbr/\u003e现在就拿起手机，\u003cbr/\u003e把你家楼下的那只流浪猫，\u003cbr/\u003e拍一个15秒的视频，\u003cbr/\u003e配上一段伤感的音乐，\u003cbr/\u003e发出去。\u003cbr/\u003e看看会不会有100个播放。\u003c/li\u003e\u003cli data-pid=\"M3956eK4\"\u003e\u003cb\u003e别再犹豫你的“窄巷子”到底够不够窄了。\u003c/b\u003e\u003cbr/\u003e现在就去你所在城市的一个本地论坛，\u003cbr/\u003e或者豆瓣小组里，\u003cbr/\u003e发一个帖子：\u003cbr/\u003e“本人XX行业从业者，\u003cbr/\u003e免费回答3个关于XX的问题，\u003cbr/\u003e先到先得。”\u003cbr/\u003e看看会不会有人理你。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"sgUEOlCb\"\u003e\u003cb\u003e行动，是治愈一切焦虑和幻想的，唯一解药。\u003c/b\u003e\u003cbr/\u003e当你开出了第一枪，\u003cbr/\u003e哪怕打偏了，\u003cbr/\u003e你也获得了，\u003cbr/\u003e比所有观望者，\u003cbr/\u003e都宝贵的东西：\u003cbr/\u003e\u003cb\u003e反馈。\u003c/b\u003e\u003cbr/\u003e市场的反馈，\u003cbr/\u003e用户的反馈。\u003cbr/\u003e这个反馈，\u003cbr/\u003e会告诉你，\u003cbr/\u003e你的下一枪，\u003cbr/\u003e该朝哪个方向瞄准。\u003cbr/\u003e而那些，\u003cbr/\u003e还在靶场外面，\u003cbr/\u003e研究“射击理论”的人，\u003cbr/\u003e他们永远，\u003cbr/\u003e都不会有开枪的机会。\u003c/p\u003e\u003chr/\u003e\u003cp data-pid=\"suauo4ox\"\u003e好了，\u003cbr/\u003e三口“白米饭”，\u003cbr/\u003e给你了。\u003c/p\u003e\u003cp data-pid=\"pQSnETQ0\"\u003e第一口，\u003cbr/\u003e\u003cb\u003e去“垃圾堆”里捡“信息差”\u003c/b\u003e，\u003cbr/\u003e解决你的生存问题。\u003c/p\u003e\u003cp data-pid=\"_KTrzfZu\"\u003e第二口，\u003cbr/\u003e\u003cb\u003e在“窄巷子”里卖“确定性”\u003c/b\u003e，\u003cbr/\u003e解决你的温饱问题。\u003c/p\u003e\u003cp data-pid=\"qMFlNjQw\"\u003e第三口，\u003cbr/\u003e\u003cb\u003e用“先开一枪”的莽劲\u003c/b\u003e，\u003cbr/\u003e解决你“想得太多，做得太少”的内耗问题。\u003c/p\u003e\u003cp data-pid=\"s-2W_-ux\"\u003e这三个路子，\u003cbr/\u003e都不性感，\u003cbr/\u003e都不高级。\u003cbr/\u003e但它们，\u003cbr/\u003e足够“靠谱”。\u003cbr/\u003e因为它们，\u003cbr/\u003e不需要你，\u003cbr/\u003e有任何资本、人脉和背景。\u003cbr/\u003e它们唯一需要的，\u003cbr/\u003e就是你，\u003cbr/\u003e放下所有的幻想和包袱，\u003cbr/\u003e像一个饿疯了的野狗一样，\u003cbr/\u003e扑向离你最近的那块，\u003cbr/\u003e能吃的肉。\u003c/p\u003e\u003cp data-pid=\"SB1Ly_U_\"\u003e如果你想知道，\u003cbr/\u003e我是如何运用这套“野狗战术”，\u003cbr/\u003e从零开始，\u003cbr/\u003e一步步吃饱，\u003cbr/\u003e吃好，\u003cbr/\u003e并最终赚到第一桶金的。\u003c/p\u003e\u003cp data-pid=\"hWYJvSp_\"\u003e我把我的思考和实操过程，\u003cbr/\u003e都毫无保留地写在了这篇文章里，\u003cbr/\u003e有缘人可以看看：\u003cbr/\u003e\u003cb\u003e\u003cu\u003e\u003ca href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/kkE5NUU0FXqi-Z_S0QbgFA\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e阿凯：《 互联网创业之：第一桶金\u0026amp;0-1实操方法论》\u003c/a\u003e\u003c/u\u003e\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"FOXR9vah\"\u003e如果上面那个不方便，\u003cbr/\u003e也可以去我的公号【阿凯财富论】，\u003cbr/\u003e发送“第一桶金”这三个字，\u003cbr/\u003e系统会自动发给你。\u003c/p\u003e\u003cp data-pid=\"abua0f55\"\u003e希望它能成为，\u003cbr/\u003e你咬下去的，\u003cbr/\u003e第一口，\u003cbr/\u003e坚实的，\u003cbr/\u003e能救命的，\u003cbr/\u003e“白米饭”。\u003c/p\u003e\u003cp data-pid=\"tdE7VNkt\"\u003e最后，\u003cbr/\u003e送你一句话：\u003c/p\u003e\u003cp data-pid=\"ShMhlOfG\"\u003e别再找路了，你把脚下的坑填平，路就出来了。\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":67,"favorite_count":5,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1921243255661627166}","attached_info":"CpUGCOD5laeW9LTCsgEQBBoJNzMzOTYxNTE3IJfm7sIGKAQwAEBPSiMKGFRTX1NPVVJDRV9XQVJNX1VQX0JPT1NUMRIBMBgAIAA6AEotCiJUU19TT1VSQ0VfV0FSTV9VUF9ISUdIX0lOVEVSQUNUSU9OEgEwGAAgADoAWgkxMTQ4OTc0ODliIGE4NDViNTdjZWFkMzQwN2I5YzhhOThjYTMyMmM0NzFichMxOTIxMjQzMjU1NjYxNjI3MTY2igETMTkwNTAzNTc0NDI3NzQyNzgzM6oBCXJlY29tbWVuZMIBIDc3MGFjNWQ4NTc0MzYzOTQ1MjliZWQ2NTZlYTFmN2M48gEKCAwSBk5vcm1hbPIBKAgKEiRmMDllYWNkNy0xMzE5LTQ3YzEtOWRhNi1kOGJkYzM2ZjlhNGHyAQYICxICMTSCAgCIAuC04s36MpICIDc3MGFjNWQ4NTc0MzYzOTQ1MjliZWQ2NTZlYTFmN2M4mgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCG0ludGVyYWN0aW9uU2hvckludGVyZXN0UnVsZcoCGFBlcmlvZEludGVyZXN0V2VpZ2h0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZdoCGFRTX1NPVVJDRV9XQVJNX1VQX0JPT1NUMegCA/oCC05PUk1BTF9GTE9XigMgZDRhNDg1Zjc2NjFkNDBlYWFmYmE4YzExZjg4N2I4MzeaAw0KAnYyEAAaBW90aGVyqAND2AMA6gMedGV4dF9oaWdoX2ludGVyYWN0aW9uX3JlY2FsbGVy+gMfEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERYAEAIgEAJIEBk5vcm1hbJoEATOgBACoBACwBAC6BAJhacIEAzQwMMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAAB3grz+BBQAAAAAAAAAAiQULA+Fgj37SP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AUOkAYAoAZQqAYDkgIuCgk3MzM5NjE1MTcSEzE5MjEyNDMyNTU2NjE2MjcxNjYYBCIKSU1BR0VfVEVYVA==","action_card":false},{"id":"80_1750899137.337","type":"feed","offset":80,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899137,"updated_time":1750899137,"target":{"id":"1920799642095968590","type":"answer","url":"https://api.zhihu.com/answers/1920799642095968590","author":{"id":"5de8d36016d620412ecbde364592a2a2","url":"https://api.zhihu.com/people/5de8d36016d620412ecbde364592a2a2","user_type":"people","url_token":"wo-de-qing-chun-wo-zuo-zhu-16","name":"我的青春我做主","headline":"读书、音乐、旅行、电影，人生四大美事。","avatar_url":"https://picx.zhimg.com/50/v2-3223e263327199caf73dac76d0d0f8c8_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":14,"is_following":false,"is_followed":false},"created_time":1750734321,"updated_time":1750734321,"voteup_count":49,"thanks_count":4,"comment_count":18,"is_copyable":true,"question":{"id":"1918261062500877575","type":"question","url":"https://api.zhihu.com/questions/1918261062500877575","author":{"id":"10011d7d11772094c59845862445fc11","url":"https://api.zhihu.com/people/10011d7d11772094c59845862445fc11","user_type":"people","url_token":"61-75-73-81","name":"锦上添花文旅","headline":"不夜城点亮文商旅地","avatar_url":"https://picx.zhimg.com/50/v2-5beed1f2e72f13c7b95ed8811a7ccbda_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":68,"is_following":false,"is_followed":false},"title":"为什么人总想去旅游？","created":1750129076,"answer_count":0,"follower_count":0,"comment_count":0,"bound_topic_ids":[444,12460,2204977,2511383],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"你有没有发现一个很有意思的现象，那些生活美满、内心充实的人，都有个特征——不厌其烦地往外跑。 别说休年假去旅游，就是个普通周末，都带着一家人各处玩 曾经，我也很不理解，觉得在家歇歇不好吗？ 但接触过一些很宅的朋友后，我终于明白： 整天待在家里，人会慢慢地像见不着阳光的盆栽一样萎靡不振。 工作上的钩心斗角、生活中的琐碎日常、和人打交道的麻烦，常常把我们耗得身心疲惫。可生命是需要滋养的，能量是流动的，人…","excerpt_new":"你有没有发现一个很有意思的现象，那些生活美满、内心充实的人，都有个特征——不厌其烦地往外跑。 别说休年假去旅游，就是个普通周末，都带着一家人各处玩 曾经，我也很不理解，觉得在家歇歇不好吗？ 但接触过一些很宅的朋友后，我终于明白： 整天待在家里，人会慢慢地像见不着阳光的盆栽一样萎靡不振。 工作上的钩心斗角、生活中的琐碎日常、和人打交道的麻烦，常常把我们耗得身心疲惫。可生命是需要滋养的，能量是流动的，人…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"wUB5cWpn\"\u003e你有没有发现一个很有意思的现象，那些生活美满、内心充实的人，都有个特征——不厌其烦地往外跑。\u003c/p\u003e\u003cp data-pid=\"uQukqMqh\"\u003e别说休年假去旅游，就是个普通周末，都带着一家人各处玩\u003c/p\u003e\u003cp data-pid=\"ZlkzS79d\"\u003e曾经，我也很不理解，觉得在家歇歇不好吗？\u003c/p\u003e\u003cp data-pid=\"TAR6VsuO\"\u003e但接触过一些很宅的朋友后，我终于明白：\u003c/p\u003e\u003cp data-pid=\"lStAQqSt\"\u003e整天待在家里，人会慢慢地像见不着阳光的盆栽一样萎靡不振。\u003c/p\u003e\u003cp data-pid=\"BQkETQBQ\"\u003e工作上的钩心斗角、生活中的琐碎日常、和人打交道的麻烦，常常把我们耗得身心疲惫。可生命是需要滋养的，能量是流动的，人不能长期生活在逼仄的环境中。\u003c/p\u003e\u003cp data-pid=\"LNYruuo3\"\u003e只有走出去，才能为生命攒够能量。\u003c/p\u003e\u003cp data-pid=\"t5tnBq6v\"\u003e废掉一个人，就让他长期待在家里。\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":7539,"favorite_count":35,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1920799642095968590}","attached_info":"CogGCOD5laeW9LTCsgEQBBoJNzMzNzMxMjkxIPGr6MIGKDEwEkBQSigKE1RTX1NPVVJDRV9GRUVEUkVfVjkSATAYACAAOgp7InJhdyI6IiJ9WgkxMTU0MjM1MjRiIGE4NDViNTdjZWFkMzQwN2I5YzhhOThjYTMyMmM0NzFichMxOTIwNzk5NjQyMDk1OTY4NTkwigETMTkxODI2MTA2MjUwMDg3NzU3NaoBCXJlY29tbWVuZMIBIDVkZThkMzYwMTZkNjIwNDEyZWNiZGUzNjQ1OTJhMmEy8gEKCAwSBk5vcm1hbPIBKAgKEiQ1MzA5ZjRmYi1jYTA1LTQ3YTUtOThmMS01MDQyZWZhZjVhYmTyAQYICxICMTSCAgCIAuC04s36MpICIDVkZThkMzYwMTZkNjIwNDEyZWNiZGUzNjQ1OTJhMmEymgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCFkFjdGlvblNob3JJbnRlcmVzdFJ1bGXKAhtJbnRlcmFjdGlvblNob3JJbnRlcmVzdFJ1bGXKAhZSZXZpc2l0VmFsdWVXZWlnaHRSdWxlygIYUGVyaW9kSW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxl2gITVFNfU09VUkNFX0ZFRURSRV9WOegCAvoCC05PUk1BTF9GTE9XigMgZDRhNDg1Zjc2NjFkNDBlYWFmYmE4YzExZjg4N2I4MzeaAw0KAnYyEAAaBW90aGVyqAPzOtgDAOoDCWZlZWRyZV92OfoDHxIMVU5LTk9XTl9NT0RFIAAqDU5PX0lNQUdFX01PREWABACIBACSBAZOb3JtYWyaBAEyoAQAqAQAsAQAugQGbWFudWFswgQDMTcwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAABA7zvAP4EFAAAAAAAAAACJBQsD4WCPftI/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBQ6QBgCgBlGoBgCSAi4KCTczMzczMTI5MRITMTkyMDc5OTY0MjA5NTk2ODU5MBgEIgpJTUFHRV9URVhU","action_card":false},{"id":"81_1750899137.555","type":"feed","offset":81,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899137,"updated_time":1750899137,"target":{"id":"34236046287","type":"answer","url":"https://api.zhihu.com/answers/34236046287","author":{"id":"385dea39a29d29c1fa0fd7f369c2da5e","url":"https://api.zhihu.com/people/385dea39a29d29c1fa0fd7f369c2da5e","user_type":"people","url_token":"23-3-81-13","name":"断水流","headline":"","avatar_url":"https://pica.zhimg.com/50/v2-b64b4f72de36f016dc279bf8625f24cc_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":181,"is_following":false,"is_followed":false},"created_time":1731897454,"updated_time":1732559749,"voteup_count":1304,"thanks_count":52,"comment_count":219,"is_copyable":true,"question":{"id":"581089880","type":"question","url":"https://api.zhihu.com/questions/581089880","author":{"id":"6db48006b34257dcd77077b16b992e9b","url":"https://api.zhihu.com/people/6db48006b34257dcd77077b16b992e9b","user_type":"people","url_token":"bi-qin-zhai-zhu","name":"无梦楼主","headline":"海内存知己，天涯若比邻。","avatar_url":"https://picx.zhimg.com/50/v2-af961cae9ce266b1a0662144c154e582_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":664,"is_following":false,"is_followed":false},"title":"马斯克的成功主要靠的是什么？","created":1674964539,"answer_count":0,"follower_count":0,"comment_count":5,"bound_topic_ids":[922,962,2143,7614,24600],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"第一，出身，网上把马斯克爸爸说的很不堪，什么家暴男，渣男，事实是马斯克和他爸爸大部分时间关系都很好，马斯克爸爸本身就是企业家，马斯克90年代初做zip2还是靠他爹给的三万美金起步。那时候天天睡办公室，省钱，三万美金那时候可以在美国买一套别墅，在上海买最少一两套房子。 马斯克的妈妈是南非小姐冠军，普通人她会嫁吗？他外公上世纪三十年代都有自己的私人飞机已经在全世界自己开飞机旅行了。想象一下要是你妈妈是中国…","excerpt_new":"第一，出身，网上把马斯克爸爸说的很不堪，什么家暴男，渣男，事实是马斯克和他爸爸大部分时间关系都很好，马斯克爸爸本身就是企业家，马斯克90年代初做zip2还是靠他爹给的三万美金起步。那时候天天睡办公室，省钱，三万美金那时候可以在美国买一套别墅，在上海买最少一两套房子。 马斯克的妈妈是南非小姐冠军，普通人她会嫁吗？他外公上世纪三十年代都有自己的私人飞机已经在全世界自己开飞机旅行了。想象一下要是你妈妈是中国…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"NBoe8ewI\"\u003e第一，出身，网上把马斯克爸爸说的很不堪，什么家暴男，渣男，事实是马斯克和他爸爸大部分时间关系都很好，马斯克爸爸本身就是企业家，马斯克90年代初做zip2还是靠他爹给的三万美金起步。那时候天天睡办公室，省钱，三万美金那时候可以在美国买一套别墅，在上海买最少一两套房子。\u003c/p\u003e\u003cp data-pid=\"mCrOOteW\"\u003e马斯克的妈妈是南非小姐冠军，普通人她会嫁吗？他外公上世纪三十年代都有自己的私人飞机已经在全世界自己开飞机旅行了。想象一下要是你妈妈是中国小姐冠军，你爸爸是企业家，你外公在抗战时就有私人飞机，你现在会是个啥样？总不至于一个月三五千，给人打工去吧？\u003c/p\u003e\u003cp data-pid=\"yscGmjWR\"\u003e马斯克在上世纪七零年代他爸就给他买电脑了，那时候中国还在闹文革。他这辈子赚的第一比钱是80年代初靠电脑编程搞了个小游戏，那会他快上中学了，赚了好像两三千美金。爽翻了，很刺激。\u003c/p\u003e\u003cp data-pid=\"adPqdCpP\"\u003e而且马斯克智商180，你不能说这不是遗传，你说这是后天努力，靠自己努力一路考试考到斯坦福？\u003c/p\u003e\u003cp data-pid=\"1cw0L62P\"\u003e马斯克还有个弟弟，混的也很好。就是他们本身家庭就很不错，只是爹妈中途离婚，但是小时候的底子和智商都在。差不到哪里。\u003c/p\u003e\u003cp data-pid=\"BoMfRHNf\"\u003e马斯克要是普通收入家庭，普通智商，基本就是和大部分南非白人一样，跑路去美国或者英国澳洲，打个工，踏踏实实，中产阶级。\u003c/p\u003e\u003cp data-pid=\"0owaUQ-w\"\u003e普通人不要异想天开，以为努力一下，天下就是你的。\u003c/p\u003e\u003cp data-pid=\"UGJcu6Ax\"\u003e特靠谱那么火，但是你要知道，特朗普他爹在三四十年前就给了他4亿美金遗产，相当于现在一百亿。现在他身家多少，也就二十多亿。途中还破产四次。特朗普家族最牛的是他爷爷，一穷二白来美国打拼，成为富豪。虽然是捞偏门。\u003c/p\u003e\u003cp data-pid=\"JxywCKK4\"\u003e男人要不计一切都要发家致富的典型。\u003c/p\u003e\u003cp data-pid=\"L3qMFpuV\"\u003e世界就是这样。\u003c/p\u003e\u003cp data-pid=\"vy3cCU8d\"\u003e哪有什么公平不公平？\u003c/p\u003e\u003cp data-pid=\"V2T__1e_\"\u003e第二，马斯克靠的也是时代的运气。纵然你有冲天壮志，非运不可自通，他那一波也是抓住了互联网的一波红利。我们国家的腾讯阿里巴巴金山老板，也都是吃了这一波，变成首富。\u003c/p\u003e\u003cp data-pid=\"r1_rEuP8\"\u003e第三，体力好，这体格，天生的996材料，不来中国都可惜了，他特么一天干16小时。跑外卖一天16小时也快发财了，更何况他是掘金。身弱不担财，所以，年轻人一定要重视体格的培养。\u003c/p\u003e\u003cp data-pid=\"_lzCE37y\"\u003e不要去仰望马斯克，没有意义。他也不是什么人类灯塔，人类的灯塔是牛顿，是特斯拉，是欧几里得，这类人。他只是个工程师有点小贡献，只是会营销。elon musk is great not because he sell cars，but he sell dreams.\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":134681,"favorite_count":880,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 34236046287}","attached_info":"CrIGCOD5laeW9LTCsgEQBBoJNjk5OTYzMzExIO7Q6rkGKJgKMNsBQFFKSAofVFNfU09VUkNFX1pSRUNBTExfSVRFTUNGX1VQVk9URRIfZG9jX3R5cGU6IEFuc3dlcgppZDogNjAxNzk2ODk3ChgAIAA6AFoIOTE0MTI4NzFiIGE4NDViNTdjZWFkMzQwN2I5YzhhOThjYTMyMmM0NzFicgszNDIzNjA0NjI4N4oBCTU4MTA4OTg4MKoBCXJlY29tbWVuZMIBIDM4NWRlYTM5YTI5ZDI5YzFmYTBmZDdmMzY5YzJkYTVl8gEKCAwSBk5vcm1hbPIBKAgKEiQ5ZmJjMWJlNS0xYTU3LTRjNjctOGVlMy0yMDI1Y2U5YmYxNzDyAQYICxICMTSCAgCIAuC04s36MpICIDM4NWRlYTM5YTI5ZDI5YzFmYTBmZDdmMzY5YzJkYTVlmgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCFkFjdGlvblNob3JJbnRlcmVzdFJ1bGXKAhtJbnRlcmFjdGlvblNob3JJbnRlcmVzdFJ1bGXKAhhQZXJpb2RJbnRlcmVzdFdlaWdodFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXKAhRDb250ZW50QWdlV2VpZ2h0UnVsZdoCH1RTX1NPVVJDRV9aUkVDQUxMX0lURU1DRl9VUFZPVEXoAgL6AgtOT1JNQUxfRkxPV4oDIGQ0YTQ4NWY3NjYxZDQwZWFhZmJhOGMxMWY4ODdiODM3mgMNCgJ2MhAAGgVvdGhlcqgDmZwI2AMA6gMZdGV4dEFsbFNpdGVBY3Rpb25JdGVtQ0ZWMvoDHxIMVU5LTk9XTl9NT0RFIAAqDU5PX0lNQUdFX01PREWABACIBACSBAZOb3JtYWyaBAEyoAQAqAQAsAQAugQGbWFudWFswgQDMTYwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAADgjq3FP4EFAAAAAAAAAACJBQsD4WCPftI/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBQ6QBgCgBlKoBgCSAiYKCTY5OTk2MzMxMRILMzQyMzYwNDYyODcYBCIKSU1BR0VfVEVYVA==","action_card":false},{"id":"82_1750899137.717","type":"feed","offset":82,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750899137,"updated_time":1750899137,"target":{"id":"1921150259909883041","type":"answer","url":"https://api.zhihu.com/answers/1921150259909883041","author":{"id":"b06f175132efde3e7587c7588f7f5b08","url":"https://api.zhihu.com/people/b06f175132efde3e7587c7588f7f5b08","user_type":"people","url_token":"ruanfans","name":"ruanfans","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":71,"is_following":false,"is_followed":false},"created_time":1750817915,"updated_time":1750818122,"voteup_count":1,"thanks_count":0,"comment_count":0,"is_copyable":true,"question":{"id":"23273263","type":"question","url":"https://api.zhihu.com/questions/23273263","author":{"id":"3e44fd0dbe6a6d846fe1c82b5425c3e8","url":"https://api.zhihu.com/people/3e44fd0dbe6a6d846fe1c82b5425c3e8","user_type":"people","url_token":"langweixiaoxiaosu","name":"谈谈游戏吧","headline":"美好，等着我们探索发现，同名公众号：浪味小小酥","avatar_url":"https://pica.zhimg.com/50/v2-60c3ee35cc8866f0342a2d999f1758cb_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":67,"is_following":false,"is_followed":false},"title":"大数据最核心的价值是什么？","created":1396577381,"answer_count":0,"follower_count":0,"comment_count":35,"bound_topic_ids":[1047,1103,1740,3074,63708],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"发现联系 大数据分析用户的行为和习惯还是非常粗糙的。尤其现代社会，变化快，如今的历史分析能力，非常的初级，还处于笑话的阶段。 如今时代，群体相对好分析，个体非常难。如今群体还没搞定，个体分析更是笑话。","excerpt_new":"发现联系 大数据分析用户的行为和习惯还是非常粗糙的。尤其现代社会，变化快，如今的历史分析能力，非常的初级，还处于笑话的阶段。 如今时代，群体相对好分析，个体非常难。如今群体还没搞定，个体分析更是笑话。","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"8ow9JGxU\"\u003e发现联系\u003c/p\u003e\u003cp data-pid=\"ycb3PdeN\"\u003e大数据分析用户的行为和习惯还是非常粗糙的。尤其现代社会，变化快，如今的历史分析能力，非常的初级，还处于笑话的阶段。\u003c/p\u003e\u003cp data-pid=\"TzKjtJIN\"\u003e如今时代，群体相对好分析，个体非常难。如今群体还没搞定，个体分析更是笑话。\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":32,"favorite_count":1,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1921150259909883041}","attached_info":"CpoGCOD5laeW9LTCsgEQBBoJNzMzODk2MjkyIPu47cIGKAEwAEBSSiQKGVRTX1NPVVJDRV9XQVJNX1VQX05PUk1BTDISATAYACAAOgBKLwokVFNfU09VUkNFX1dBUk1VUF9UV09UT1dFUl9FWFBWMl9URVhUEgEwGAAgADoAWgcxNDkwNTc2YiBhODQ1YjU3Y2VhZDM0MDdiOWM4YTk4Y2EzMjJjNDcxYnITMTkyMTE1MDI1OTkwOTg4MzA0MYoBCDIzMjczMjYzqgEJcmVjb21tZW5kwgEgYjA2ZjE3NTEzMmVmZGUzZTc1ODdjNzU4OGY3ZjViMDjyAQoIDBIGTm9ybWFs8gEoCAoSJDNmZjczYjExLTQ0MmItNDFlNi1iYWM1LTgzNjg2YmRlZWU5YvIBBggLEgIxNIICAIgC4LTizfoykgIgYjA2ZjE3NTEzMmVmZGUzZTc1ODdjNzU4OGY3ZjViMDiaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIYUGVyaW9kSW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygIYQ29udGVudFdhcm1VcEJyZWFrSW5SdWxl2gIZVFNfU09VUkNFX1dBUk1fVVBfTk9STUFMMugCAvoCC05PUk1BTF9GTE9XigMgZDRhNDg1Zjc2NjFkNDBlYWFmYmE4YzExZjg4N2I4MzeaAw0KAnYyEAAaBW90aGVyqAMg2AMA6gMvY29udGVudFdhcm11cFR3b1Rvd2VyVHZwVGV4dE5vcm1hbEV4cFYyUmVjYWxsZXL6Ax8SDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFgAQAiAQAkgQGTm9ybWFsmgQBMqAEAKgEALAEALoEAmFpwgQDNDAwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAADADDOWP4EFAAAAAAAAAACJBQsD4WCPftI/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBQ6QBgCgBlOoBgGSAi4KCTczMzg5NjI5MhITMTkyMTE1MDI1OTkwOTg4MzA0MRgEIgpJTUFHRV9URVhU","action_card":false},{"id":"83_1750899137.413","type":"feed","offset":83,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750899137,"updated_time":1750899137,"target":{"id":"698502893","type":"article","url":"https://api.zhihu.com/articles/698502893","author":{"id":"c8c2d21ccde113479dadc7f999e51634","url":"https://api.zhihu.com/people/c8c2d21ccde113479dadc7f999e51634","user_type":"people","url_token":"yang-zhi-zheng-74","name":"社恐患者杨老师","headline":"AI领域研究者","avatar_url":"https://picx.zhimg.com/50/v2-94587b62e22c3028e8feb6047cda43fe_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":3030,"is_following":false,"is_followed":false},"title":"重新发现VAE（Variational Autoencoders）","image_url":"https://picx.zhimg.com/v2-7ee4fcce1aaa36357819c5b572625238.jpg?source=7e7ef6e2\u0026needBackground=1","comment_permission":"all","created":1716050336,"updated":1716050336,"voteup_count":888,"voting":0,"comment_count":22,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"ICLR2024评选的首个时间检验奖本月初公布了。冠军颁给Diederik Kingma, Max Welling于2014年发表的 变分自动编码器VAE。这篇跨越十年的论文，是今天以diffusion扩散模型在内的生成模型的重要起点，才有了今天的DALL-E3、Stable Diffusion，包括今年openAI发布的Sora都是建立在VAE的基础之上。此外，在音频、文本、生成模型领域都有广泛应用，是深度学习中的最为重要的技术之一。论文一作Kingma曾经担任openAI的创始成员也是著名…","excerpt_new":"ICLR2024评选的首个时间检验奖本月初公布了。冠军颁给Diederik Kingma, Max Welling于2014年发表的 变分自动编码器VAE。这篇跨越十年的论文，是今天以diffusion扩散模型在内的生成模型的重要起点，才有了今天的DALL-E3、Stable Diffusion，包括今年openAI发布的Sora都是建立在VAE的基础之上。此外，在音频、文本、生成模型领域都有广泛应用，是深度学习中的最为重要的技术之一。论文一作Kingma曾经担任openAI的创始成员也是著名…","preview_type":"default","preview_text":"","content":"\u003cp data-pid=\"rPcqiKwj\"\u003eICLR2024评选的首个时间检验奖本月初公布了。冠军颁给Diederik Kingma, Max Welling于2014年发表的\u003cb\u003e变分自动编码器VAE。\u003c/b\u003e这篇跨越十年的论文，是今天以diffusion扩散模型在内的生成模型的重要起点，才有了今天的DALL-E3、Stable Diffusion，包括今年openAI发布的Sora都是建立在VAE的基础之上。此外，在音频、文本、生成模型领域都有广泛应用，是深度学习中的最为重要的技术之一。论文一作Kingma曾经担任openAI的创始成员也是著名的Adam优化器的作者。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-f1d78313dae328447877af1606aebe92_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1339\" data-rawheight=\"1357\" data-original-token=\"v2-9e0e0ca8680bbaa28fe8a2f94df8372f\" class=\"origin_image zh-lightbox-thumb\" width=\"1339\" data-original=\"https://pic3.zhimg.com/v2-f1d78313dae328447877af1606aebe92_r.jpg\"/\u003e\u003cfigcaption\u003eICLR2024时间检验奖\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"iJfvREkA\"\u003eICLR2024给出的获奖理由是概率建模是对世界进行推理的最基本方式之一。这篇论文率先将深度学习与可扩展概率推理（通过所谓的重新参数化技巧摊销均值场变分推理）相结合，从而催生了变分自动编码器 (VAE)。这项工作的持久价值源于其优雅性。用于开发 VAE 的原理加深了我们对深度学习和概率建模之间相互作用的理解，并引发了许多后续有趣的概率模型和编码方法的开发。这篇论文对于深度学习和生成模型领域产生了重大影响。站在2024年的今天，我们似乎已经习惯了生成式AI给我们带来的种种惊喜，但是我个人认为我们非常有必要回顾一下十年前这篇论文的横空出世具体意味着什么，因此就有了这篇文章的内容，我想通过这篇文章给各位读者详细介绍一下VAE诞生的背景，VAE实现的具体原理，以及VAE被用来解决那些问题。接下来就让我们跟随时间的脚步，重温这篇经得起时间检验的经典模型，重新发现VAE的巨大价值！本文主要是在\u003ca href=\"https://link.zhihu.com/?target=https%3A//towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003eUnderstanding Variational Autoencoders (VAEs) | by Joseph Rocca | Towards Data Science\u003c/a\u003e基础之上结合本人的一点浅显理解而成，感谢\u003ca href=\"https://link.zhihu.com/?target=https%3A//medium.com/%40joseph.rocca%3Fsource%3Dpost_page-----f70510919f73--------------------------------\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003eJoseph Rocca\u003c/a\u003e大神的无私分享。\u003c/p\u003e\u003cp data-pid=\"Qd3U_nXF\"\u003e\u003cb\u003eVAE的核心思想是把隐向量看作是一个概率分布\u003c/b\u003e。具体而言，编码器（encoder）不直接输出一个隐向量，而是输出一个均值向量和一个方差向量，它们刻画了隐变量的高斯分布。这样一来,我们就可以从这个分布中随机采样隐向量，再用解码器（decoder）生成新图片了。\u003c/p\u003e\u003cp data-pid=\"qoa_rDNd\"\u003e简而言之，VAE是一个自动编码器，其编码分布在训练期间被规范化，以确保其潜在空间具有良好的属性，使我们能够生成一些新数据。可以提出很多问题。什么是自动编码器？什么是潜空间，为什么要规范它？如何从VAE生成新数据？VAE和变分推理之间有什么联系？为了尽可能地描述清楚VAE，本文将带着各位读者抽丝剥茧通过回答这一系列问题，来帮助大家逐步构建起这些概念的具体含义。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch2\u003e背景知识\u003c/h2\u003e\u003cp data-pid=\"uqidfup8\"\u003e在开始介绍VAE的一系列概念之前，我们需要先学习和了解一些基础背景知识，主要包括Dimensionality Reduction降维, PCA主成分分析以及autoencoders自动编码器。\u003c/p\u003e\u003ch3\u003eDimensionality Reduction 降维\u003c/h3\u003e\u003cp data-pid=\"B0pCIn_k\"\u003e在机器学习(machine learning)中，降维特指减少描述某些数据的特征数量的过程。这种减少过程可以通过选择保留一些现有特征或提取基于旧特征创建较少数量的新特征来完成，这也是传统机器学习的特征工程中常见的处理方式。并且在许多需要低维数据（包括数据可视化、数据存储、多重计算等）的情况下非常有用。尽管存在许多不同的降维方法(例如LDA)，但我们可以设置一个与大多数方法相匹配的全局框架。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-8467d4d02653c8998a0a22e14f497564_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1815\" data-rawheight=\"764\" data-original-token=\"v2-feb7ea12b03ea7b35070315ae94dd895\" class=\"origin_image zh-lightbox-thumb\" width=\"1815\" data-original=\"https://pica.zhimg.com/v2-8467d4d02653c8998a0a22e14f497564_r.jpg\"/\u003e\u003cfigcaption\u003e使用encoder与decoder进行降维的原理\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"C3VAIMAH\"\u003e如果我们将编码器(encoder)称为从“旧特征”表示（通过选择或提取）生成“新特征”表示的过程，那么其反向过程称为解码器(decoder)。降维就可以解释为数据压缩的过程，其中编码器压缩数据从初始空间到编码空间也称为潜空间(latent space)，而解码器的工作就是把被压缩大片潜空间的数据进行解压缩的过程。当然，根据初始数据分布、潜空间维度和编码器定义，这种压缩可能是有损的，这意味着部分信息在编码过程中回丢失，在解码时无法完全恢复。\u003c/p\u003e\u003cp data-pid=\"xZzVqx6d\"\u003e降维方法的主要目的是在给定系列中找到最佳编码器/解码器对(encoder/decoder pair)。换句话说，对于一组给定的可能的编码器和解码器，我们正在寻找在编码时保持最大信息的对，因此在解码时具有最小的重建误差。如果我们分别用 E 和 D 表示我们正在考虑的编码器和解码器系列，那么降维问题就可以写成：\u003c/p\u003e\u003cp data-pid=\"MEkRlSb2\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cleft%28e%5E%7B%2A%7D%2C+d%5E%7B%2A%7D%5Cright%29%3D%5Cunderset%7B%28e%2C+d%29+%5Cin+E+%5Ctimes+D%7D%7B%5Carg+%5Cmin+%7D+%5Cepsilon%28x%2C+d%28e%28x%29%29%29\" alt=\"\\left(e^{*}, d^{*}\\right)=\\underset{(e, d) \\in E \\times D}{\\arg \\min } \\epsilon(x, d(e(x)))\" eeimg=\"1\"/\u003e \u003c/p\u003e\u003cp data-pid=\"J3s6nNhz\"\u003e其中： \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cepsilon%28x%2C+d%28e%28x%29%29%29\" alt=\"\\epsilon(x, d(e(x)))\" eeimg=\"1\"/\u003e 定义了给定输入数据 x 和编码解码数据 d(e(x)) 之间的重建误差度量。在下文中，我们将N 用来表示数据的数量，n_d表示初始（解码）空间的维度，n_e表示缩减（编码）空间的维度。\u003c/p\u003e\u003ch3\u003ePrincipal Components Analysis 主成分分析(PCA)\u003c/h3\u003e\u003cp data-pid=\"JoPOxS8v\"\u003e在谈到降维时，机器学习研究者(machine learner)首先想到的方法之一是主成分分析（PCA）。这里我们对 PCA 的工作原理先做一个简要的概述，以方便后续更好的理解与自动编码器的联系。\u003c/p\u003e\u003cp data-pid=\"3rJIk782\"\u003ePCA 的思想是构建n_e新的独立特征，这些特征是n_d旧特征的线性组合，因此这些新特征定义的子空间(注意这里的空间并非指的是物理空间概念，而是数学的向量空间概念)上的数据投影尽可能接近初始数据（用欧几里得距离表示）。换句话说，PCA正在寻找初始空间的最佳线性子空间（由新特征的正交基础描述），以便通过它们在该子空间上的投影来近似数据的误差尽可能的小。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-50355499c488362bb359d288898d8886_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"464\" data-rawheight=\"427\" data-original-token=\"v2-17d2f002aa1a35ddb38637c147016b68\" class=\"origin_image zh-lightbox-thumb\" width=\"464\" data-original=\"https://pica.zhimg.com/v2-50355499c488362bb359d288898d8886_r.jpg\"/\u003e\u003cfigcaption\u003e主成分分析（PCA）实现降维的基本原理\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"LY-ZYdBf\"\u003e如图所示，PCA的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，新的坐标轴的选择与数据本身是密切相关的。其中，第一个新坐标轴选择是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第1,2个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。通过这种方式获得的新的坐标轴，我们发现，大部分方差都包含在前面k个坐标轴中，后面的坐标轴所含的方差几乎为0。于是，我们可以忽略余下的坐标轴，只保留前面k个含有绝大部分方差的坐标轴。事实上，这相当于只保留包含绝大部分方差的维度特征，而忽略包含方差几乎为0的特征维度，实现对数据特征的降维处理。\u003c/p\u003e\u003cp data-pid=\"ZVL-zPLh\"\u003e在我们的体系中，我们所寻找的正是n_e中的E编码器，通过n_d矩阵（线性变换），其行是正交矩阵（特征独立性），以及n_e矩阵在n_d中的相关D解码器。可以证明，对应于协方差特征矩阵的n_e最大特征值（以范数为单位）的单位特征向量是正交的（或者可以选择正交），并定义了维数n_e的最佳子空间，以最小的近似误差投射数据。因此，这些n_e特征向量可以被选为我们的新特征，降维问题可以表示为特征值/特征向量问题。此外，还可以证明，在这种情况下，解码器矩阵是编码器矩阵的转置。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-049925e82264f97c50e417dde649904e_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1815\" data-rawheight=\"723\" data-original-token=\"v2-994cb09c6655d8fb5d1fc9d9cbf6a1e1\" class=\"origin_image zh-lightbox-thumb\" width=\"1815\" data-original=\"https://pic1.zhimg.com/v2-049925e82264f97c50e417dde649904e_r.jpg\"/\u003e\u003cfigcaption\u003ePCA 与编码器-解码器框架\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3\u003eAutoencoders 自动编码器\u003c/h3\u003e\u003cp data-pid=\"9s-QAbz5\"\u003e理解了降维和PCA的概念之后，我们再来理解自动编码器就非常简单了，自动编码器简单来说就是使用神经网络进行降维。自动编码器的一般思想非常简单，包括将编码器和解码器设置为神经网络，并使用以梯度下降为代表的迭代优化方式来学习最佳编码-解码方案。因此，在每次迭代中，我们都会向自动编码器架构（编码器后跟解码器）提供一些数据，我们将编码解码后的输出与初始数据进行比较，并通过神经网络架构的误差反向传播算法来更新网络的权重。\u003c/p\u003e\u003cp data-pid=\"5HUugCg9\"\u003e简单来说，整个自动编码器架构（编码器+解码器）为数据创造了一个瓶颈，确保只有信息的主要结构化部分才能通过和重建。从我们的通用框架来看，编码器E由编码器网络架构定义，解码器D由解码器网络架构定义，编码器和解码器的搜索通过对这些网络参数的梯度下降来完成，以最小化重建误差。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-ecb5cc3928e8c315751ae5334eb97ba4_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1100\" data-rawheight=\"601\" data-original-token=\"v2-cdd18565e8e068c33083d3c1ade47335\" class=\"origin_image zh-lightbox-thumb\" width=\"1100\" data-original=\"https://pic3.zhimg.com/v2-ecb5cc3928e8c315751ae5334eb97ba4_r.jpg\"/\u003e\u003cfigcaption\u003e带有损失函数的自动编码器的图示\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"wxvd6Fv8\"\u003e首先假设我们的编码器和解码器架构都只有一个没有非线性的层（线性自编码器）。然后，这种编码器和解码器是可以表示为矩阵的简单线性变换。在这种情况下，我们可以看到与PCA的明确联系，就像PCA一样，我们正在寻找最佳的线性子空间来投射数据，同时尽可能减少信息丢失。用 PCA 获得的编码和解码矩阵自然定义了我们可以通过梯度下降达到的解决方案之一，但我们应该清晰的意识到这并非是唯一解。事实上，我们完全可以选择多个基来描述相同的最优子空间，因此，同时存在多个编码器/解码器对(encoder/decoder pair)可以给出最佳的重建误差。此外，对于线性自编码器，与PCA相反，我们最终获得的新特征不必是独立的（神经网络中没有正交性约束）。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-311b509b92a8449ce343570859527842_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1789\" data-rawheight=\"852\" data-original-token=\"v2-166a1238c9d5f923debf6b7a2c28d976\" class=\"origin_image zh-lightbox-thumb\" width=\"1789\" data-original=\"https://pic3.zhimg.com/v2-311b509b92a8449ce343570859527842_r.jpg\"/\u003e\u003cfigcaption\u003e线性自编码器和 PCA 之间的关联\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"MFY2y6Km\"\u003e现在，让我们假设编码器和解码器都是深度和非线性的。在这种情况下，神经网络的结构越复杂，自动编码器就越能实现高维降维，同时保持低重建损耗。直观地说，如果我们的编码器和解码器具有足够的高自由度，我们可以将任何初始维度降低到 1维。事实上，具有“无限功率”的编码器理论上可以获取我们的 N 个初始数据点并将它们编码为 1、2、3、......最多N和相关的解码器可以进行反向变换，在此过程中没有损失。当然这种情况仅存在与理想当中。\u003c/p\u003e\u003cp data-pid=\"uCmSqaZr\"\u003e但是我们的目标并非是为了降维而降维。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"-anPAeuw\"\u003e首先，没有重建损失的重要降维往往伴随着代价：潜空间中缺乏可解释和可利用的结构（缺乏规律性）。\u003c/li\u003e\u003cli data-pid=\"6WyYi2Kb\"\u003e其次，大多数情况下，降维的最终目的不仅仅只是减少数据的维数，而是减少这些维数，同时将数据结构信息的主要部分保留在简化的表示中。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"-NCbxmJ1\"\u003e由于这两个原因，必须根据降维的最终目的仔细控制和调整潜空间的尺寸和自动编码器的“深度”（定义压缩的程度和质量）。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-eade4c23403d1bca5de145a8577e38bc_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1815\" data-rawheight=\"718\" data-original-token=\"v2-a812896ef0797439d7d4a86cb9b3cb14\" class=\"origin_image zh-lightbox-thumb\" width=\"1815\" data-original=\"https://pic1.zhimg.com/v2-eade4c23403d1bca5de145a8577e38bc_r.jpg\"/\u003e\u003cfigcaption\u003e在降低维数的同时，我们更希望保持原始数据中存在的主要结构信息。\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2\u003eVariational Auto Encoders 变分自动编码器(VAE)\u003c/h2\u003e\u003cp data-pid=\"W3_Tbh3Q\"\u003e我们在上文已经介绍了自动编码器，这些自动编码器是可以通过梯度下降来进行训练的编码器-解码器架构。现在让我们与内容生成之间的关系，看看当前形式的自动编码器对这个问题的局限性，并介绍变分自动编码器。\u003c/p\u003e\u003ch3\u003e自动编码器在内容生成方面的局限性\u003c/h3\u003e\u003cp data-pid=\"dLiRUVQu\"\u003e一旦自动编码器被训练，我们就同时拥有了编码器和解码器，但仍然没有真正的方法来生成任何新内容。乍一看，你可能会认为，如果潜在空间足够有规律（在训练过程中由编码器很好地“组织”），我们可以从该潜空间中随机获取一个点并对其进行解码以生成新的内容。\u003c/p\u003e\u003cp data-pid=\"lmiZUaMA\"\u003e然而，正如我们在前面所讨论的，自动编码器潜在空间的规律性是一个难点，它取决于初始空间中数据的分布、潜空间的维度和编码器的架构。因此，要先验地确保编码器将以与我们刚才描述的生成过程兼容的智能方式组织潜空间是相当困难的。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-24563284666ecc9064461b48ebb5638c_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1100\" data-rawheight=\"573\" data-original-token=\"v2-4481d26e1e6892e0ee60e6f59e311a44\" class=\"origin_image zh-lightbox-thumb\" width=\"1100\" data-original=\"https://pica.zhimg.com/v2-24563284666ecc9064461b48ebb5638c_r.jpg\"/\u003e\u003cfigcaption\u003e通过解码从潜空间随机采样的点来生成新数据，生成数据的质量和相关性取决于潜空间的规律性。\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"-ux3nGGx\"\u003e假设我们拥有了一个理想的编码器和解码器，可以将任何 N 个初始训练数据放到实轴上（每个数据点被编码为一个实值）并解码它们而不会造成任何重建损失即可实现无损压缩与解压。在这种情况下，自动编码器的高度自由度使得编码和解码而不会丢失信息（尽管潜空间的维数较低），导致严重的过拟合，这意味着潜空间的某些点一旦解码就会产生无意义的内容。如果这个一维的例子被自愿选择为相当极端的例子，我们可以注意到，自编码器潜空间规律性的问题比这要普遍得多，需要特别注意。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-971085ded16f625cdaec982513c71c48_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1804\" data-rawheight=\"600\" data-original-token=\"v2-21c54599eacde80707046241fc003bd0\" class=\"origin_image zh-lightbox-thumb\" width=\"1804\" data-original=\"https://pic3.zhimg.com/v2-971085ded16f625cdaec982513c71c48_r.jpg\"/\u003e\u003cfigcaption\u003e不规则的潜空间让我们无法使用自动编码器来生成新内容\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"wwHJQ5Fx\"\u003e我们只需仔细想一下，不难察觉其实在潜空间中编码的数据之间缺乏结构与规律是很正常的现象。事实上，在自动编码器的任务中，没有任何东西被训练来强制执行这样的组织：自动编码器只被训练为编码和解码，无论潜空间如何组织，都尽可能少地损失。因此，如果我们不小心架构的定义，那么在训练过程中，神经网络自然会利用任何过拟合的可能性来尽可能地完成其任务......除非我们明确地规范它！\u003c/p\u003e\u003ch3\u003eVariational Auto Encoders变分自动编码器的定义\u003c/h3\u003e\u003cp data-pid=\"ZNtiu4VG\"\u003e为了能够将自动编码器的解码器用于生成目的，我们必须确保潜空间保持足够规律性。而要解决规律性这个问题，首先可能解决方案是在训练过程中引入显式正则化。因此，变分自编码器可以定义为一个自编码器，其训练是正则化的，以避免过度拟合，并确保在潜空间具有支持生成过程的良好性能。\u003c/p\u003e\u003cp data-pid=\"F40ZroNQ\"\u003e与标准自动编码器一样，变分自动编码器是一种由编码器和解码器组成的体系结构，经过训练可以最大程度地减少编码解码数据与初始数据之间的重建误差。然而，为了引入潜空间的一些正则化，我们需要对编码-解码过程进行轻微的修改：我们不是将输入编码为单个点，而是将其编码为潜在空间上的分布。然后，按如下方式训练模型：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"HFA0UIQS\"\u003e首先，输入被编码为在潜空间上的分布。\u003c/li\u003e\u003cli data-pid=\"lCc5qXFZ\"\u003e其次，从该分布中抽取潜空间中的一个点。\u003c/li\u003e\u003cli data-pid=\"-1yam8VZ\"\u003e第三，对采样点进行解码，计算重构误差。\u003c/li\u003e\u003cli data-pid=\"nt-FirqB\"\u003e最后，通过神经网络的误差反向传播算法重建误差。\u003c/li\u003e\u003c/ul\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-76d2f3deb0e9acba3e16e9bc387c8046_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1804\" data-rawheight=\"596\" data-original-token=\"v2-874693e48306ed40b2279bf5c98d4e0e\" class=\"origin_image zh-lightbox-thumb\" width=\"1804\" data-original=\"https://pic1.zhimg.com/v2-76d2f3deb0e9acba3e16e9bc387c8046_r.jpg\"/\u003e\u003cfigcaption\u003e自动编码器（确定性）和变分自动编码器（概率）之间的区别。\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"dTn9Ifgx\"\u003e在实践中，编码分布通常优先选择为正态分布，以便可以训练编码器返回描述这些高斯的均值和协方差矩阵。之所以将输入编码为具有一定方差的分布而不是单个点，是因为它可以非常自然地表达潜空间正则化：编码器返回的分布被强制接近标准正态分布。我们将在本文后面看到，我们以这种方式确保潜空间的局部和全局正则化（局部是因为方差控制，全局是因为均值控制）。\u003c/p\u003e\u003cp data-pid=\"pjtgs0ZB\"\u003e因此，在训练VAE时最小化的损失函数由一个“重建项”（在最后一层）和一个“正则化项”（在潜在层上）组成，前者倾向于使编码-解码方案尽可能高性能，后者倾向于通过使编码器返回的分布接近标准正态分布来正则化潜在空间的组织。该正则化项表示为返回分布和标准高斯分布之间的 Kulback-Leibler 散度简称KL散度，其公式为：\u003c/p\u003e\u003cp data-pid=\"Nhj_Gf7l\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=D_%7BK+L%7D%28p%28x%29+%5C%7C+q%28x%29%29%3D%5Cint+p%28x%29+%5Clog+%5Cleft%28%5Cfrac%7Bp%28x%29%7D%7Bq%28x%29%7D%5Cright%29+d+x\" alt=\"D_{K L}(p(x) \\| q(x))=\\int p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right) d x\" eeimg=\"1\"/\u003e \u003c/p\u003e\u003cp data-pid=\"fvXAsG2K\"\u003eKL散度是用于比较两个分布之间的距离的衡量指标。可以看到两个高斯分布之间的KL散度具有闭合形式，可以直接用两个分布的均值和协方差矩阵表示。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-ce1d400ca89c6b52951985db70e72f06_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1100\" data-rawheight=\"534\" data-original-token=\"v2-e2207de479319c2335661b9bb36a379b\" class=\"origin_image zh-lightbox-thumb\" width=\"1100\" data-original=\"https://pic1.zhimg.com/v2-ce1d400ca89c6b52951985db70e72f06_r.jpg\"/\u003e\u003cfigcaption\u003e在变分自动编码器中，损失函数由重构项（使编码-解码方案高效）和正则化项（使潜空间规则）组成\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3\u003e关于正则化\u003c/h3\u003e\u003cp data-pid=\"NjMdb_RD\"\u003e为了使生成过程成为可能，从潜空间中期望的规律性可以通过两个主要属性来表示：连续性（潜空间中的两个紧密点在解码后不应给出两个完全不同的内容）和完整性（对于选定的分布，从潜空间采样的点一旦解码就应该给出“有意义的”内容）\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-0219a24742a0918cd4e93fe3eee78b73_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1871\" data-rawheight=\"683\" data-original-token=\"v2-de64d868fc9dc97e17f2ecbc0dc24e56\" class=\"origin_image zh-lightbox-thumb\" width=\"1871\" data-original=\"https://pic4.zhimg.com/v2-0219a24742a0918cd4e93fe3eee78b73_r.jpg\"/\u003e\u003cfigcaption\u003e“规则”和“不规则”潜空间之间的区别。\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"WVZFkq_C\"\u003eVAE（变分自编码器）只是将输入编码为分布而不是简单的点，仅仅这一点是不足以确保连续性和完备性。如果没有明确定义的正则化项，模型为了最小化重构误差，可能会“忽略”返回的分布事实，并且表现得几乎像经典的自编码器一样会导致过拟合。为此，编码器可以返回方差极小的分布（这将趋向于是点分布），或者返回均值非常不同的分布（这将在潜空间中彼此相距甚远）。在这两种情况下，分布的使用方式都是错误的（取消了预期的收益），从而无法满足连续性和完整性。\u003c/p\u003e\u003cp data-pid=\"a3nCdka0\"\u003e因此，为了避免这些影响，我们必须正则化协方差矩阵和编码器返回的分布均值。在实践中，这种正则化是通过强制分布接近标准正态分布（居中和约简）来完成的。这样，我们要求协方差矩阵接近恒等式，防止准时分布，并且均值接近 0，防止编码分布彼此相距太远。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-b272bd85ae58a3f47e7bc50c5f2e3563_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1871\" data-rawheight=\"683\" data-original-token=\"v2-d8a13e3f531958962018dd3b3f46b6f6\" class=\"origin_image zh-lightbox-thumb\" width=\"1871\" data-original=\"https://pic2.zhimg.com/v2-b272bd85ae58a3f47e7bc50c5f2e3563_r.jpg\"/\u003e\u003cfigcaption\u003e必须对VAE的返回分布进行正则化，以获得具有良好性质的潜空间。\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"vRwoag5J\"\u003e使用这个正则化项，我们防止模型在潜空间中对相距很远的数据进行编码，并鼓励返回的分布尽可能多地“重叠”，从而满足预期的连续性和完整性的条件。当然，对于任何正则化项，这是以训练数据更高的重建误差为代价的。然而，重建误差和KL散度之间的权衡是可以调整的，接下来在下一节中我们通过数学推导过程可以看到平衡是如何自然地出现的。\u003c/p\u003e\u003cp data-pid=\"pL_IvY9f\"\u003e我们可以观察到，通过正则化获得的连续性和完整性倾向于在潜空间中编码的信息上产生“梯度”。例如，潜空间的一个点位于来自不同训练数据的两个编码分布的均值之间，应该在给出第一个分布的数据和给出第二个分布的数据之间的某个地方进行解码，因为在这两种情况下，自动编码器都可以对其进行采样。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-0cf4ba2014863c579dd52aecbf067129_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1100\" data-rawheight=\"593\" data-original-token=\"v2-02bb586cf7a911a5c2a5a168f6bd537b\" class=\"origin_image zh-lightbox-thumb\" width=\"1100\" data-original=\"https://pic2.zhimg.com/v2-0cf4ba2014863c579dd52aecbf067129_r.jpg\"/\u003e\u003cfigcaption\u003e正则化倾向于在潜在空间中编码的信息上创建“梯度”。\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3\u003e\u003cb\u003eThe variational bound 变分边界的数学推导\u003c/b\u003e\u003c/h3\u003e\u003cp data-pid=\"IBBOdYst\"\u003eVAE是自动编码器，它将输入编码为分布而不是点，其潜空间“组织”通过约束编码器返回的分布来规范化，使其接近标准高斯分布。在这一小节中，我们将给出 VAE 的更多数学推导过程，这样能够更严格地证明正则化项的合理性。\u003c/p\u003e\u003cp data-pid=\"KBsbL0a4\"\u003e首先需要构建具有连续隐变量的概率图模型的lower bound来描述我们的数据。我们用 x 表示表示我们数据的变量，并假设 x 是由未直接观察到的潜在变量 z（编码表示）生成的。因此，对于每个数据点，假设生成过程为以下两个步骤：\u003c/p\u003e\u003cp data-pid=\"446BkRNM\"\u003e1\u0026gt; 从先验分布\u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bz%7D%29\" alt=\"p_{\\theta} (\\mathbb{z})\" eeimg=\"1\"/\u003e随机采样生成\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cmathbb%7Bz%7D%5E%7B%28i%29%7D\" alt=\"\\mathbb{z}^{(i)}\" eeimg=\"1\"/\u003e；\u003c/p\u003e\u003cp data-pid=\"gaUw9ej6\"\u003e2\u0026gt; 从条件概率分布\u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bx%7D%7C%5Cmathbb%7Bz%7D%29\" alt=\"p_{\\theta} (\\mathbb{x}|\\mathbb{z})\" eeimg=\"1\"/\u003e中采样生成\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cmathbb%7Bx%7D%5E%7B%28i%29%7D\" alt=\"\\mathbb{x}^{(i)}\" eeimg=\"1\"/\u003e。但这个过程大部分都是隐藏的，难以求取。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-da0b94b69dd66a70c15752963f046054_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"552\" data-rawheight=\"498\" data-original-token=\"v2-9fdb492dae41e35cb7aac95c785376ce\" class=\"origin_image zh-lightbox-thumb\" width=\"552\" data-original=\"https://pica.zhimg.com/v2-da0b94b69dd66a70c15752963f046054_r.jpg\"/\u003e\u003cfigcaption\u003e概率图模型\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"XCqDeupI\"\u003e这里的\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/\u003e指的是分布的参数，比如对于高斯分布就是均值和标准差。我们希望找到一个参数\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Ctheta%5E%2A\" alt=\"\\theta^*\" eeimg=\"1\"/\u003e来最大化生成真实数据的概率。这里\u003cimg src=\"https://www.zhihu.com/equation?tex=p_%5Ctheta%28%5Cmathbf%7Bx%7D%5E%7B%28i%29%7D%29\" alt=\"p_\\theta(\\mathbf{x}^{(i)})\" eeimg=\"1\"/\u003e可以通过对\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cmathbf%7Bz%7D\" alt=\"\\mathbf{z}\" eeimg=\"1\"/\u003e积分得到：\u003c/p\u003e\u003cp data-pid=\"5AKA-S8l\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=p_%5Ctheta%28%5Cmathbf%7Bx%7D%5E%7B%28i%29%7D%29+%3D+%5Cint+p_%5Ctheta%28%5Cmathbf%7Bx%7D%5E%7B%28i%29%7D%5Cvert%5Cmathbf%7Bz%7D%29+p_%5Ctheta%28%5Cmathbf%7Bz%7D%29+d%5Cmathbf%7Bz%7D+%5C%5C\" alt=\"p_\\theta(\\mathbf{x}^{(i)}) = \\int p_\\theta(\\mathbf{x}^{(i)}\\vert\\mathbf{z}) p_\\theta(\\mathbf{z}) d\\mathbf{z} \\\\\" eeimg=\"1\"/\u003e\u003c/p\u003e\u003cp data-pid=\"IeND_37e\"\u003e而实际上要根据上述积分是不现实的，一方面先验分布\u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D%28%5Cmathbf%7Bz%7D%29\" alt=\"p_{\\theta}(\\mathbf{z})\" eeimg=\"1\"/\u003e是未知的，而且如果分布比较复杂，对\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cmathbf%7Bz%7D\" alt=\"\\mathbf{z}\" eeimg=\"1\"/\u003e穷举计算也是极其耗时的。为了解决这个难题，变分推断引入后验分布\u003cimg src=\"https://www.zhihu.com/equation?tex=p_%5Ctheta%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29\" alt=\"p_\\theta(\\mathbf{z}\\vert\\mathbf{x})\" eeimg=\"1\"/\u003e来联合建模，即由每一个样本点\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cmathbb%7Bx%7D\" alt=\"\\mathbb{x}\" eeimg=\"1\"/\u003e，可以学出一个对应的隐层分布\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cmathbb%7Bz+%7D\" alt=\"\\mathbb{z }\" eeimg=\"1\"/\u003e（注意，此处为每一个样本均可学出其对应的隐层z分布）；并使用\u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bx%7D%7C%5Cmathbb%7Bz%7D%29\" alt=\"p_{\\theta} (\\mathbb{x}|\\mathbb{z})\" eeimg=\"1\"/\u003e作为decoder过程进行解码，实现模型生成。\u003c/p\u003e\u003cp data-pid=\"hUlFJB7x\"\u003e有了这样的概率模型，我们可以重新定义编码器和解码器的概念。事实上，与考虑确定性编码器和解码器的简单自动编码器相反，我们现在将考虑这两个对象的概率版本。“概率解码器”自然由 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bx%7D%7C%5Cmathbb%7Bz%7D%29\" alt=\"p_{\\theta} (\\mathbb{x}|\\mathbb{z})\" eeimg=\"1\"/\u003e 定义，它描述了给定编码变量的解码变量的分布，而“概率编码器”由 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bz%7D%7C%5Cmathbb%7Bx%7D%29\" alt=\"p_{\\theta} (\\mathbb{z}|\\mathbb{x})\" eeimg=\"1\"/\u003e 定义，它描述了给定解码变量的编码变量的分布。\u003c/p\u003e\u003cp data-pid=\"cm8onXJn\"\u003e根据\u003ca href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Bayes%2527_theorem\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e贝叶斯公式\u003c/a\u003e，后验等于：\u003c/p\u003e\u003cp data-pid=\"fOrhaEng\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=p_%5Ctheta%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%3D+%5Cfrac%7Bp_%5Ctheta%28%5Cmathbf%7Bx%7D%5Cvert%5Cmathbf%7Bz%7D%29p_%7B%5Ctheta%7D%28%5Cmathbf%7Bz%7D%29%7D%7Bp_%7B%5Ctheta%7D%28%5Cmathbf%7Bx%7D%29%7D+%3D%5Cfrac%7Bp_%5Ctheta%28%5Cmathbf%7Bx%7D%5Cvert%5Cmathbf%7Bz%7D%29p_%7B%5Ctheta%7D%28%5Cmathbf%7Bz%7D%29%7D%7B%5Cint+p_%5Ctheta%28%5Cmathbf%7Bx%7D%5E%7B%28i%29%7D%5Cvert%5Cmathbf%7Bz%7D%29+p_%5Ctheta%28%5Cmathbf%7Bz%7D%29+d%5Cmathbf%7Bz%7D%7D+\" alt=\"p_\\theta(\\mathbf{z}\\vert\\mathbf{x}) = \\frac{p_\\theta(\\mathbf{x}\\vert\\mathbf{z})p_{\\theta}(\\mathbf{z})}{p_{\\theta}(\\mathbf{x})} =\\frac{p_\\theta(\\mathbf{x}\\vert\\mathbf{z})p_{\\theta}(\\mathbf{z})}{\\int p_\\theta(\\mathbf{x}^{(i)}\\vert\\mathbf{z}) p_\\theta(\\mathbf{z}) d\\mathbf{z}} \" eeimg=\"1\"/\u003e\u003c/p\u003e\u003cp data-pid=\"rzx7EbX4\"\u003e现在让我们假设 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bz%7D%29\" alt=\"p_{\\theta} (\\mathbb{z})\" eeimg=\"1\"/\u003e 是标准高斯分布， \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bx%7D%7C%5Cmathbb%7Bz%7D%29\" alt=\"p_{\\theta} (\\mathbb{x}|\\mathbb{z})\" eeimg=\"1\"/\u003e 是高斯分布，其均值由 z 变量的确定性函数 f 定义，其协方差矩阵具有正常数 c 的形式，该常数乘以单位矩阵 I。假定函数 f 属于表示为 F 的函数族，该函数族暂时未指定，稍后将选择。因此，我们有：\u003c/p\u003e\u003cp data-pid=\"4YEcB2tO\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Barray%7D%7Bl%7D+p_%7B%5Ctheta%7D+%28%5Cmathbf%7Bz%7D%29+%5Cequiv+%5Cmathcal%7BN%7D%280%2C+I%29+%5C%5C+p_%7B%5Ctheta%7D+%28%5Cmathbf%7Bx%7D%7C%5Cmathbf%7Bz%7D%29+%5Cequiv+%5Cmathcal%7BN%7D%28f%28z%29%2C+c+I%29+%5Cquad+f+%5Cin+F+%5Cquad+c%3E0+%5Cend%7Barray%7D\" alt=\"\\begin{array}{l} p_{\\theta} (\\mathbf{z}) \\equiv \\mathcal{N}(0, I) \\\\ p_{\\theta} (\\mathbf{x}|\\mathbf{z}) \\equiv \\mathcal{N}(f(z), c I) \\quad f \\in F \\quad c\u0026gt;0 \\end{array}\" eeimg=\"1\"/\u003e \u003c/p\u003e\u003cp data-pid=\"4hu-v-Va\"\u003e现在，让我们考虑一下 f 是定义良好且固定的。从理论上讲，正如我们所知的 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D%28%5Cmathbf%7Bz%7D%29\" alt=\"p_{\\theta}(\\mathbf{z})\" eeimg=\"1\"/\u003e 和 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bx%7D%7C%5Cmathbb%7Bz%7D%29\" alt=\"p_{\\theta} (\\mathbb{x}|\\mathbb{z})\" eeimg=\"1\"/\u003e ，我们可以使用贝叶斯定理来计算 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bz%7D%7C%5Cmathbb%7Bx%7D%29\" alt=\"p_{\\theta} (\\mathbb{z}|\\mathbb{x})\" eeimg=\"1\"/\u003e ：这是一个经典的贝叶斯推理问题。然而，正如我们在上面提到的，这种计算通常是非常棘手的（因为分母处的积分），并且需要使用近似技术，如变分推断。\u003c/p\u003e\u003cp data-pid=\"4e-zR8n9\"\u003e注意。在这里我们可以提到的 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D%28%5Cmathbf%7Bz%7D%29\" alt=\"p_{\\theta}(\\mathbf{z})\" eeimg=\"1\"/\u003e 和 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bx%7D%7C%5Cmathbb%7Bz%7D%29\" alt=\"p_{\\theta} (\\mathbb{x}|\\mathbb{z})\" eeimg=\"1\"/\u003e都是高斯分布。因此，如果我们有 \u003cimg src=\"https://www.zhihu.com/equation?tex=+E%EF%BC%88x%7Cz%EF%BC%89%3Df%EF%BC%88z%EF%BC%89%3Dz\" alt=\" E（x|z）=f（z）=z\" eeimg=\"1\"/\u003e ，这意味着 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bz%7D%7C%5Cmathbb%7Bx%7D%29\" alt=\"p_{\\theta} (\\mathbb{z}|\\mathbb{x})\" eeimg=\"1\"/\u003e 也应该遵循高斯分布，并且从理论上讲，我们“只能”尝试表示 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bz%7D%7C%5Cmathbb%7Bx%7D%29\" alt=\"p_{\\theta} (\\mathbb{z}|\\mathbb{x})\" eeimg=\"1\"/\u003e 相对于 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D%28%5Cmathbf%7Bz%7D%29\" alt=\"p_{\\theta}(\\mathbf{z})\" eeimg=\"1\"/\u003e 和 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bx%7D%7C%5Cmathbb%7Bz%7D%29\" alt=\"p_{\\theta} (\\mathbb{x}|\\mathbb{z})\" eeimg=\"1\"/\u003e 的均值和协方差矩阵的均值和协方差矩阵。然而，在实践中，这个条件并没有得到满足，我们需要使用一种近似技术，如变分推断，这使得该方法非常通用，并且对模型假设中的某些变化更加鲁棒。\u003c/p\u003e\u003ch3\u003eVariational Inference Formulation 变分推断公式\u003c/h3\u003e\u003cp data-pid=\"_K8vk9zN\"\u003e在统计学中，变分推断 （VI） 是一种近似复杂分布的技术。这个想法是设置一个参数化的分布族（例如高斯族，其参数是均值和协方差），并在该族中寻找我们目标分布的最佳近似值。该系列中最好的元素是最小化给定近似误差测量值的元素（大多数情况下是近似值和目标值之间的 KL 散度），并且通过对描述该系列的参数进行梯度下降来找到。\u003c/p\u003e\u003cp data-pid=\"Lz6_QjMH\"\u003e在这里，我们将通过高斯分布 \u003cimg src=\"https://www.zhihu.com/equation?tex=q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29\" alt=\"q_\\phi(\\mathbf{z}\\vert\\mathbf{x})\" eeimg=\"1\"/\u003e 来近似 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bz%7D%7C%5Cmathbb%7Bx%7D%29\" alt=\"p_{\\theta} (\\mathbb{z}|\\mathbb{x})\" eeimg=\"1\"/\u003e ，它也可以用一个网络来学习，这个网络可以看成一个probabilistic encoder。其均值和协方差由参数 x 的两个函数 \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/\u003e 和 \u003cimg src=\"https://www.zhihu.com/equation?tex=+%5Cphi\" alt=\" \\phi\" eeimg=\"1\"/\u003e 定义。这两个函数应该分别属于函数 G 和 H 的族，这些函数将在后面指定，但应该被参数化。因此，我们可以表示\u003c/p\u003e\u003cp data-pid=\"fBJL1F3z\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%5Cequiv+%5Cmathcal%7BN%7D%28%5Ctheta%28x%29%2C++%5Cphi%28x%29%29+%5Cquad+%5Ctheta+%5Cin+G+%5Cquad++%5Cphi+%5Cin+H\" alt=\"q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\equiv \\mathcal{N}(\\theta(x),  \\phi(x)) \\quad \\theta \\in G \\quad  \\phi \\in H\" eeimg=\"1\"/\u003e \u003c/p\u003e\u003cp data-pid=\"CYzsqN18\"\u003e因此，我们已经以这种方式定义了变分推断的建模过程，现在需要通过优化函数\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/\u003e 和 \u003cimg src=\"https://www.zhihu.com/equation?tex=+%5Cphi\" alt=\" \\phi\" eeimg=\"1\"/\u003e（实际上是它们的参数）来最小化近似值 \u003cimg src=\"https://www.zhihu.com/equation?tex=q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29\" alt=\"q_\\phi(\\mathbf{z}\\vert\\mathbf{x})\" eeimg=\"1\"/\u003e 和目标 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bz%7D%7C%5Cmathbb%7Bx%7D%29\" alt=\"p_{\\theta} (\\mathbb{z}|\\mathbb{x})\" eeimg=\"1\"/\u003e 之间的\u003cb\u003eKL散度\u003c/b\u003e，从而找到该系列中的最佳近似值。换句话说，我们正在寻找最佳 \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D\" alt=\"\\theta^{*}, \\phi^{*}\" eeimg=\"1\"/\u003e 如下所示： ​\u003c/p\u003e\u003cp data-pid=\"8SiTwL6L\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%26+%5Cleft%28%5Ctheta%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D%5Cright%29%3D%5Cunderset%7B%28%5Ctheta%2C+%5Cphi%29+%5Cin+G+%5Ctimes+H%7D%7B%5Carg+%5Cmin+%7DD_%5Ctext%7BKL%7D%28+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%5C%7C+p_%5Ctheta%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%29+%26+%5C%5C+%26%3D%5Cunderset%7B%28%5Ctheta%2C+%5Cphi%29+%5Cin+G+%5Ctimes+H%7D%7B%5Carg+%5Cmin+%7D%5Cint+q_%5Cphi%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29+%5Clog%5Cfrac%7Bq_%5Cphi%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29%7D%7Bp_%5Ctheta%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29%7D+d%5Cmathbf%7Bz%7D+%26+%5C%5C+%26%3D%5Cunderset%7B%28%5Ctheta%2C+%5Cphi%29+%5Cin+G+%5Ctimes+H%7D%7B%5Carg+%5Cmin+%7D%5Cint+q_%5Cphi%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29+%5Clog%5Cfrac%7Bq_%5Cphi%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29p_%5Ctheta%28%5Cmathbf%7Bx%7D%29%7D%7Bp_%5Ctheta%28%5Cmathbf%7Bz%7D%2C+%5Cmathbf%7Bx%7D%29%7D+d%5Cmathbf%7Bz%7D+%26+%5Cscriptstyle%7B%5Ctext%7B%3B+Because+%7Dp%28z+%5Cvert+x%29+%3Dp%28z%2C+x%29+%2F+p%28x%29%7D+%5C%5C+%26%3D%5Cunderset%7B%28%5Ctheta%2C+%5Cphi%29+%5Cin+G+%5Ctimes+H%7D%7B%5Carg+%5Cmin+%7D%5Cint+q_%5Cphi%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29+%5Cbig%28+%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%29+%2B+%5Clog%5Cfrac%7Bq_%5Cphi%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29%7D%7Bp_%5Ctheta%28%5Cmathbf%7Bz%7D%2C+%5Cmathbf%7Bx%7D%29%7D+%5Cbig%29+d%5Cmathbf%7Bz%7D+%26+%5C%5C+%26%3D%5Cunderset%7B%28%5Ctheta%2C+%5Cphi%29+%5Cin+G+%5Ctimes+H%7D%7B%5Carg+%5Cmin+%7D%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%29+%2B+%5Cint+q_%5Cphi%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29%5Clog%5Cfrac%7Bq_%5Cphi%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29%7D%7Bp_%5Ctheta%28%5Cmathbf%7Bz%7D%2C+%5Cmathbf%7Bx%7D%29%7D+d%5Cmathbf%7Bz%7D+%26+%5Cscriptstyle%7B%5Ctext%7B%3B+Because+%7D%5Cint+q%28z+%5Cvert+x%29+dz+%3D+1%7D%5C%5C+%26%3D%5Cunderset%7B%28%5Ctheta%2C+%5Cphi%29+%5Cin+G+%5Ctimes+H%7D%7B%5Carg+%5Cmin+%7D%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%29+%2B+%5Cint+q_%5Cphi%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29%5Clog%5Cfrac%7Bq_%5Cphi%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29%7D%7Bp_%5Ctheta%28%5Cmathbf%7Bx%7D%5Cvert%5Cmathbf%7Bz%7D%29p_%5Ctheta%28%5Cmathbf%7Bz%7D%29%7D+d%5Cmathbf%7Bz%7D+%26+%5Cscriptstyle%7B%5Ctext%7B%3B+Because+%7Dp%28z%2C+x%29+%3D+p%28x+%5Cvert+z%29+p%28z%29%7D+%5C%5C+%26%3D%5Cunderset%7B%28%5Ctheta%2C+%5Cphi%29+%5Cin+G+%5Ctimes+H%7D%7B%5Carg+%5Cmin+%7D%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%29+%2B+%5Cmathbb%7BE%7D_%7B%5Cmathbf%7Bz%7D%5Csim+q_%5Cphi%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29%7D%5B%5Clog+%5Cfrac%7Bq_%5Cphi%28%5Cmathbf%7Bz%7D+%5Cvert+%5Cmathbf%7Bx%7D%29%7D%7Bp_%5Ctheta%28%5Cmathbf%7Bz%7D%29%7D+-+%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D+%5Cvert+%5Cmathbf%7Bz%7D%29%5D+%26%5C%5C+%26%3D%5Cunderset%7B%28%5Ctheta%2C+%5Cphi%29+%5Cin+G+%5Ctimes+H%7D%7B%5Carg+%5Cmin+%7D%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%29+%2B+D_%5Ctext%7BKL%7D%28q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%5C%7C+p_%5Ctheta%28%5Cmathbf%7Bz%7D%29%29+-+%5Cmathbb%7BE%7D_%7B%5Cmathbf%7Bz%7D%5Csim+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29%7D%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%5Cvert%5Cmathbf%7Bz%7D%29+%26+%5Cend%7Baligned%7D%5C%5C\" alt=\"\\begin{aligned} \u0026amp; \\left(\\theta^{*}, \\phi^{*}\\right)=\\underset{(\\theta, \\phi) \\in G \\times H}{\\arg \\min }D_\\text{KL}( q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z}\\vert\\mathbf{x}) ) \u0026amp; \\\\ \u0026amp;=\\underset{(\\theta, \\phi) \\in G \\times H}{\\arg \\min }\\int q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) \\log\\frac{q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{p_\\theta(\\mathbf{z} \\vert \\mathbf{x})} d\\mathbf{z} \u0026amp; \\\\ \u0026amp;=\\underset{(\\theta, \\phi) \\in G \\times H}{\\arg \\min }\\int q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) \\log\\frac{q_\\phi(\\mathbf{z} \\vert \\mathbf{x})p_\\theta(\\mathbf{x})}{p_\\theta(\\mathbf{z}, \\mathbf{x})} d\\mathbf{z} \u0026amp; \\scriptstyle{\\text{; Because }p(z \\vert x) =p(z, x) / p(x)} \\\\ \u0026amp;=\\underset{(\\theta, \\phi) \\in G \\times H}{\\arg \\min }\\int q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) \\big( \\log p_\\theta(\\mathbf{x}) + \\log\\frac{q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{p_\\theta(\\mathbf{z}, \\mathbf{x})} \\big) d\\mathbf{z} \u0026amp; \\\\ \u0026amp;=\\underset{(\\theta, \\phi) \\in G \\times H}{\\arg \\min }\\log p_\\theta(\\mathbf{x}) + \\int q_\\phi(\\mathbf{z} \\vert \\mathbf{x})\\log\\frac{q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{p_\\theta(\\mathbf{z}, \\mathbf{x})} d\\mathbf{z} \u0026amp; \\scriptstyle{\\text{; Because }\\int q(z \\vert x) dz = 1}\\\\ \u0026amp;=\\underset{(\\theta, \\phi) \\in G \\times H}{\\arg \\min }\\log p_\\theta(\\mathbf{x}) + \\int q_\\phi(\\mathbf{z} \\vert \\mathbf{x})\\log\\frac{q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{p_\\theta(\\mathbf{x}\\vert\\mathbf{z})p_\\theta(\\mathbf{z})} d\\mathbf{z} \u0026amp; \\scriptstyle{\\text{; Because }p(z, x) = p(x \\vert z) p(z)} \\\\ \u0026amp;=\\underset{(\\theta, \\phi) \\in G \\times H}{\\arg \\min }\\log p_\\theta(\\mathbf{x}) + \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}[\\log \\frac{q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{p_\\theta(\\mathbf{z})} - \\log p_\\theta(\\mathbf{x} \\vert \\mathbf{z})] \u0026amp;\\\\ \u0026amp;=\\underset{(\\theta, \\phi) \\in G \\times H}{\\arg \\min }\\log p_\\theta(\\mathbf{x}) + D_\\text{KL}(q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z})) - \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z}\\vert\\mathbf{x})}\\log p_\\theta(\\mathbf{x}\\vert\\mathbf{z}) \u0026amp; \\end{aligned}\\\\\" eeimg=\"1\"/\u003e\u003c/p\u003e\u003cp data-pid=\"noSUJysS\"\u003e最终可以得到：\u003c/p\u003e\u003cp data-pid=\"NbWI60HW\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=D_%5Ctext%7BKL%7D%28+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%5C%7C+p_%5Ctheta%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%29+%3D%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%29+%2B+D_%5Ctext%7BKL%7D%28q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%5C%7C+p_%5Ctheta%28%5Cmathbf%7Bz%7D%29%29+-+%5Cmathbb%7BE%7D_%7B%5Cmathbf%7Bz%7D%5Csim+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29%7D%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%5Cvert%5Cmathbf%7Bz%7D%29+%5C%5C\" alt=\"D_\\text{KL}( q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z}\\vert\\mathbf{x}) ) =\\log p_\\theta(\\mathbf{x}) + D_\\text{KL}(q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z})) - \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z}\\vert\\mathbf{x})}\\log p_\\theta(\\mathbf{x}\\vert\\mathbf{z}) \\\\\" eeimg=\"1\"/\u003e\u003c/p\u003e\u003cp data-pid=\"jUCYC4aM\"\u003e这里我们适当调整一下上述等式中各个项的位置，可以得到：\u003c/p\u003e\u003cp data-pid=\"8l5kmC-5\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%29+-+D_%5Ctext%7BKL%7D%28+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%5C%7C+p_%5Ctheta%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%29+%3D+%5Cmathbb%7BE%7D_%7B%5Cmathbf%7Bz%7D%5Csim+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29%7D%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%5Cvert%5Cmathbf%7Bz%7D%29+-+D_%5Ctext%7BKL%7D%28q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%5C%7C+p_%5Ctheta%28%5Cmathbf%7Bz%7D%29%29+%5C%5C\" alt=\"\\log p_\\theta(\\mathbf{x}) - D_\\text{KL}( q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z}\\vert\\mathbf{x}) ) = \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z}\\vert\\mathbf{x})}\\log p_\\theta(\\mathbf{x}\\vert\\mathbf{z}) - D_\\text{KL}(q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z})) \\\\\" eeimg=\"1\"/\u003e\u003c/p\u003e\u003cp data-pid=\"EenI-Dp3\"\u003e这里\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%29\" alt=\"\\log p_\\theta(\\mathbf{x})\" eeimg=\"1\"/\u003e是生成真实数据的对数似然，对于生成模型，我们希望最大化这个对数似然，而\u003cimg src=\"https://www.zhihu.com/equation?tex=D_%5Ctext%7BKL%7D%28+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%5C%7C+p_%5Ctheta%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%29\" alt=\"D_\\text{KL}( q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z}\\vert\\mathbf{x}) )\" eeimg=\"1\"/\u003e是估计的后验分布和真实分布的KL散度，我们希望最小化该KL散度（KL散度为0时两个分布没有差异），所以上述等式的左边就是联合建模的最大化优化目标，这等价于最大化等式的右边。这个等式的右边又称为\u003cb\u003eEvidence lower bound，简称为ELBO。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"2puDrwkj\"\u003e\u003ca href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Evidence_lower_bound\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003eELBO\u003c/a\u003e是变分推断中经常用到的优化目标。对于VAE，ELBO取负就是其要最小化的训练目标：\u003c/p\u003e\u003cp data-pid=\"kDT2KUrc\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+L_%5Ctext%7BVAE%7D%28%5Ctheta%2C+%5Cphi%29++%26%3D+-+%5Cmathbb%7BE%7D_%7B%5Cmathbf%7Bz%7D+%5Csim+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29%7D+%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%5Cvert%5Cmathbf%7Bz%7D%29+%2B+D_%5Ctext%7BKL%7D%28+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%5C%7C+p_%5Ctheta%28%5Cmathbf%7Bz%7D%29+%29+%5C%5C+%5Ctheta%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D+%26%3D+%5Carg%5Cmin_%7B%5Ctheta%2C+%5Cphi%7D+L_%5Ctext%7BVAE%7D+%5Cend%7Baligned%7D%5C%5C\" alt=\"\\begin{aligned} L_\\text{VAE}(\\theta, \\phi)  \u0026amp;= - \\mathbb{E}_{\\mathbf{z} \\sim q_\\phi(\\mathbf{z}\\vert\\mathbf{x})} \\log p_\\theta(\\mathbf{x}\\vert\\mathbf{z}) + D_\\text{KL}( q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z}) ) \\\\ \\theta^{*}, \\phi^{*} \u0026amp;= \\arg\\min_{\\theta, \\phi} L_\\text{VAE} \\end{aligned}\\\\\" eeimg=\"1\"/\u003e\u003c/p\u003e\u003cp data-pid=\"U8LzE4yg\"\u003e到目前为止，我们已经假设了函数 f 已知且固定，并且我们已经证明，在这样的假设下，我们可以使用变分推理技术近似后验 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%5Ctheta%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%29\" alt=\"p_\\theta(\\mathbf{z}\\vert\\mathbf{x}) )\" eeimg=\"1\"/\u003e 。然而，在实践中，定义解码器的函数 f 是未知的，也需要选择。为此，让我们提醒一下，我们最初的目标是找到一种高性能的编码-解码方案，其潜在空间足够规则，可以用于生成目的。如果规律性主要由潜在空间上的先验分布决定，则整体编码-解码方案的性能在很大程度上取决于函数 f 的选择。事实上，由于 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%5Ctheta%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%29\" alt=\"p_\\theta(\\mathbf{z}\\vert\\mathbf{x}) )\" eeimg=\"1\"/\u003e 可以从 \u003cimg src=\"https://www.zhihu.com/equation?tex=p%28z%29\" alt=\"p(z)\" eeimg=\"1\"/\u003e 和 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%5Ctheta%28%5Cmathbf%7Bx%7D%5Cvert%5Cmathbf%7Bz%7D%29\" alt=\"p_\\theta(\\mathbf{x}\\vert\\mathbf{z})\" eeimg=\"1\"/\u003e 中得到近似（通过变分推断），并且由于 \u003cimg src=\"https://www.zhihu.com/equation?tex=p%28z%29\" alt=\"p(z)\" eeimg=\"1\"/\u003e 是一个简单的标准高斯，因此我们在模型中唯一可以使用的两个杠杆来进行优化是参数 c（定义似然的方差）和函数 f（定义似然的均值）。我们可以为 F 中的任何函数 f（每个函数定义不同的概率解码器 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%5Ctheta%28%5Cmathbf%7Bx%7D%5Cvert%5Cmathbf%7Bz%7D%29\" alt=\"p_\\theta(\\mathbf{x}\\vert\\mathbf{z})\" eeimg=\"1\"/\u003e 获得 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%7B%5Ctheta%7D+%28%5Cmathbb%7Bz%7D%7C%5Cmathbb%7Bx%7D%29\" alt=\"p_{\\theta} (\\mathbb{z}|\\mathbb{x})\" eeimg=\"1\"/\u003e 的最佳近似值，表示为 \u003cimg src=\"https://www.zhihu.com/equation?tex=q_%5Cphi%5E%2A%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29\" alt=\"q_\\phi^*(\\mathbf{z}\\vert\\mathbf{x})\" eeimg=\"1\"/\u003e 。尽管它具有概率性质，但我们正在寻找一种尽可能高效的编码-解码方案，然后，我们希望选择函数 f，当从 \u003cimg src=\"https://www.zhihu.com/equation?tex=q_%5Cphi%5E%2A%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29\" alt=\"q_\\phi^*(\\mathbf{z}\\vert\\mathbf{x})\" eeimg=\"1\"/\u003e 采样时，该函数使给定 z 的 x 的预期对数似然最大化。换句话说，对于给定的输入 x，当我们从分布 \u003cimg src=\"https://www.zhihu.com/equation?tex=q_%5Cphi%5E%2A%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29\" alt=\"q_\\phi^*(\\mathbf{z}\\vert\\mathbf{x})\" eeimg=\"1\"/\u003e 中采样 z，然后从分布 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%5Ctheta%28%5Cmathbf%7Bx%7D%5Cvert%5Cmathbf%7Bz%7D%29\" alt=\"p_\\theta(\\mathbf{x}\\vert\\mathbf{z})\" eeimg=\"1\"/\u003e 中采样 x̂ 时，我们希望最大化 x̂ = x 的概率。因此，我们正在寻找最佳 f*，以便:\u003c/p\u003e\u003cp data-pid=\"qTQzo5fy\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+f%5E%7B%2A%7D+%26%3D+%5Carg%5Cmin_%7Bf%5Cin+F%7D++%5Cmathbb%7BE%7D_%7B%5Cmathbf%7Bz%7D+%5Csim+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29%7D+%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%5Cvert%5Cmathbf%7Bz%7D%29++%5Cend%7Baligned%7D%5C%5C\" alt=\"\\begin{aligned} f^{*} \u0026amp;= \\arg\\min_{f\\in F}  \\mathbb{E}_{\\mathbf{z} \\sim q_\\phi(\\mathbf{z}\\vert\\mathbf{x})} \\log p_\\theta(\\mathbf{x}\\vert\\mathbf{z})  \\end{aligned}\\\\\" eeimg=\"1\"/\u003e将所有部分收集在一起，我们正在寻找最佳的 \u003cimg src=\"https://www.zhihu.com/equation?tex=f%2A\" alt=\"f*\" eeimg=\"1\"/\u003e 、 \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%2A%7D\" alt=\"\\theta^{*}\" eeimg=\"1\"/\u003e 和 \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cphi%5E%7B%2A%7D+\" alt=\"\\phi^{*} \" eeimg=\"1\"/\u003e ，以便:\u003c/p\u003e\u003cp data-pid=\"y7BDsdO5\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+f%5E%7B%2A%7D%2C%5Ctheta%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D++%26%3D+%5Carg%5Cmin_%7Bf%5Cin+F%7D++%5Cmathbb%7BE%7D_%7B%5Cmathbf%7Bz%7D+%5Csim+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29%7D+%5Clog+p_%5Ctheta%28%5Cmathbf%7Bx%7D%5Cvert%5Cmathbf%7Bz%7D%29%2B+D_%5Ctext%7BKL%7D%28+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%5C%7C+p_%5Ctheta%28%5Cmathbf%7Bz%7D%29+%29+%5C%5C++%5Cend%7Baligned%7D%5C%5C\" alt=\"\\begin{aligned} f^{*},\\theta^{*}, \\phi^{*}  \u0026amp;= \\arg\\min_{f\\in F}  \\mathbb{E}_{\\mathbf{z} \\sim q_\\phi(\\mathbf{z}\\vert\\mathbf{x})} \\log p_\\theta(\\mathbf{x}\\vert\\mathbf{z})+ D_\\text{KL}( q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z}) ) \\\\  \\end{aligned}\\\\\" eeimg=\"1\"/\u003e \u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+f%5E%7B%2A%7D%2C%5Ctheta%5E%7B%2A%7D%2C+%5Cphi%5E%7B%2A%7D++%26%3D+%5Carg%5Cmin_%7Bf%2C%5Ctheta%2C++%5Cphi+%5Cin+F%5Ctimes+G+%5Ctimes+H%7D++%28%5Cmathbb%7BE%7D_%7B%5Cmathbf%7Bz%7D+%5Csim+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29%7D+%28-%5Cfrac%7B%28%5Cparallel+x-f%28z%29%5Cparallel%29+%5E2%7D%7B2c%7D%29+-+D_%5Ctext%7BKL%7D%28+q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29+%5C%7C+p_%5Ctheta%28%5Cmathbf%7Bz%7D%29+%29%29+%5C%5C++%5Cend%7Baligned%7D%5C%5C\" alt=\"\\begin{aligned} f^{*},\\theta^{*}, \\phi^{*}  \u0026amp;= \\arg\\min_{f,\\theta,  \\phi \\in F\\times G \\times H}  (\\mathbb{E}_{\\mathbf{z} \\sim q_\\phi(\\mathbf{z}\\vert\\mathbf{x})} (-\\frac{(\\parallel x-f(z)\\parallel) ^2}{2c}) - D_\\text{KL}( q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z}) )) \\\\  \\end{aligned}\\\\\" eeimg=\"1\"/\u003e 在这个目标函数中，我们可以识别上VAE 直观描述中引入的元素：x和 \u003cimg src=\"https://www.zhihu.com/equation?tex=f%28z%29\" alt=\"f(z)\" eeimg=\"1\"/\u003e 之间的重建误差以及 \u003cimg src=\"https://www.zhihu.com/equation?tex=q_%5Cphi%28%5Cmathbf%7Bz%7D%5Cvert%5Cmathbf%7Bx%7D%29\" alt=\"q_\\phi(\\mathbf{z}\\vert\\mathbf{x})\" eeimg=\"1\"/\u003e 和 \u003cimg src=\"https://www.zhihu.com/equation?tex=p_%5Ctheta%28%5Cmathbf%7Bz%7D%29+%29\" alt=\"p_\\theta(\\mathbf{z}) )\" eeimg=\"1\"/\u003e 之间的 KL 散度给出的正则化项（这是一个标准高斯分布）。我们还可以注意到控制前两项之间平衡的常数 c。c越高，我们就越假设模型中概率解码器在 \u003cimg src=\"https://www.zhihu.com/equation?tex=f%28z%29\" alt=\"f(z)\" eeimg=\"1\"/\u003e 周围的方差越高，因此，我们越倾向于正则化项而不是重建项（如果c为低，则相反）\u003c/p\u003e\u003cp data-pid=\"m8jHxiE5\"\u003e到目前为止，我们已经建立了一个概率模型，该模型依赖于三个函数，f，θ和π，并使用变分推理表示要解决的优化问题，以便得到f*，θ*和π*，从而给出最佳的编码-解码方案。由于我们不能轻易地在整个函数空间上进行优化，因此我们限制了优化域，并决定将 f、g 和 h 表示为神经网络。因此，F、G 和 H 分别对应于网络架构定义的函数族，并对这些网络的参数进行优化。\u003c/p\u003e\u003ch2\u003eVAE的本质结构\u003c/h2\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-2f40f349013931efd6ae96c2a97d1940_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"802\" data-rawheight=\"401\" data-original-token=\"v2-16b514ff273cfb56359f00074b936df8\" class=\"origin_image zh-lightbox-thumb\" width=\"802\" data-original=\"https://pic1.zhimg.com/v2-2f40f349013931efd6ae96c2a97d1940_r.jpg\"/\u003e\u003cfigcaption\u003eVAE变分自动编码器的本质结构\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"fbJEKQ0_\"\u003e这里引用苏神文章中对VAE本质的概况：它本质上就是在我们常规的自动编码器的基础上，对encoder的结果（在VAE中对应着计算均值的网络）加上了“高斯噪声”，使得结果decoder能够对噪声有鲁棒性；而那个额外的KL loss（目的是让均值为0，方差为1），事实上就是相当于对encoder的一个正则项，希望encoder出来的东西均有零均值。\u003c/p\u003e\u003cp data-pid=\"TvMjxh5K\"\u003e那另外一个encoder（对应着计算方差的网络）的作用呢？它是用来动态调节噪声的强度的。直觉上来想，\u003cb\u003e当decoder还没有训练好时（重构误差远大于KL loss），就会适当降低噪声（KL loss增加），使得拟合起来容易一些（重构误差开始下降）；反之，如果decoder训练得还不错时（重构误差小于KL loss），这时候噪声就会增加（KL loss减少），使得拟合更加困难了（重构误差又开始增加），这时候decoder就要想办法提高它的生成能力了。\u003c/b\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-9065a138f0f8275dab35de64472fc650_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1664\" data-rawheight=\"1002\" data-original-token=\"v2-9c1cda487d9e91a2591b2e98f704c5e2\" class=\"origin_image zh-lightbox-thumb\" width=\"1664\" data-original=\"https://pic3.zhimg.com/v2-9065a138f0f8275dab35de64472fc650_r.jpg\"/\u003e\u003cfigcaption\u003eVAE变分自动编码器表示。\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"m_L5AjA2\"\u003e重构的过程是希望没噪声的，而KL loss则希望有高斯噪声的，两者是对立的。所以，VAE跟GAN一样，内部其实是包含了一个对抗的过程，只不过它们两者是混合起来，共同进化的。\u003c/p\u003e\u003cp data-pid=\"ahuMVQjN\"\u003e参考文献：\u003c/p\u003e\u003cp data-pid=\"VX_77WPD\"\u003e\u003ca href=\"https://link.zhihu.com/?target=https%3A//towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003eUnderstanding Variational Autoencoders (VAEs) | by Joseph Rocca | Towards Data Science\u003c/a\u003e\u003c/p\u003e\u003cp data-pid=\"MjnDbWzu\"\u003e苏剑林. (Mar. 18, 2018). 《变分自编码器（一）：原来是这么一回事 》[Blog post]. Retrieved from\u003ca href=\"https://link.zhihu.com/?target=https%3A//kexue.fm/archives/5253\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003ekexue.fm/archives/5253\u003c/span\u003e\u003cspan class=\"invisible\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003cp data-pid=\"Dn359ksf\"\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/452743042\" class=\"internal\" target=\"_blank\"\u003e生成模型之VAE - 知乎 (zhihu.com)\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e","is_labeled":false,"visited_count":36760,"thumbnails":["https://picx.zhimg.com/v2-7ee4fcce1aaa36357819c5b572625238.jpg?source=7e7ef6e2\u0026needBackground=1","https://picx.zhimg.com/50/v2-99d9bc0f4811eed2be44be590e2ac488_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-376750917c78f6b1d7599a5684cb27ff_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-3a138a1f322c39510f6f2d3dee27a06a_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-e663746a18de0795da8ac9ab5a00446f_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-232b37cf954436e93c36304ced0f1c2e_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-a5db468835a8e01b74d466247bd42031_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-1cab939f86016408f4eb2c731a3e928d_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-8fe6e795db26090ef10d68b3fb6d0d6b_720w.jpg?source=b6762063"],"favorite_count":1882,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 698502893}","attached_info":"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","action_card":false}],"paging":{"is_end":false,"is_start":false,"next":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=down\u0026ad_interval=-10\u0026after_id=83\u0026desktop=true\u0026end_offset=84\u0026page_number=15\u0026session_token=a845b57cead3407b9c8a98ca322c471b","previous":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=pull\u0026ad_interval=-10\u0026before_id=83\u0026desktop=true\u0026end_offset=84\u0026page_number=15\u0026session_token=a845b57cead3407b9c8a98ca322c471b","totals":0},"fresh_text":"推荐已更新"}
