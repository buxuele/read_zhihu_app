{"data":[{"id":"36_1750899273.983","type":"feed","offset":36,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750899273,"updated_time":1750899273,"target":{"id":"1910639471566774576","type":"article","url":"https://api.zhihu.com/articles/1910639471566774576","author":{"id":"39fad59a1070650438ef4a30ed484038","url":"https://api.zhihu.com/people/39fad59a1070650438ef4a30ed484038","user_type":"people","url_token":"62-97-41","name":"军哥副业社","headline":"互联网创业9年，专注自媒体运营|职场干货|自我管理与提升","avatar_url":"https://picx.zhimg.com/50/v2-0fadcc5d4937b1a70687c8b1efc50a23_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":668,"is_following":false,"is_followed":false},"title":"搞钱的方式有10000种，你却只知道打工","image_url":"https://picx.zhimg.com/v2-5372742704e9ec8ca8e376e0f440e5a8.jpg?source=7e7ef6e2\u0026needBackground=1","comment_permission":"all","created":1748311948,"updated":1748311948,"voteup_count":54,"voting":0,"comment_count":3,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"这个世界上的财富是无穷尽的，关键是你用什么方式获取。 资本家都是靠剥削和掠夺；老百姓靠出卖体力赢得生活补贴。 在农民眼里能把地种好，一亩地能多产出200斤粮食，就是一种成功； 但靠种地获得的收入是有限的。 正如在底层人眼里：他们所谓的收入，就是给别人打工，打一天工就多一分钱，今天没上班就感觉到空虚恐惧焦虑，因为没收入。 财富是认知的变现，你的认知边界决定了你的收入方式。 有些人一年忙到头手里存不了5万块，…","excerpt_new":"这个世界上的财富是无穷尽的，关键是你用什么方式获取。 资本家都是靠剥削和掠夺；老百姓靠出卖体力赢得生活补贴。 在农民眼里能把地种好，一亩地能多产出200斤粮食，就是一种成功； 但靠种地获得的收入是有限的。 正如在底层人眼里：他们所谓的收入，就是给别人打工，打一天工就多一分钱，今天没上班就感觉到空虚恐惧焦虑，因为没收入。 财富是认知的变现，你的认知边界决定了你的收入方式。 有些人一年忙到头手里存不了5万块，…","preview_type":"default","preview_text":"","content":"\u003cp\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg data-caption=\"\" data-rawheight=\"292\" data-rawwidth=\"440\" data-size=\"normal\" src=\"https://picx.zhimg.com/v2-11e4bee2cac956797af48a04e9c6e747_1440w.jpg\" data-original-token=\"v2-11e4bee2cac956797af48a04e9c6e747\" class=\"origin_image zh-lightbox-thumb\" width=\"440\" data-original=\"https://picx.zhimg.com/v2-11e4bee2cac956797af48a04e9c6e747_r.jpg\"/\u003e\u003c/figure\u003e\u003c/p\u003e\u003cp data-pid=\"JTuO9xhE\"\u003e这个世界上的财富是无穷尽的，关键是你用什么方式获取。\u003c/p\u003e\u003cp data-pid=\"jZlS-6xJ\"\u003e资本家都是靠剥削和掠夺；老百姓靠出卖体力赢得生活补贴。\u003c/p\u003e\u003cp data-pid=\"YzmftT3O\"\u003e在农民眼里能把地种好，一亩地能多产出200斤粮食，就是一种成功；\u003c/p\u003e\u003cp data-pid=\"pzaXPoT5\"\u003e但靠种地获得的收入是有限的。\u003c/p\u003e\u003cp data-pid=\"DjmV5OFk\"\u003e正如在底层人眼里：他们所谓的收入，就是给别人打工，打一天工就多一分钱，今天没上班就感觉到空虚恐惧焦虑，因为没收入。\u003c/p\u003e\u003cp data-pid=\"70FtMeQ_\"\u003e财富是认知的变现，你的认知边界决定了你的收入方式。\u003c/p\u003e\u003cp data-pid=\"AVtaBH05\"\u003e有些人一年忙到头手里存不了5万块，而有些人一个月就能赚10万；\u003c/p\u003e\u003cp data-pid=\"Spiry11s\"\u003e有的人在工厂一天工作13个小时，却只能拿200块钱；有的人一小时直播就卖出几万块。\u003c/p\u003e\u003cp data-pid=\"UhtrlnZV\"\u003e搞钱的方式有10000种，你却只知道打工！\u003c/p\u003e\u003cp\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg data-caption=\"\" data-rawheight=\"460\" data-rawwidth=\"690\" data-size=\"normal\" src=\"https://pic4.zhimg.com/v2-d025dab77a41ee092c245013ba0c6801_1440w.jpg\" data-original-token=\"v2-d025dab77a41ee092c245013ba0c6801\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic4.zhimg.com/v2-d025dab77a41ee092c245013ba0c6801_r.jpg\"/\u003e\u003c/figure\u003e\u003c/p\u003e\u003cp data-pid=\"NXtHyAdb\"\u003e01\u003c/p\u003e\u003cp data-pid=\"vQ07Nrxk\"\u003e先定位好方向，你要赚什么钱？\u003c/p\u003e\u003cp data-pid=\"txiDUEOH\"\u003e①、你开实体店赚差价的钱？比如你开水果店，源头直采2块钱一斤的草莓，你卖5块钱一斤，中间3块钱就是你的利润，一天卖300斤，就能赚900元。\u003c/p\u003e\u003cp data-pid=\"SEZ3aDIl\"\u003e实体店的类型有很多，餐饮、饰品店、办公用品、婚庆用品、服装、鞋子、化妆品店等等。\u003c/p\u003e\u003cp data-pid=\"CnoJmt0e\"\u003e②、卖虚拟资料\u003c/p\u003e\u003cp data-pid=\"xndJF7sp\"\u003e比如你在闲鱼、某多多、某宝上卖学习资料，像考公、考研、养生、PPT模版等等。\u003c/p\u003e\u003cp data-pid=\"tthVfARt\"\u003e比如定价19.9元，一天卖50份，就能轻松赚1000元，这是纯利润哦。\u003c/p\u003e\u003cp data-pid=\"BMSU4nbs\"\u003e③、卖服务\u003c/p\u003e\u003cp data-pid=\"wYaHlRfi\"\u003e比如情感、心理咨询、创业指导、课程培训、社群陪伴等服务；\u003c/p\u003e\u003cp data-pid=\"DSIzsK5P\"\u003e服务的价格自行定义，几百几千几万的都有，看你的受众群体。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"DPFNd44g\"\u003e02\u003c/p\u003e\u003cp data-pid=\"PVGMIZuz\"\u003e为什么你认为搞钱很难？\u003c/p\u003e\u003cp data-pid=\"tvguQLsK\"\u003e因为你没有找到适合自己的赛道，没有找到能帮扶你一把的人；\u003c/p\u003e\u003cp data-pid=\"Fu-iQPJH\"\u003e同样的项目别人做就能赚钱，换作你去做的时候就亏钱；为什么？\u003c/p\u003e\u003cp data-pid=\"QChWspdB\"\u003e成功是不可复制的，可以模仿他们的思维和成事逻辑。\u003c/p\u003e\u003cp data-pid=\"Rc57A4MP\"\u003e认知度低，就会掉入很多坑。\u003c/p\u003e\u003cp data-pid=\"hSdbvyNE\"\u003e人要有定力，定力来自明确的价值观和自我认知。\u003c/p\u003e\u003cp data-pid=\"hIvA3d12\"\u003e清楚自己要什么，对于社会上的各种潮流有自己的判断；\u003c/p\u003e\u003cp data-pid=\"LOSoY_U2\"\u003e清楚自己是一个什么样的人，你的性情、禀赋、能力在什么地方？\u003c/p\u003e\u003cp data-pid=\"Q-Ej1oxw\"\u003e找到自己合意的位置，你找到了自己的位置，就不会和别人攀比。\u003c/p\u003e\u003cp data-pid=\"XawNWYPn\"\u003e往往是找不到自己位置的人，在自己做的事情里面找不到乐趣，就会变得很慌张。\u003c/p\u003e\u003cp data-pid=\"HoEHNOi7\"\u003e知道你能做什么很重要，知道你能赚什么钱更重要。\u003c/p\u003e\u003cp\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg data-caption=\"\" data-rawheight=\"916\" data-rawwidth=\"690\" data-size=\"normal\" src=\"https://pica.zhimg.com/v2-004e6635806a730a648a27d5188139b4_1440w.jpg\" data-original-token=\"v2-004e6635806a730a648a27d5188139b4\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pica.zhimg.com/v2-004e6635806a730a648a27d5188139b4_r.jpg\"/\u003e\u003c/figure\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"q7MA3hkj\"\u003e03\u003c/p\u003e\u003cp data-pid=\"9Q1R6BK0\"\u003e如何突破自己的思维和认知？\u003c/p\u003e\u003cp data-pid=\"baamB3Kg\"\u003e①多看看外面的世界\u003c/p\u003e\u003cp data-pid=\"3RQKccvn\"\u003e想赚钱，就去拆解优秀同行的商业案例，看他们是怎么赚钱的？与什么套路？\u003c/p\u003e\u003cp data-pid=\"wLAcNK5c\"\u003e多链接优秀人的圈子，多看眼界；才能发现更多的商机。\u003c/p\u003e\u003cp data-pid=\"oPK5rn51\"\u003e马云如果没有出国考察，就不会发现互联网的魅力，也不会做出阿里巴巴这样的伟大企业。\u003c/p\u003e\u003cp data-pid=\"i21L-WwH\"\u003e不要闭门造车，多出去走走，外面的世界很精彩。\u003c/p\u003e\u003cp data-pid=\"Dja8xI4p\"\u003e②、多拆解研究\u003c/p\u003e\u003cp data-pid=\"bbhwjE0K\"\u003e拆解的案例多了，你就会发现搞钱的逻辑都是相通的。\u003c/p\u003e\u003cp data-pid=\"D1lxS-5_\"\u003e大道至简，你能跑通一个项目，同样能跑通10个项目。\u003c/p\u003e\u003cp data-pid=\"mzyuqtg4\"\u003e在很多人的认知里，一提到做生意，就是开奶茶店、早餐店、服装店等。\u003c/p\u003e\u003cp data-pid=\"PsZetZ00\"\u003e这几年经济环境不太好，千万不要碰实体。\u003c/p\u003e\u003cp data-pid=\"Wvm_TVc4\"\u003e选择互联网轻资产创业的项目，即便是亏损了，也没什么影响。\u003c/p\u003e\u003cp data-pid=\"twKYjdX9\"\u003e③对标优质账号极致模仿\u003c/p\u003e\u003cp data-pid=\"IJA2pdaz\"\u003e一边抄一边学一边干；在执行中理解，在理解中执行。\u003c/p\u003e\u003cp data-pid=\"DU_BMi1v\"\u003e和有结果的人在一起，你慢慢地也会做出结果来了。\u003c/p\u003e\u003cp data-pid=\"Fa5XnpzW\"\u003e不要搞创新，那是一条不归路，你的条件不允许。\u003c/p\u003e\u003cp data-pid=\"8dbLqFh5\"\u003e别人怎么做，你就跟着怎么做就行了；其他的不重要。\u003c/p\u003e\u003cp data-pid=\"KjrxKQWo\"\u003e专注聚焦持续模仿，你的能力也就提高了。\u003c/p\u003e\u003cp data-pid=\"228NflSt\"\u003e先模仿再超越，先确定自己走在正确的路上，然后再把事情做正确，一点点的超越。\u003c/p\u003e\u003cp data-pid=\"Ky352hLs\"\u003e“做别人视野范围内最懂某件事的人每个人的视野范围都是有限的，洗头不会找一公里以外的tony，找家教不会跨一个城市驱车前往，旅游订酒店超出不了app榜单和小红书推荐前十页。\u003c/p\u003e\u003cp data-pid=\"YCLlh2pl\"\u003e所以，你的技能、专业，成为了很多人视野内的当前最优解以后，就自动会有源源不断的人来找你解决问题，钱反而成为了被动的附加品。\u003c/p\u003e\u003cp data-pid=\"2n-ifm9n\"\u003e你要尽可能多地闯入别人的视野,\u003c/p\u003e\u003cp data-pid=\"8gNYbSP-\"\u003e你要大方对外输出你的价值和技能”。\u003c/p\u003e\u003cp data-pid=\"Ig2RerE_\"\u003e点亮【在看和赞】，你我共同成长。\u003c/p\u003e\u003cp data-pid=\"wmR6v4Z-\"\u003e\u003cstrong\u003e作者简介\u003c/strong\u003e\u003c/p\u003e\u003cp data-pid=\"WBD343Ft\"\u003e专注分享自媒体干货+自我精进+认知提升，在成为自由职业者的路上\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"IhMqYOM2\"\u003e我能提供的价值：\u003c/p\u003e\u003cp data-pid=\"QddmCbRj\"\u003e1、1年写作成长陪伴社群：399元/年\u003c/p\u003e","is_labeled":false,"visited_count":2509,"thumbnails":["https://picx.zhimg.com/v2-5372742704e9ec8ca8e376e0f440e5a8.jpg?source=7e7ef6e2\u0026needBackground=1","https://pic1.zhimg.com/50/v2-c0a2e80aea0ed738330506f1bca10b20_720w.jpg?source=b6762063"],"favorite_count":160,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1910639471566774576}","attached_info":"CqEHCNvCqJK0sIiAiAEQBxoJMjU4MjQyNjczIIy/1MEGKDYwA0AkSjAKBkl0ZW1DRhIgZG9jX3R5cGU6IEFydGljbGUKaWQ6IDI1NzkxNDc4NQoYACAAOgBiIGYzZjJkZjQ2ZDNjNzZhMzMzMmU1Nzk2ZDE5MTlhMTUwchMxOTEwNjM5NDcxNTY2Nzc0NTc2ggFfaHR0cHM6Ly9waWN4LnpoaW1nLmNvbS92Mi01MzcyNzQyNzA0ZTllYzhjYThlMzc2ZTBmNDQwZTVhOC5qcGc/c291cmNlPTdlN2VmNmUyJm5lZWRCYWNrZ3JvdW5kPTGqAQlyZWNvbW1lbmTCASAzOWZhZDU5YTEwNzA2NTA0MzhlZjRhMzBlZDQ4NDAzOPIBCggMEgZOb3JtYWzyASgIChIkZmMxYTk3MjQtMzA0OS00MGYzLWE3YTMtY2FkMWI1ZGQxYWNl8gEFCAsSATeCAgCIAorh6s36MpICIDM5ZmFkNTlhMTA3MDY1MDQzOGVmNGEzMGVkNDg0MDM4mgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZdoCBkl0ZW1DRugCAvoCC05PUk1BTF9GTE9XigMgNWFjYmY4NTYyNTNhNDVmNWEyN2RmNjY1ODkxOGJiYWSaAw0KAnYyEAAaBW90aGVyqAPNE9gDAOoDFXRleHRBbGxTaXRlTXZJdGVtQ0ZWMvoD2wESDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFOi0IAxC4AxikAiIjdjItMTFlNGJlZTJjYWM5NTY3OTdhZjQ4YTA0ZTljNmU3NDc6LQgDELIFGMwDIiN2Mi1kMDI1ZGFiNzdhNDFlZTA5MmMyNDUwMTNiYTBjNjgwMTotCAMQsgUYlAciI3YyLTAwNGU2NjM1ODA2YTczMGE2NDhhMjdkNTE4ODEzOWI0Oi0IAxCyBRilAiIjdjItNTM3Mjc0MjcwNGU5ZWM4Y2E4ZTM3NmUwZjQ0MGU1YTiABACIBACSBAZOb3JtYWyaBAEyoAQAqAQAsAQAugQGbWFudWFswgQDMTcwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAAAAMIO0P4EFAAAAAAAAAACJBXliBXe3EtI/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBQeQBgCgBiSoBgGSAi4KCTI1ODI0MjY3MxITMTkxMDYzOTQ3MTU2Njc3NDU3NhgHIgpJTUFHRV9URVhU","action_card":false},{"id":"37_1750899273.749","type":"feed","offset":37,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750899273,"updated_time":1750899273,"target":{"id":"1921166120641082542","type":"article","url":"https://api.zhihu.com/articles/1921166120641082542","author":{"id":"f19734f97e3e31e277a1b178e31bb436","url":"https://api.zhihu.com/people/f19734f97e3e31e277a1b178e31bb436","user_type":"people","url_token":"kenhe0512","name":"小和尚爱爬山","headline":"小和尚爱爬山，爬山！","avatar_url":"https://pic1.zhimg.com/50/v2-aadc43fe191053e88754c982d1daffb7_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":159,"is_following":false,"is_followed":false},"title":"NVIDIA Tensor Core演进：从Volta到Blackwell的技术革命","comment_permission":"all","created":1750822072,"updated":1750822072,"voteup_count":4,"voting":0,"comment_count":0,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"NVIDIA Tensor Core演进：从Volta到Blackwell的技术革命引言在人工智能和深度学习的快速发展浪潮中，GPU计算能力的提升一直是推动整个行业前进的核心动力。NVIDIA的Tensor Core技术作为现代AI计算的基石，从Volta架构首次引入到最新的Blackwell架构，经历了一场深刻的技术革命。本文将深入探讨这一演进过程，揭示其背后的技术原理、设计哲学和未来发展方向。   图1：GPU计算性能演进图。该图展示了过去十年中GPU计算能力的指数级…","excerpt_new":"NVIDIA Tensor Core演进：从Volta到Blackwell的技术革命引言在人工智能和深度学习的快速发展浪潮中，GPU计算能力的提升一直是推动整个行业前进的核心动力。NVIDIA的Tensor Core技术作为现代AI计算的基石，从Volta架构首次引入到最新的Blackwell架构，经历了一场深刻的技术革命。本文将深入探讨这一演进过程，揭示其背后的技术原理、设计哲学和未来发展方向。   图1：GPU计算性能演进图。该图展示了过去十年中GPU计算能力的指数级…","preview_type":"default","preview_text":"","content":"\u003ch2\u003eNVIDIA Tensor Core演进：从Volta到Blackwell的技术革命\u003c/h2\u003e\u003ch3\u003e引言\u003c/h3\u003e\u003cp data-pid=\"pylqLfpD\"\u003e在人工智能和深度学习的快速发展浪潮中，GPU计算能力的提升一直是推动整个行业前进的核心动力。NVIDIA的Tensor Core技术作为现代AI计算的基石，从Volta架构首次引入到最新的Blackwell架构，经历了一场深刻的技术革命。本文将深入探讨这一演进过程，揭示其背后的技术原理、设计哲学和未来发展方向。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-3b4482a602f86b12966c2b8e3422cdd4_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"768\" data-rawheight=\"480\" data-original-token=\"v2-079dd608179514766e67a69840f9452b\" class=\"origin_image zh-lightbox-thumb\" width=\"768\" data-original=\"https://pic3.zhimg.com/v2-3b4482a602f86b12966c2b8e3422cdd4_r.jpg\"/\u003e\u003cfigcaption\u003e在这里插入图片描述\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"PFc301L7\"\u003e\u003ci\u003e图1：GPU计算性能演进图。该图展示了过去十年中GPU计算能力的指数级增长，特别是在AI和深度学习应用中的性能提升。从2015年的P100到2025年的GB300，性能提升超过1000倍，体现了Tensor Core技术的巨大贡献。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"TRKNJ7Se\"\u003e当谈到AI和深度学习时，GPU计算能力的改进速度已经超越了摩尔定律的步伐，持续提供着令人瞩目的\u0026#34;黄氏定律\u0026#34;性能提升。推动这一改进的核心技术正是Tensor Core。虽然Tensor Core无疑是现代AI和机器学习基础的基石，但即使是该领域的许多经验丰富的从业者也并不完全理解它。GPU架构和运行在此架构上的编程模型的快速演进意味着，机器学习研究人员和科学家要跟上Tensor Core的最新变化并掌握这些变化的含义变得越来越具有挑战性。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-5b6142842b225ed73d6e2aa4d47b701e_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1642\" data-rawheight=\"972\" data-original-token=\"v2-10d0e50fb4db24c1e07b8f3498a323a6\" class=\"origin_image zh-lightbox-thumb\" width=\"1642\" data-original=\"https://pic1.zhimg.com/v2-5b6142842b225ed73d6e2aa4d47b701e_r.jpg\"/\u003e\u003cfigcaption\u003e在这里插入图片描述\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"_1zFNIQa\"\u003e\u003ci\u003e图2：NVIDIA单GPU密集吞吐量性能图。该图详细展示了从V100到GB300各代GPU在不同精度（FP4、INT8/FP8、FP16、FP32）下的计算吞吐量。可以看到，随着Tensor Core技术的演进，低精度计算的性能提升尤为显著。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"5u5Imzr6\"\u003e在本报告中，我们将介绍主要数据中心GPU的核心特性，首先解释性能工程的重要基本原理。然后，我们将追踪NVIDIA Tensor Core架构和编程模型的演进，突出这一演进背后的动机。我们的最终目标是提供一个理解NVIDIA GPU架构的资源，并对其架构演进提供直观的见解。只有在解释了每个架构之后，我们才能解释Blackwell Tensor Core的美妙之处以及其新内存层次结构的优势。\u003c/p\u003e\u003ch3\u003e性能优先原则：理解现代计算的基础\u003c/h3\u003e\u003ch3\u003eAmdahl定律：并行计算的理论基础\u003c/h3\u003e\u003cp data-pid=\"oaqrWP-F\"\u003e在深入探讨Tensor Core的技术细节之前，我们必须首先理解支撑现代高性能计算的基本原理。Amdahl定律作为并行计算领域的基础理论，为我们理解GPU架构设计提供了重要的理论框架。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-7032fde4b01234379d852dadbe9f1d1d_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1919\" data-rawheight=\"522\" data-original-token=\"v2-3ad1a245f83aab80c94728c45e8b07a3\" class=\"origin_image zh-lightbox-thumb\" width=\"1919\" data-original=\"https://pic2.zhimg.com/v2-7032fde4b01234379d852dadbe9f1d1d_r.jpg\"/\u003e\u003cfigcaption\u003e在这里插入图片描述\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"p4YkFyMG\"\u003e\u003ci\u003e图3：Amdahl定律示意图。该图展示了并行计算中串行部分对整体性能提升的限制作用。即使并行部分的性能无限提升，整体性能的提升仍然受到串行部分的制约。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"PpARvAXp\"\u003eAmdahl定律揭示了一个关键洞察：系统的整体性能提升受到其最慢组件的限制。在GPU计算的背景下，这意味着即使我们拥有数千个计算核心，如果存在无法并行化的瓶颈，整体性能仍然会受到严重制约。这一原理直接影响了NVIDIA在设计Tensor Core时的策略选择。\u003c/p\u003e\u003cp data-pid=\"mEaOI7L-\"\u003e具体而言，Amdahl定律可以用以下公式表示：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e加速比 = 1 / ((1 - P) + P/N)\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"HRhWZeDV\"\u003e其中： - P是可以并行化的程序部分比例 - N是处理器数量 - (1 - P)是必须串行执行的部分\u003c/p\u003e\u003cp data-pid=\"bvR1hEly\"\u003e这个公式告诉我们，当P接近1（即大部分计算都可以并行化）时，增加处理器数量N可以带来显著的性能提升。但是，即使很小的串行部分也会严重限制整体性能的提升。\u003c/p\u003e\u003ch3\u003e强扩展性与弱扩展性\u003c/h3\u003e\u003cp data-pid=\"2wDan-zO\"\u003e在并行计算中，我们通常区分两种扩展性模式：强扩展性（Strong Scaling）和弱扩展性（Weak Scaling）。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-52d0374246dccc599dfef316ff88544d_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2560\" data-rawheight=\"1807\" data-original-token=\"v2-ed06811a472d93c5dc39a437d1f9f4bc\" class=\"origin_image zh-lightbox-thumb\" width=\"2560\" data-original=\"https://pic2.zhimg.com/v2-52d0374246dccc599dfef316ff88544d_r.jpg\"/\u003e\u003cfigcaption\u003e在这里插入图片描述\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"3DKOi7vx\"\u003e\u003ci\u003e图4：强扩展性与弱扩展性对比图。强扩展性关注固定问题规模下增加处理器数量的效果，而弱扩展性关注问题规模与处理器数量同时增长的情况。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"U7hCyLUI\"\u003e\u003cb\u003e强扩展性\u003c/b\u003e指的是在固定问题规模下，通过增加处理器数量来减少计算时间的能力。在理想情况下，如果我们将处理器数量翻倍，计算时间应该减半。然而，由于Amdahl定律的限制，实际的强扩展性往往达不到理想状态。\u003c/p\u003e\u003cp data-pid=\"0MglI6N4\"\u003e\u003cb\u003e弱扩展性\u003c/b\u003e则关注在增加处理器数量的同时，按比例增加问题规模时系统的表现。在这种情况下，我们希望计算时间保持相对稳定，即使问题规模在增长。\u003c/p\u003e\u003cp data-pid=\"7v27i9Bj\"\u003e对于深度学习应用而言，弱扩展性往往更为重要，因为随着模型规模的不断增长（如从GPT-3的1750亿参数到更大的模型），我们需要能够有效利用更多计算资源的架构。\u003c/p\u003e\u003ch3\u003e数据移动：计算的根本问题\u003c/h3\u003e\u003cp data-pid=\"Fs7ccDgt\"\u003e现代计算系统面临的最大挑战之一是数据移动的成本。正如图5所示，数据移动已经成为制约性能和能效的\u0026#34;根本罪恶\u0026#34;。\u003c/p\u003e\u003cp data-pid=\"jH2Hk0wC\"\u003e在现代GPU中，从DRAM读取数据的能耗可能比执行一次浮点运算高出数百倍。这种巨大的差异促使GPU架构师们设计了复杂的内存层次结构，包括：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"d0rg0uGi\"\u003e\u003cb\u003e寄存器文件\u003c/b\u003e：最快的存储，但容量有限\u003c/li\u003e\u003cli data-pid=\"Fb41yZe9\"\u003e\u003cb\u003e共享内存\u003c/b\u003e：在SM（Streaming Multiprocessor）内部共享，延迟较低\u003c/li\u003e\u003cli data-pid=\"T_lLunY4\"\u003e\u003cb\u003eL1缓存\u003c/b\u003e：每个SM的私有缓存\u003c/li\u003e\u003cli data-pid=\"eeIdsZlb\"\u003e\u003cb\u003eL2缓存\u003c/b\u003e：全局共享缓存\u003c/li\u003e\u003cli data-pid=\"hpcdZCAz\"\u003e\u003cb\u003eHBM/GDDR内存\u003c/b\u003e：主内存，容量大但延迟高\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"DfAHWdQP\"\u003eTensor Core的设计哲学正是围绕最小化数据移动而展开的。通过在计算单元附近集成专用的内存结构，并优化数据流模式，Tensor Core能够在保持高计算吞吐量的同时，显著降低能耗。\u003c/p\u003e\u003ch3\u003e计算密度与内存带宽的平衡\u003c/h3\u003e\u003cp data-pid=\"WwMcaEDb\"\u003e现代GPU设计面临的另一个关键挑战是平衡计算密度与内存带宽。随着计算能力的快速增长，内存带宽往往成为瓶颈。这种现象被称为\u0026#34;内存墙\u0026#34;问题。\u003c/p\u003e\u003cp data-pid=\"1KtQC7QP\"\u003e为了解决这一问题，GPU架构师们采用了多种策略：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"HmpYNfag\"\u003e\u003cb\u003e提高计算强度\u003c/b\u003e：通过执行更多的计算操作来摊销内存访问成本\u003c/li\u003e\u003cli data-pid=\"ZbeWDOQk\"\u003e\u003cb\u003e数据重用\u003c/b\u003e：在多个计算操作中重复使用已加载的数据\u003c/li\u003e\u003cli data-pid=\"uRB9HS5S\"\u003e\u003cb\u003e预取和缓存\u003c/b\u003e：预测性地加载数据并在层次化缓存中保存\u003c/li\u003e\u003cli data-pid=\"beOFDXOr\"\u003e\u003cb\u003e压缩和量化\u003c/b\u003e：减少数据传输量\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"oWZ3cgNe\"\u003eTensor Core的矩阵乘法操作天然具有高计算强度的特点。一个典型的矩阵乘法操作可以在相对较少的内存访问基础上执行大量的计算，这使得Tensor Core能够有效地隐藏内存延迟。\u003c/p\u003e\u003ch3\u003eTensor Core架构演进概览\u003c/h3\u003e\u003ch3\u003e技术演进的驱动力\u003c/h3\u003e\u003cp data-pid=\"Hy6vgtcx\"\u003eNVIDIA Tensor Core的演进并非偶然，而是由多个技术和市场因素共同驱动的结果。理解这些驱动力对于把握Tensor Core未来发展方向至关重要。\u003c/p\u003e\u003cp data-pid=\"yqVJdH8H\"\u003e\u003cb\u003e深度学习模型复杂度的指数增长\u003c/b\u003e是推动Tensor Core演进的首要因素。从早期的AlexNet到现在的大型语言模型，参数数量和计算需求呈指数级增长。这种增长对计算硬件提出了前所未有的挑战。\u003c/p\u003e\u003cp data-pid=\"h6rcifZS\"\u003e\u003cb\u003e能效要求的不断提升\u003c/b\u003e也是重要驱动力。随着数据中心规模的扩大和环保意识的增强，提高每瓦特性能成为硬件设计的关键目标。Tensor Core通过专用化设计实现了比通用计算单元更高的能效。\u003c/p\u003e\u003cp data-pid=\"39Vrxsuq\"\u003e\u003cb\u003e精度需求的多样化\u003c/b\u003e反映了不同应用场景的差异化需求。训练阶段通常需要较高精度以保证收敛性，而推理阶段则可以容忍更低的精度以换取更高的性能。这促使NVIDIA在不同代际的Tensor Core中支持越来越多的数据类型。\u003c/p\u003e\u003cp data-pid=\"1qf6Mhtx\"\u003e\u003cb\u003e内存系统的演进\u003c/b\u003e也深刻影响了Tensor Core的设计。随着HBM内存技术的发展和内存带宽的提升，Tensor Core需要相应地调整其架构以充分利用这些改进。\u003c/p\u003e\u003ch3\u003e代际演进的关键里程碑\u003c/h3\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-49b4246ba14303a1db6f3fd6fb06a7a3_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1818\" data-rawheight=\"1291\" data-original-token=\"v2-5ad30096ab62e3bc72ed6567d6383413\" class=\"origin_image zh-lightbox-thumb\" width=\"1818\" data-original=\"https://pic4.zhimg.com/v2-49b4246ba14303a1db6f3fd6fb06a7a3_r.jpg\"/\u003e\u003cfigcaption\u003e在这里插入图片描述\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"VRKPlSjB\"\u003e\u003cb\u003e第一代：Volta架构（2017年）\u003c/b\u003e - 首次引入Tensor Core概念 - 支持混合精度训练（FP16输入，FP32累加） - 4×4×4矩阵操作 - 主要面向深度学习训练\u003c/p\u003e\u003cp data-pid=\"84G80wD1\"\u003e\u003cb\u003e第二代：Turing架构（2018年）\u003c/b\u003e - 扩展到消费级GPU - 增加INT8和INT4支持 - 改进的调度和数据流 - 开始关注推理应用\u003c/p\u003e\u003cp data-pid=\"qK3WpeeF\"\u003e\u003cb\u003e第三代：Ampere架构（2020年）\u003c/b\u003e - 引入稀疏性支持（2:4结构化稀疏） - 支持BF16数据类型 - 改进的异步执行 - 更大的矩阵尺寸支持\u003c/p\u003e\u003cp data-pid=\"g3_DInkt\"\u003e\u003cb\u003e第四代：Hopper架构（2022年）\u003c/b\u003e - 引入Transformer Engine - 支持FP8数据类型 - Thread Block Cluster概念 - Tensor Memory Accelerator (TMA)\u003c/p\u003e\u003cp data-pid=\"eumAStf5\"\u003e\u003cb\u003e第五代：Blackwell架构（2024年）\u003c/b\u003e - 第二代Transformer Engine - 改进的FP8支持 - 新的内存层次结构 - 增强的稀疏性支持\u003c/p\u003e\u003ch3\u003e性能提升的量化分析\u003c/h3\u003e\u003cp data-pid=\"i59XuyZi\"\u003e从数量角度来看，Tensor Core的性能提升是惊人的。以FP16精度的矩阵乘法为例：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"lpuy79HR\"\u003e\u003cb\u003eVolta V100\u003c/b\u003e：约125 TFLOPS\u003c/li\u003e\u003cli data-pid=\"BbBWPekl\"\u003e\u003cb\u003eTuring RTX 2080 Ti\u003c/b\u003e：约107 TFLOPS（消费级）\u003c/li\u003e\u003cli data-pid=\"eXOTY1iv\"\u003e\u003cb\u003eAmpere A100\u003c/b\u003e：约312 TFLOPS\u003c/li\u003e\u003cli data-pid=\"xvc7FnL-\"\u003e\u003cb\u003eHopper H100\u003c/b\u003e：约989 TFLOPS\u003c/li\u003e\u003cli data-pid=\"te5_Gngg\"\u003e\u003cb\u003eBlackwell B100\u003c/b\u003e：预计超过1500 TFLOPS\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"PmXQTFyD\"\u003e这种性能提升不仅来自于制程工艺的改进，更重要的是架构创新和专用化设计的贡献。每一代Tensor Core都在前一代的基础上引入了新的优化技术和功能特性。\u003c/p\u003e\u003ch3\u003ePre-Tensor Core时代：传统GPU计算的局限性\u003c/h3\u003e\u003ch3\u003e传统CUDA核心的工作原理\u003c/h3\u003e\u003cp data-pid=\"5mcbcSqY\"\u003e在Tensor Core出现之前，GPU计算主要依赖于传统的CUDA核心。这些核心设计用于执行标量和向量运算，虽然在并行计算方面表现出色，但在处理深度学习工作负载时存在明显的局限性。\u003c/p\u003e\u003cp data-pid=\"D9Euz13N\"\u003e传统CUDA核心的设计基于SIMT（Single Instruction, Multiple Threads）模型，其中每个核心执行相同的指令但处理不同的数据。对于矩阵乘法这样的操作，传统方法需要：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"zRio0nyv\"\u003e\u003cb\u003e多次内存访问\u003c/b\u003e：每个元素的计算都需要从内存中读取操作数\u003c/li\u003e\u003cli data-pid=\"yERDGtkg\"\u003e\u003cb\u003e复杂的调度\u003c/b\u003e：需要协调大量线程来完成矩阵运算\u003c/li\u003e\u003cli data-pid=\"jpvAXl9q\"\u003e\u003cb\u003e有限的数据重用\u003c/b\u003e：难以有效重用已加载的数据\u003c/li\u003e\u003cli data-pid=\"7joUKaCw\"\u003e\u003cb\u003e精度限制\u003c/b\u003e：主要支持FP32，缺乏混合精度能力\u003c/li\u003e\u003c/ol\u003e\u003ch3\u003ePTX指令集的演进\u003c/h3\u003e\u003cp data-pid=\"nT6V1CZE\"\u003ePTX（Parallel Thread Execution）是NVIDIA GPU的虚拟指令集架构，它为GPU编程提供了稳定的接口。随着深度学习需求的增长，PTX指令集也在不断演进以支持新的计算模式。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-bd4094f45a39bf2b8e18ddf6d4e922f1_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1020\" data-rawheight=\"706\" data-original-token=\"v2-15dd8f768ba9d6407ddf9990b8802e83\" class=\"origin_image zh-lightbox-thumb\" width=\"1020\" data-original=\"https://picx.zhimg.com/v2-bd4094f45a39bf2b8e18ddf6d4e922f1_r.jpg\"/\u003e\u003cfigcaption\u003e在这里插入图片描述\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"KCaVyftL\"\u003e\u003ci\u003e图8：PTX指令集架构图。该图展示了PTX指令集的层次结构和与硬件的映射关系，说明了从高级编程语言到硬件执行的转换过程。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"gIGSjYT9\"\u003e在Pre-Tensor Core时代，矩阵乘法主要通过以下PTX指令实现：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003e// 传统的标量乘法累加操作\nfma.rn.f32 %r1, %r2, %r3, %r4;  // r1 = r2 * r3 + r4\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"ADT7D7Gr\"\u003e这种方法需要大量的指令来完成一个完整的矩阵乘法操作，导致： - 指令开销大 - 寄存器压力高 - 内存带宽利用率低 - 能效比差\u003c/p\u003e\u003ch3\u003e为什么NVIDIA引入Tensor Core\u003c/h3\u003e\u003cp data-pid=\"v-xXHiJa\"\u003e深度学习工作负载的特殊性质暴露了传统GPU架构的不足，促使NVIDIA开发专用的Tensor Core。\u003c/p\u003e\u003cp data-pid=\"fTfKEDSu\"\u003e\u003cb\u003e深度学习的计算特点\u003c/b\u003e： 1. \u003cb\u003e矩阵运算密集\u003c/b\u003e：神经网络的前向和反向传播主要由矩阵乘法组成 2. \u003cb\u003e数据局部性强\u003c/b\u003e：相邻的计算操作往往访问相似的数据 3. \u003cb\u003e精度容忍性\u003c/b\u003e：许多深度学习算法可以在较低精度下正常工作 4. \u003cb\u003e批处理友好\u003c/b\u003e：可以同时处理多个样本以提高效率\u003c/p\u003e\u003cp data-pid=\"lEV1YtL8\"\u003e\u003cb\u003e传统架构的局限性\u003c/b\u003e： 1. \u003cb\u003e计算效率低\u003c/b\u003e：标量运算无法充分利用矩阵运算的并行性 2. \u003cb\u003e内存带宽浪费\u003c/b\u003e：频繁的内存访问导致带宽利用率低 3. \u003cb\u003e能耗过高\u003c/b\u003e：大量的控制逻辑和通用性设计增加了功耗 4. \u003cb\u003e编程复杂\u003c/b\u003e：需要复杂的优化才能达到较好的性能\u003c/p\u003e\u003cp data-pid=\"aUAMITr1\"\u003e\u003cb\u003eTensor Core的解决方案\u003c/b\u003e： 1. \u003cb\u003e专用矩阵单元\u003c/b\u003e：直接支持矩阵乘法操作 2. \u003cb\u003e混合精度支持\u003c/b\u003e：允许使用较低精度进行计算 3. \u003cb\u003e优化的数据流\u003c/b\u003e：减少内存访问和数据移动 4. \u003cb\u003e简化的编程模型\u003c/b\u003e：提供高级API隐藏底层复杂性\u003c/p\u003e\u003ch3\u003e性能对比分析\u003c/h3\u003e\u003cp data-pid=\"j8f51oUi\"\u003e为了量化Tensor Core带来的改进，我们可以比较相同硬件上传统CUDA核心和Tensor Core的性能：\u003c/p\u003e\u003cp data-pid=\"Ijr1J-CZ\"\u003e\u003cb\u003eV100 GPU上的矩阵乘法性能（GEMM）\u003c/b\u003e： - 使用CUDA核心（FP32）：约15 TFLOPS - 使用Tensor Core（FP16）：约125 TFLOPS - 性能提升：约8.3倍\u003c/p\u003e\u003cp data-pid=\"K2MMKS_x\"\u003e这种巨大的性能提升不仅来自于精度降低（FP32到FP16），更重要的是专用化设计带来的效率提升。即使在相同精度下，Tensor Core仍然能够提供显著的性能优势。\u003c/p\u003e\u003cp data-pid=\"G6iS5ndd\"\u003e\u003cb\u003e能效对比\u003c/b\u003e： - CUDA核心：约0.3 TFLOPS/W - Tensor Core：约2.5 TFLOPS/W - 能效提升：约8.3倍\u003c/p\u003e\u003cp data-pid=\"kIX3Xj0W\"\u003e这种能效提升对于大规模数据中心部署具有重要意义，不仅降低了运营成本，也减少了环境影响。\u003c/p\u003e\u003ch3\u003eMMA指令：矩阵乘法累加的硬件实现\u003c/h3\u003e\u003ch3\u003eMMA指令的基本概念\u003c/h3\u003e\u003cp data-pid=\"9JrFN3Sl\"\u003eMMA（Matrix Multiply-Accumulate）指令是Tensor Core的核心，它将矩阵乘法和累加操作融合为单一的原子操作。这种设计大大简化了编程模型，同时提供了优异的性能。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-c78cb9ad34e3a20075bbf058c75dc206_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2359\" data-rawheight=\"2221\" data-original-token=\"v2-2cb3c6e1daf72a815e33243c6a6f3e3d\" class=\"origin_image zh-lightbox-thumb\" width=\"2359\" data-original=\"https://pic1.zhimg.com/v2-c78cb9ad34e3a20075bbf058c75dc206_r.jpg\"/\u003e\u003cfigcaption\u003e在这里插入图片描述\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"8JgOQIEz\"\u003e\u003ci\u003e图10：MMA指令概览图。该图展示了MMA指令的基本结构和执行流程，包括输入矩阵、计算过程和输出结果的组织方式。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"sfmq6h3Q\"\u003eMMA指令的基本形式可以表示为：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003eD = A × B + C\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"1ie-nOEh\"\u003e其中： - A和B是输入矩阵（通常使用较低精度，如FP16或INT8） - C是累加矩阵（通常使用较高精度，如FP32） - D是输出矩阵（与C相同精度）\u003c/p\u003e\u003cp data-pid=\"8DyJvbxr\"\u003e这种混合精度设计允许在保持数值稳定性的同时获得性能优势。较低精度的输入减少了内存带宽需求和存储开销，而较高精度的累加确保了计算精度。\u003c/p\u003e\u003ch3\u003e异步执行模型\u003c/h3\u003e\u003cp data-pid=\"q-LdwsNw\"\u003e现代Tensor Core支持异步执行模型，允许计算和内存操作重叠进行，从而隐藏内存延迟并提高整体吞吐量。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-d259d7517a7cc39abbda6f5000b94155_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1603\" data-rawheight=\"339\" data-original-token=\"v2-de87dea913a27a7e77f9ad0692a2ae08\" class=\"origin_image zh-lightbox-thumb\" width=\"1603\" data-original=\"https://pic4.zhimg.com/v2-d259d7517a7cc39abbda6f5000b94155_r.jpg\"/\u003e\u003cfigcaption\u003e异步执行流程图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"0VAKblmZ\"\u003e\u003ci\u003e图11：异步执行流程图。该图对比了同步和异步执行模式，展示了异步执行如何通过重叠计算和内存操作来提高性能。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"e0AikgWz\"\u003e异步执行的关键优势包括：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"uEoMorVY\"\u003e\u003cb\u003e延迟隐藏\u003c/b\u003e：在执行计算的同时进行数据传输\u003c/li\u003e\u003cli data-pid=\"JkOeDlGu\"\u003e\u003cb\u003e流水线化\u003c/b\u003e：多个操作可以并行进行\u003c/li\u003e\u003cli data-pid=\"vvw2ONWG\"\u003e\u003cb\u003e资源利用率提升\u003c/b\u003e：计算单元和内存系统可以同时工作\u003c/li\u003e\u003cli data-pid=\"9m3Qi6TA\"\u003e\u003cb\u003e编程灵活性\u003c/b\u003e：开发者可以更好地控制执行顺序\u003c/li\u003e\u003c/ol\u003e\u003ch3\u003eCUTLASS库的作用\u003c/h3\u003e\u003cp data-pid=\"heiSO9p_\"\u003eCUTLASS（CUDA Templates for Linear Algebra Subroutines）是NVIDIA开发的高性能线性代数库，专门为Tensor Core优化。它提供了高效的GEMM（General Matrix Multiply）实现和易用的编程接口。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-b35152e40f726442c0b4c56d35301388_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"806\" data-rawheight=\"1026\" data-original-token=\"v2-b2f79bbcd3e1ed8788fc93ab7360830a\" class=\"origin_image zh-lightbox-thumb\" width=\"806\" data-original=\"https://pic3.zhimg.com/v2-b35152e40f726442c0b4c56d35301388_r.jpg\"/\u003e\u003cfigcaption\u003eCUTLASS架构图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"yJNlhurG\"\u003e\u003ci\u003e图12：CUTLASS架构图。该图展示了CUTLASS库的层次结构，从底层的Tensor Core指令到高层的应用接口，说明了如何通过软件栈来充分利用硬件能力。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"eP-g_-uV\"\u003eCUTLASS的主要特性包括：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"E7RabNlD\"\u003e\u003cb\u003e模板化设计\u003c/b\u003e：支持多种数据类型和矩阵尺寸\u003c/li\u003e\u003cli data-pid=\"QpTSN0YC\"\u003e\u003cb\u003e性能优化\u003c/b\u003e：针对不同GPU架构进行专门优化\u003c/li\u003e\u003cli data-pid=\"bLSnoUxM\"\u003e\u003cb\u003e易用性\u003c/b\u003e：提供简洁的API隐藏底层复杂性\u003c/li\u003e\u003cli data-pid=\"jVPeL0O_\"\u003e\u003cb\u003e可扩展性\u003c/b\u003e：支持自定义操作和融合\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"mwO3T2mM\"\u003e通过CUTLASS，开发者可以轻松地在应用中集成高性能的矩阵运算，而无需深入了解底层的硬件细节。\u003c/p\u003e\u003ch3\u003e编程示例：使用MMA指令\u003c/h3\u003e\u003cp data-pid=\"8sRN3cS2\"\u003e以下是一个使用MMA指令进行矩阵乘法的简化示例：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;cutlass/cutlass.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;cutlass/gemm/device/gemm.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e// 定义GEMM操作的参数\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eusing\u003c/span\u003e \u003cspan class=\"n\"\u003eGemm\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003egemm\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003edevice\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eGemm\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ehalf_t\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e                    \u003cspan class=\"c1\"\u003e// 输入A的数据类型\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eRowMajor\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e          \u003cspan class=\"c1\"\u003e// 输入A的布局\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ehalf_t\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e                    \u003cspan class=\"c1\"\u003e// 输入B的数据类型\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eColumnMajor\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e       \u003cspan class=\"c1\"\u003e// 输入B的布局\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e                              \u003cspan class=\"c1\"\u003e// 输出C的数据类型\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eRowMajor\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e          \u003cspan class=\"c1\"\u003e// 输出C的布局\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e                              \u003cspan class=\"c1\"\u003e// 累加器的数据类型\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003earch\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eOpClassTensorOp\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e     \u003cspan class=\"c1\"\u003e// 使用Tensor Core\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003earch\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eSm80\u003c/span\u003e                 \u003cspan class=\"c1\"\u003e// 目标架构（Ampere）\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e// 矩阵维度\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eM\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1024\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1024\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eK\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1024\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 分配内存\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ehalf_t\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eC\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eD\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecudaMalloc\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eM\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eK\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"k\"\u003esizeof\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ehalf_t\u003c/span\u003e\u003cspan class=\"p\"\u003e));\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecudaMalloc\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eK\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"k\"\u003esizeof\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ehalf_t\u003c/span\u003e\u003cspan class=\"p\"\u003e));\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecudaMalloc\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eC\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eM\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"k\"\u003esizeof\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"p\"\u003e));\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecudaMalloc\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eD\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eM\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"k\"\u003esizeof\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"p\"\u003e));\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 初始化GEMM操作\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003eGemm\u003c/span\u003e \u003cspan class=\"n\"\u003egemm_op\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 设置参数\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"k\"\u003etypename\u003c/span\u003e \u003cspan class=\"n\"\u003eGemm\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eArguments\u003c/span\u003e \u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eM\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eK\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e                      \u003cspan class=\"c1\"\u003e// 矩阵维度\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eK\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e                         \u003cspan class=\"c1\"\u003e// 矩阵A及其leading dimension\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eK\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e                         \u003cspan class=\"c1\"\u003e// 矩阵B及其leading dimension\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eC\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e                         \u003cspan class=\"c1\"\u003e// 矩阵C及其leading dimension\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eD\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e                         \u003cspan class=\"c1\"\u003e// 矩阵D及其leading dimension\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"mf\"\u003e1.0f\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.0f\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e                   \u003cspan class=\"c1\"\u003e// alpha和beta系数\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 执行GEMM操作\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eStatus\u003c/span\u003e \u003cspan class=\"n\"\u003estatus\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003egemm_op\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 检查执行状态\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003estatus\u003c/span\u003e \u003cspan class=\"o\"\u003e!=\u003c/span\u003e \u003cspan class=\"n\"\u003ecutlass\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eStatus\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ekSuccess\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n        \u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ecerr\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;GEMM execution failed\u0026#34;\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eendl\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 清理内存\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ecudaFree\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecudaFree\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecudaFree\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eC\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecudaFree\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eD\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"niJIzgxc\"\u003e这个示例展示了如何使用CUTLASS库来执行高性能的矩阵乘法操作。代码中的关键点包括：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"1uz30iXv\"\u003e\u003cb\u003e数据类型选择\u003c/b\u003e：输入使用FP16，输出使用FP32，实现混合精度计算\u003c/li\u003e\u003cli data-pid=\"R5qA5j-F\"\u003e\u003cb\u003e内存布局\u003c/b\u003e：指定矩阵的存储格式（行主序或列主序）\u003c/li\u003e\u003cli data-pid=\"BZwhHpBV\"\u003e\u003cb\u003e架构目标\u003c/b\u003e：指定目标GPU架构以启用相应的优化\u003c/li\u003e\u003cli data-pid=\"4LMIly54\"\u003e\u003cb\u003e参数配置\u003c/b\u003e：设置矩阵维度和计算系数\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"3VE1W4jh\"\u003e通过这种方式，开发者可以充分利用Tensor Core的性能优势，而无需编写复杂的底层代码。\u003c/p\u003e\u003ch3\u003eVolta架构：第一代Tensor Core的诞生\u003c/h3\u003e\u003ch3\u003e革命性的架构创新\u003c/h3\u003e\u003cp data-pid=\"rBLxc5lm\"\u003e2017年，NVIDIA发布了Volta架构，标志着GPU计算历史上的一个重要转折点。Volta不仅仅是传统GPU架构的渐进式改进，而是一次根本性的重新思考，专门针对深度学习和AI工作负载进行了优化。\u003c/p\u003e\u003cp data-pid=\"vNthZqGA\"\u003eVolta架构的核心创新在于引入了专用的Tensor Core单元，这些单元能够执行混合精度的矩阵乘法累加操作。与传统的CUDA核心相比，Tensor Core在处理深度学习工作负载时提供了数量级的性能提升。\u003c/p\u003e\u003ch3\u003e第一代Tensor Core的技术规格\u003c/h3\u003e\u003cp data-pid=\"f5wB4Moh\"\u003e第一代Tensor Core支持4×4×4的矩阵操作，具体规格如下：\u003c/p\u003e\u003cp data-pid=\"RIoAQXgj\"\u003e\u003cb\u003e支持的数据类型\u003c/b\u003e： - 输入矩阵：FP16（半精度浮点） - 累加器：FP32（单精度浮点） - 输出：FP32（单精度浮点）\u003c/p\u003e\u003cp data-pid=\"pFsA0Lui\"\u003e\u003cb\u003e操作模式\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-text\"\u003eD = A × B + C\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"rZfjSH2G\"\u003e其中A和B是4×4的FP16矩阵，C和D是4×4的FP32矩阵。\u003c/p\u003e\u003cp data-pid=\"MeTPG73g\"\u003e\u003cb\u003e性能特性\u003c/b\u003e： - 每个时钟周期可以执行64次乘法累加操作 - 在V100上提供高达125 TFLOPS的混合精度性能 - 相比传统CUDA核心提供约8倍的性能提升\u003c/p\u003e\u003ch3\u003eWarp级别的矩阵操作\u003c/h3\u003e\u003cp data-pid=\"GmrAd6C7\"\u003eTensor Core操作是在warp级别执行的，这意味着一个warp（32个线程）协作完成一次矩阵乘法操作。这种设计有几个重要优势：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"KYnPnM_A\"\u003e\u003cb\u003e简化同步\u003c/b\u003e：warp内的线程天然同步，无需额外的同步原语\u003c/li\u003e\u003cli data-pid=\"K2vYFvvs\"\u003e\u003cb\u003e提高效率\u003c/b\u003e：减少了线程间的通信开销\u003c/li\u003e\u003cli data-pid=\"nsM52oWA\"\u003e\u003cb\u003e优化内存访问\u003c/b\u003e：可以更好地利用内存合并访问模式\u003c/li\u003e\u003c/ol\u003e\u003ch3\u003e编程模型的演进\u003c/h3\u003e\u003cp data-pid=\"YDsfTZxe\"\u003e为了支持Tensor Core，NVIDIA引入了新的编程接口。最初的接口相对底层，需要开发者直接处理warp级别的操作：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;mma.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eusing\u003c/span\u003e \u003cspan class=\"k\"\u003enamespace\u003c/span\u003e \u003cspan class=\"n\"\u003envcuda\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e// Warp级别的矩阵乘法累加\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003e__device__\u003c/span\u003e \u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003ewmma_example\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e// 声明矩阵片段\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003efragment\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ematrix_a\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehalf\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003erow_major\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003ea_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003efragment\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ematrix_b\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehalf\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ecol_major\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eb_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003efragment\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eaccumulator\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 从全局内存加载矩阵片段\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eload_matrix_sync\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ea_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ea_ptr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eload_matrix_sync\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eb_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eb_ptr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eload_matrix_sync\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ec_ptr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 执行矩阵乘法累加\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003emma_sync\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ea_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eb_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 将结果存储回全局内存\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003estore_matrix_sync\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ec_ptr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003emem_row_major\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"RpWU9_DX\"\u003e这个编程模型虽然功能强大，但对开发者的要求较高，需要深入理解GPU的内存层次结构和执行模型。\u003c/p\u003e\u003ch3\u003e混合精度训练的突破\u003c/h3\u003e\u003cp data-pid=\"VdcxY7Lo\"\u003e第一代Tensor Core最重要的贡献之一是使混合精度训练成为现实。混合精度训练允许在保持模型精度的同时显著提高训练速度和减少内存使用。\u003c/p\u003e\u003cp data-pid=\"ORMX41GT\"\u003e\u003cb\u003e混合精度训练的原理\u003c/b\u003e： 1. \u003cb\u003e前向传播\u003c/b\u003e：使用FP16进行大部分计算，减少内存带宽需求 2. \u003cb\u003e梯度计算\u003c/b\u003e：在FP16精度下计算梯度 3. \u003cb\u003e参数更新\u003c/b\u003e：使用FP32精度进行参数更新，保证数值稳定性 4. \u003cb\u003e损失缩放\u003c/b\u003e：通过缩放损失函数来避免梯度下溢\u003c/p\u003e\u003cp data-pid=\"6RVSLp-X\"\u003e\u003cb\u003e实现示例\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch.cuda.amp\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eautocast\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eGradScaler\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# 创建梯度缩放器\u003c/span\u003e\n\u003cspan class=\"n\"\u003escaler\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eGradScaler\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# 训练循环\u003c/span\u003e\n\u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003edataloader\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eoptimizer\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ezero_grad\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# 使用自动混合精度\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"n\"\u003eautocast\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eoutput\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eloss\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecriterion\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eoutput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# 缩放损失并反向传播\u003c/span\u003e\n    \u003cspan class=\"n\"\u003escaler\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003escale\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eloss\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebackward\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# 更新参数\u003c/span\u003e\n    \u003cspan class=\"n\"\u003escaler\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estep\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eoptimizer\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003escaler\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eupdate\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e性能分析与优化\u003c/h3\u003e\u003cp data-pid=\"AVtgUKoz\"\u003e第一代Tensor Core在实际应用中的性能表现令人印象深刻。以ResNet-50训练为例：\u003c/p\u003e\u003cp data-pid=\"PsKog7G4\"\u003e\u003cb\u003e传统FP32训练\u003c/b\u003e： - 训练时间：约100分钟/epoch - 内存使用：约15GB - 吞吐量：约200 images/second\u003c/p\u003e\u003cp data-pid=\"CHAMbMdz\"\u003e\u003cb\u003eTensor Core混合精度训练\u003c/b\u003e： - 训练时间：约60分钟/epoch - 内存使用：约8GB - 吞吐量：约350 images/second - 性能提升：约1.75倍\u003c/p\u003e\u003cp data-pid=\"2ZiEpsH0\"\u003e这种性能提升不仅来自于Tensor Core的计算能力，还得益于： 1. \u003cb\u003e内存带宽节省\u003c/b\u003e：FP16数据传输量减半 2. \u003cb\u003e内存容量节省\u003c/b\u003e：可以训练更大的模型或使用更大的批次 3. \u003cb\u003e缓存效率提升\u003c/b\u003e：更多数据可以保存在缓存中\u003c/p\u003e\u003ch3\u003e局限性与挑战\u003c/h3\u003e\u003cp data-pid=\"zmjh9Xah\"\u003e尽管第一代Tensor Core带来了显著的性能提升，但也存在一些局限性：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"nMgWC80o\"\u003e\u003cb\u003e数据类型限制\u003c/b\u003e：仅支持FP16输入和FP32累加\u003c/li\u003e\u003cli data-pid=\"3euMpLap\"\u003e\u003cb\u003e矩阵尺寸限制\u003c/b\u003e：固定的4×4×4操作可能不适合所有应用\u003c/li\u003e\u003cli data-pid=\"SJqPfRj9\"\u003e\u003cb\u003e编程复杂性\u003c/b\u003e：需要开发者手动管理内存和同步\u003c/li\u003e\u003cli data-pid=\"48Tablzb\"\u003e\u003cb\u003e数值稳定性\u003c/b\u003e：某些模型在混合精度下可能出现收敛问题\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"ftgqrcst\"\u003e这些局限性为后续架构的改进指明了方向，也推动了软件生态系统的发展。\u003c/p\u003e\u003ch3\u003eTuring架构：Tensor Core的普及化\u003c/h3\u003e\u003ch3\u003e消费级GPU的AI加速\u003c/h3\u003e\u003cp data-pid=\"h0DnDNFD\"\u003e2018年，NVIDIA发布了Turing架构，将Tensor Core技术首次引入消费级GPU市场。这一举措不仅扩大了Tensor Core的应用范围，也为AI技术的民主化做出了重要贡献。\u003c/p\u003e\u003cp data-pid=\"xauDhoSi\"\u003eTuring架构的Tensor Core在保持高性能的同时，针对消费级市场的需求进行了优化，特别是在推理应用方面。\u003c/p\u003e\u003ch3\u003e第二代Tensor Core的改进\u003c/h3\u003e\u003cp data-pid=\"DdC5yMhl\"\u003eTuring架构的第二代Tensor Core相比Volta有了显著改进：\u003c/p\u003e\u003cp data-pid=\"a_kiSsIV\"\u003e\u003cb\u003e新增数据类型支持\u003c/b\u003e： - INT8：适用于推理优化 - INT4：极致的推理性能 - INT1：二值化网络支持\u003c/p\u003e\u003cp data-pid=\"1gK1JUW4\"\u003e\u003cb\u003e改进的调度机制\u003c/b\u003e： - 更好的指令流水线 - 减少的延迟 - 提高的吞吐量\u003c/p\u003e\u003cp data-pid=\"hR3YElil\"\u003e\u003cb\u003e增强的编程支持\u003c/b\u003e： - 更简化的API - 更好的编译器优化 - 改进的调试工具\u003c/p\u003e\u003ch3\u003e推理优化的重点\u003c/h3\u003e\u003cp data-pid=\"d-4Wy2wQ\"\u003eTuring架构特别关注推理应用的优化，这反映了AI应用从研究阶段向生产部署的转变。\u003c/p\u003e\u003cp data-pid=\"sA_A4GTK\"\u003e\u003cb\u003eINT8量化的实现\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003e\u003cspan class=\"c1\"\u003e// INT8 Tensor Core操作示例\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003e__device__\u003c/span\u003e \u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eint8_gemm_example\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e// 声明INT8矩阵片段\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003efragment\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ematrix_a\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003eint8_t\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003erow_major\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003ea_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003efragment\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ematrix_b\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003eint8_t\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ecol_major\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eb_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003efragment\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eaccumulator\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003eint32_t\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 加载量化后的权重和激活\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eload_matrix_sync\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ea_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ea_int8_ptr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eload_matrix_sync\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eb_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eb_int8_ptr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e16\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003efill_fragment\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 执行INT8矩阵乘法\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003emma_sync\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ea_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eb_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 反量化并存储结果\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"c1\"\u003e// ... 反量化逻辑 ...\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"71nU1k5V\"\u003e\u003cb\u003e量化感知训练\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch.quantization\u003c/span\u003e \u003cspan class=\"kn\"\u003eas\u003c/span\u003e \u003cspan class=\"nn\"\u003equant\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# 定义量化配置\u003c/span\u003e\n\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eQuantizedModel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModule\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n        \u003cspan class=\"nb\"\u003esuper\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003equant\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003equantization\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eQuantStub\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\n        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edequant\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003equantization\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDeQuantStub\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eforward\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003equant\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edequant\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# 量化感知训练\u003c/span\u003e\n\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eqconfig\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003equant\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_default_qat_qconfig\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;fbgemm\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003emodel_prepared\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003equant\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eprepare_qat\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# 训练循环\u003c/span\u003e\n\u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003edataloader\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eoptimizer\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ezero_grad\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eoutput\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel_prepared\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eloss\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecriterion\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eoutput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eloss\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebackward\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eoptimizer\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estep\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# 转换为量化模型\u003c/span\u003e\n\u003cspan class=\"n\"\u003emodel_quantized\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003equant\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econvert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emodel_prepared\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e实时AI应用的支持\u003c/h3\u003e\u003cp data-pid=\"4GXS3Vuj\"\u003eTuring架构的Tensor Core特别适合实时AI应用，如：\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"p2UY71LO\"\u003e\u003cb\u003e实时语音识别\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"yDXoBCQN\"\u003e\u003cb\u003e实时图像处理\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"S4wD7o5C\"\u003e\u003cb\u003e游戏中的AI增强\u003c/b\u003e\u003c/li\u003e\u003cli data-pid=\"FNFf4dOk\"\u003e\u003cb\u003e边缘计算应用\u003c/b\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"7zUajtCQ\"\u003e这些应用对延迟有严格要求，Turing的低延迟设计和高效的推理能力使其成为理想选择。\u003c/p\u003e\u003ch3\u003eAmpere架构：稀疏性与异步执行的突破\u003c/h3\u003e\u003ch3\u003e第三代Tensor Core的革命性特性\u003c/h3\u003e\u003cp data-pid=\"rlC_5yZf\"\u003e2020年发布的Ampere架构标志着Tensor Core技术的又一次重大飞跃。第三代Tensor Core不仅在性能上有了显著提升，更重要的是引入了结构化稀疏性支持和改进的异步执行模型。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-07708ad31b5869b13c1e200b2496c138_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2028\" data-rawheight=\"1004\" data-original-token=\"v2-02edceba545aa6270151f337436b07e3\" class=\"origin_image zh-lightbox-thumb\" width=\"2028\" data-original=\"https://pic1.zhimg.com/v2-07708ad31b5869b13c1e200b2496c138_r.jpg\"/\u003e\u003cfigcaption\u003eHopper架构内部结构图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"Gw4tcjMU\"\u003e\u003ci\u003e图13：Hopper架构内部结构图。该图展示了现代GPU架构的复杂性，包括多个SM、内存层次结构和互连网络的组织方式。\u003c/i\u003e\u003c/p\u003e\u003ch3\u003e2:4结构化稀疏性\u003c/h3\u003e\u003cp data-pid=\"ZpDmUeP4\"\u003eAmpere架构引入的2:4结构化稀疏性是一个重要创新，它允许在保持计算效率的同时减少模型的存储和计算需求。\u003c/p\u003e\u003cp data-pid=\"14bzB94-\"\u003e\u003cb\u003e2:4稀疏性的原理\u003c/b\u003e： - 在每4个连续的权重中，有2个为零 - 硬件可以跳过零权重的计算 - 理论上可以提供2倍的性能提升\u003c/p\u003e\u003cp data-pid=\"rC5ElR2s\"\u003e\u003cb\u003e稀疏性的实现\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch.nn.utils.prune\u003c/span\u003e \u003cspan class=\"kn\"\u003eas\u003c/span\u003e \u003cspan class=\"nn\"\u003eprune\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# 应用2:4结构化稀疏性\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eapply_24_sparsity\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emodule\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# 获取权重张量\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eweight\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodule\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eweight\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# 重塑为4的倍数\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ereshaped\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eweight\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eview\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# 在每组4个元素中保留最大的2个\u003c/span\u003e\n    \u003cspan class=\"n\"\u003e_\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eindices\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etopk\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eabs\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ereshaped\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edim\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# 创建掩码\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emask\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ezeros_like\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ereshaped\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emask\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003escatter_\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eindices\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# 应用掩码\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eweight\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eweight\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eview\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003emask\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eview\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eweight\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eshape\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# 在模型中应用稀疏性\u003c/span\u003e\n\u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003emodule\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emodules\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"nb\"\u003eisinstance\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emodule\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eLinear\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eapply_24_sparsity\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emodule\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e异步数据复制\u003c/h3\u003e\u003cp data-pid=\"A0DVM0M3\"\u003eAmpere架构改进了异步执行模型，特别是在数据复制方面。新的异步复制指令允许在执行计算的同时进行数据传输，从而更好地隐藏内存延迟。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-d259d7517a7cc39abbda6f5000b94155_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1603\" data-rawheight=\"339\" data-original-token=\"v2-de87dea913a27a7e77f9ad0692a2ae08\" class=\"origin_image zh-lightbox-thumb\" width=\"1603\" data-original=\"https://pic4.zhimg.com/v2-d259d7517a7cc39abbda6f5000b94155_r.jpg\"/\u003e\u003cfigcaption\u003e异步数据复制流程图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"IQsjozCq\"\u003e\u003ci\u003e图14：异步数据复制流程图。该图对比了同步和异步数据复制的执行模式，展示了异步复制如何提高整体性能。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"Qhpe0xql\"\u003e\u003cb\u003e异步复制的实现\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003e\u003cspan class=\"c1\"\u003e// 使用异步复制指令\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003e__device__\u003c/span\u003e \u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003easync_copy_example\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"n\"\u003e__shared__\u003c/span\u003e \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e \u003cspan class=\"n\"\u003eshared_mem\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e1024\u003c/span\u003e\u003cspan class=\"p\"\u003e];\u003c/span\u003e\n    \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eglobal_mem\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"cm\"\u003e/* 全局内存指针 */\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 启动异步复制\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003e__pipeline_memcpy_async\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eshared_mem\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eglobal_mem\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \n                           \u003cspan class=\"k\"\u003esizeof\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mi\"\u003e1024\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 在数据传输的同时执行其他计算\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"c1\"\u003e// ... 其他计算操作 ...\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e// 等待异步复制完成\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003e__pipeline_commit\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n    \u003cspan class=\"n\"\u003e__pipeline_wait_prior\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 现在可以安全使用shared_mem中的数据\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003eBF16数据类型支持\u003c/h3\u003e\u003cp data-pid=\"kfMtV02_\"\u003eAmpere架构引入了对BF16（Brain Floating Point 16）数据类型的支持。BF16相比FP16有更大的指数范围，在某些应用中提供更好的数值稳定性。\u003c/p\u003e\u003cp data-pid=\"jg2WCvh0\"\u003e\u003cb\u003eBF16 vs FP16对比\u003c/b\u003e： - \u003cb\u003eFP16\u003c/b\u003e：1位符号 + 5位指数 + 10位尾数 - \u003cb\u003eBF16\u003c/b\u003e：1位符号 + 8位指数 + 7位尾数\u003c/p\u003e\u003cp data-pid=\"YN0bCE_u\"\u003e\u003cb\u003eBF16的优势\u003c/b\u003e： 1. \u003cb\u003e更大的数值范围\u003c/b\u003e：与FP32相同的指数范围 2. \u003cb\u003e更好的稳定性\u003c/b\u003e：减少溢出和下溢问题 3. \u003cb\u003e简化转换\u003c/b\u003e：与FP32的转换更简单\u003c/p\u003e\u003cp data-pid=\"9S4mv0zy\"\u003e\u003cb\u003e使用示例\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# 启用BF16训练\u003c/span\u003e\n\u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eto\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebfloat16\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eoptimizer\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eoptim\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAdamW\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eparameters\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003edataloader\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eto\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebfloat16\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003etarget\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eto\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebfloat16\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"n\"\u003eoptimizer\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ezero_grad\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eoutput\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eloss\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecriterion\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eoutput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eloss\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebackward\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eoptimizer\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estep\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e性能提升分析\u003c/h3\u003e\u003cp data-pid=\"j5nLvBbH\"\u003eAmpere架构的A100 GPU在各种工作负载上都展现出了显著的性能提升：\u003c/p\u003e\u003cp data-pid=\"IF6lg8Mi\"\u003e\u003cb\u003e训练性能（相比V100）\u003c/b\u003e： - ResNet-50：约1.6倍提升 - BERT-Large：约1.7倍提升 - GPT-3：约2.0倍提升\u003c/p\u003e\u003cp data-pid=\"VgpYQKF_\"\u003e\u003cb\u003e推理性能（相比V100）\u003c/b\u003e： - INT8推理：约2.5倍提升 - FP16推理：约1.9倍提升 - 稀疏推理：约3.0倍提升\u003c/p\u003e\u003cp data-pid=\"maIC58dw\"\u003e这些性能提升来自于多个方面的改进： 1. \u003cb\u003e更高的计算吞吐量\u003c/b\u003e 2. \u003cb\u003e改进的内存子系统\u003c/b\u003e 3. \u003cb\u003e更好的指令调度\u003c/b\u003e 4. \u003cb\u003e稀疏性支持\u003c/b\u003e\u003c/p\u003e\u003ch3\u003eHopper架构：Transformer Engine的革命\u003c/h3\u003e\u003ch3\u003e第四代Tensor Core的突破性创新\u003c/h3\u003e\u003cp data-pid=\"grvWbUaW\"\u003e2022年，NVIDIA发布了Hopper架构，引入了革命性的Transformer Engine和第四代Tensor Core。这一代架构专门针对大型语言模型和Transformer架构进行了深度优化。\u003c/p\u003e\u003ch3\u003eTransformer Engine的核心技术\u003c/h3\u003e\u003cp data-pid=\"lkqMWT5k\"\u003eTransformer Engine是Hopper架构的核心创新，它通过硬件和软件的协同设计，为Transformer模型提供了前所未有的性能。\u003c/p\u003e\u003cp data-pid=\"8M8j4M6S\"\u003e\u003cb\u003e主要特性\u003c/b\u003e： 1. \u003cb\u003eFP8数据类型支持\u003c/b\u003e 2. \u003cb\u003e动态精度调整\u003c/b\u003e 3. \u003cb\u003e优化的注意力机制\u003c/b\u003e 4. \u003cb\u003e改进的内存管理\u003c/b\u003e\u003c/p\u003e\u003ch3\u003eFP8：下一代精度标准\u003c/h3\u003e\u003cp data-pid=\"phXAvhaE\"\u003eFP8是Hopper架构引入的新数据类型，提供了比FP16更高的计算密度，同时保持足够的精度。\u003c/p\u003e\u003cp data-pid=\"eCiRyng0\"\u003e\u003cb\u003eFP8格式\u003c/b\u003e： - \u003cb\u003eE4M3\u003c/b\u003e：4位指数 + 3位尾数（适合前向传播） - \u003cb\u003eE5M2\u003c/b\u003e：5位指数 + 2位尾数（适合反向传播）\u003c/p\u003e\u003cp data-pid=\"Q1wu6R_Q\"\u003e\u003cb\u003eFP8的优势\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"c1\"\u003e# FP8训练示例\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etransformer_engine.pytorch\u003c/span\u003e \u003cspan class=\"kn\"\u003eas\u003c/span\u003e \u003cspan class=\"nn\"\u003ete\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eTransformerLayer\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModule\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehidden_size\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003enum_heads\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n        \u003cspan class=\"nb\"\u003esuper\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eattention\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ete\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMultiheadAttention\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehidden_size\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003enum_heads\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \n            \u003cspan class=\"n\"\u003efp8_autocast\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 启用FP8自动转换\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emlp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ete\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eLinear\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehidden_size\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehidden_size\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \n                           \u003cspan class=\"n\"\u003efp8_autocast\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eforward\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# 自注意力层\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eattn_out\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eattention\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"n\"\u003eattn_out\u003c/span\u003e\n\n        \u003cspan class=\"c1\"\u003e# MLP层\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emlp_out\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emlp\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"n\"\u003emlp_out\u003c/span\u003e\n\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003eThread Block Cluster\u003c/h3\u003e\u003cp data-pid=\"bAjSoIWm\"\u003eHopper架构引入了Thread Block Cluster概念，允许多个Thread Block协作执行，提供更大的并行度和更好的资源利用率。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-f16d85083ce07125e387e012121d7caf_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1955\" data-rawheight=\"1940\" data-original-token=\"v2-19ff97814711971e70cb2b8c33b4107c\" class=\"origin_image zh-lightbox-thumb\" width=\"1955\" data-original=\"https://pic4.zhimg.com/v2-f16d85083ce07125e387e012121d7caf_r.jpg\"/\u003e\u003cfigcaption\u003eTMA多播示意图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"8Cs_TWw6\"\u003e\u003ci\u003e图15：TMA多播示意图。该图展示了Tensor Memory Accelerator如何通过多播机制高效地分发数据到多个计算单元。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"Eswt-X3z\"\u003e\u003cb\u003eCluster编程模型\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;cuda/experimental/cluster\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\n\u003cspan class=\"n\"\u003e__global__\u003c/span\u003e \u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003ecluster_kernel\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e// 获取cluster信息\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"k\"\u003eauto\u003c/span\u003e \u003cspan class=\"n\"\u003ecluster\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecuda\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eexperimental\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ecluster\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ethis_cluster\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eauto\u003c/span\u003e \u003cspan class=\"n\"\u003eblock_rank\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecluster\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eblock_rank\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eauto\u003c/span\u003e \u003cspan class=\"n\"\u003ecluster_size\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecluster\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 在cluster内同步\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ecluster\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esync\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// cluster级别的内存操作\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eblock_rank\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e// 只有rank 0的block执行某些操作\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e        \u003cspan class=\"c1\"\u003e// ...\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n    \u003cspan class=\"n\"\u003ecluster\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esync\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e// 启动cluster kernel\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003edim3\u003c/span\u003e \u003cspan class=\"nf\"\u003egrid_size\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"n\"\u003edim3\u003c/span\u003e \u003cspan class=\"nf\"\u003eblock_size\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e256\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"n\"\u003edim3\u003c/span\u003e \u003cspan class=\"nf\"\u003ecluster_size\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// 2个block组成一个cluster\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\n\u003cspan class=\"n\"\u003ecudaLaunchKernelEx\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecluster_kernel\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003egrid_size\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eblock_size\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \n    \u003cspan class=\"k\"\u003enullptr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003enullptr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecluster_size\u003c/span\u003e\n\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003eTensor Memory Accelerator (TMA)\u003c/h3\u003e\u003cp data-pid=\"YIr9N-nI\"\u003eTMA是Hopper架构的另一个重要创新，它专门用于优化Tensor操作的内存访问模式。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-f2b8fe5fc55365771ce42ede2f4e950c_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"2425\" data-rawheight=\"1903\" data-original-token=\"v2-e67d54d57a198e62badfa12995b19391\" class=\"origin_image zh-lightbox-thumb\" width=\"2425\" data-original=\"https://pica.zhimg.com/v2-f2b8fe5fc55365771ce42ede2f4e950c_r.jpg\"/\u003e\u003cfigcaption\u003eWGMMA流程图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"nkrXy0jM\"\u003e\u003ci\u003e图16：WGMMA流程图。该图展示了Warp Group Matrix Multiply Accumulate操作的详细流程，包括数据加载、计算和存储的各个阶段。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"Wtkwn8pY\"\u003e\u003cb\u003eTMA的特性\u003c/b\u003e： 1. \u003cb\u003e硬件加速的内存复制\u003c/b\u003e 2. \u003cb\u003e多播支持\u003c/b\u003e 3. \u003cb\u003e压缩数据传输\u003c/b\u003e 4. \u003cb\u003e自动化的内存管理\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"QktRRAfu\"\u003e\u003cb\u003eTMA使用示例\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003e\u003cspan class=\"c1\"\u003e// TMA异步复制\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003e__device__\u003c/span\u003e \u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003etma_copy_example\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e// 定义TMA描述符\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003eCUtensorMap\u003c/span\u003e \u003cspan class=\"n\"\u003etma_desc\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 启动TMA复制\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"kt\"\u003euint64_t\u003c/span\u003e \u003cspan class=\"n\"\u003etma_ptr\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003ereinterpret_cast\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003euint64_t\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003etma_desc\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"k\"\u003easm\u003c/span\u003e \u003cspan class=\"k\"\u003evolatile\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes\u0026#34;\u003c/span\u003e\n                 \u003cspan class=\"s\"\u003e\u0026#34; [%0], [%1, {%2, %3}], [%4];\u0026#34;\u003c/span\u003e\n                 \u003cspan class=\"o\"\u003e:\u003c/span\u003e\n                 \u003cspan class=\"o\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;r\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eshared_ptr\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;l\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etma_ptr\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \n                   \u003cspan class=\"s\"\u003e\u0026#34;r\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecoord_x\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;r\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecoord_y\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;r\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003embar_ptr\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n                 \u003cspan class=\"o\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;memory\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e性能突破\u003c/h3\u003e\u003cp data-pid=\"zydMAlwA\"\u003eHopper架构在大型语言模型训练和推理方面实现了显著的性能突破：\u003c/p\u003e\u003cp data-pid=\"jtbz8F7S\"\u003e\u003cb\u003eGPT-3训练性能（H100 vs A100）\u003c/b\u003e： - 训练吞吐量：约3.0倍提升 - 内存效率：约2.4倍提升 - 能效比：约2.5倍提升\u003c/p\u003e\u003cp data-pid=\"gW9cyLYj\"\u003e\u003cb\u003e推理性能提升\u003c/b\u003e： - BERT推理：约4.5倍提升 - GPT推理：约6.0倍提升 - T5推理：约5.2倍提升\u003c/p\u003e\u003cp data-pid=\"yAqd0qKe\"\u003e这些性能提升主要来自于： 1. \u003cb\u003eFP8精度的使用\u003c/b\u003e 2. \u003cb\u003eTransformer Engine的优化\u003c/b\u003e 3. \u003cb\u003e改进的内存子系统\u003c/b\u003e 4. \u003cb\u003e更高的计算密度\u003c/b\u003e\u003c/p\u003e\u003ch3\u003eBlackwell架构：第五代Tensor Core的巅峰\u003c/h3\u003e\u003ch3\u003e下一代AI计算的基石\u003c/h3\u003e\u003cp data-pid=\"oa-1w2W4\"\u003e2024年，NVIDIA发布了最新的Blackwell架构，代表了Tensor Core技术发展的最新成果。第五代Tensor Core在前几代的基础上，进一步提升了性能、能效和功能性。\u003c/p\u003e\u003ch3\u003e第二代Transformer Engine\u003c/h3\u003e\u003cp data-pid=\"9BcqUfbP\"\u003eBlackwell架构搭载了第二代Transformer Engine，在第一代的基础上进行了全面升级：\u003c/p\u003e\u003cp data-pid=\"fxjIHA7n\"\u003e\u003cb\u003e主要改进\u003c/b\u003e： 1. \u003cb\u003e增强的FP8支持\u003c/b\u003e：更精确的动态范围调整 2. \u003cb\u003e改进的稀疏性处理\u003c/b\u003e：支持更灵活的稀疏模式 3. \u003cb\u003e优化的内存访问\u003c/b\u003e：减少内存带宽需求 4. \u003cb\u003e更好的编程接口\u003c/b\u003e：简化开发流程\u003c/p\u003e\u003ch3\u003e新的内存层次结构\u003c/h3\u003e\u003cp data-pid=\"0T87B9oF\"\u003eBlackwell架构引入了新的内存层次结构，包括更大的共享内存和改进的缓存系统。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-c226160ce8c3406376dc2cec791d17ca_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1005\" data-original-token=\"v2-7221b164d06c3e88eb80fe40456e061f\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pica.zhimg.com/v2-c226160ce8c3406376dc2cec791d17ca_r.jpg\"/\u003e\u003cfigcaption\u003eTensor内存访问示意图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"s628yEKy\"\u003e\u003ci\u003e图17：Tensor内存访问示意图。该图展示了Blackwell架构中Tensor内存的组织方式和访问模式，突出了新的内存层次结构的优势。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"RHc53tkd\"\u003e\u003cb\u003e内存层次结构的改进\u003c/b\u003e： 1. \u003cb\u003e更大的共享内存\u003c/b\u003e：每个SM的共享内存容量翻倍 2. \u003cb\u003e改进的L1缓存\u003c/b\u003e：更高的命中率和更低的延迟 3. \u003cb\u003e优化的L2缓存\u003c/b\u003e：更大的容量和更好的带宽 4. \u003cb\u003e新的Tensor内存\u003c/b\u003e：专门为Tensor操作优化的内存层\u003c/p\u003e\u003ch3\u003e第五代MMA指令\u003c/h3\u003e\u003cp data-pid=\"Lr1Kfi3r\"\u003e第五代Tensor Core支持更大的矩阵尺寸和更多的数据类型组合。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-9adcd97da3de8b8a6fea954489715476_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1954\" data-rawheight=\"2178\" data-original-token=\"v2-6d1bbfe46c0b51efef8771f1c8114a44\" class=\"origin_image zh-lightbox-thumb\" width=\"1954\" data-original=\"https://pic3.zhimg.com/v2-9adcd97da3de8b8a6fea954489715476_r.jpg\"/\u003e\u003cfigcaption\u003e第五代Tensor Core MMA流程图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"B3C8McOP\"\u003e\u003ci\u003e图18：第五代Tensor Core MMA流程图。该图详细展示了最新一代Tensor Core的矩阵乘法累加操作流程，包括数据流、计算过程和结果输出。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"WRa8WuZz\"\u003e\u003cb\u003e新的MMA指令特性\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003e\u003cspan class=\"c1\"\u003e// 第五代Tensor Core MMA指令示例\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003e__device__\u003c/span\u003e \u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003egen5_mma_example\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e// 支持更大的矩阵尺寸\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003efragment\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ematrix_a\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003e__nv_fp8_e4m3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003erow_major\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003ea_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003efragment\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ematrix_b\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003e__nv_fp8_e5m2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ecol_major\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eb_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003efragment\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eaccumulator\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 加载矩阵片段\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eload_matrix_sync\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ea_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ea_ptr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eload_matrix_sync\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eb_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eb_ptr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003efill_fragment\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.0f\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 执行混合精度矩阵乘法\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003emma_sync\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ea_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eb_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 存储结果\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003estore_matrix_sync\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ec_ptr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ec_frag\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ewmma\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003emem_row_major\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3\u003e增强的稀疏性支持\u003c/h3\u003e\u003cp data-pid=\"yKg0qm9K\"\u003eBlackwell架构进一步扩展了稀疏性支持，不仅支持2:4结构化稀疏，还支持更灵活的稀疏模式。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-27e300266e6edf42bd5d381ca2ee3e5a_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"660\" data-rawheight=\"511\" data-original-token=\"v2-569a359ab82a7afaec4fd33ac224cbbc\" class=\"origin_image zh-lightbox-thumb\" width=\"660\" data-original=\"https://pica.zhimg.com/v2-27e300266e6edf42bd5d381ca2ee3e5a_r.jpg\"/\u003e\u003cfigcaption\u003e稀疏性支持示意图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"3rcd3itm\"\u003e\u003ci\u003e图19：稀疏性支持示意图。该图展示了Blackwell架构支持的各种稀疏性模式，包括结构化稀疏和非结构化稀疏的处理方式。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"gtVhnvXO\"\u003e\u003cb\u003e新的稀疏性特性\u003c/b\u003e： 1. \u003cb\u003e灵活的稀疏模式\u003c/b\u003e：支持N:M稀疏性的多种变体 2. \u003cb\u003e动态稀疏性\u003c/b\u003e：运行时调整稀疏模式 3. \u003cb\u003e混合稀疏性\u003c/b\u003e：在同一模型中使用不同的稀疏策略 4. \u003cb\u003e硬件加速\u003c/b\u003e：专用硬件单元处理稀疏计算\u003c/p\u003e\u003ch3\u003e性能预测与分析\u003c/h3\u003e\u003cp data-pid=\"pTgQiE_g\"\u003e基于已公布的信息，Blackwell架构预计将在多个方面实现显著提升：\u003c/p\u003e\u003cp data-pid=\"meL9ywZJ\"\u003e\u003cb\u003e计算性能（预估）\u003c/b\u003e： - FP8性能：超过1500 TFLOPS - FP16性能：超过750 TFLOPS - INT8性能：超过3000 TOPS\u003c/p\u003e\u003cp data-pid=\"smbxdDE5\"\u003e\u003cb\u003e能效提升（相比Hopper）\u003c/b\u003e： - 训练能效：约1.8倍提升 - 推理能效：约2.2倍提升 - 整体能效：约2.0倍提升\u003c/p\u003e\u003cp data-pid=\"GQql1WNA\"\u003e\u003cb\u003e内存性能\u003c/b\u003e： - 内存带宽：约8TB/s - 内存容量：高达192GB HBM3e - 内存效率：约1.5倍提升\u003c/p\u003e\u003ch3\u003eTensor Core架构演进总结\u003c/h3\u003e\u003ch3\u003e技术发展轨迹\u003c/h3\u003e\u003cp data-pid=\"gJRFV9pP\"\u003e从Volta到Blackwell，NVIDIA Tensor Core的演进展现了清晰的技术发展轨迹：\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-df6dfb559469790d9270611eba015024_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1566\" data-rawheight=\"632\" data-original-token=\"v2-9b920bffa3ba492651e3cf388d0ff406\" class=\"origin_image zh-lightbox-thumb\" width=\"1566\" data-original=\"https://pic1.zhimg.com/v2-df6dfb559469790d9270611eba015024_r.jpg\"/\u003e\u003cfigcaption\u003eTensor Core架构演进图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"fT68B1ZG\"\u003e\u003ci\u003e图20：Tensor Core架构演进图。该图总结了从第一代到第五代Tensor Core的主要技术特性和性能提升，展示了技术演进的清晰轨迹。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"XkzzyrZB\"\u003e\u003cb\u003e第一代（Volta）\u003c/b\u003e：建立基础 - 引入混合精度概念 - 4×4×4矩阵操作 - FP16/FP32混合精度\u003c/p\u003e\u003cp data-pid=\"kcFXUfLA\"\u003e\u003cb\u003e第二代（Turing）\u003c/b\u003e：扩展应用 - 支持INT8/INT4推理 - 消费级GPU普及 - 推理优化重点\u003c/p\u003e\u003cp data-pid=\"Oh76zy6k\"\u003e\u003cb\u003e第三代（Ampere）\u003c/b\u003e：突破创新 - 2:4结构化稀疏性 - BF16数据类型 - 异步执行改进\u003c/p\u003e\u003cp data-pid=\"kb41KOcv\"\u003e\u003cb\u003e第四代（Hopper）\u003c/b\u003e：专业化发展 - Transformer Engine - FP8数据类型 - Thread Block Cluster\u003c/p\u003e\u003cp data-pid=\"CIjgLF83\"\u003e\u003cb\u003e第五代（Blackwell）\u003c/b\u003e：技术巅峰 - 第二代Transformer Engine - 增强的稀疏性支持 - 新的内存层次结构\u003c/p\u003e\u003ch3\u003e尺寸增长趋势\u003c/h3\u003e\u003cp data-pid=\"ojdzfOjY\"\u003eTensor Core的物理尺寸也在不断增长，以支持更大的矩阵操作和更高的性能。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-83b4ecfd46b5f6922b9f57055ad02d36_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"882\" data-rawheight=\"350\" data-original-token=\"v2-912d4f3371a23a301b106b0309b09de0\" class=\"origin_image zh-lightbox-thumb\" width=\"882\" data-original=\"https://pic1.zhimg.com/v2-83b4ecfd46b5f6922b9f57055ad02d36_r.jpg\"/\u003e\u003cfigcaption\u003eTensor Core尺寸增长图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"0yo0gj6c\"\u003e\u003ci\u003e图21：Tensor Core尺寸增长图。该图展示了各代Tensor Core支持的矩阵尺寸变化，反映了对更大规模计算的支持。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"c3Vjt9Xw\"\u003e\u003cb\u003e尺寸演进\u003c/b\u003e： - \u003cb\u003e第一代\u003c/b\u003e：4×4×4 - \u003cb\u003e第二代\u003c/b\u003e：8×8×4, 16×8×8 - \u003cb\u003e第三代\u003c/b\u003e：16×8×16, 16×16×16 - \u003cb\u003e第四代\u003c/b\u003e：16×16×16, 32×8×16 - \u003cb\u003e第五代\u003c/b\u003e：32×32×32, 64×8×16\u003c/p\u003e\u003cp data-pid=\"qdbLogLy\"\u003e更大的矩阵尺寸带来的优势： 1. \u003cb\u003e更高的计算效率\u003c/b\u003e：减少指令开销 2. \u003cb\u003e更好的数据重用\u003c/b\u003e：提高缓存命中率 3. \u003cb\u003e更大的并行度\u003c/b\u003e：支持更复杂的模型 4. \u003cb\u003e更低的功耗\u003c/b\u003e：提高能效比\u003c/p\u003e\u003ch3\u003e内存容量的增长\u003c/h3\u003e\u003cp data-pid=\"f9QnDEmM\"\u003e随着模型规模的不断增长，GPU内存容量也在快速提升。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-a6a8ba5bb321d9865e6673c5afac6652_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1464\" data-rawheight=\"432\" data-original-token=\"v2-bdc6fa4632f1170a8fb94f6acb509436\" class=\"origin_image zh-lightbox-thumb\" width=\"1464\" data-original=\"https://pica.zhimg.com/v2-a6a8ba5bb321d9865e6673c5afac6652_r.jpg\"/\u003e\u003cfigcaption\u003e内存容量增长图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"3fszteJN\"\u003e\u003ci\u003e图22：内存容量增长图。该图展示了NVIDIA数据中心GPU内存容量的增长趋势，反映了对大型模型支持能力的提升。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"ztdaCgNb\"\u003e\u003cb\u003e内存容量演进\u003c/b\u003e： - \u003cb\u003eV100\u003c/b\u003e：16GB/32GB HBM2 - \u003cb\u003eA100\u003c/b\u003e：40GB/80GB HBM2e - \u003cb\u003eH100\u003c/b\u003e：80GB HBM3 - \u003cb\u003eB100\u003c/b\u003e：预计192GB HBM3e\u003c/p\u003e\u003cp data-pid=\"jB_FJPWh\"\u003e内存容量增长的意义： 1. \u003cb\u003e支持更大模型\u003c/b\u003e：可以训练参数更多的模型 2. \u003cb\u003e提高批次大小\u003c/b\u003e：改善训练效率 3. \u003cb\u003e减少内存碎片\u003c/b\u003e：更好的内存利用率 4. \u003cb\u003e支持多任务\u003c/b\u003e：同时运行多个模型\u003c/p\u003e\u003ch3\u003e异步执行的演进\u003c/h3\u003e\u003cp data-pid=\"s-CFa0dI\"\u003e异步执行能力的改进是Tensor Core演进的重要方面。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-2c2ab1ee1d11d941a91a21f21f2d5f7e_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"882\" data-rawheight=\"270\" data-original-token=\"v2-7fa9bbaf6c0d56f7d4c050ce57a19948\" class=\"origin_image zh-lightbox-thumb\" width=\"882\" data-original=\"https://pic1.zhimg.com/v2-2c2ab1ee1d11d941a91a21f21f2d5f7e_r.jpg\"/\u003e\u003cfigcaption\u003e异步执行演进图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"xI82Gz4v\"\u003e\u003ci\u003e图23：异步执行演进图。该图展示了MMA指令异步执行能力的发展，包括延迟隐藏和并行度的改进。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"KidxlQrX\"\u003e\u003cb\u003e异步执行的发展\u003c/b\u003e： 1. \u003cb\u003e基础异步\u003c/b\u003e：简单的计算与内存重叠 2. \u003cb\u003e改进的流水线\u003c/b\u003e：更深的指令流水线 3. \u003cb\u003e多级异步\u003c/b\u003e：支持多层次的异步操作 4. \u003cb\u003e智能调度\u003c/b\u003e：硬件自动优化执行顺序\u003c/p\u003e\u003ch3\u003e数据类型精度的演进\u003c/h3\u003e\u003cp data-pid=\"e5FH6Bm5\"\u003e数据类型支持的扩展反映了对不同应用场景的适应。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-49e646dc0ba18562d3382ce5866b8c37_1440w.jpg\" data-size=\"normal\" data-rawwidth=\"1956\" data-rawheight=\"960\" data-original-token=\"v2-f78d797a839fdc2ff00359fcc83f18e8\" class=\"origin_image zh-lightbox-thumb\" width=\"1956\" data-original=\"https://picx.zhimg.com/v2-49e646dc0ba18562d3382ce5866b8c37_r.jpg\"/\u003e\u003cfigcaption\u003e数据类型精度演进图\u003c/figcaption\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"BujTf16H\"\u003e\u003ci\u003e图24：数据类型精度演进图。该图展示了Tensor Core支持的数据类型从FP32到FP8的演进过程，以及精度降低对性能提升的贡献。\u003c/i\u003e\u003c/p\u003e\u003cp data-pid=\"sSa8ksdY\"\u003e\u003cb\u003e精度演进的驱动力\u003c/b\u003e： 1. \u003cb\u003e性能需求\u003c/b\u003e：更低精度提供更高性能 2. \u003cb\u003e能效要求\u003c/b\u003e：降低功耗和散热需求 3. \u003cb\u003e模型特性\u003c/b\u003e：深度学习对精度的容忍性 4. \u003cb\u003e硬件限制\u003c/b\u003e：芯片面积和复杂度的平衡\u003c/p\u003e\u003ch3\u003e未来发展趋势与技术展望\u003c/h3\u003e\u003ch3\u003e下一代技术方向\u003c/h3\u003e\u003cp data-pid=\"gSTnAvN-\"\u003e基于当前的技术发展轨迹，我们可以预测Tensor Core未来的发展方向：\u003c/p\u003e\u003cp data-pid=\"023OYbtU\"\u003e\u003cb\u003e更低精度的探索\u003c/b\u003e： - FP4和INT4的广泛应用 - 动态精度调整技术 - 混合精度的进一步优化\u003c/p\u003e\u003cp data-pid=\"UdYvmYZ3\"\u003e\u003cb\u003e更大规模的并行\u003c/b\u003e： - 支持更大的矩阵尺寸 - 多GPU协作的硬件支持 - 分布式计算的原生支持\u003c/p\u003e\u003cp data-pid=\"MzMJEArn\"\u003e\u003cb\u003e专用化程度的提升\u003c/b\u003e： - 针对特定模型架构的优化 - 领域特定的加速器 - 可重配置的计算单元\u003c/p\u003e\u003ch3\u003e软件生态系统的发展\u003c/h3\u003e\u003cp data-pid=\"2JGeg_qk\"\u003e硬件的发展必须与软件生态系统的完善相配合：\u003c/p\u003e\u003cp data-pid=\"DVtmGcyY\"\u003e\u003cb\u003e编程模型的简化\u003c/b\u003e： - 更高级的抽象接口 - 自动化的性能优化 - 跨平台的兼容性\u003c/p\u003e\u003cp data-pid=\"zTOTIM_H\"\u003e\u003cb\u003e开发工具的完善\u003c/b\u003e： - 更强大的调试工具 - 性能分析和优化工具 - 可视化开发环境\u003c/p\u003e\u003cp data-pid=\"iEdaCgSs\"\u003e\u003cb\u003e标准化的推进\u003c/b\u003e： - 行业标准的建立 - 开源生态的发展 - 互操作性的提升\u003c/p\u003e\u003ch3\u003e应用领域的扩展\u003c/h3\u003e\u003cp data-pid=\"90HOalVI\"\u003eTensor Core技术将在更多领域发挥作用：\u003c/p\u003e\u003cp data-pid=\"qsQX0sB5\"\u003e\u003cb\u003e科学计算\u003c/b\u003e： - 气候模拟 - 药物发现 - 材料科学\u003c/p\u003e\u003cp data-pid=\"EpIkaoT5\"\u003e\u003cb\u003e边缘计算\u003c/b\u003e： - 移动设备AI - 物联网应用 - 实时处理\u003c/p\u003e\u003cp data-pid=\"aY1hsD3m\"\u003e\u003cb\u003e新兴应用\u003c/b\u003e： - 量子计算模拟 - 生物信息学 - 虚拟现实\u003c/p\u003e\u003ch3\u003e结论\u003c/h3\u003e\u003cp data-pid=\"lkc-p-A0\"\u003eNVIDIA Tensor Core从Volta到Blackwell的演进历程，展现了现代计算架构设计的精妙之处。通过专用化设计、混合精度计算、稀疏性支持和异步执行等创新技术，Tensor Core不仅推动了AI技术的快速发展，也为整个计算行业树立了新的标杆。\u003c/p\u003e\u003cp data-pid=\"ZdxqJOeI\"\u003e这一技术演进的成功，源于对应用需求的深刻理解、对硬件特性的充分利用，以及软硬件协同设计的理念。随着AI技术的不断发展和应用场景的不断扩展，我们有理由相信，Tensor Core技术将继续引领计算架构的创新，为人工智能的未来发展提供强有力的支撑。\u003c/p\u003e\u003cp data-pid=\"keaAX3CF\"\u003e从技术发展的角度来看，Tensor Core的演进体现了几个重要趋势：专用化程度的不断提升、精度与性能的平衡优化、以及硬件与软件的深度融合。这些趋势不仅适用于GPU计算，也为其他类型的专用计算架构提供了重要的参考和启示。\u003c/p\u003e\u003cp data-pid=\"Jj-4cp8Y\"\u003e展望未来，随着模型规模的进一步增长和应用需求的不断变化，Tensor Core技术必将继续演进，为我们带来更多的惊喜和突破。这不仅是技术进步的必然结果，也是人类对更强大计算能力永恒追求的体现。\u003c/p\u003e\u003chr/\u003e\u003cp data-pid=\"klylJgZb\"\u003e\u003cb\u003e参考文献\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"ffszcWNu\"\u003e[1] SemiAnalysis. \u0026#34;NVIDIA Tensor Core Evolution: From Volta To Blackwell.\u0026#34; \u003ca href=\"https://link.zhihu.com/?target=https%3A//semianalysis.com/2025/06/23/nvidia-tensor-core-evolution-from-volta-to-blackwell/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003esemianalysis.com/2025/0\u003c/span\u003e\u003cspan class=\"invisible\"\u003e6/23/nvidia-tensor-core-evolution-from-volta-to-blackwell/\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003cp data-pid=\"kbi-L2bt\"\u003e[2] NVIDIA Corporation. \u0026#34;NVIDIA Tesla V100 GPU Architecture.\u0026#34; NVIDIA Whitepaper, 2017.\u003c/p\u003e\u003cp data-pid=\"PCBmPfLp\"\u003e[3] NVIDIA Corporation. \u0026#34;NVIDIA Turing GPU Architecture.\u0026#34; NVIDIA Whitepaper, 2018.\u003c/p\u003e\u003cp data-pid=\"zNgH6Tt4\"\u003e[4] NVIDIA Corporation. \u0026#34;NVIDIA A100 Tensor Core GPU Architecture.\u0026#34; NVIDIA Whitepaper, 2020.\u003c/p\u003e\u003cp data-pid=\"-Efbjx1H\"\u003e[5] NVIDIA Corporation. \u0026#34;NVIDIA H100 Tensor Core GPU Architecture.\u0026#34; NVIDIA Whitepaper, 2022.\u003c/p\u003e\u003cp data-pid=\"WrTMCanE\"\u003e[6] Micikevicius, Paulius, et al. \u0026#34;Mixed precision training.\u0026#34; arXiv preprint arXiv:1710.03740 (2017).\u003c/p\u003e\u003cp data-pid=\"1QlP2biZ\"\u003e[7] NVIDIA Corporation. \u0026#34;CUTLASS: Fast Linear Algebra in CUDA C++.\u0026#34; \u003ca href=\"https://link.zhihu.com/?target=https%3A//github.com/NVIDIA/cutlass\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003egithub.com/NVIDIA/cutla\u003c/span\u003e\u003cspan class=\"invisible\"\u003ess\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003cp data-pid=\"qm1siFiC\"\u003e[8] NVIDIA Corporation. \u0026#34;Transformer Engine Documentation.\u0026#34; \u003ca href=\"https://link.zhihu.com/?target=https%3A//docs.nvidia.com/deeplearning/transformer-engine/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003edocs.nvidia.com/deeplea\u003c/span\u003e\u003cspan class=\"invisible\"\u003erning/transformer-engine/\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003cp data-pid=\"jMXWTMq7\"\u003e[9] Pool, Jeff, and Chong Yu. \u0026#34;Channel permutations for N: M sparsity.\u0026#34; Advances in Neural Information Processing Systems 34 (2021).\u003c/p\u003e\u003cp data-pid=\"zbYrQopt\"\u003e[10] NVIDIA Corporation. \u0026#34;NVIDIA Blackwell Platform Architecture Overview.\u0026#34; NVIDIA Technical Brief, 2024.\u003c/p\u003e","is_labeled":false,"visited_count":148,"thumbnails":["https://picx.zhimg.com/50/v2-ff79a2469ad9ba75ddaef3083c02ca92_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-17ec5928118552ec403b5301650623bb_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-9e3b70db7f2a8ce98351a47af72cb935_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-c69265f4ee0575081eec8f3049c5dc1d_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-b0b6b9e8f85c25c6d28a66ed1317bb1d_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-91dd177699397c1715d3dad582764f3d_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-8cd3f35b1bb2f03d9ec0a81338c0afb7_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-09f52474e41053786f4e9675ce419751_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-8eec96d78bbaa59337f97a4e47adb094_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-c3711072747968ae0c5295951ce6913d_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-4e3622b45b976081f0f0df04fc9a3df8_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-58e1919ddc80b38792e6d865fa1c3490_720w.jpg?source=b6762063"],"favorite_count":16,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1921166120641082542}","attached_info":"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","action_card":false},{"id":"38_1750899273.145","type":"feed","offset":38,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750899273,"updated_time":1750899273,"target":{"id":"1913961508800538083","type":"article","url":"https://api.zhihu.com/articles/1913961508800538083","author":{"id":"dbf6fa2cd16c6091a654dd29f6750998","url":"https://api.zhihu.com/people/dbf6fa2cd16c6091a654dd29f6750998","user_type":"people","url_token":"29-33-3-55-32","name":"沐沐妈","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-407b8c150fad538be1a1c3ad2af0fd8c_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":1063,"is_following":false,"is_followed":false},"title":"利润吓人的9个冷门创业","comment_permission":"all","created":1749340071,"updated":1749340071,"voteup_count":101,"voting":0,"comment_count":13,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"1、社区小厨房 在生活小区租用一个30平方米以上的门面房，月租金约2500元，购买灶具，炊具等物品需5000元左右，初期投入2万元左右即可开张。社区小厨房跟普通餐馆不一样，它主要针对某一社区的居民，提供一些菜品;另外，可由顾客提供原材料，小厨房帮着加工，加工费用按客人提供的材料多少计算最重要的是要保证服务质量。 2、风水堪舆 看风水行业绝对是一个暴利行业，现在请人看风水，一般的师傅都是好几百块钱起，如果是有名的…","excerpt_new":"1、社区小厨房 在生活小区租用一个30平方米以上的门面房，月租金约2500元，购买灶具，炊具等物品需5000元左右，初期投入2万元左右即可开张。社区小厨房跟普通餐馆不一样，它主要针对某一社区的居民，提供一些菜品;另外，可由顾客提供原材料，小厨房帮着加工，加工费用按客人提供的材料多少计算最重要的是要保证服务质量。 2、风水堪舆 看风水行业绝对是一个暴利行业，现在请人看风水，一般的师傅都是好几百块钱起，如果是有名的…","preview_type":"default","preview_text":"","content":"\u003cp data-pid=\"dFaH9QQE\"\u003e1、社区小厨房\u003c/p\u003e\u003cp data-pid=\"Fzi10L0l\"\u003e在生活小区租用一个30平方米以上的门面房，月租金约2500元，购买灶具，炊具等物品需5000元左右，初期投入2万元左右即可开张。社区小厨房跟普通餐馆不一样，它主要针对某一社区的居民，提供一些菜品;另外，可由顾客提供原材料，小厨房帮着加工，加工费用按客人提供的材料多少计算最重要的是要保证服务质量。\u003c/p\u003e\u003cp data-pid=\"w335C7bs\"\u003e2、风水堪舆\u003c/p\u003e\u003cp data-pid=\"IB458Zyx\"\u003e看风水行业绝对是一个暴利行业，现在请人看风水，一般的师傅都是好几百块钱起，如果是有名的风水师傅，他们的收费就更贵。\u003c/p\u003e\u003cp data-pid=\"nMoM8FXK\"\u003e3、卖虚拟资料\u003c/p\u003e\u003cp data-pid=\"5FsDi5wX\"\u003e卖虚拟资料，0成本，卖出去就是利润，而且，能长期做，很适合普通人做的一个项目如果不知道怎么卖虚拟资料的，可以去多关注些优秀的公众号，比如:“乐一笔记”，这上面有非常多的虚拟资料课程，够你学了，还有很多实用的项目经验和案例解析，博主每天都在更新。\u003c/p\u003e\u003cp data-pid=\"546QbPob\"\u003e4、男士美容\u003c/p\u003e\u003cp data-pid=\"VDoEKgnm\"\u003e主要针对的是30-45岁的高端商务人士，他们大多身居要职，收入不菲，是消费市场的主力军\u003c/p\u003e\u003cp data-pid=\"oZW8IRIi\"\u003e5、狗粮试吃员\u003c/p\u003e\u003cp data-pid=\"tK5nPxK_\"\u003e“狗粮试吃员”这一职业最早源于国外，他们的职责就是品尝各种狗粮，包括磨牙棒、零食罐头、饼干等，并从味道、肉质、香味、口感等40多个方面一一记录，在统一严格的标准下打分，提出改良的意见。这就要求从业者具有相当敏锐的味觉和嗅觉。\u003c/p\u003e\u003cp data-pid=\"TCaeyPUp\"\u003e6、网上农业经纪人\u003c/p\u003e\u003cp data-pid=\"3qeYBWJv\"\u003e改变传统的农产品经营方式，依托当地特色农产品，在网上开办农业经纪人之家栏目向外界介绍和推广。此项目初期投资不高仅需一台电脑，一台扫描仪即可，但对网络技术的要求比较高，是一个很有发展前景的绿色。\u003c/p\u003e\u003cp data-pid=\"rxkIVuOO\"\u003e7、亲情出租店\u003c/p\u003e\u003cp data-pid=\"A5hiqEZO\"\u003e针对目前社会老龄化的趋势，开家亲情出租店，专门为老年人服务，前景很可观。该项目的主要服务内容一般包括两个方面，一是出租临时家庭成员，陪老年人聊天，进餐，消磨时光，解除他们的孤独和寂寞;二是提供临时服务，如买菜，做饭，购物，陪同看病，陪护等。租一间固定的门面房，备一部电话和其他必需办公用品，再雇一些层次不同的人员即可开张营业。所雇人员平时可以不在店里上班，但需要时应随叫随到。也可先培训几名固定服务人员，处理店里的日常事务。\u003c/p\u003e\u003cp data-pid=\"5wbrXtsl\"\u003e8、病人饮食服务公司\u003c/p\u003e\u003cp data-pid=\"AGIDvNTg\"\u003e地址适宜选择在大中型医院附近，针对各种病人群体的不同状况，分别开列菜单。经营上应格外重视灶间卫生，不能像一般餐厅和送餐公司那么简单。前期应针对病人不同的病症制定出合理的食谱，顾客上门时要问清病人的症状身体条件，心理状态，便于更好地服务;病人的订餐档案应妥善保管，不可出现任何差错。初期投入主要是房租，购买灶具等费用，约2万元左右。\u003c/p\u003e\u003cp data-pid=\"-wIsqqWY\"\u003e9、出租休闲菜园\u003c/p\u003e\u003cp data-pid=\"sCB1ZfuV\"\u003e到城郊租赁一块交通便利，排灌设施齐全的农田，雇佣民工将其分割成100平方左右的若于个小田块，向城区居民招租，作为他们种植瓜果，花卉的休闲场所。经营者可按田块每年每亩收取3000元左右租金租用农民土地每亩租金不超过1000元。首期投入5万元左右。\u003c/p\u003e","is_labeled":false,"visited_count":12835,"favorite_count":236,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1913961508800538083}","attached_info":"CtQFCNvCqJK0sIiAiAEQBxoJMjU4NjE1MjU5IKefk8IGKGUwDUAmSjAKBkl0ZW1DRhIgZG9jX3R5cGU6IEFydGljbGUKaWQ6IDI1NzkxNDc4NQoYACAAOgBiIGYzZjJkZjQ2ZDNjNzZhMzMzMmU1Nzk2ZDE5MTlhMTUwchMxOTEzOTYxNTA4ODAwNTM4MDgzqgEJcmVjb21tZW5kwgEgZGJmNmZhMmNkMTZjNjA5MWE2NTRkZDI5ZjY3NTA5OTjyAQoIDBIGTm9ybWFs8gEoCAoSJDNmNDExOTBiLWQ0MzctNDBmNS1hYTZhLTRjMTBiZjI3YjU2OPIBBQgLEgE3ggIAiAKL4erN+jKSAiBkYmY2ZmEyY2QxNmM2MDkxYTY1NGRkMjlmNjc1MDk5OJoCAMoCFlNob3JJbnRlcmVzdFdlaWdodFJ1bGXKAhZBY3Rpb25TaG9ySW50ZXJlc3RSdWxlygIbSW50ZXJhY3Rpb25TaG9ySW50ZXJlc3RSdWxlygIYUGVyaW9kSW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxl2gIGSXRlbUNG6AIC+gILTk9STUFMX0ZMT1eKAyA1YWNiZjg1NjI1M2E0NWY1YTI3ZGY2NjU4OTE4YmJhZJoDDQoCdjIQABoFb3RoZXKoA6Nk2AMA6gMVdGV4dEFsbFNpdGVNdkl0ZW1DRlYy+gMfEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERYAEAIgEAJIEBk5vcm1hbJoEATKgBACoBACwBAC6BAZtYW51YWzCBAMxNzDIBADSBA/mjqjojZDlt7Lmm7TmlrDYBADwBAD5BAAAAKAJF8g/gQUAAAAAAAAAAIkFeWIFd7cS0j+SBQCaBQNkZnSiBQNkZnSyBQExuQUAAAAAAAAAANAFAOAFAOgFAPAFB5AGAKAGJqgGAJICLgoJMjU4NjE1MjU5EhMxOTEzOTYxNTA4ODAwNTM4MDgzGAciCklNQUdFX1RFWFQ=","action_card":false},{"id":"39_1750899273.310","type":"feed","offset":39,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750899273,"updated_time":1750899273,"target":{"id":"1921171031059572314","type":"article","url":"https://api.zhihu.com/articles/1921171031059572314","author":{"id":"4fb720b13e01af09302e757fe72bcb79","url":"https://api.zhihu.com/people/4fb720b13e01af09302e757fe72bcb79","user_type":"people","url_token":"zhi-neng-liang-hua-jiao-yi","name":"博森科技-泰隆","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-ccfd51491ef614fcef0f7ce283c77101_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":222,"is_following":false,"is_followed":false},"title":"国企副厂长炒币负债300万，妻离子散后开网约车还债","comment_permission":"all","created":1750822927,"updated":1750822927,"voteup_count":30,"voting":0,"comment_count":9,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"打开加密推特，你总能看到那些炫耀自己资产超过 8 位数，合约一单赚到饱的币圈大神。 滤镜也好，实力也罢，在币圈能拿到大结果，这份幸运其实并不属于每一个普通人。 最近，B 站知名 up 主\u0026#34;峰哥亡命天涯\u0026#34;（峰哥），用镜头记录了一位曾经是河北邯郸某国企副厂长的男人，因炒币亏损负债 300 万，人生就此跌落的故事。 截止发稿时该视频已经有 75 万播放，社媒上关于该故事的讨论也不绝于耳。   撕开光鲜的暴富幻象，这是一个普通炒币…","excerpt_new":"打开加密推特，你总能看到那些炫耀自己资产超过 8 位数，合约一单赚到饱的币圈大神。 滤镜也好，实力也罢，在币圈能拿到大结果，这份幸运其实并不属于每一个普通人。 最近，B 站知名 up 主\u0026#34;峰哥亡命天涯\u0026#34;（峰哥），用镜头记录了一位曾经是河北邯郸某国企副厂长的男人，因炒币亏损负债 300 万，人生就此跌落的故事。 截止发稿时该视频已经有 75 万播放，社媒上关于该故事的讨论也不绝于耳。   撕开光鲜的暴富幻象，这是一个普通炒币…","preview_type":"default","preview_text":"","content":"\u003cp data-pid=\"L8j4Hm1s\"\u003e打开加密推特，你总能看到那些炫耀自己资产超过 8 位数，合约一单赚到饱的币圈大神。\u003c/p\u003e\u003cp data-pid=\"RLMv5-A6\"\u003e滤镜也好，实力也罢，在币圈能拿到大结果，这份幸运其实并不属于每一个普通人。\u003c/p\u003e\u003cp data-pid=\"p1WKVw0y\"\u003e最近，B 站知名 up 主\u0026#34;峰哥亡命天涯\u0026#34;（峰哥），用镜头记录了一位曾经是河北邯郸某国企副厂长的男人，因炒币亏损负债 300 万，人生就此跌落的故事。\u003c/p\u003e\u003cp data-pid=\"iCAwnsO7\"\u003e截止发稿时该视频已经有 75 万播放，社媒上关于该故事的讨论也不绝于耳。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-726bb7bcc80a7acfc600dedcd599128a_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"799\" data-original-token=\"v2-af81b2695c4c4e25f0f8cf2c506362ce\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-726bb7bcc80a7acfc600dedcd599128a_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"LU494JWA\"\u003e撕开光鲜的暴富幻象，这是一个普通炒币者受制于信息差、受困于贪欲的真实故事。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003e\u003cb\u003e从厂长到负债开网约车\u003c/b\u003e\u003c/h3\u003e\u003cp data-pid=\"xph58G2s\"\u003e由于原采访中并没有提到故事主角的具体名字，但受访者 B 站 ID 为“浙里重生”，下文将用重生哥这一称呼来指代他。\u003c/p\u003e\u003cp data-pid=\"C-w2_xR4\"\u003e曾经，重生哥的生活令人艳羡。\u003c/p\u003e\u003cp data-pid=\"a4aT2SrC\"\u003e据他自己在镜头前透露，他曾是河北邯郸某国企洗煤厂副厂长，税后月薪 9000 元，住无贷款的房子，开奥迪车，管理 20-30 人，副科级干部的身份也带来了旁人的尊重。\u003c/p\u003e\u003cp data-pid=\"hTvNTaoH\"\u003e2018 年，重生哥与妻子结婚，育有一个五岁女儿，家庭幸福美满。\u003c/p\u003e\u003cp data-pid=\"oyA47U_y\"\u003e“我们也算是小康家庭…比上不足比下有余。”他回忆时，语气带着一种遥远的温暖感。\u003c/p\u003e\u003cp data-pid=\"1o7NuenH\"\u003e那时的他，带女儿游玩山东、郑州，践行“富养女”的理念，父母的退休金让家庭毫无经济压力。这样的日子稳固如磐石，你也很难找到崩塌的痕迹。\u003c/p\u003e\u003cp data-pid=\"88BHrQr0\"\u003e如今，一切灰飞烟灭。\u003c/p\u003e\u003cp data-pid=\"Psu2grUp\"\u003e视频的开头，重生哥展示了自己手机上各种贷款 APP 的界面和负债情况，其中一个 APP 上就欠下了 10 多万的贷款，而炒币也让他总计亏损了 300 万，每天都在为还清高额贷款而努力。\u003c/p\u003e\u003cp data-pid=\"3EROPhgW\"\u003e现在他每天开网约车 13-14 小时，流水 300 元，扣除车租和生活费，仅剩 100 元。租住 600 元/月的单间，独立卫浴是他最后的体面。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-94fb98f41eee30f1f779050e6e4d811e_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1069\" data-rawheight=\"599\" data-qrcode-action=\"none\" data-original-token=\"v2-42088f3dcb44ac285a5661c00dfff36d\" class=\"origin_image zh-lightbox-thumb\" width=\"1069\" data-original=\"https://pica.zhimg.com/v2-94fb98f41eee30f1f779050e6e4d811e_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"v-7zMyVo\"\u003e百万债务如影随形，年利息 20-30 万，大部分借款早已全面逾期，催债电话也不绝于耳。\u003c/p\u003e\u003cp data-pid=\"-lT_VLvO\"\u003e而面对为什么要接受峰哥采访并可能会被公之于众时，重生哥是这么说的：\u003c/p\u003e\u003cp data-pid=\"0Iji5iIj\"\u003e\u0026#34;我当初拒绝您采访的原因，最主要就是因为怕影响工作。现在因为已经不打算回去再干了，回不去了啊，索性就什么顾虑也没有，踏踏实实地在外面自己闯，自己挣钱还债。\u0026#34;\u003c/p\u003e\u003cp data-pid=\"9_dn568A\"\u003e和敢于面对镜头和生活的勇气形成对比的，是家庭的崩塌：\u003c/p\u003e\u003cp data-pid=\"OgF5j8iv\"\u003e两个月前，妻子因债务危机离婚，带走女儿；父母也彻底绝望，父亲的短信留言更加刺心：“这个家已经没有你了，你的一切事情已经完了”。\u003c/p\u003e\u003cp data-pid=\"iZAHRyuV\"\u003e五岁女儿因为年纪小尚不知真相，只知“爸爸出去工作了”。\u003c/p\u003e\u003cp data-pid=\"6RoDS51y\"\u003e从国企高管到负债司机，受访者的坠落确实令人唏嘘。而急速坠落的原因，则来自于币圈高杠杆的疯狂，与借债翻身的执念。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003e\u003cb\u003e山寨币，高杠杆，不止损\u003c/b\u003e\u003c/h3\u003e\u003cp data-pid=\"nGCQN6QK\"\u003e他的故事，或许也是无数普通炒币者的缩影——被贪婪与幻梦吞噬，往往不是一把梭哈，而是一个过程。\u003c/p\u003e\u003cp data-pid=\"OkwRqga7\"\u003e镜头下，重生哥也坦白了自己的币圈之路：从初尝甜头到高杠杆，300 万的亏损不是一夜崩盘，是无数次上头行为的累积。\u003c/p\u003e\u003cp data-pid=\"beqxzRKY\"\u003e重生哥的币圈启蒙，始于更早的邮币卡交易。2010 年代，邮币卡作为一种线上金融产品，号称以邮票为支撑，吸引了无数散户入场。重生哥试水后小赚一两万，侥幸逃出崩盘，积累了“低买高卖”的信心。\u003c/p\u003e\u003cp data-pid=\"xvQxFvqu\"\u003e他坦言，彼时尚存谨慎，但这种甜头却已埋下投机的种子。\u003c/p\u003e\u003cp data-pid=\"qzTJ-gsW\"\u003e2020 年他进入币圈，开始尝试现货交易，起初小心翼翼，但贪欲很快就被放大。\u003c/p\u003e\u003cp data-pid=\"MXfnp0bQ\"\u003e为了获得更多利润，他开始追逐山寨币并开了合约。合约交易允许借贷放大本金，10 倍、50 倍甚至 100 倍杠杆让利润与风险成倍放大。\u003c/p\u003e\u003cp data-pid=\"GDhEuH3h\"\u003e据他自己描述，几百块的本金一开始能干到 40-50%的利润，于是开始逐渐加码，在投入本金和杠杆倍数上都开始加的更多。\u003c/p\u003e\u003cp data-pid=\"NIIvGBuV\"\u003e重生哥自己形容这叫“钝刀子割肉”，从来没有一次把钱就借出来全部投进去梭哈，更像温水煮青蛙，今天充 2 万块钱亏掉，明天再去借 2 万块钱过来再充进去搏。\u003c/p\u003e\u003cp data-pid=\"Bzi5e5AO\"\u003e原视频采访中一个让人啼笑皆非的细节在于，up 主峰哥认为他的这种分批进场的行为还算稳扎稳打，而重生哥则立马否定了自己：\u003c/p\u003e\u003cp data-pid=\"Y_7uwotH\"\u003e\u003cb\u003e“也不是稳扎稳打，假如我今天有 2 万块钱开合约话，我就会开的杠杆特别低，不会开那么高的杠杆，低杠杆山寨币合约基本不会有问题...因为那时候心里已经扭曲变态了，太想把钱给赚回来，就会在自己认为一个合适的点，开始高杠杆，10 倍、50 倍、100 倍也开过。”\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-3aaa9b90e0add839356d7c0c005cd6c3_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"488\" data-rawheight=\"693\" data-original-token=\"v2-40d04e8a3cd1c9a10f2d4d606775eca0\" class=\"origin_image zh-lightbox-thumb\" width=\"488\" data-original=\"https://pic2.zhimg.com/v2-3aaa9b90e0add839356d7c0c005cd6c3_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"aiiSZn58\"\u003e显然重生哥低估了币圈山寨币的波动性，爆仓也在情理之中。而另一个让他不断借钱填窟窿的地方在于，交易没有纪律性。\u003c/p\u003e\u003cp data-pid=\"H8_98peH\"\u003e重生哥说自己最大的一个毛病是不设止损，到设了止损位以后，自己也会再把那个止损给取消掉，心中幻想着还能反弹。\u003c/p\u003e\u003cp data-pid=\"y-65h-ez\"\u003e这种非理性博弈，也让他一次次爆仓，一次次借钱继续，但最终的结果大家也知道了。\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003e\u003cb\u003e四次借钱，无一翻身\u003c/b\u003e\u003c/h3\u003e\u003cp data-pid=\"WdYNZTi3\"\u003e2020 年，他耗尽 1 万元积蓄，初次尝到爆仓的苦果。\u003c/p\u003e\u003cp data-pid=\"3-hVxoqd\"\u003e他通过支付宝借呗、安逸花等网贷借 10 万，亲友凑 12 万，填补 22 万窟窿，父母掏空积蓄还清。这之后他承诺不玩了，却在不到半年后又点燃了想法，“刷到比特币暴涨的新闻…让自己误认为有机会了”。\u003c/p\u003e\u003cp data-pid=\"RphsvUzq\"\u003e第二次，他借网贷 15 万、亲友 15 万，共 30 万，继续高杠杆炒币。爆仓后，他自欺“几万块钱自己可以慢慢解决”，却埋下更大隐患。\u003c/p\u003e\u003cp data-pid=\"NQk6WDXz\"\u003e2023 年，债务飙至 60 多万，网贷和亲友借款已难凑齐还钱。他卖掉妹妹不到 70 平的房子换了 50 万，亲戚再补了 10 万，又一次彻底还清了债务。\u003c/p\u003e\u003cp data-pid=\"SoiycStB\"\u003e不过这份短暂的“上岸”，并未给他带来解脱，反而更加加深了那种失意需要赚回来的扭曲心理 --- 卖房让妹妹失去嫁妆，父母震惊情绪崩溃，他显然有自责，并直言\u0026#34;活得特别压抑\u0026#34;。\u003c/p\u003e\u003cp data-pid=\"-1GsD2Ds\"\u003e币圈有周期，低谷逐渐暴富的故事也左右着失意者的入场选择，更成为了再一次入场赢回来的动机。\u003c/p\u003e\u003cp data-pid=\"4Y9pkIul\"\u003e2024-2025 年，他抵押了自家房子，借高利贷 (20-30%利息）70 万、网贷 30 万继续炒币，也让自己的债务总额突破百万。\u003c/p\u003e\u003cp data-pid=\"Dgq382kQ\"\u003e当然，每一次借钱开合约，都没有让自己翻身。\u003c/p\u003e\u003cp data-pid=\"M5bA6BX7\"\u003e借债的代价不仅是金钱，更是信任的崩塌。为了筹钱，他编造谎言，骗取亲友信任；经常骗人的朋友也知道，当你为了圆一个谎时，往往需要用更大的谎言覆盖，透支更多的人脉和信用。\u003c/p\u003e\u003cp data-pid=\"K3bbiUSY\"\u003e\u0026#34;人前装人背后装鬼，连做人的底线都没有...\u0026#34;重生哥在煎熬中也迎来了东窗事发。\u003c/p\u003e\u003cp data-pid=\"SH4H09aO\"\u003e一位朋友向他的妻子告密，使得自己的债务总量暴露，妻子崩溃提出离婚；父母得知他抵押房子，也彻底绝望，并留下了这样的短信：\u003c/p\u003e\u003cp data-pid=\"ESXAkXKu\"\u003e“你已经入魔了，你把房子都给压了…这个家已经没有你了”。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-c3e2f849a98fc0a5ee2fa45b7eff3a33_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"704\" data-original-token=\"v2-56c1a560c93e817891dc955a9057aeeb\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-c3e2f849a98fc0a5ee2fa45b7eff3a33_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"IfJlVFMj\"\u003e重生哥在接受峰哥采访后，自己也开了账号，并且告诫大家不要借钱再碰类似的产品，“我把特别美好的生活一手自己亲手给毁掉了”。\u003c/p\u003e\u003cp data-pid=\"pWaB4vEr\"\u003e翻身这两个字，可以是深圳的某个地铁站名，是输太多时的不甘幻想，但更可能是滚雪球式的贪欲深渊。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003e\u003cb\u003e凉兮助阵，前路漫漫\u003c/b\u003e\u003c/h3\u003e\u003cp data-pid=\"0b1eAo9V\"\u003e在峰哥的视频被传播后，华语币圈里最爱开合约的 KOL 凉兮发帖，宣布要资助重生哥 50,000 人民币，并额外提供 60,000 元作为一年内的月生活费（每月 5,000 元），以防止他继续炒币。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-446448375949aab778a816e73bfa3ca2_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"658\" data-rawheight=\"748\" data-original-token=\"v2-cbdc8d154d43239f80581e1667a4a481\" class=\"origin_image zh-lightbox-thumb\" width=\"658\" data-original=\"https://pica.zhimg.com/v2-446448375949aab778a816e73bfa3ca2_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"xkpbMBz2\"\u003e凉兮自然能理解重生哥，都是合约刀尖上跳舞，也都曾体验过爆仓的滋味。这波相助，从动机上来看更像是救济了曾经的自己。\u003c/p\u003e\u003cp data-pid=\"JNSf4Ej7\"\u003e不过任何善举，在实施过程中或许也应该有边界。\u003c/p\u003e\u003cp data-pid=\"WFN07Lfo\"\u003e重生哥的炒币成瘾心理不容忽视。“翻身”执念和沉没成本加持，他仍可能继续走上不归路，尤其在币圈文化中，“借钱翻身”的叙事比比皆是，更何况借他钱的这个人，本身就是合约戏剧效应拉满的凉兮本人。\u003c/p\u003e\u003cp data-pid=\"Xv8AP0Ae\"\u003e一个合约大师借钱救济你，让你不要再玩合约，你会就此收手么？\u003c/p\u003e\u003cp data-pid=\"8Ze2i-NS\"\u003e不要忘记，现实里重生哥目前仍在靠着做网约车司机维持开支，这份体力透支攒下的辛苦钱，和合约短时间带来的快感比，还是太慢了。\u003c/p\u003e\u003cp data-pid=\"X9p34IM4\"\u003e百万债务如影随形，我们仍不知道他会选择哪条路，也不知道是为了另一次翻身暴富，还是为了赎回那份失去的尊严。\u003c/p\u003e","is_labeled":true,"visited_count":3199,"thumbnails":["https://pica.zhimg.com/50/v2-233e82ebd541f58304ce94732a9e70e1_720w.jpg?source=b6762063","https://pica.zhimg.com/50/v2-c2c096b6c5691fa7ad4076c7a18e25e8_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-76e92c5f0854cdb36cf449ba4305566c_720w.jpg?source=b6762063"],"favorite_count":25,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1921171031059572314}","attached_info":"Ct4GCNvCqJK0sIiAiAEQBxoJMjU5NTI5OTQ0II/g7cIGKB4wCUAnSigKE1RTX1NPVVJDRV9GRUVEUkVfVjkSATAYACAAOgp7InJhdyI6IiJ9SigKHVRTX1NPVVJDRV9ORUFSTElORV9DT05URU5UX1YyEgEwGAAgADoAYiBmM2YyZGY0NmQzYzc2YTMzMzJlNTc5NmQxOTE5YTE1MHITMTkyMTE3MTAzMTA1OTU3MjMxNKoBCXJlY29tbWVuZMIBIDRmYjcyMGIxM2UwMWFmMDkzMDJlNzU3ZmU3MmJjYjc58gEKCAwSBk5vcm1hbPIBKAgKEiQ3N2Q1N2NiYi0wZjliLTQ1YzgtODFkMC04YjhiYjVhYTcxNjbyAQUICxIBN4ICAIgCi+HqzfoykgIgNGZiNzIwYjEzZTAxYWYwOTMwMmU3NTdmZTcyYmNiNzmaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxl2gITVFNfU09VUkNFX0ZFRURSRV9WOegCA/oCC05PUk1BTF9GTE9XigMgNWFjYmY4NTYyNTNhNDVmNWEyN2RmNjY1ODkxOGJiYWSaAw0KAnYyEAAaBW90aGVyqAP/GNgDAOoDCWZlZWRyZV92OfoD2wESDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFOi0IARC4CBifBiIjdjItYWY4MWIyNjk1YzRjNGUyNWYwZjhjZjJjNTA2MzYyY2U6LQgCEOgDGLUFIiN2Mi00MGQwNGU4YTNjZDFjOWExMGYyZDRkNjA2Nzc1ZWNhMDotCAIQuAgYwAUiI3YyLTU2YzFhNTYwYzkzZTgxNzg5MWRjOTU1YTkwNTdhZWViOi0IAhCSBRjsBSIjdjItY2JkYzhkMTU0ZDQzMjM5ZjgwNTgxZTE2NjdhNGE0ODGABACIBACSBAZOb3JtYWyaBAEzoAQAqAQAsAQAugQCYWnCBAM0MDDIBADSBA/mjqjojZDlt7Lmm7TmlrDYBADwBAD5BAAAAKDwPrA/gQUAAAAAAAAAAIkFeWIFd7cS0j+SBQCaBQNkZnSiBQNkZnSyBQExuQUAAAAAAAAAANAFAOAFAOgFAPAFB5AGAKAGJ6gGAJICLgoJMjU5NTI5OTQ0EhMxOTIxMTcxMDMxMDU5NTcyMzE0GAciCklNQUdFX1RFWFQ=","action_card":false},{"id":"40_1750899273.332","type":"feed","offset":40,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750899273,"updated_time":1750899273,"target":{"id":"1921194537423963315","type":"article","url":"https://api.zhihu.com/articles/1921194537423963315","author":{"id":"9aadfa0b2958a09b7a5668013bfef4ea","url":"https://api.zhihu.com/people/9aadfa0b2958a09b7a5668013bfef4ea","user_type":"people","url_token":"zhi-liao-96-19","name":"王十二","headline":"开始认真读书吧","avatar_url":"https://pic1.zhimg.com/50/63b9742923e92f773bdf87ff1e931d63_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":2,"is_following":false,"is_followed":false},"title":"[教程]用hugo搭建博客站","comment_permission":"all","created":1750828602,"updated":1750828602,"voteup_count":1,"voting":0,"comment_count":0,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"环境准备：wsl 中安装好了 go, hugo, npm, node 初始化hugo site hugo new site MyFreshWebsite --format yaml 2. 下载主题 https://github.com/adityatelange/hugo-PaperMod/archive/v7.0.zip 将这个主题下载解压缩到MyFreshWebsite/themes/PaperMod文件夹3. 配置主题 echo \u0026#34;theme: [\u0026#34;PaperMod\u0026#34;]\u0026#34; \u0026gt;\u0026gt; hugo.yaml接下来，就可以通过 hugo server 命令运行项目了。对于一个新网站，还没有任何内容。可以参考 https://github.com/adityatelange/hugo-PaperMod/tree/exampleSite 往content中添加文件。 hugo new content cont…","excerpt_new":"环境准备：wsl 中安装好了 go, hugo, npm, node 初始化hugo site hugo new site MyFreshWebsite --format yaml 2. 下载主题 https://github.com/adityatelange/hugo-PaperMod/archive/v7.0.zip 将这个主题下载解压缩到MyFreshWebsite/themes/PaperMod文件夹3. 配置主题 echo \u0026#34;theme: [\u0026#34;PaperMod\u0026#34;]\u0026#34; \u0026gt;\u0026gt; hugo.yaml接下来，就可以通过 hugo server 命令运行项目了。对于一个新网站，还没有任何内容。可以参考 https://github.com/adityatelange/hugo-PaperMod/tree/exampleSite 往content中添加文件。 hugo new content cont…","preview_type":"default","preview_text":"","content":"\u003cp data-pid=\"xjaPz3ku\"\u003e环境准备：wsl 中安装好了 go, hugo, npm, node\u003c/p\u003e\u003col\u003e\u003cli data-pid=\"m39Cz3Wv\"\u003e初始化hugo site\u003c/li\u003e\u003c/ol\u003e\u003cp data-pid=\"if540Xjt\"\u003e\u003ccode\u003ehugo new site MyFreshWebsite --format yaml\u003c/code\u003e \u003c/p\u003e\u003cp data-pid=\"TuTtAluW\"\u003e2. 下载主题\u003c/p\u003e\u003cp data-pid=\"eQG2YqQv\"\u003e\u003ca href=\"https://link.zhihu.com/?target=https%3A//github.com/adityatelange/hugo-PaperMod/archive/v7.0.zip\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003egithub.com/adityatelang\u003c/span\u003e\u003cspan class=\"invisible\"\u003ee/hugo-PaperMod/archive/v7.0.zip\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e 将这个主题下载解压缩到\u003ccode\u003eMyFreshWebsite/themes/PaperMod\u003c/code\u003e文件夹\u003c/p\u003e\u003cp data-pid=\"u9mPNvMm\"\u003e3. 配置主题\u003c/p\u003e\u003cp data-pid=\"vB1AMfcZ\"\u003e\u003ccode\u003eecho \u0026#34;theme: [\u0026#34;PaperMod\u0026#34;]\u0026#34; \u0026gt;\u0026gt; hugo.yaml\u003c/code\u003e\u003c/p\u003e\u003cp data-pid=\"M4DCkBV2\"\u003e接下来，就可以通过\u003ccode\u003ehugo server\u003c/code\u003e 命令运行项目了。\u003c/p\u003e\u003cp data-pid=\"EYS_HOkK\"\u003e对于一个新网站，还没有任何内容。可以参考 \u003ca href=\"https://link.zhihu.com/?target=https%3A//github.com/adityatelange/hugo-PaperMod/tree/exampleSite\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003egithub.com/adityatelang\u003c/span\u003e\u003cspan class=\"invisible\"\u003ee/hugo-PaperMod/tree/exampleSite\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e 往content中添加文件。\u003c/p\u003e\u003cp data-pid=\"6mDVroT3\"\u003e\u003ccode\u003ehugo new content content/posts/hugo-tutorial.md\u003c/code\u003e\u003c/p\u003e\u003cp data-pid=\"V7qpa4-7\"\u003e添加上文章内容后，运行 \u003ccode\u003ehugo server -D\u003c/code\u003e 看测试效果。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-fb95b7a1cdd369d3048b32d290b25d54_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1075\" data-rawheight=\"474\" data-original-token=\"v2-fb95b7a1cdd369d3048b32d290b25d54\" class=\"origin_image zh-lightbox-thumb\" width=\"1075\" data-original=\"https://pic3.zhimg.com/v2-fb95b7a1cdd369d3048b32d290b25d54_r.jpg\"/\u003e\u003c/figure\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-ecbd2f725152eb08b926b4dfd70c463d_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1022\" data-rawheight=\"886\" data-original-token=\"v2-ecbd2f725152eb08b926b4dfd70c463d\" class=\"origin_image zh-lightbox-thumb\" width=\"1022\" data-original=\"https://picx.zhimg.com/v2-ecbd2f725152eb08b926b4dfd70c463d_r.jpg\"/\u003e\u003c/figure\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"rkO3QCZE\"\u003e如果需要发布网站，运行 \u003ccode\u003ehugo\u003c/code\u003e, 网站就打包到 public 文件夹中了。\u003c/p\u003e\u003cp data-pid=\"ghXUzVNu\"\u003e当然，别忘了设置 hugo.yaml 中的 baseURL 和 title, 改成你自己的域名名称。\u003c/p\u003e\u003cp data-pid=\"GUEJh6_B\"\u003e看看效果吧 \u003ca href=\"https://link.zhihu.com/?target=https%3A//brainbuild.netlify.app/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003ebrainbuild.netlify.app/\u003c/span\u003e\u003cspan class=\"invisible\"\u003e\u003c/span\u003e\u003c/a\u003e \u003c/p\u003e\u003cp data-pid=\"zMXTppg8\"\u003e还有很多细节要修改，但目前就先上第一版。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"fIso1h9T\"\u003e参考资料：\u003c/p\u003e\u003cp data-pid=\"wI_dT5WY\"\u003e\u003ca href=\"https://link.zhihu.com/?target=https%3A//github.com/adityatelange/hugo-PaperMod/wiki/Installation\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003egithub.com/adityatelang\u003c/span\u003e\u003cspan class=\"invisible\"\u003ee/hugo-PaperMod/wiki/Installation\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003cp data-pid=\"zzN1CvON\"\u003e\u003ca href=\"https://link.zhihu.com/?target=https%3A//gohugo.io/getting-started/quick-start/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttps://\u003c/span\u003e\u003cspan class=\"visible\"\u003egohugo.io/getting-start\u003c/span\u003e\u003cspan class=\"invisible\"\u003eed/quick-start/\u003c/span\u003e\u003cspan class=\"ellipsis\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e","is_labeled":false,"visited_count":18,"thumbnails":["https://picx.zhimg.com/50/v2-63e53896c7e51ef8a7575f25ea66760d_720w.jpg?source=b6762063"],"favorite_count":1,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1921194537423963315}","attached_info":"CuMGCNvCqJK0sIiAiAEQBxoJMjU5NTMzMjM3ILqM7sIGKAEwAEAoSiQKGVRTX1NPVVJDRV9XQVJNX1VQX05PUk1BTDISATAYACAAOgBKLwokVFNfU09VUkNFX1dBUk1VUF9UV09UT1dFUl9FWFBWMl9URVhUEgEwGAAgADoAYiBmM2YyZGY0NmQzYzc2YTMzMzJlNTc5NmQxOTE5YTE1MHITMTkyMTE5NDUzNzQyMzk2MzMxNaoBCXJlY29tbWVuZMIBIDlhYWRmYTBiMjk1OGEwOWI3YTU2NjgwMTNiZmVmNGVh8gEKCAwSBk5vcm1hbPIBKAgKEiRhMjk0ZTM5Ni1hMjY1LTRhYjgtOTc4NS0zZWM0MmUyMmUxZmPyAQUICxIBN4ICAIgCi+HqzfoykgIgOWFhZGZhMGIyOTU4YTA5YjdhNTY2ODAxM2JmZWY0ZWGaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIYUGVyaW9kSW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygIYQ29udGVudFdhcm1VcEJyZWFrSW5SdWxl2gIZVFNfU09VUkNFX1dBUk1fVVBfTk9STUFMMugCAvoCC05PUk1BTF9GTE9XigMgNWFjYmY4NTYyNTNhNDVmNWEyN2RmNjY1ODkxOGJiYWSaAw0KAnYyEAAaBW90aGVyqAMS2AMA6gMvY29udGVudFdhcm11cFR3b1Rvd2VyVHZwVGV4dE5vcm1hbEV4cFYyUmVjYWxsZXL6A30SDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFOi0IAhCzCBjaAyIjdjItZmI5NWI3YTFjZGQzNjlkMzA0OGIzMmQyOTBiMjVkNTQ6LQgCEP4HGPYGIiN2Mi1lY2JkMmY3MjUxNTJlYjA4YjkyNmI0ZGZkNzBjNDYzZIAEAIgEAJIEBk5vcm1hbJoEATKgBACoBACwBAC6BAJhacIEAzQwMMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAABP9ij+BBQAAAAAAAAAAiQV5YgV3txLSP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AUHkAYAoAYoqAYBkgIuCgkyNTk1MzMyMzcSEzE5MjExOTQ1Mzc0MjM5NjMzMTUYByIKSU1BR0VfVEVYVA==","action_card":false},{"id":"41_1750899273.310","type":"feed","offset":41,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750899273,"updated_time":1750899273,"target":{"id":"1921202089884882869","type":"article","url":"https://api.zhihu.com/articles/1921202089884882869","author":{"id":"19d5bf405ac28244a5f38db5582799f8","url":"https://api.zhihu.com/people/19d5bf405ac28244a5f38db5582799f8","user_type":"people","url_token":"kingjie-63-98","name":"外贸那些事儿","headline":"","avatar_url":"https://pic1.zhimg.com/50/v2-3db1a63ae17bc1f5e998b1caa946208f_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":836,"is_following":false,"is_followed":false},"title":"开发客户太累？这份宝藏工具汇总请收好！","comment_permission":"all","created":1750830293,"updated":1750830293,"voteup_count":0,"voting":0,"comment_count":0,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"还在为找不到精准客户发愁？这份涵盖沟通、营销、背调、工具的外贸神器清单，按场景分类整理，助你开发客户事半功倍！ 1. 即时通讯与国际电话 国际电话类 叮咚：通过 Facebook 账号注册，可免费拨打电话、发消息，需配合梯子使用，适合日常客户联络。 Ringo：苹果端专用，通话清晰且显示主叫号码，打国际长途性价比高，无录音功能需外接工具。 Callbacker：支持全球号码拨打，自动录音 + 主叫显示，按国家收费，信号稳定性强。 …","excerpt_new":"还在为找不到精准客户发愁？这份涵盖沟通、营销、背调、工具的外贸神器清单，按场景分类整理，助你开发客户事半功倍！ 1. 即时通讯与国际电话 国际电话类 叮咚：通过 Facebook 账号注册，可免费拨打电话、发消息，需配合梯子使用，适合日常客户联络。 Ringo：苹果端专用，通话清晰且显示主叫号码，打国际长途性价比高，无录音功能需外接工具。 Callbacker：支持全球号码拨打，自动录音 + 主叫显示，按国家收费，信号稳定性强。 …","preview_type":"default","preview_text":"","content":"\u003cp data-pid=\"vGzNDpEQ\"\u003e还在为找不到精准客户发愁？这份涵盖沟通、营销、背调、工具的外贸神器清单，按场景分类整理，助你开发客户事半功倍！\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"2ztP8Yeu\"\u003e\u003cb\u003e1. 即时通讯与国际电话\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"u6auH5t1\"\u003e\u003cb\u003e国际电话类\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"TEQOntXg\"\u003e\u003cb\u003e叮咚：\u003c/b\u003e通过 Facebook 账号注册，可免费拨打电话、发消息，需配合梯子使用，适合日常客户联络。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"NryHghmb\"\u003e\u003cb\u003eRingo：\u003c/b\u003e苹果端专用，通话清晰且显示主叫号码，打国际长途性价比高，无录音功能需外接工具。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"hFL1JBLJ\"\u003e\u003cb\u003eCallbacker：\u003c/b\u003e支持全球号码拨打，自动录音 + 主叫显示，按国家收费，信号稳定性强。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"3wHQk1rl\"\u003e\u003cb\u003e电话会议类\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"IJoxdhRS\"\u003e\u003cb\u003eZoom：\u003c/b\u003e无需注册即可通过网页入会，支持视频协作，是外贸人常用的跨国会议工具。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"thR4402Q\"\u003e\u003cb\u003eTauria：\u003c/b\u003e主打安全隐私的视频会议平台，界面简洁，适合对数据保密要求高的场景。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"OU9Fv7cB\"\u003e\u003cb\u003eGoogle Meet：\u003c/b\u003e完全免费的浏览器端会议工具，支持即时发起会议，适合临时沟通。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"FI2r3pId\"\u003e\u003cb\u003eWhatsApp：\u003c/b\u003e仅支持 1 对 1 视频通话，需依赖稳定 Wi-Fi，适合轻量化客户沟通。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"-NmVYFEv\"\u003e\u003cb\u003e2. 社媒营销与引流工具\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"3ys2y5dz\"\u003e\u003cb\u003eTagboard：\u003c/b\u003e实时抓取社交媒体关键词内容，支持自定义布局，适合展会或活动现场的实时互动展示。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"lt_vApbE\"\u003e\u003cb\u003eTagsFinder：\u003c/b\u003e输入 10 个关键词即可生成精准 Hashtag，可按国家筛选并排除无效标签，提升 LinkedIn/Ins 曝光率。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"a1Z-yNSv\"\u003e\u003cb\u003eMeta Hashtag：\u003c/b\u003e通过关键词检索 Ins 相关标签帖子，快速定位目标客户的社媒足迹。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"hFQN-g1W\"\u003e\u003cb\u003eSocial Mention：\u003c/b\u003e免费的社媒舆情搜索工具，实时监控品牌或产品关键词讨论。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"7ZFfkotx\"\u003e\u003cb\u003eBrand Mention：\u003c/b\u003e进阶版分析工具，生成包含地域、语种、KOL 影响力的详细报告，支持谷歌趋势联动。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"2walUZG9\"\u003e\u003cb\u003eAgorapulse：\u003c/b\u003e一站式社媒管理平台，可批量运营多账号，自动回复粉丝互动，提升客户粘性。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"mIm0yXQ3\"\u003e\u003cb\u003e3. 企业信息查询与背调工具\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"xtebNYeI\"\u003e\u003cb\u003eopencorporates：\u003c/b\u003e全球最大的公司信息数据库，数据涵盖 129 国家 / 地区的 1.6 亿家公司。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"uW26yacy\"\u003e\u003cb\u003eWhois：\u003c/b\u003e域名查询，可查企业官网注册时间、所有者信息（姓名 / 邮箱 / 电话）、域名有效期。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"JoO61Yk2\"\u003e\u003cb\u003e搜索引擎：\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"hdbOtchd\"\u003eGoogle 地图搜索 “公司名 + scam” 或 “公司名 + review”，查看是否有负面评价；\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"SWVZQXp-\"\u003eGoogle 地图实景查看客户办公地、仓库规模及周边环境。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"eDRdHlPj\"\u003eLinkedIn：搜索客户公司名称，查看员工数量、关键人职位；检查公司主页更新动态；通过共同联系人间接了解客户口碑。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"m0zVbuc8\"\u003e海关数据：查看客户历史进口记录（供应商、采购量、频率），验证客户真实性，发现现有供应商，制定竞争策略。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"W331vQub\"\u003e\u003cb\u003e4. 图片音频处理工具\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"GUbISedX\"\u003e\u003cb\u003e图片压缩与编辑\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"zB0xiKfF\"\u003e\u003cb\u003eTinyJPG：\u003c/b\u003e批量压缩 JPG/BMP 格式图片，体积仅 320KB，绿色免安装，适合快速处理产品图。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"yqzEecZB\"\u003e\u003cb\u003eJPEGmini：\u003c/b\u003e无损压缩 JPG 图片，最高可压缩 80% 体积，拖拽即可批量处理，保留高清画质。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"6XyJ2XGV\"\u003e\u003cb\u003eRemove：\u003c/b\u003e全自动 AI 去背景工具，免费且操作零门槛，适合电商产品图精修。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"eAQgBgbW\"\u003e\u003cb\u003e视频与水印工具\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"87O6p3kp\"\u003e\u003cb\u003e\u003ca href=\"https://link.zhihu.com/?target=http%3A//Veed.io\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e\u003cspan class=\"invisible\"\u003ehttp://\u003c/span\u003e\u003cspan class=\"visible\"\u003eVeed.io\u003c/span\u003e\u003cspan class=\"invisible\"\u003e\u003c/span\u003e\u003c/a\u003e、剪映在线 / 客户端：\u003c/b\u003e视频剪辑工具，支持字幕添加、片段裁剪，剪映 PC 版更易上手。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"Svl5sjiU\"\u003e\u003cb\u003ePicasa3：\u003c/b\u003eGoogle 出品的免费图片处理软件，可制作带水印的报价单，适配外贸场景。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"r7Pmp9Nu\"\u003e\u003cb\u003epicmarkr：\u003c/b\u003e在线图片加水印网站，支持文字 /logo 批量添加，保护品牌版权。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"CQHEg4VQ\"\u003e\u003cb\u003eAwesome Screenshot：\u003c/b\u003eChrome 浏览器插件，可截取整页网页并标注，适合竞品页面分析或客户案例整理。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"8nLNoVFS\"\u003e\u003cb\u003e5. 大文件传输工具\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"eiO-RTLu\"\u003e\u003cb\u003eDropbox：\u003c/b\u003e在线存储服务，借助云计算技术实现网络文件同步功能，用户能够存储文件和文件夹并进行共享。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"e9RrJOZo\"\u003e\u003cb\u003egoogle drive：\u003c/b\u003e在线存储服务，分别提供 2GB/15GB 免费空间，适合同步文档或小文件。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"pmmCQeyN\"\u003e\u003cb\u003eWeTransfer：\u003c/b\u003e支持传输 200GB 大文件，全球可达，但国内下载速度较慢，适合创意素材传输。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"NfukYDxT\"\u003e\u003cb\u003eSendanywhere：\u003c/b\u003e韩国开发的跨设备传输工具，可通过 6 位提取码或局域网传输，速度优于微信，支持多端同步。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"83Hgx6jE\"\u003e\u003cb\u003e6. 附加实用工具\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"hz9CHuUt\"\u003e\u003cb\u003e语言学习类\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"lApF0xj9\"\u003e\u003cb\u003eItalki：\u003c/b\u003e全球最大在线语言学习平台，130 + 语种、200 + 国家母语教师，针对性提升外贸口语。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"dvMzwiD_\"\u003e\u003cb\u003eBusuu：\u003c/b\u003e多端同步的外语互助社区，可与 1 亿 + 母语者互改作业，掌握更地道的商务表达。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"jnUEQYLP\"\u003e\u003cb\u003e竞品分析类\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"cIRgI83e\"\u003e\u003cb\u003eKeepa：\u003c/b\u003e免费查询亚马逊产品上架时长、历史价格，独立站选品可参考主流平台定价趋势。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"A45KGQ0r\"\u003e\u003cb\u003eAhrefs：\u003c/b\u003e大公司常用，可查反向链接、关键词、广告数据，帮助提升独立站谷歌排名，适合分析外链。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"_R7I3pNC\"\u003e\u003cb\u003eSemrush：\u003c/b\u003e能彻底看透竞品网站，还能指导自己的内容、社媒和广告，有中文版。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"Cqqau1wR\"\u003e\u003cb\u003eSpyfu：\u003c/b\u003e专注 Google 广告与 SEO 分析，拆解竞品 PPC 关键词策略，精准投放广告预算。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"b_Ajcr9M\"\u003e\u003cb\u003eLogo 图标生成\u003c/b\u003e\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"i7XMEntu\"\u003e\u003cb\u003eLogo Maker Ucraft：\u003c/b\u003e用库里的图标和字体，自己组合设计 logo。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"Q-X16BTz\"\u003e\u003cb\u003eLaunchaco：\u003c/b\u003e能排版名片，也能设计 logo。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"_D-v_vQx\"\u003e\u003cb\u003eLogaster：\u003c/b\u003e输入公司名或商标，自动生成 logo，还能生成名片、胸牌等 VI 案例，免费功能够用。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"3k3AMZne\"\u003e\u003cb\u003eYEELOGO：\u003c/b\u003e免费，集合前三个工具的功能，能自由编辑设计，还能一键预览 logo 在不同场景的效果。\u003c/p\u003e\u003cp class=\"ztext-empty-paragraph\"\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp data-pid=\"sAyaopVw\"\u003e别再让低效拖慢你的外贸步伐！用好这些工具，开发客户不再是大海捞针，而是精准出击、事半功倍！赶紧收藏起来，下次找客户，效率直接拉满。\u003c/p\u003e\u003cp data-pid=\"H68DSfe4\"\u003e公众号：外贸那些事儿\u003c/p\u003e","is_labeled":false,"visited_count":28,"favorite_count":4,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 1921202089884882869}","attached_info":"CoYGCNvCqJK0sIiAiAEQBxoJMjU5NTM0MjYyINWZ7sIGKAAwAEApSiMKGFRTX1NPVVJDRV9XQVJNX1VQX0JPT1NUMRIBMBgAIAA6AEovCiRUU19TT1VSQ0VfV0FSTVVQX1RXT1RPV0VSX0VYUFYyX1RFWFQSATAYACAAOgBiIGYzZjJkZjQ2ZDNjNzZhMzMzMmU1Nzk2ZDE5MTlhMTUwchMxOTIxMjAyMDg5ODg0ODgyODY5qgEJcmVjb21tZW5kwgEgMTlkNWJmNDA1YWMyODI0NGE1ZjM4ZGI1NTgyNzk5ZjjyAQoIDBIGTm9ybWFs8gEoCAoSJDc0ZGUzMDIxLTM3MDctNDUwNC1iYmUzLWUzNWFlOTRhYjNjNvIBBQgLEgE3ggIAiAKL4erN+jKSAiAxOWQ1YmY0MDVhYzI4MjQ0YTVmMzhkYjU1ODI3OTlmOJoCAMoCFlNob3JJbnRlcmVzdFdlaWdodFJ1bGXKAhhQZXJpb2RJbnRlcmVzdFdlaWdodFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXKAhxCYXllc0ZpcnN0TGV2ZWxJc29sYXRpb25SdWxl2gIYVFNfU09VUkNFX1dBUk1fVVBfQk9PU1Qx6AIC+gILTk9STUFMX0ZMT1eKAyA1YWNiZjg1NjI1M2E0NWY1YTI3ZGY2NjU4OTE4YmJhZJoDDQoCdjIQABoFb3RoZXKoAxzYAwDqAy5jb250ZW50V2FybXVwVHdvVG93ZXJUdnBUZXh0Qm9vc3RFeHBWMlJlY2FsbGVy+gMfEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERYAEAIgEAJIEBk5vcm1hbJoEATKgBACoBACwBAC6BAJhacIEAzQwMMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAIFuziD+BBQAAAAAAAAAAiQV5YgV3txLSP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AUHkAYAoAYpqAYAkgIuCgkyNTk1MzQyNjISEzE5MjEyMDIwODk4ODQ4ODI4NjkYByIKSU1BR0VfVEVYVA==","action_card":false}],"paging":{"is_end":false,"is_start":false,"next":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=down\u0026ad_interval=-10\u0026after_id=41\u0026desktop=true\u0026end_offset=41\u0026page_number=8\u0026session_token=f3f2df46d3c76a3332e5796d1919a150","previous":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=pull\u0026ad_interval=-10\u0026before_id=41\u0026desktop=true\u0026end_offset=41\u0026page_number=8\u0026session_token=f3f2df46d3c76a3332e5796d1919a150","totals":0},"fresh_text":"推荐已更新"}
