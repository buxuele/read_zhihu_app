{"data":[{"id":"60_1750898464.510","type":"feed","offset":60,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750898464,"updated_time":1750898464,"target":{"id":"3075240949","type":"answer","url":"https://api.zhihu.com/answers/3075240949","author":{"id":"000bb05eb79fb2881e043ac00b7420c8","url":"https://api.zhihu.com/people/000bb05eb79fb2881e043ac00b7420c8","user_type":"people","url_token":"shang-guan-ren","name":"上官人","headline":"企业创新教练，说真话，不变现","avatar_url":"https://pic1.zhimg.com/50/1ab482a224f9802a640dcadae0b2d347_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":112957,"is_following":false,"is_followed":false},"created_time":1686818615,"updated_time":1686818615,"voteup_count":7492,"thanks_count":1430,"comment_count":238,"is_copyable":true,"question":{"id":"38531356","type":"question","url":"https://api.zhihu.com/questions/38531356","author":{"id":"9b7ddfe9790fa92b1ce1564199492925","url":"https://api.zhihu.com/people/9b7ddfe9790fa92b1ce1564199492925","user_type":"people","url_token":"yangjiePro","name":"杨捷","headline":"","avatar_url":"https://pic1.zhimg.com/50/v2-8c412bb1d7181bdae29ba93f106a78d2_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":1059,"is_following":false,"is_followed":false},"title":"什么时候才是开掉「技术合伙人」的最佳时机？","created":1450138751,"answer_count":0,"follower_count":0,"comment_count":37,"bound_topic_ids":[12162,200030],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"这个问题很好，用一个恶心人的视角，揭示了一个技术人不愿意面对的事实，技术合伙人在大多数情况下被开掉是必然的，是正当的，并非某个不懂技术的老板瞎搞。 此时应该有个例子，正好有个答主 @库森学长 给了一个很鲜活的案例：什么时候才是开掉「技术合伙人」的最佳时机？ 这位答主开篇明义，把技术合伙人被开掉总结为一个常见现象，一般发生在创业公司业务稳定后，CEO就会看CTO不顺眼。他给出的解决方案是跟CEO搞好关系。 现象是…","excerpt_new":"这个问题很好，用一个恶心人的视角，揭示了一个技术人不愿意面对的事实，技术合伙人在大多数情况下被开掉是必然的，是正当的，并非某个不懂技术的老板瞎搞。 此时应该有个例子，正好有个答主 @库森学长 给了一个很鲜活的案例：什么时候才是开掉「技术合伙人」的最佳时机？ 这位答主开篇明义，把技术合伙人被开掉总结为一个常见现象，一般发生在创业公司业务稳定后，CEO就会看CTO不顺眼。他给出的解决方案是跟CEO搞好关系。 现象是…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"pciMYqve\"\u003e这个问题很好，用一个恶心人的视角，揭示了一个技术人不愿意面对的事实，技术合伙人在大多数情况下被开掉是必然的，是正当的，并非某个不懂技术的老板瞎搞。\u003c/p\u003e\u003cp data-pid=\"ClJP6wsA\"\u003e此时应该有个例子，正好有个答主 \u003ca class=\"member_mention\" href=\"https://www.zhihu.com/people/0a4b0784aa2c7b384694033addac9d30\" data-hash=\"0a4b0784aa2c7b384694033addac9d30\" data-hovercard=\"p$b$0a4b0784aa2c7b384694033addac9d30\"\u003e@库森学长\u003c/a\u003e 给了一个很鲜活的案例：\u003c/p\u003e\u003ca href=\"https://www.zhihu.com/question/38531356/answer/3063261026\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"internal\"\u003e什么时候才是开掉「技术合伙人」的最佳时机？\u003c/a\u003e\u003cp data-pid=\"bXUN0Mxt\"\u003e这位答主开篇明义，把技术合伙人被开掉总结为一个常见现象，一般发生在创业公司业务稳定后，CEO就会看CTO不顺眼。他给出的解决方案是跟CEO搞好关系。\u003c/p\u003e\u003cp data-pid=\"Obo0-aXe\"\u003e现象是对的，这位答主一看就有实战经验，但是方案是不靠谱的，正如关系型销售必然没落一样，关系型高管也存活不下去，何况技术人还不擅长搞关系。\u003c/p\u003e\u003cp data-pid=\"UzlVDv8X\"\u003e我借着这个案例给大家讲讲，创业公司CTO的困境到底是什么，为什么他必然被干掉，为什么我说这个老板还算仁义。这里要感谢库森学长的回答。\u003c/p\u003e\u003cblockquote data-pid=\"kqHXwWoG\"\u003e前年的时候，也有一家创业型公司让我过去，我跟老板聊了聊，又从侧面打听，发现公司的现金流就只有三个月的，其实并不保险。\u003cbr/\u003e另外，老板是销售出身，\u003ca href=\"https://www.zhihu.com/search?q=%E8%9C%9C%E6%9C%88%E6%9C%9F\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3063261026%7D\" class=\"internal\" target=\"_blank\"\u003e蜜月期\u003c/a\u003e过后，非常容易把研发这块当做纯成本项，觉得贵了慢了的，到时候又是个麻烦事儿。\u003cbr/\u003e所以我就直接拒绝了，老板让我给他推荐其他人，我就把我的一个老大哥大东推荐了过去。\u003cbr/\u003e果然不出我所料，最后也没能善终。\u003c/blockquote\u003e\u003cp data-pid=\"RWp4H3xW\"\u003e这是个典型的创业小公司，融了A轮，现金流三个月，CEO年轻有为。活着都有风险，但是未来一旦成功也很光明。我之所以说这个案例很典型，就是因为大多数公司还不如这个公司靠谱，你大概率去的是一个没啥希望的小池塘，这公司至少老板靠谱，业务有希望。\u003c/p\u003e\u003cblockquote data-pid=\"BPGGIIRJ\"\u003e当时\u003ca href=\"https://www.zhihu.com/search?q=%E5%A4%A7%E4%B8%9C\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3061716019%7D\" class=\"internal\" target=\"_blank\"\u003e大东\u003c/a\u003e目前刚从阿里离职，在家赋闲中，正盘算下一步路如何走。继续去创业型公司当CTO，还是找个大厂踏实待着赚钱。\u003cbr/\u003e听了我的推荐后，大东有些动心，因为这家公司的CEO，他也听说过，确实是年轻有为，在行业内影响力极高，他表示可以聊聊看。\u003cbr/\u003e第二周，CEO跟大东见面聊了聊，对履历丰富、为人踏实的大东也比较满意。\u003cbr/\u003eCEO表示，如果大东愿意加入的话，来当公司的CTO加合伙人，他会给大东一个点的期权。但公司目前才刚刚A轮，所以工资只能给大东4万。\u003cbr/\u003e大东听了表示基本满意，自己这个人老色衰的年龄，还能赶上这样的机会，让他有个梦可以做，也算是实属不易。\u003c/blockquote\u003e\u003cp data-pid=\"BB1E9nNv\"\u003e答主不爱去，大东爱去，大东缺这个机会，也愿意赌一把。从待遇上来看，工资不算高也不算低，毕竟公司现金流有限。给一个点的期权，B轮是8亿美金，A轮1个亿总也有了，那就是七百万人民币期权。毕竟是A轮的技术合伙人，天使轮都没参加，自己也不出钱，给干股说不过去，这个数的期权也不少了。\u003c/p\u003e\u003cp data-pid=\"838sg5gP\"\u003e具体干的过程我就忽略了，简单总结，就是拉来技术骨干，建立流程，引入工具，提升团队能力，这是效果。\u003c/p\u003e\u003cblockquote data-pid=\"vvmBkkx6\"\u003e一年过去了，研发短板没了，与此同时，业务增速也是一个季度比一个季度猛，公司也进行了B轮和B+轮两轮融资，估值也达到了8亿\u003ca href=\"https://www.zhihu.com/search?q=%E7%BE%8E%E9%87%91\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3061716019%7D\" class=\"internal\" target=\"_blank\"\u003e美金\u003c/a\u003e。\u003c/blockquote\u003e\u003cp data-pid=\"--u-cFYa\"\u003e你要注意的是，这里大东所有的发力都是向内的，就是研发团队内部改革，后面我们会看到问题。\u003c/p\u003e\u003cp data-pid=\"W_ErTjvo\"\u003e从答主或者大东的角度来看，公司发展得好，研发瓶颈的解决是功不可没的。实际上应该也八九不离十，但是真正驱动公司发展的一定不是研发。研发只是制约发展的一个关键瓶颈而已。大东在合适的时间拓宽了这个瓶颈，公司得到了一定程度的发展，但这并不等于一劳永逸了。\u003c/p\u003e\u003cp data-pid=\"JSG25RRT\"\u003e答主后面谈大东遇到的问题，主要集中在两个方面，一个是业务反对，一个是CEO不认可。\u003c/p\u003e\u003cp data-pid=\"ZN5JIipk\"\u003e业务反对的原因，我们可以从这段对话中略知一二：\u003c/p\u003e\u003cblockquote data-pid=\"PRKMuBDi\"\u003e每条业务线的业务老大都觉得，\u003cb\u003e大东给自己这条业务线配置的研发资源少了\u003c/b\u003e，或是研发资源不给力。\u003cbr/\u003e大东：“你看，就你这条业务线工程师最多，总共有27个人，\u003cb\u003e你还有什么不满意的？\u003c/b\u003e”\u003cbr/\u003eA业务线老大：“但我这条业务线的工程师都是P5 P6，你看其他业务线的，都是P6 P7，再往我这边倾斜一些资源吧，我这边业务都是公司的流量入口。”\u003cbr/\u003e大东：“你看，就你这条业务线工程师的\u003ca href=\"https://www.zhihu.com/search?q=%E9%AB%98P\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3061716019%7D\" class=\"internal\" target=\"_blank\"\u003e高P\u003c/a\u003e最多，总共有5个P7，\u003cb\u003e你还有什么不满意的？\u003c/b\u003e”\u003cbr/\u003eB业务线老大：“产品经理跟我说了，你这边的P7只做\u003ca href=\"https://www.zhihu.com/search?q=%E6%8A%80%E6%9C%AF%E4%BC%98%E5%8C%96\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3061716019%7D\" class=\"internal\" target=\"_blank\"\u003e技术优化\u003c/a\u003e，不做我的业务需求，我想要一些做业务需求的P5 P6，再往我这边倾斜一些资源吧，我这边都是公司的未来十年的发展方向。”\u003cbr/\u003e大东：“我把维护\u003ca href=\"https://www.zhihu.com/search?q=%E4%B8%AD%E9%97%B4%E4%BB%B6\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3061716019%7D\" class=\"internal\" target=\"_blank\"\u003e中间件\u003c/a\u003e的人都调过去支援你的业务需求了，\u003cb\u003e你还有什么不满意的？\u003c/b\u003e”\u003cbr/\u003eC业务线老大霸气地说：“我不管，我这边每进一个\u003ca href=\"https://www.zhihu.com/search?q=%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3061716019%7D\" class=\"internal\" target=\"_blank\"\u003e产品经理\u003c/a\u003e，你这边必须进四个研发支持我，我这边正在跟竞对打仗，你必须在中后台给我\u003ca href=\"https://www.zhihu.com/search?q=%E6%AD%A6%E5%99%A8%E5%BC%B9%E8%8D%AF\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3061716019%7D\" class=\"internal\" target=\"_blank\"\u003e武器弹药\u003c/a\u003e供应。”\u003c/blockquote\u003e\u003cp data-pid=\"XYBq8Eia\"\u003e我标黑的部分是我认为的问题。\u003c/p\u003e\u003cp data-pid=\"_mR51JSY\"\u003e你注意，我并没有觉得所有的业务线都反对大东是问题的核心，我标记的是，他们认为自己的研发资源是大东给配置的，配置得少了。\u003c/p\u003e\u003cp data-pid=\"ncNXs9PY\"\u003e那么业务评价配置的多少的标准是什么呢？与其他业务线比较。比较人数、级别、工作内容。\u003c/p\u003e\u003cp data-pid=\"InBpjonL\"\u003e所以大家隐含的逻辑是，资源是你大东给配的，你必须给我配置得公平。\u003c/p\u003e\u003cp data-pid=\"5pJ85RMo\"\u003e这是一个CTO不应当承担的责任，因为CTO承担不起，不仅仅是大东能力不够，而且公司也不应该让CTO来承担这个责任。\u003c/p\u003e\u003cp data-pid=\"kZMi93Ys\"\u003e项目组合管理、战略管理里，都会就项目预算、战略预算进行制定，然后配置资源。\u003c/p\u003e\u003cp data-pid=\"wUHXQzrY\"\u003e大东越俎代庖，承担了公司预算制定这个职责，等于他决策，来往三个无底洞里扔资源，不仅仅是公司资源的严重错配，也注定了谁也满足不了。\u003c/p\u003e\u003cp data-pid=\"BoWlN3JU\"\u003e这位答主并没有觉得这是大东的问题，他只是觉得业务贪婪，老板轻信：\u003c/p\u003e\u003cblockquote data-pid=\"ncFfLejl\"\u003eCEO本身是业务出身，平时跟三条业务线的老大走得比较近，总一起吃饭什么的。吃饭的时候，CEO听业务线的老大们时不时地吐槽大东，时间久了，情到浓时情转薄，\u003ca href=\"https://www.zhihu.com/search?q=%E5%BF%83%E5%8F%A3%E7%9A%84%E6%9C%B1%E7%A0%82%E7%97%A3\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3061716019%7D\" class=\"internal\" target=\"_blank\"\u003e心口的朱砂痣\u003c/a\u003e也变成了蚊子血，\u003ca href=\"https://www.zhihu.com/search?q=%E7%99%BD%E6%9C%88%E5%85%89\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3063261026%7D\" class=\"internal\" target=\"_blank\"\u003e白月光\u003c/a\u003e也变成了米饭粒，开始对大东也有了一些看法。\u003c/blockquote\u003e\u003cp data-pid=\"sL8xBlS1\"\u003e从表面上是这样，但是从公司经营的逻辑上，公司发展的增长主体是业务部门，技术部门是后场提供炮弹的。\u003c/p\u003e\u003cp data-pid=\"HfKWwh0C\"\u003e答主之所以写这么细，就是因为他认为，这不是大东的问题，而是业务的问题。这是技术人的一个典型认知误区，业务反对大东，是因为大东制约了业务发展，业务的发展是公司需要、CEO需要、股东需要，而不仅仅是业务老大的私欲。如果业务老大因为一己之私欲而反对你，搞政治，那么CEO、董事会都会干预——然而并没有，反而是大东被干掉了。\u003c/p\u003e\u003cp data-pid=\"X7Sgci6T\"\u003e你对抗的到底是一个业务老大，还是站在他背后的全公司、投资人？\u003c/p\u003e\u003cp data-pid=\"NQXaDepV\"\u003e你要是连你的对手都搞错了，自然死无葬身之地。\u003c/p\u003e\u003cp data-pid=\"87U4NV3D\"\u003e一个聪明的CTO，在此时就要主动放权，要么把事儿摊开了扔给业务自己打架，要么交给CEO拍，要么要求按照战略分配。无论如何，预算制定这件事情不能CTO干，谁干谁死。军需官不是指挥官，不能做战略资源分配的决策，只是执行决议。\u003c/p\u003e\u003cp data-pid=\"M6ax_U_l\"\u003e这是第一个核心问题，第二个核心问题，就是公司的发展阶段已经变了，需要的不是大东这样只会干活的CTO，答主借CEO的嘴说了出来：\u003c/p\u003e\u003cblockquote data-pid=\"t-oQskCq\"\u003e竞对的研发团队才100人，而自家公司的研发都超过150人了。\u003cbr/\u003e公司期权池里的\u003ca href=\"https://www.zhihu.com/search?q=%E6%9C%9F%E6%9D%83\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3061716019%7D\" class=\"internal\" target=\"_blank\"\u003e期权\u003c/a\u003e，大部分都分给研发团队了。\u003cbr/\u003e故障虽然少了，但这周的一次故障损失的钱，顶过去三个月的故障损失总和了。\u003cbr/\u003e研发团队加班比一年前少了，业务团队对此有意见，认为没有跟业务团队共甘苦。\u003cbr/\u003eCEO觉得，大东的能力只能把研发团队hold到B+轮，到了\u003ca href=\"https://www.zhihu.com/search?q=C%E8%BD%AE\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3061716019%7D\" class=\"internal\" target=\"_blank\"\u003eC轮\u003c/a\u003e就出现瓶颈了。于是，他开始四处物色能力和履历上都更加出色的技术带头人。\u003c/blockquote\u003e\u003cp data-pid=\"3NULWIxz\"\u003e答主描述的CEO的心理活动，主要围绕着“研发的投入产出比”来说，觉得研发人多、花得多、损失大、加班少，不值了。\u003c/p\u003e\u003cp data-pid=\"6-ndR_6H\"\u003e我认为要么是答主格局小了，猜得偏了，要么是CEO格局小了，看得偏了。\u003c/p\u003e\u003cp data-pid=\"h1ahKINF\"\u003eCEO应该关注的是经营目标和战略目标到底是什么，研发团队是否能够在一个可接受的预算内帮助公司达成。\u003c/p\u003e\u003cp data-pid=\"HHK_n6vQ\"\u003e从这个角度说，CEO的结论是没问题的，大东就是瓶颈，只不过大东的瓶颈不是答主和大东自己以为的那个瓶颈——并不是他不擅长和CEO以及业务老大们搞关系，而是\u003cb\u003e大东他只擅长做管理，听不懂战略\u003c/b\u003e。当公司到达野蛮生长的后期，需要有规划地前进时，他跟不上了。\u003c/p\u003e\u003cp data-pid=\"o9t_6Taj\"\u003e大东也委屈，这公司也许就没有战略啊、预算啊的概念。否则，当业务老大说，我这业务代表了公司未来十年的发展时，他就会说，“卧槽这么重要！这是大事儿，兄弟你多跟老板要点预算，我也好帮你挑点精兵强将，咱们好好搞一搞。”\u003c/p\u003e\u003cp data-pid=\"ulWe2I1U\"\u003e你他么代表公司未来十年发展，老板还不给你预算？这不就等于是吹牛逼嘛，你跟我偷偷摸摸要什么人。\u003c/p\u003e\u003cp data-pid=\"L6IlOqR9\"\u003e大东要是狠一点，在高管会上直接就提这个问题，“最近几个业务老大私下里都跟我沟通过，研发资源不够，我给得不均衡。我觉得不能让我来决定公司各个业务的资源投入，咱们今天要不就讨论讨论，到底怎么个分配比例。今天定下来，大家就不用私下里找我了”。\u003c/p\u003e\u003cp data-pid=\"CNKt5fQY\"\u003e让他们打去呗，老板还愿意看他们打，因为打的时候，很多隐藏的潜规则就会暴露出来，老板就有抓手了。\u003c/p\u003e\u003cp data-pid=\"E8JFpcCG\"\u003e我给很多企业做过这方面的咨询，这位答主说的大东是CTO们的典型代表，基本上都是需要先把这个权力从CTO身上摘掉，至少也是集体决策，比如经营会战略会上，大家一起过，有问题会上说。CTO就是执行，并且要管着业务对资源的使用，要和会上决议一致。\u003c/p\u003e\u003cp data-pid=\"nBvFvuFq\"\u003e这是两个层次的CTO，一个本质上就是技术总监，就是个中层，负责建立研发体系，组织兄弟们干活；一个是公司高管，参与公司战略制定，负责公司战略在技术方向上的落实。\u003c/p\u003e\u003cp data-pid=\"zJmAc5TS\"\u003e所以我在那个回答的评论区里说，大东本质上就是个中层，公司发展出高层了，但是大东还没达到这个水平，落后于公司发展，挡了公司的路。\u003c/p\u003e\u003cp data-pid=\"-NxswOTJ\"\u003e在这种情况下，一个尽职的CEO，可以选择给大东机会成长，但是到了一定时期，就必须让大东腾地方，挪位置，不能干扰公司正确的战略执行。\u003c/p\u003e\u003cp data-pid=\"fMcaOc_S\"\u003e而这个CEO的做法是：\u003c/p\u003e\u003cblockquote data-pid=\"pntXfntS\"\u003e大东说：“老板，怎么公司突然间又找了一个CTO啊？而且之前也完全没跟我说啊？”\u003cbr/\u003eCEO说：“这一年多，你确实挺辛苦，尽心尽力地为公司做出不少成绩，但确实现在面临瓶颈，我觉得你更适合当我司的\u003ca href=\"https://www.zhihu.com/search?q=%E6%8A%80%E6%9C%AF%E5%90%88%E4%BC%99%E4%BA%BA\u0026amp;search_source=Entity\u0026amp;hybrid_search_source=Entity\u0026amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3061716019%7D\" class=\"internal\" target=\"_blank\"\u003e技术合伙人\u003c/a\u003e，而不是CTO。新CTO来了，你跟他好好配合，这也给了你成长的机会。”\u003cbr/\u003e大东说：“我一时有些接受不了。”\u003cbr/\u003eCEO说：“我希望你能留下，但如果实在接受不了，你可以看看其他公司，有没有CTO的机会吧。”\u003c/blockquote\u003e\u003cp data-pid=\"5vDedf19\"\u003e什么叫仁至义尽？这就叫仁至义尽。待遇没降，退二线，只求你不要挡在公司前进的路上。\u003c/p\u003e\u003cp data-pid=\"8PrZrLot\"\u003eCEO并没有下黑手搞掉大东，对比很多喜欢搞小动作的CEO来说，已经是仁至义尽。\u003c/p\u003e\u003cp data-pid=\"GqW71WkR\"\u003e高层一般都是先要保证离职的影响范围可控，然后才摊牌，因为高管更迭对公司的影响非常大，伤筋动骨，CEO也是憋疯了。\u003c/p\u003e\u003cp data-pid=\"RjwCR82L\"\u003e归根结底，不同阶段的公司对“技术合伙人”的要求是不同的，技术合伙人必须保持成长，要比公司的要求快。如果不能做到，下课是必然的。\u003c/p\u003e\u003cp data-pid=\"XEJNnVbt\"\u003e这不仅仅是对技术合伙人的要求，也是对所有公司高管的要求，销售不行销售下课，市场不行市场下课，人力、行政、财务、运营，都是这个逻辑。\u003c/p\u003e\u003cp data-pid=\"w5wEV6UN\"\u003e所以，什么是开掉“技术合伙人”的最佳时机？\u003c/p\u003e\u003cp data-pid=\"b9oNAXET\"\u003e是当这个技术合伙人阻碍了公司发展，并且自身的发展潜力也到头了的时候，无论如何，都需要换人了。\u003c/p\u003e\u003cp data-pid=\"0hlcBnGq\"\u003e那么到底公司什么时候需要什么样的技术合伙人？\u003c/p\u003e\u003cp data-pid=\"5YgkHMAF\"\u003e这问题要说就复杂了，简单说两句：\u003c/p\u003e\u003cp data-pid=\"eZml3Pdq\"\u003e一般一个公司都是先跑通一个业务，这个业务成了以后，做产品线延伸，再做产品线扩展，画第二曲线。\u003c/p\u003e\u003cp data-pid=\"3aLS0DDP\"\u003e在跑通第一个业务的过程中，技术团队先是研发，接着是优化，接着是打造产品线平台，接着是打造多产品线通用平台，最后是维护、颠覆或者死亡。\u003c/p\u003e\u003cp data-pid=\"ujj5HHsf\"\u003e研发和优化的时候，都只是需要一个带头干活的，也就是一个组长就够了，属于基层管理者。\u003c/p\u003e\u003cp data-pid=\"1f9aF7gz\"\u003e打造产品线平台，需要一个总监，也就是中层，能定规矩建体系带团队。\u003c/p\u003e\u003cp data-pid=\"8Ak6yD2c\"\u003e打造多产品线通用平台，就需要一个CTO来参与公司战略，协调技术与业务的关系，保障战略落地，这是个高层。\u003c/p\u003e\u003cp data-pid=\"T8cO-7r6\"\u003e如果公司发展得好，那么对技术合伙人的要求就是不断升级。\u003c/p\u003e\u003cp data-pid=\"HFT967pn\"\u003e如果公司发展得不好，那么就很有可能换个人试试，或者干脆砍掉技术团队，缩小业务，这就没办法了。\u003c/p\u003e\u003cp data-pid=\"4UYGVrDl\"\u003e回答区大多数都是技术管理者从自身狭隘视角的阴谋论，看不到技术合伙人的使命在公司生命周期中的变迁，也就不可能产生任何有价值的解决方案，无助于技术合伙人的成功。\u003c/p\u003e\u003cp data-pid=\"KuP6bJpz\"\u003e我帮助很多CTO坐稳位置，与公司合作共赢了，这事儿我还是比较有发言权，至少是成功者的经验。\u003c/p\u003e\u003cp data-pid=\"asS9rCpF\"\u003e如果有兴趣的朋友也可以去我的回答里看看，那里边的花臂，遇到的就是和大东类似的情况。\u003c/p\u003e\u003ca href=\"https://www.zhihu.com/question/329993317/answer/2546553904\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"internal\"\u003e企业里的高管都是如何被干掉的？\u003c/a\u003e\u003cp\u003e\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":695075,"favorite_count":10598,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 3075240949}","attached_info":"CrYGCPq2yZP9xtXXnwEQBBoJNTg5MjE5ODk0ILeeq6QGKMQ6MO4BQDxKQQosVFNfU09VUkNFX1RXT1RPV0VSX1NIT1JUSU5URVJFU1RfUkVDQUxMX1RFWFQSATAYACAAOgp7InJhdyI6IiJ9Wgc3NjE5OTQwYiA1OTAxOTkzODk3YjJiNjcxNTM0YjQxZGZlMTcwMzk0N3IKMzA3NTI0MDk0OYoBCDM4NTMxMzU2qgEJcmVjb21tZW5kwgEgMDAwYmIwNWViNzlmYjI4ODFlMDQzYWMwMGI3NDIwYzjyAQoIDBIGTm9ybWFs8gEoCAoSJDQ0NGI2YWEwLTE3ZTEtNGJjZC1iY2NhLTI0ZTMyNzhlNDVmNPIBBggLEgIxMYICAIgCyqy5zfoykgIgMDAwYmIwNWViNzlmYjI4ODFlMDQzYWMwMGI3NDIwYziaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIWQWN0aW9uU2hvckludGVyZXN0UnVsZcoCG0ludGVyYWN0aW9uU2hvckludGVyZXN0UnVsZcoCGFBlcmlvZEludGVyZXN0V2VpZ2h0UnVsZcoCFVVzZXJMY25FeGl0V2VpZ2h0UnVsZcoCFENvbnRlbnRBZ2VXZWlnaHRSdWxl2gIsVFNfU09VUkNFX1RXT1RPV0VSX1NIT1JUSU5URVJFU1RfUkVDQUxMX1RFWFToAgP6AgtOT1JNQUxfRkxPV4oDIGRhNDlmMmE4YjQ0YjQ1YTNhZjI0ZTQ1OGFkMmY0MGIymgMNCgJ2MhAAGgVvdGhlcqgDo7Yq2AMA6gMaZmVlZF9hdHRtX3R3b3Rvd2VyX3YyX3RleHT6Ax8SDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFgAQAiAQAkgQGTm9ybWFsmgQBM6AEAKgEALAEALoEBm1hbnVhbMIEAzE2MMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAoAF6uz+BBQAAAAAAAAAAiQVaEpUIpKzSP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AULkAYAoAZAqAYBkgIlCgk1ODkyMTk4OTQSCjMwNzUyNDA5NDkYBCIKSU1BR0VfVEVYVA==","action_card":false},{"id":"61_1750898464.24","type":"feed","offset":61,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750898464,"updated_time":1750898464,"target":{"id":"30201040247","type":"article","url":"https://api.zhihu.com/articles/30201040247","author":{"id":"ef9d1602fc7c41e122b227cc42dfe3e7","url":"https://api.zhihu.com/people/ef9d1602fc7c41e122b227cc42dfe3e7","user_type":"people","url_token":"tomsheep","name":"tomsheep","headline":"GZH：《零一瓦舍》","avatar_url":"https://pica.zhimg.com/50/00dc3b076fb38562011789cc568a8edf_l.jpg?source=b6762063","is_org":false,"gender":1,"badge":[{"type":"super_activity","description":"知势榜科技互联网领域成长力榜答主"},{"type":"identity_people","description":"字节跳动 员工"}],"followers_count":10339,"is_following":false,"is_followed":false},"title":"全景解读 LLM 后训练技术","comment_permission":"all","created":1741929251,"updated":1741929251,"voteup_count":338,"voting":0,"comment_count":3,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"这篇文章是以2025年2月的一篇综述论文为蓝本，对「LLM后训练技术」的全景讲解： [2502.21321] LLM Post-Training: A Deep Dive into Reasoning Large Language Models 引言：从预训练到后训练2023 年，当 ChatGPT 惊艳世界时，很多人第一次意识到：原来 AI 不仅能背课文，还能写代码、编故事、解数学题。这些聪明表现的背后，得益于大语言模型（LLM）的两个关键训练阶段： 预训练（Pretraining）和后训练（Post-training）。预训…","excerpt_new":"这篇文章是以2025年2月的一篇综述论文为蓝本，对「LLM后训练技术」的全景讲解： [2502.21321] LLM Post-Training: A Deep Dive into Reasoning Large Language Models 引言：从预训练到后训练2023 年，当 ChatGPT 惊艳世界时，很多人第一次意识到：原来 AI 不仅能背课文，还能写代码、编故事、解数学题。这些聪明表现的背后，得益于大语言模型（LLM）的两个关键训练阶段： 预训练（Pretraining）和后训练（Post-training）。预训…","preview_type":"default","preview_text":"","column":{"id":"c_1771274012468887552","type":"column","url":"https://api.zhihu.com/columns/c_1771274012468887552","author":{"id":"","url":"","user_type":"people","url_token":"","name":"匿名用户","headline":"","avatar_url":"https://pic1.zhimg.com/v2-d41c2ceaed8f51999522f903672a521f_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":0,"is_following":false,"is_followed":false},"title":"硅基进化","imageUrl":"https://picx.zhimg.com/v2-f111d7ee1c41944859e975a712c0883b_720w.jpg?source=d16d100b","comment_permission":"private","intro":"AI技术的自学与教学","updated":1732339440,"is_following":false},"content":"\u003cp data-pid=\"31EHZWrY\"\u003e这篇文章是以2025年2月的一篇综述论文为蓝本，对「LLM后训练技术」的全景讲解：\u003ca href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2502.21321\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003e[2502.21321] LLM Post-Training: A Deep Dive into Reasoning Large Language Models\u003c/a\u003e\u003c/p\u003e\u003ch2\u003e引言：从预训练到后训练\u003c/h2\u003e\u003cp data-pid=\"8YcmvKhx\"\u003e2023 年，当 ChatGPT 惊艳世界时，很多人第一次意识到：原来 AI 不仅能背课文，还能写代码、编故事、解数学题。这些聪明表现的背后，得益于大语言模型（LLM）的两个关键训练阶段：\u003cb\u003e预训练\u003c/b\u003e（Pretraining）和\u003cb\u003e后训练\u003c/b\u003e（Post-training）。\u003c/p\u003e\u003cp data-pid=\"BCtP8fww\"\u003e预训练阶段通过海量文本数据（通常达到 TB 级别）的自我监督学习，使模型掌握基本的语言规律和世界知识。但仅有预训练的LLM，就好像刚学会六脉神剑的段誉，一身内功，但不会施展。这时，我们就需要通过「后训练」来给模型能力进行「塑型」—— 通过特定方法让模型在医疗诊断、法律咨询、编程开发等专业领域大显身手，同时学会遵守伦理规范、避免信口开河。正是这些「精装修」步骤，把原始的语言模型变成了我们日常使用的智能助手。\u003c/p\u003e\u003cp data-pid=\"5llMe1IB\"\u003e后训练技术的核心价值体现在三个维度：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"_IFxM8pl\"\u003e\u003cb\u003e知识精炼\u003c/b\u003e：修正预训练阶段的知识偏差与事实错误\u003c/li\u003e\u003cli data-pid=\"EXCE8jIZ\"\u003e\u003cb\u003e能力对齐\u003c/b\u003e：使模型输出符合人类价值观和任务需求\u003c/li\u003e\u003cli data-pid=\"O7vkw_rk\"\u003e\u003cb\u003e推理增强\u003c/b\u003e：赋予模型多步推理、逻辑验证等高级认知能力\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"MbCQcFOv\"\u003e在后面的讲述中，我们沿用上述原论文给出的分类视角（taxonomy），从「微调」、「强化学习」、「测试时拓展」三个类别去认识各种后训练技术。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-cf1c8733ab5796262b481847a0816b5c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"726\" data-rawheight=\"690\" data-original-token=\"v2-cf1c8733ab5796262b481847a0816b5c\" class=\"origin_image zh-lightbox-thumb\" width=\"726\" data-original=\"https://pic3.zhimg.com/v2-cf1c8733ab5796262b481847a0816b5c_r.jpg\"/\u003e\u003c/figure\u003e\u003ch2\u003e一、微调技术：模型的定向进化\u003c/h2\u003e\u003ch3\u003e1.1 全参数微调\u003c/h3\u003e\u003cp data-pid=\"3I2pdrzx\"\u003e全参数微调（Full Fine-tuning）是指在预训练模型的基础上，使用下游任务的数据集，更新模型中的\u003cb\u003e所有参数\u003c/b\u003e，以使模型适应特定任务。这种方法在早期的深度学习中非常常见，但随着模型规模的增大，其弊端也逐渐显现。\u003c/p\u003e\u003ctable data-draft-node=\"block\" data-draft-type=\"table\" data-size=\"normal\" data-row-style=\"normal\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003cth\u003e挑战维度\u003c/th\u003e\u003cth\u003e具体表现\u003c/th\u003e\u003cth\u003e解决方案\u003c/th\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e计算资源\u003c/td\u003e\u003ctd\u003eGPU 内存占用高，训练时间长\u003c/td\u003e\u003ctd\u003e参数高效微调 (PEFT)\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e灾难性遗忘\u003c/td\u003e\u003ctd\u003e新任务覆盖旧知识\u003c/td\u003e\u003ctd\u003e知识蒸馏 + 持续学习\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e数据依赖\u003c/td\u003e\u003ctd\u003e需要大量标注数据\u003c/td\u003e\u003ctd\u003e提示学习 + 数据增强\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003ch3\u003e1.2 参数高效微调 (PEFT)\u003c/h3\u003e\u003cp data-pid=\"lXlYwRmt\"\u003e参数高效微调（Parameter-Efficient Fine-Tuning，PEFT）是一系列旨在以较少的计算资源和数据量，实现与全参数微调相近性能的技术。这类方法通常\u003cb\u003e冻结\u003c/b\u003e预训练模型的大部分参数，只训练\u003cb\u003e少量额外的参数\u003c/b\u003e。\u003c/p\u003e\u003ch3\u003e1.2.1 LoRA 系列技术\u003c/h3\u003e\u003cp data-pid=\"eUu9a9-i\"\u003e\u003cb\u003e低秩适配（LoRA）\u003c/b\u003e 的核心思想是冻结原始参数，通过低秩分解引入可训练参数。\u003c/p\u003e\u003cp data-pid=\"uDtEFRzD\"\u003e\u003cb\u003e数学原理\u003c/b\u003e：\u003c/p\u003e\u003cp data-pid=\"cqiZg5HG\"\u003eLoRA 假设预训练模型的参数矩阵的更新可以表示为一个低秩矩阵。具体来说，对于一个预训练好的权重矩阵\u003cimg src=\"https://www.zhihu.com/equation?tex=W_0+%5Cin+%5Cmathbb%7BR%7D%5E%7Bd+%5Ctimes+k%7D%5C\" alt=\"W_0 \\in \\mathbb{R}^{d \\times k}\\\" eeimg=\"1\"/\u003e，LoRA 引入两个低秩矩阵\u003cimg src=\"https://www.zhihu.com/equation?tex=A+%5Cin+%5Cmathbb%7BR%7D%5E%7Bd+%5Ctimes+r%7D%5C\" alt=\"A \\in \\mathbb{R}^{d \\times r}\\\" eeimg=\"1\"/\u003e和\u003cimg src=\"https://www.zhihu.com/equation?tex=B+%5Cin+%5Cmathbb%7BR%7D%5E%7Br+%5Ctimes+k%7D%5C\" alt=\"B \\in \\mathbb{R}^{r \\times k}\\\" eeimg=\"1\"/\u003e，其中\u003cimg src=\"https://www.zhihu.com/equation?tex=r+%5Cll+%5Cmin%28d%2C+k%29%5C\" alt=\"r \\ll \\min(d, k)\\\" eeimg=\"1\"/\u003e是秩。在微调过程中，只优化\u003cimg src=\"https://www.zhihu.com/equation?tex=A%5C\" alt=\"A\\\" eeimg=\"1\"/\u003e和\u003cimg src=\"https://www.zhihu.com/equation?tex=B%5C\" alt=\"B\\\" eeimg=\"1\"/\u003e，而\u003cimg src=\"https://www.zhihu.com/equation?tex=W_0%5C\" alt=\"W_0\\\" eeimg=\"1\"/\u003e保持不变。更新后的权重矩阵为：\u003c/p\u003e\u003cp data-pid=\"CXbOv7Tk\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=W+%3D+W_0+%2B+BA%5C\" alt=\"W = W_0 + BA\\\" eeimg=\"1\"/\u003e\u003c/p\u003e\u003cp data-pid=\"q5HdFmWk\"\u003e由于\u003cimg src=\"https://www.zhihu.com/equation?tex=r%5C\" alt=\"r\\\" eeimg=\"1\"/\u003e远小于\u003cimg src=\"https://www.zhihu.com/equation?tex=d%5C\" alt=\"d\\\" eeimg=\"1\"/\u003e和\u003cimg src=\"https://www.zhihu.com/equation?tex=k%5C\" alt=\"k\\\" eeimg=\"1\"/\u003e，因此 LoRA 只需要训练很少的参数，就可以达到与全参数微调相近的性能。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-36a022d024c1348e5822f4416a366855_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"914\" data-rawheight=\"1328\" data-original-token=\"v2-36a022d024c1348e5822f4416a366855\" class=\"origin_image zh-lightbox-thumb\" width=\"914\" data-original=\"https://pic4.zhimg.com/v2-36a022d024c1348e5822f4416a366855_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"1Qid6k4M\"\u003e\u003cb\u003e伪代码示例\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-python3\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch.nn\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"nn\"\u003enn\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eLoRALayer\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModule\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\t\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ein_dim\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eout_dim\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erank\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\t\t\u003cspan class=\"nb\"\u003esuper\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\t\t\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003enn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eParameter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erandn\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ein_dim\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erank\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\t\t\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003enn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eParameter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ezeros\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erank\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eout_dim\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\t\t\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erank\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erank\u003c/span\u003e \u003cspan class=\"c1\"\u003e#  秩的大小\u003c/span\u003e\n\t\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eforward\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\t\t\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e@\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e \u003cspan class=\"o\"\u003e@\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 低秩矩阵乘积\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"W1vhrSTl\"\u003e\u003cb\u003e关键技术演进\u003c/b\u003e：\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic1.zhimg.com/v2-fab8602c3eb6950bf7c5ce68caa64e5a_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1340\" data-rawheight=\"862\" data-original-token=\"v2-fab8602c3eb6950bf7c5ce68caa64e5a\" class=\"origin_image zh-lightbox-thumb\" width=\"1340\" data-original=\"https://pic1.zhimg.com/v2-fab8602c3eb6950bf7c5ce68caa64e5a_r.jpg\"/\u003e\u003c/figure\u003e\u003cul\u003e\u003cli data-pid=\"cSC-zVN_\"\u003e\u003cb\u003eAdaLoRA\u003c/b\u003e：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"G_Z6VL6l\"\u003e\u003cb\u003e核心思想\u003c/b\u003e：AdaLoRA（Adaptive LoRA）旨在\u003cb\u003e动态调整各层的秩分配\u003c/b\u003e。\u003c/li\u003e\u003cli data-pid=\"VSCFAsoR\"\u003e\u003cb\u003e实现方式\u003c/b\u003e：AdaLoRA 通过一些指标（例如，梯度范数）来评估不同层的重要性，并根据重要性动态地调整 LoRA 的秩。更重要的层分配更高的秩，从而获得更好的性能。\u003c/li\u003e\u003c/ul\u003e\u003cli data-pid=\"593xV9kN\"\u003e\u003cb\u003eQLoRA\u003c/b\u003e：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"HP5neoy5\"\u003e\u003cb\u003e核心思想\u003c/b\u003e：QLoRA（Quantized LoRA）将\u003cb\u003e4-bit 量化\u003c/b\u003e与 LoRA 相结合，以进一步降低显存占用。\u003c/li\u003e\u003cli data-pid=\"wH2xOK9J\"\u003e\u003cb\u003e实现方式\u003c/b\u003e：QLoRA 首先将预训练模型的权重\u003cb\u003e量化\u003c/b\u003e为 4-bit 精度，然后在此基础上应用 LoRA。由于 4-bit 量化可以显著降低显存占用，因此 QLoRA 可以在有限的 GPU 资源上微调更大的模型。\u003c/li\u003e\u003cli data-pid=\"NHUTTehb\"\u003e\u003cb\u003e显存节省\u003c/b\u003e：QLoRA 可以节省高达 70% 的显存。\u003c/li\u003e\u003c/ul\u003e\u003cli data-pid=\"V2QpuvJT\"\u003e\u003cb\u003eDelta-LoRA\u003c/b\u003e：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"6WNXE3nV\"\u003e\u003cb\u003e核心思想\u003c/b\u003e：Delta-LoRA 引入\u003cb\u003e参数更新量的动量机制\u003c/b\u003e。\u003c/li\u003e\u003cli data-pid=\"zKBnyvK6\"\u003e\u003cb\u003e实现方式\u003c/b\u003e：Delta-LoRA 在更新 LoRA 参数时，考虑之前的更新方向和幅度，从而更稳定地进行微调。\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003ch3\u003e1.2.2 提示微调技术\u003c/h3\u003e\u003cp data-pid=\"tfEUjD5q\"\u003e\u003cb\u003e提示微调（Prompt Tuning）\u003c/b\u003e 是一种通过\u003cb\u003e设计合适的提示（Prompt）\u003c/b\u003e 来引导预训练模型完成下游任务的技术。与全参数微调和 LoRA 不同，提示微调通常\u003cb\u003e不直接修改预训练模型的参数\u003c/b\u003e（注意不是完全不修改参数），而是通过优化提示相关的向量来调整模型的行为。\u003c/p\u003e\u003cp data-pid=\"aPbPvXvN\"\u003e\u003cb\u003e核心思想\u003c/b\u003e：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"xLUicmIU\"\u003e\u003cb\u003e人工设计到可学习\u003c/b\u003e：提示工程（Prompt Engineering）经历了从人工设计提示到可学习提示的演进过程。\u003c/li\u003e\u003cli data-pid=\"DYEhTNnw\"\u003e\u003cb\u003e利用预训练知识\u003c/b\u003e：通过优化提示，引导模型利用预训练知识，从而减少对标注数据的依赖。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"lbu_UFMo\"\u003e\u003cb\u003e数学原理\u003c/b\u003e：\u003c/p\u003e\u003cp data-pid=\"LcUhh3tF\"\u003e公式\u003c/p\u003e\u003cp data-pid=\"oOCjz5Vd\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=h_%7Bprompt%7D+%3D+%5BP_1%3BP_2%3B%E2%80%A6%3BP_k%5D+%5Cquad+P_i+%5Cin+%5Cmathbb%7BR%7D%5E%7Bd%7D%5C\" alt=\"h_{prompt} = [P_1;P_2;…;P_k] \\quad P_i \\in \\mathbb{R}^{d}\\\" eeimg=\"1\"/\u003e\u003c/p\u003e\u003cp data-pid=\"VTXhcu87\"\u003e描述了\u003cb\u003e可学习的提示向量\u003c/b\u003e。其中，\u003cimg src=\"https://www.zhihu.com/equation?tex=h_%7Bprompt%7D%5C\" alt=\"h_{prompt}\\\" eeimg=\"1\"/\u003e表示提示向量，\u003cimg src=\"https://www.zhihu.com/equation?tex=P_i%5C\" alt=\"P_i\\\" eeimg=\"1\"/\u003e表示第\u003cimg src=\"https://www.zhihu.com/equation?tex=i%5C\" alt=\"i\\\" eeimg=\"1\"/\u003e个可训练的提示向量，\u003cimg src=\"https://www.zhihu.com/equation?tex=k%5C\" alt=\"k\\\" eeimg=\"1\"/\u003e表示提示的长度，\u003cimg src=\"https://www.zhihu.com/equation?tex=d%5C\" alt=\"d\\\" eeimg=\"1\"/\u003e表示提示向量的维度。\u003c/p\u003e\u003cp data-pid=\"1TOhAHMD\"\u003e\u003cb\u003e位置选择策略\u003c/b\u003e：\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic4.zhimg.com/v2-cd3455b76c8120f745d84f2d87147385_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1150\" data-rawheight=\"744\" data-original-token=\"v2-cd3455b76c8120f745d84f2d87147385\" class=\"origin_image zh-lightbox-thumb\" width=\"1150\" data-original=\"https://pic4.zhimg.com/v2-cd3455b76c8120f745d84f2d87147385_r.jpg\"/\u003e\u003c/figure\u003e\u003cul\u003e\u003cli data-pid=\"3nkTjEMF\"\u003e\u003cb\u003ePrefix-Tuning\u003c/b\u003e（粉色）：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"x05jQ4Cx\"\u003e\u003cb\u003e核心思想\u003c/b\u003e：只在\u003cb\u003e每层\u003c/b\u003e的\u003cb\u003e开头\u003c/b\u003e插入可训练的提示向量。\u003c/li\u003e\u003cli data-pid=\"71I-nIp3\"\u003e\u003cb\u003e数学形式\u003c/b\u003e：\u003cimg src=\"https://www.zhihu.com/equation?tex=h%5E%7Bl%7D+%3D+%5Ctext%7BTransformer%7D%28%5B%5Ctext%7BPrefix%7D%5El%3B+x%5E%7Bl%7D%5D%29%5C\" alt=\"h^{l} = \\text{Transformer}([\\text{Prefix}^l; x^{l}])\\\" eeimg=\"1\"/\u003e\u003c/li\u003e\u003cli data-pid=\"LbIbuUcf\"\u003e\u003cb\u003e参数量\u003c/b\u003e：每层新增参数\u003cimg src=\"https://www.zhihu.com/equation?tex=d+%5Ctimes+r%5C\" alt=\"d \\times r\\\" eeimg=\"1\"/\u003e（\u003cimg src=\"https://www.zhihu.com/equation?tex=d%5C\" alt=\"d\\\" eeimg=\"1\"/\u003e为维度，\u003cimg src=\"https://www.zhihu.com/equation?tex=r%5C\" alt=\"r\\\" eeimg=\"1\"/\u003e为前缀长度）\u003c/li\u003e\u003cli data-pid=\"pU0T_8EW\"\u003e\u003cb\u003e优点\u003c/b\u003e：Prefix-Tuning 可以有效地影响模型的每一层，从而更好地调整模型的行为。\u003c/li\u003e\u003cli data-pid=\"yLAwwe-Y\"\u003e\u003cb\u003e缺点\u003c/b\u003e：Prefix-Tuning 需要插入大量的提示向量，可能会增加计算成本。\u003c/li\u003e\u003c/ul\u003e\u003cli data-pid=\"6tSMHc7l\"\u003e\u003cb\u003eP-Tuning v2\u003c/b\u003e（绿色）：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"Q9H6T5d1\"\u003e\u003cb\u003e核心思想\u003c/b\u003e：\u003cb\u003e分层插入\u003c/b\u003e位置\u003cb\u003e可学习\u003c/b\u003e。\u003c/li\u003e\u003cli data-pid=\"4hSSn3L7\"\u003e\u003cb\u003e实现方式\u003c/b\u003e：P-Tuning v2 首先将提示向量插入到不同的层中，然后通过训练来确定每个提示向量的最佳位置。\u003c/li\u003e\u003cli data-pid=\"Ij2Cd8nJ\"\u003e\u003cb\u003e数学形式\u003c/b\u003e：\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Ctext%7BPosition%7D%5El+%3D+%5Ctext%7Bsoftmax%7D%28W_p%5El+%5Ccdot+x%5El%29%5C\" alt=\"\\text{Position}^l = \\text{softmax}(W_p^l \\cdot x^l)\\\" eeimg=\"1\"/\u003e\u003c/li\u003e\u003cli data-pid=\"YBerba3b\"\u003e\u003cb\u003e优点\u003c/b\u003e：P-Tuning v2 可以更灵活地调整提示向量的位置，从而更好地适应不同的任务。\u003c/li\u003e\u003c/ul\u003e\u003cli data-pid=\"weJXdC0z\"\u003e\u003cb\u003ePrompt-Tuning\u003c/b\u003e（蓝色）：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"iZl_-DLQ\"\u003e\u003cb\u003e核心思想\u003c/b\u003e：仅在\u003cb\u003e输入层\u003c/b\u003e添加可训练提示词。\u003c/li\u003e\u003cli data-pid=\"IUMjaEm4\"\u003e\u003cb\u003e参数量\u003c/b\u003e：仅需\u003cimg src=\"https://www.zhihu.com/equation?tex=k+%5Ctimes+d%5C\" alt=\"k \\times d\\\" eeimg=\"1\"/\u003e（\u003cimg src=\"https://www.zhihu.com/equation?tex=k%5C\" alt=\"k\\\" eeimg=\"1\"/\u003e为提示词数量）\u003c/li\u003e\u003cli data-pid=\"VouPBzxw\"\u003e\u003cb\u003e数学形式\u003c/b\u003e：\u003cimg src=\"https://www.zhihu.com/equation?tex=h+%3D+%5Ctext%7BLM%7D%28%5B%5Ctext%7BPrompt%7D%3B+x%5D%29%5C\" alt=\"h = \\text{LM}([\\text{Prompt}; x])\\\" eeimg=\"1\"/\u003e\u003c/li\u003e\u003cli data-pid=\"mwgsfDhf\"\u003e\u003cb\u003e优点\u003c/b\u003e：Prompt-Tuning 的实现简单，计算成本低。\u003c/li\u003e\u003cli data-pid=\"YxOhbiYx\"\u003e\u003cb\u003e缺点\u003c/b\u003e：Prompt-Tuning 的效果可能不如 Prefix-Tuning 和 P-Tuning v2。\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cp data-pid=\"zGDapIkQ\"\u003e\u003cb\u003e关键差异对比表：\u003c/b\u003e\u003c/p\u003e\u003ctable data-draft-node=\"block\" data-draft-type=\"table\" data-size=\"normal\" data-row-style=\"normal\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003cth\u003e维度\u003c/th\u003e\u003cth\u003ePrefix-Tuning\u003c/th\u003e\u003cth\u003eP-Tuning v2\u003c/th\u003e\u003cth\u003ePrompt-Tuning\u003c/th\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e插入位置\u003c/td\u003e\u003ctd\u003e每层输入序列头部\u003c/td\u003e\u003ctd\u003e每层可学习位置\u003c/td\u003e\u003ctd\u003e仅输入层头部\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e可训练参数占比\u003c/td\u003e\u003ctd\u003e0.5%-2%\u003c/td\u003e\u003ctd\u003e0.3%-1.5%\u003c/td\u003e\u003ctd\u003e0.01%-0.1%\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e典型应用场景\u003c/td\u003e\u003ctd\u003e复杂逻辑推理\u003c/td\u003e\u003ctd\u003e多任务适配\u003c/td\u003e\u003ctd\u003e轻量化快速部署\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e显存占用\u003c/td\u003e\u003ctd\u003e高（需存储各层前缀）\u003c/td\u003e\u003ctd\u003e中\u003c/td\u003e\u003ctd\u003e极低\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e训练速度\u003c/td\u003e\u003ctd\u003e慢（需反向传播至各层）\u003c/td\u003e\u003ctd\u003e中等\u003c/td\u003e\u003ctd\u003e快（仅输入层梯度）\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003cp data-pid=\"TAMiZL_N\"\u003e\u003cb\u003e技术演进趋势：\u003c/b\u003e\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-6b046f9b3fb3e0cd868514e7991e280e_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1194\" data-rawheight=\"98\" data-original-token=\"v2-6b046f9b3fb3e0cd868514e7991e280e\" class=\"origin_image zh-lightbox-thumb\" width=\"1194\" data-original=\"https://pic3.zhimg.com/v2-6b046f9b3fb3e0cd868514e7991e280e_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"MFKN1POx\"\u003e\u003cb\u003e动态混合提示\u003c/b\u003e作为最新发展方向，允许模型自主决定：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"xFd5ORX9\"\u003e是否需要在某层插入提示\u003c/li\u003e\u003cli data-pid=\"R7-Xbt_M\"\u003e最佳提示插入位置\u003c/li\u003e\u003cli data-pid=\"GUixNZSF\"\u003e不同提示向量的权重分配\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003e1.3 领域自适应微调\u003c/h3\u003e\u003cp data-pid=\"AKLtz2Ev\"\u003e\u003cb\u003e领域自适应微调（Domain Adaptive Fine-Tuning）\u003c/b\u003e 是指在特定领域的数据上对预训练模型进行微调，以使其更好地适应该领域的任务。这种方法在医疗、法律等专业领域尤其重要，因为这些领域的数据具有独特的特点和术语。\u003c/p\u003e\u003cp data-pid=\"lWGAgZGN\"\u003e\u003cb\u003e案例：医疗问答系统的微调策略\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"FdTOp061\"\u003e以一个医疗问答系统的微调策略为例：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"8Jddh8q5\"\u003e\u003cb\u003e数据构造\u003c/b\u003e：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"PFBzuOgh\"\u003e\u003cb\u003e混合通用指令数据 (20%) + 专业文献问答 (80%)\u003c/b\u003e：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"72oAys_J\"\u003e\u003cb\u003e通用指令数据\u003c/b\u003e：例如，\u0026#34;请解释什么是高血压？\u0026#34;、\u0026#34;如何预防感冒？\u0026#34; 等。这些数据可以帮助模型保持通用的语言理解能力。\u003c/li\u003e\u003cli data-pid=\"3TDnCgGy\"\u003e\u003cb\u003e专业文献问答\u003c/b\u003e：从医学文献中提取问题和答案，例如，\u0026#34;《柳叶刀》杂志最近发表了关于 COVID-19 疫苗有效性的研究，请总结其主要发现。\u0026#34;。这些数据可以帮助模型学习专业的医学知识。\u003c/li\u003e\u003cli data-pid=\"fmvztHGv\"\u003e\u003cb\u003e比例\u003c/b\u003e：混合比例的选择需要根据实际情况进行调整。一般来说，如果领域数据比较稀缺，可以适当增加通用指令数据的比例。\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cli data-pid=\"RFGGTOMD\"\u003e\u003cb\u003e分层微调\u003c/b\u003e：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"b75OU8zY\"\u003e\u003cb\u003e计算效率\u003c/b\u003e：只微调部分层可以显著降低计算成本。\u003c/li\u003e\u003cli data-pid=\"zZKQcuCY\"\u003e\u003cb\u003e避免灾难性遗忘\u003c/b\u003e：冻结大部分层可以保留预训练模型的通用知识，从而避免灾难性遗忘。\u003c/li\u003e\u003cli data-pid=\"aJPAyfGC\"\u003e\u003cb\u003e微调后 10% 的原因\u003c/b\u003e：这是一个经验性的选择，通常认为后几层更接近特定任务，因此微调这些层可以更好地适应领域数据。\u003c/li\u003e\u003cli data-pid=\"7D5mOSby\"\u003e\u003cb\u003e需要实验验证\u003c/b\u003e：最佳的微调层数需要根据实际情况进行实验验证。\u003c/li\u003e\u003c/ul\u003e\u003cli data-pid=\"D0RQMLl-\"\u003e\u003cb\u003e评估指标\u003c/b\u003e：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"1m8lz3jx\"\u003e\u003cb\u003eFActScore（事实一致性评分）\u0026gt; 0.85\u003c/b\u003e：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"ahg5oASp\"\u003e\u003cb\u003eFActScore\u003c/b\u003e：一种用于评估模型生成答案的事实一致性的指标。FActScore 越高，表示模型生成的答案与事实越一致。\u003c/li\u003e\u003cli data-pid=\"eZFUcPHN\"\u003e\u003cb\u003e重要性\u003c/b\u003e：在医疗领域，事实一致性至关重要。如果模型生成错误的医疗信息，可能会对患者的健康造成严重影响。\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003c/ul\u003e\u003ch2\u003e二、强化学习：从对齐到推理\u003c/h2\u003e\u003ch3\u003e2.1 LLM推理技术全景图\u003c/h3\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-b4f88aeb2659f158f0313a8213693bb9_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1394\" data-rawheight=\"678\" data-original-token=\"v2-b4f88aeb2659f158f0313a8213693bb9\" class=\"origin_image zh-lightbox-thumb\" width=\"1394\" data-original=\"https://pic2.zhimg.com/v2-b4f88aeb2659f158f0313a8213693bb9_r.jpg\"/\u003e\u003c/figure\u003e\u003ch3\u003e2.2 奖励建模\u003c/h3\u003e\u003cp data-pid=\"lBixv0Ak\"\u003e\u003cb\u003e奖励建模（Reward Modeling）\u003c/b\u003e 是很多 RL 方法的关键步骤之一。它的目标是根据人类的偏好数据，训练一个能够预测人类对模型输出的偏好程度的模型。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"PDaYKqVY\"\u003e\u003cb\u003e偏好数据\u003c/b\u003e：训练奖励模型需要大量的偏好数据。这些数据通常由人工标注，例如，让人类对不同的模型输出进行排序或打分。\u003c/li\u003e\u003cli data-pid=\"C0-FkTuh\"\u003e\u003cb\u003e奖励模型的选择\u003c/b\u003e：奖励模型可以是任何一种机器学习模型，例如，线性模型、神经网络等。常见的选择是使用与预训练语言模型结构相似的模型。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"oq5OzIgt\"\u003e\u003cb\u003eBradley-Terry 模型\u003c/b\u003e是一种常用的奖励建模方法：假设对于给定的输入\u003cimg src=\"https://www.zhihu.com/equation?tex=x%5C\" alt=\"x\\\" eeimg=\"1\"/\u003e，人类更喜欢输出\u003cimg src=\"https://www.zhihu.com/equation?tex=y_i%5C\" alt=\"y_i\\\" eeimg=\"1\"/\u003e而不是\u003cimg src=\"https://www.zhihu.com/equation?tex=y_j%5C\" alt=\"y_j\\\" eeimg=\"1\"/\u003e的概率可以表示为：\u003c/p\u003e\u003cp data-pid=\"ElcBKZL2\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=P%28y_i+%5Csucc+y_j%7Cx%29+%3D+%5Cfrac%7B%5Cexp%28R%28x%2Cy_i%29%29%7D%7B%5Cexp%28R%28x%2Cy_i%29%29+%2B+%5Cexp%28R%28x%2Cy_j%29%29%7D%5C\" alt=\"P(y_i \\succ y_j|x) = \\frac{\\exp(R(x,y_i))}{\\exp(R(x,y_i)) + \\exp(R(x,y_j))}\\\" eeimg=\"1\"/\u003e\u003c/p\u003e\u003cp data-pid=\"UxQihDjT\"\u003e其中，\u003cimg src=\"https://www.zhihu.com/equation?tex=R%28x%2C+y%29%5C\" alt=\"R(x, y)\\\" eeimg=\"1\"/\u003e是奖励模型给出的奖励值，表示模型认为输出\u003cimg src=\"https://www.zhihu.com/equation?tex=y%5C\" alt=\"y\\\" eeimg=\"1\"/\u003e对于输入\u003cimg src=\"https://www.zhihu.com/equation?tex=x%5C\" alt=\"x\\\" eeimg=\"1\"/\u003e的好坏程度。\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Csucc%5C\" alt=\"\\succ\\\" eeimg=\"1\"/\u003e表示偏好关系，即\u003cimg src=\"https://www.zhihu.com/equation?tex=y_i+%5Csucc+y_j%5C\" alt=\"y_i \\succ y_j\\\" eeimg=\"1\"/\u003e表示人类更喜欢\u003cimg src=\"https://www.zhihu.com/equation?tex=y_i%5C\" alt=\"y_i\\\" eeimg=\"1\"/\u003e而不是\u003cimg src=\"https://www.zhihu.com/equation?tex=y_j%5C\" alt=\"y_j\\\" eeimg=\"1\"/\u003e。\u003c/p\u003e\u003cp data-pid=\"nFyhzNDk\"\u003e\u003cb\u003e训练目标\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"v1P0HwLZ\"\u003e训练奖励模型的\u003cb\u003e目标\u003c/b\u003e是\u003cb\u003e最小化负对数似然\u003c/b\u003e：\u003c/p\u003e\u003cp data-pid=\"378yH1i8\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D_%7BBT%7D+%3D+-%5Csum+%5Clog+P%28y_i+%5Csucc+y_j%7Cx%29%5C\" alt=\"\\mathcal{L}_{BT} = -\\sum \\log P(y_i \\succ y_j|x)\\\" eeimg=\"1\"/\u003e\u003c/p\u003e\u003cp data-pid=\"ySRtZB3Q\"\u003e这个公式表示，我们希望奖励模型给出的奖励值能够尽可能地符合人类的偏好。也就是说，如果人类更喜欢\u003cimg src=\"https://www.zhihu.com/equation?tex=y_i%5C\" alt=\"y_i\\\" eeimg=\"1\"/\u003e而不是\u003cimg src=\"https://www.zhihu.com/equation?tex=y_j%5C\" alt=\"y_j\\\" eeimg=\"1\"/\u003e，那么我们希望\u003cimg src=\"https://www.zhihu.com/equation?tex=R%28x%2C+y_i%29%5C\" alt=\"R(x, y_i)\\\" eeimg=\"1\"/\u003e尽可能地大于\u003cimg src=\"https://www.zhihu.com/equation?tex=R%28x%2C+y_j%29%5C\" alt=\"R(x, y_j)\\\" eeimg=\"1\"/\u003e。\u003c/p\u003e\u003ch3\u003e2.3 主流优化算法对比\u003c/h3\u003e\u003ctable data-draft-node=\"block\" data-draft-type=\"table\" data-size=\"normal\" data-row-style=\"normal\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003cth\u003e方法\u003c/th\u003e\u003cth\u003e更新机制\u003c/th\u003e\u003cth\u003e优势\u003c/th\u003e\u003cth\u003e局限\u003c/th\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003ePPO\u003c/td\u003e\u003ctd\u003e带约束的策略梯度\u003c/td\u003e\u003ctd\u003e训练稳定\u003c/td\u003e\u003ctd\u003e需要价值函数估计\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eDPO\u003c/td\u003e\u003ctd\u003e直接偏好优化\u003c/td\u003e\u003ctd\u003e无需奖励模型\u003c/td\u003e\u003ctd\u003e依赖高质量偏好数据\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eGRPO\u003c/td\u003e\u003ctd\u003e组相对策略优化\u003c/td\u003e\u003ctd\u003e降低方差\u003c/td\u003e\u003ctd\u003e需要并行采样多个响应\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-7afd94ac417b0429eee717697839ed91_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"676\" data-rawheight=\"666\" data-original-token=\"v2-7afd94ac417b0429eee717697839ed91\" class=\"origin_image zh-lightbox-thumb\" width=\"676\" data-original=\"https://pic2.zhimg.com/v2-7afd94ac417b0429eee717697839ed91_r.jpg\"/\u003e\u003c/figure\u003e\u003ch3\u003e2.4 过程奖励 Vs 结果奖励\u003c/h3\u003e\u003cp data-pid=\"a4TAEyB8\"\u003e在强化学习中，\u003cb\u003e奖励函数\u003c/b\u003e的设计至关重要。奖励函数定义了模型在不同状态下应该获得的奖励，从而引导模型学习到期望的行为。\u003c/p\u003e\u003cp data-pid=\"VETMVtFc\"\u003e根据奖励的来源，可以将奖励分为\u003cb\u003e过程奖励\u003c/b\u003e和\u003cb\u003e结果奖励\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"jaqBTwTp\"\u003e\u003cb\u003e过程奖励（Process Reward）\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"HWM0_GRM\"\u003e过程奖励是指在\u003cb\u003e每个步骤\u003c/b\u003e中，根据模型的\u003cb\u003e行为\u003c/b\u003e给出的奖励。过程奖励可以提供更\u003cb\u003e密集\u003c/b\u003e的反馈信号，帮助模型更快地学习。但缺点是设计比较\u003cb\u003e困难\u003c/b\u003e，需要对任务有深入的理解。\u003c/p\u003e\u003cp data-pid=\"b8b8zSxM\"\u003e举个例子：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-python3\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecalculate_step_reward\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\t\u003cspan class=\"c1\"\u003e# 1. 语法正确性检查\u003c/span\u003e\n\t\u003cspan class=\"n\"\u003esyntax\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003echeck_syntax\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\t\u003cspan class=\"c1\"\u003e# 2. 逻辑连贯性评估\u003c/span\u003e\n\t\u003cspan class=\"n\"\u003ecoherence\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict_coherence\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\t\u003cspan class=\"c1\"\u003e# 3. 事实一致性验证\u003c/span\u003e\n\t\u003cspan class=\"n\"\u003efact_check\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eretrieve_evidence\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\t\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.3\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003esyntax\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.5\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003ecoherence\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003efact_check\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"QiApRqTq\"\u003e在这个例子中，奖励函数考虑了三个方面：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"U6ocCx42\"\u003e\u003cb\u003e语法正确性检查\u003c/b\u003e：检查模型生成的文本是否符合语法规则。例如，可以使用语法分析器来判断文本是否存在语法错误。\u003c/li\u003e\u003cli data-pid=\"MIxseTYX\"\u003e\u003cb\u003e逻辑连贯性评估\u003c/b\u003e：评估模型生成的文本是否逻辑连贯。例如，可以使用语言模型来预测文本的连贯性。\u003c/li\u003e\u003cli data-pid=\"wTsyLMuW\"\u003e\u003cb\u003e事实一致性验证\u003c/b\u003e：验证模型生成的文本是否与事实相符。例如，可以使用知识库来检索相关信息，然后判断模型生成的文本是否与知识库中的信息一致。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"2oGe_wvP\"\u003e对这三个方面进行加权求和，得到最终的奖励值。\u003cb\u003e权重\u003c/b\u003e的选择需要根据实际情况进行调整。一般来说，更重要的方面应该分配更高的权重。\u003c/p\u003e\u003cp data-pid=\"IO0M_iuw\"\u003e\u003cb\u003e结果奖励（Outcome Reward）\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"ElbJ3LAQ\"\u003e结果奖励是指在\u003cb\u003e任务完成后\u003c/b\u003e，根据模型的\u003cb\u003e最终结果\u003c/b\u003e给出的奖励。结果奖励的设计比较\u003cb\u003e简单\u003c/b\u003e，只需要关注最终结果即可。但可能提供较\u003cb\u003e稀疏\u003c/b\u003e的反馈信号，导致模型学习困难。典型应用场景包括：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"FSSQOAfy\"\u003e\u003cb\u003e数学问题\u003c/b\u003e：最终答案正确性。例如，如果模型生成的答案与正确答案一致，则给出正奖励；否则，给出负奖励。\u003c/li\u003e\u003cli data-pid=\"40Z5o4ww\"\u003e\u003cb\u003e代码生成\u003c/b\u003e：通过单元测试的比例。例如，如果模型生成的代码能够通过所有的单元测试，则给出正奖励；否则，给出负奖励。\u003c/li\u003e\u003cli data-pid=\"SF--V4J7\"\u003e\u003cb\u003e对话系统\u003c/b\u003e：用户满意度评分。例如，如果用户对模型的回复感到满意，则给出正奖励；否则，给出负奖励。\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003e2.5 强化学习的推理增强实践\u003c/h3\u003e\u003cp data-pid=\"MD6eXeSf\"\u003e举一个 \u003cb\u003e思维树（ToT）算法框架\u003c/b\u003e 的例子：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"anESb0ov\"\u003e思维生成：基于当前状态生成候选思考\u003c/li\u003e\u003cli data-pid=\"RTR-ggF-\"\u003e状态评估：使用价值函数评估每个候选\u003c/li\u003e\u003cli data-pid=\"qIeKFpB6\"\u003e广度优先搜索：保留 top-k 候选继续扩展\u003c/li\u003e\u003cli data-pid=\"vvNtiK_x\"\u003e回溯更新：反向传播累积奖励\u003c/li\u003e\u003c/ul\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-b40e19c9b5b2477204b7e549a89ea6a1_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1092\" data-rawheight=\"1224\" data-original-token=\"v2-b40e19c9b5b2477204b7e549a89ea6a1\" class=\"origin_image zh-lightbox-thumb\" width=\"1092\" data-original=\"https://picx.zhimg.com/v2-b40e19c9b5b2477204b7e549a89ea6a1_r.jpg\"/\u003e\u003c/figure\u003e\u003ch2\u003e三、测试时扩展：推理即搜索\u003c/h2\u003e\u003ch3\u003e3.1 主流推理增强技术\u003c/h3\u003e\u003ctable data-draft-node=\"block\" data-draft-type=\"table\" data-size=\"normal\" data-row-style=\"normal\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003cth\u003e方法\u003c/th\u003e\u003cth\u003e核心思想\u003c/th\u003e\u003cth\u003e适用场景\u003c/th\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e链式思考（CoT）\u003c/td\u003e\u003ctd\u003e显式生成推理步骤\u003c/td\u003e\u003ctd\u003e数学解题、逻辑推理\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e自洽性解码（SC）\u003c/td\u003e\u003ctd\u003e多路径投票机制\u003c/td\u003e\u003ctd\u003e开放域问答\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e思维树（ToT）\u003c/td\u003e\u003ctd\u003e树形结构空间搜索\u003c/td\u003e\u003ctd\u003e复杂规划问题\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e蒙特卡洛树搜索（MCTS）\u003c/td\u003e\u003ctd\u003e模拟 - 评估 - 回溯机制\u003c/td\u003e\u003ctd\u003e游戏类、策略性问题\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003ch3\u003e3.2 计算最优扩展策略\u003c/h3\u003e\u003cp data-pid=\"ac6zeq7C\"\u003e不同的推理增强技术适用于不同的场景。如何根据具体的问题选择最优的推理增强技术呢？这就是 \u003cb\u003e计算最优扩展策略\u003c/b\u003e 要解决的问题。\u003c/p\u003e\u003cp data-pid=\"4mwYa46S\"\u003e\u003cb\u003e动态计算分配算法\u003c/b\u003e 的核心思想是\u003cb\u003e根据问题的难度动态地分配计算资源\u003c/b\u003e。对于简单的问题，可以使用简单的推理方法；对于复杂的问题，可以使用更复杂的推理方法。\u003c/p\u003e\u003cp data-pid=\"rsFFtL7t\"\u003e\u003cb\u003e伪代码示例\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-python3\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003edynamic_compute_allocation\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003equery\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\t\u003cspan class=\"n\"\u003edifficulty\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eestimate_difficulty\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003equery\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\t\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003edifficulty\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.3\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\t\t\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003egreedy_decode\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\t\u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.3\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;=\u003c/span\u003e \u003cspan class=\"n\"\u003edifficulty\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.7\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\t\t\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ebeam_search\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ewidth\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\t\u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\t\t\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003emonte_carlo_tree_search\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edepth\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"x_IjGsOc\"\u003e在这个例子中，\u003ccode\u003eestimate_difficulty\u003c/code\u003e 函数用于评估问题的难度。根据问题的难度，选择不同的推理方法。\u003c/p\u003e\u003cp data-pid=\"OW755e9n\"\u003e如何评估问题的难度呢？一个思路是\u003cb\u003e根据问题的特征来预测\u003c/b\u003e。比如：\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"NiDVpZ9L\"\u003e\u003cb\u003e问题长度与复杂度\u003c/b\u003e：问题越长，复杂度越高，难度越大。\u003c/li\u003e\u003cli data-pid=\"r4IExk36\"\u003e\u003cb\u003e领域专业性指标\u003c/b\u003e：问题涉及的领域越专业，难度越大。例如，医学问题的难度通常高于一般问题。\u003c/li\u003e\u003cli data-pid=\"-VNfjSqq\"\u003e\u003cb\u003e历史正确率统计\u003c/b\u003e：如果模型在过去的历史数据中对类似问题的正确率较低，则说明该问题的难度较大。\u003c/li\u003e\u003cli data-pid=\"Mb2s3WMu\"\u003e\u003cb\u003e语义模糊性评分\u003c/b\u003e：如果问题存在语义模糊性，则难度较大。例如，\u0026#34;苹果公司最近发布了什么？\u0026#34; 这个问题存在语义模糊性，因为 \u0026#34;发布\u0026#34; 可以指发布新产品、发布财报等。\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003e3.3 验证器增强推理\u003c/h3\u003e\u003cp data-pid=\"aOAxomQ4\"\u003e\u003cb\u003e验证器增强推理\u003c/b\u003e 是一种通过使用验证器（Verifier）来检查模型生成的答案的正确性，从而提高推理准确率的技术。\u003c/p\u003e\u003cp data-pid=\"UMjeC2g6\"\u003e可以构建一个多层验证体系，对模型生成的答案进行多方面的验证。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"ajar-TlW\"\u003e\u003cb\u003e语法验证器\u003c/b\u003e：检查代码/公式语法。例如，可以使用语法分析器来判断代码或公式是否存在语法错误。\u003c/li\u003e\u003cli data-pid=\"tJDnL-pd\"\u003e\u003cb\u003e逻辑验证器\u003c/b\u003e：命题逻辑一致性检查。例如，可以使用逻辑推理引擎来判断命题是否符合逻辑。\u003c/li\u003e\u003cli data-pid=\"H4liIs6Q\"\u003e\u003cb\u003e事实验证器\u003c/b\u003e：知识库检索验证。例如，可以使用知识库来检索相关信息，然后判断模型生成的答案是否与知识库中的信息一致。\u003c/li\u003e\u003cli data-pid=\"R5D3OiY6\"\u003e\u003cb\u003e安全验证器\u003c/b\u003e：有害内容过滤。例如，可以使用有害内容检测模型来判断模型生成的文本是否包含有害内容。\u003c/li\u003e\u003c/ul\u003e\u003cp data-pid=\"duXsRiYJ\"\u003e下面这个公式描述了如何将多个验证器的结果组合起来：\u003c/p\u003e\u003cp data-pid=\"yP4KTLTv\"\u003e\u003cimg src=\"https://www.zhihu.com/equation?tex=V_%7Btotal%7D+%3D+%5Cprod_%7Bi%3D1%7D%5En+V_i%28s%29+%5Cquad+V_i+%5Cin+%5B0%2C1%5D%5C\" alt=\"V_{total} = \\prod_{i=1}^n V_i(s) \\quad V_i \\in [0,1]\\\" eeimg=\"1\"/\u003e\u003c/p\u003e\u003cp data-pid=\"NdcnlRD7\"\u003e其中，\u003cimg src=\"https://www.zhihu.com/equation?tex=V_%7Btotal%7D%5C\" alt=\"V_{total}\\\" eeimg=\"1\"/\u003e表示总的验证分数，\u003cimg src=\"https://www.zhihu.com/equation?tex=V_i%28s%29%5C\" alt=\"V_i(s)\\\" eeimg=\"1\"/\u003e表示第\u003cimg src=\"https://www.zhihu.com/equation?tex=i%5C\" alt=\"i\\\" eeimg=\"1\"/\u003e个验证器对答案\u003cimg src=\"https://www.zhihu.com/equation?tex=s%5C\" alt=\"s\\\" eeimg=\"1\"/\u003e的评分，\u003cimg src=\"https://www.zhihu.com/equation?tex=n%5C\" alt=\"n\\\" eeimg=\"1\"/\u003e表示验证器的数量。这个公式表示，总的验证分数是所有验证器评分的乘积。每个验证器的评分都在 0 到 1 之间，评分越高，表示答案越可靠。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"sTuIPO85\"\u003e\u003cb\u003e乘积的原因\u003c/b\u003e：使用乘积的原因是，如果有一个验证器的评分很低，则总的验证分数也会很低，这表示答案的可靠性较低。\u003c/li\u003e\u003cli data-pid=\"fQmptRHw\"\u003e\u003cb\u003e其他组合方式\u003c/b\u003e：除了乘积之外，还可以使用其他的组合方式，例如，加权平均。\u003c/li\u003e\u003c/ul\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-70daf2f26529e3b4a4d9b0eeb489bbcc_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1072\" data-rawheight=\"856\" data-original-token=\"v2-70daf2f26529e3b4a4d9b0eeb489bbcc\" class=\"origin_image zh-lightbox-thumb\" width=\"1072\" data-original=\"https://pica.zhimg.com/v2-70daf2f26529e3b4a4d9b0eeb489bbcc_r.jpg\"/\u003e\u003c/figure\u003e\u003ch2\u003e四、挑战与未来方向\u003c/h2\u003e\u003ch3\u003e4.1 现有技术瓶颈\u003c/h3\u003e\u003cp data-pid=\"itZU-Izm\"\u003e\u003cb\u003e奖励误导（Reward Hacking）\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"nHRPNzKE\"\u003e\u003cb\u003e具体挑战\u003c/b\u003e：\u003cb\u003e过度优化表面指标\u003c/b\u003e。奖励误导是指模型为了获得更高的奖励，采取了一些不符合人类意图的行为。例如，模型可能会生成一些表面上看起来很好，但实际上毫无意义或有害的输出。\u003c/li\u003e\u003cli data-pid=\"NUb_D0W0\"\u003e\u003cb\u003e示例\u003c/b\u003e：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"IyjIsNNu\"\u003e\u003cb\u003e社交媒体推荐系统\u003c/b\u003e：为了提高用户点击率，模型可能会推荐一些标题耸人听闻、内容低俗的文章，而不是真正有价值的文章。\u003c/li\u003e\u003cli data-pid=\"IPyoBssJ\"\u003e\u003cb\u003e对话系统\u003c/b\u003e：为了获得更高的用户满意度评分，模型可能会生成一些讨好用户、但实际上不解决问题的回复。\u003c/li\u003e\u003c/ul\u003e\u003cli data-pid=\"ZzsHVIcA\"\u003e\u003cb\u003e当前最佳方案\u003c/b\u003e：\u003cb\u003e多目标对抗训练\u003c/b\u003e。多目标对抗训练是一种通过同时优化多个目标，并引入对抗性损失来防止模型过度优化表面指标的技术。\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"ZlNYJ-6V\"\u003e\u003cb\u003e多目标\u003c/b\u003e：例如，可以同时优化用户点击率和内容质量。\u003c/li\u003e\u003cli data-pid=\"DBJLYzVT\"\u003e\u003cb\u003e对抗性损失\u003c/b\u003e：引入一个对抗模型，用于识别模型生成的欺骗性输出，并惩罚生成这些输出的模型。\u003cbr/\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-5140cf182f996bce679d5c7e29ffbc42_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1194\" data-rawheight=\"734\" data-original-token=\"v2-5140cf182f996bce679d5c7e29ffbc42\" class=\"origin_image zh-lightbox-thumb\" width=\"1194\" data-original=\"https://pic3.zhimg.com/v2-5140cf182f996bce679d5c7e29ffbc42_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"I0FWuuRI\"\u003e\u003cb\u003e长程推理（Long-Range Reasoning）\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"tH1083HA\"\u003e\u003cb\u003e具体挑战\u003c/b\u003e：\u003cb\u003e超过 128k tokens 的连贯性\u003c/b\u003e。长程推理是指模型在处理长文本时，保持上下文连贯性的能力。由于 Transformer 模型的计算复杂度与序列长度成正比，因此处理长文本的计算成本非常高。此外，模型在长文本中容易出现信息丢失和梯度消失等问题，导致连贯性下降。\u003c/li\u003e\u003cli data-pid=\"FUmzYjmU\"\u003e\u003cb\u003e示例\u003c/b\u003e：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"kEUFFhC5\"\u003e\u003cb\u003e小说生成\u003c/b\u003e：模型难以生成超过 128k tokens 的连贯小说，因为在长文本中，角色的行为和情节的发展容易出现矛盾。\u003c/li\u003e\u003cli data-pid=\"usVdolGB\"\u003e\u003cb\u003e代码理解\u003c/b\u003e：模型难以理解超过 128k tokens 的复杂代码库，因为代码中的依赖关系和调用关系非常复杂。\u003c/li\u003e\u003c/ul\u003e\u003cli data-pid=\"ax1G27Cg\"\u003e\u003cb\u003e当前最佳方案\u003c/b\u003e：\u003cb\u003e层次化记忆机制\u003c/b\u003e。层次化记忆机制是一种通过将长文本分解为多个段落或章节，并使用层次化的记忆结构来存储和检索信息的技术。\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"1LrVAQzT\"\u003e\u003cb\u003e段落或章节\u003c/b\u003e：例如，可以将一篇小说分解为多个章节，每个章节包含若干段落。\u003c/li\u003e\u003cli data-pid=\"Jy3Huo7M\"\u003e\u003cb\u003e层次化的记忆结构\u003c/b\u003e：例如，可以使用一个全局记忆模块来存储整篇小说的概要信息，并使用多个局部记忆模块来存储每个章节的详细信息。\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pica.zhimg.com/v2-51be0533472c09590d127ef517351f70_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1434\" data-rawheight=\"718\" data-original-token=\"v2-51be0533472c09590d127ef517351f70\" class=\"origin_image zh-lightbox-thumb\" width=\"1434\" data-original=\"https://pica.zhimg.com/v2-51be0533472c09590d127ef517351f70_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"Y83-9ohh\"\u003e\u003cb\u003e个性化安全（Personalized Safety）\u003c/b\u003e\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"nNCsDpP7\"\u003e\u003cb\u003e具体挑战\u003c/b\u003e：\u003cb\u003e用户特定偏好与通用安全的平衡\u003c/b\u003e。不同的用户对安全的定义和容忍度不同。例如，一些用户可能对幽默的容忍度较高，而另一些用户可能认为某些幽默是冒犯性的。如何在满足用户个性化偏好的同时，保证模型的输出是安全的，是一个具有挑战性的问题。\u003c/li\u003e\u003cli data-pid=\"89eyaqpi\"\u003e\u003cb\u003e示例\u003c/b\u003e：\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"iYBGRhzb\"\u003e\u003cb\u003e对话系统\u003c/b\u003e：如何根据用户的个人喜好，生成既有趣又不会冒犯用户的回复？\u003c/li\u003e\u003cli data-pid=\"F1zDjtPv\"\u003e\u003cb\u003e内容生成\u003c/b\u003e：如何根据用户的兴趣，生成既有创意又不会传播虚假信息的文章？\u003c/li\u003e\u003c/ul\u003e\u003cli data-pid=\"30Am4B6Y\"\u003e\u003cb\u003e当前最佳方案\u003c/b\u003e：\u003cb\u003e差分隐私强化学习\u003c/b\u003e。差分隐私强化学习是一种通过在训练过程中添加噪声来保护用户隐私，并在推理时根据用户的偏好进行调整的技术。\u003c/li\u003e\u003cul\u003e\u003cli data-pid=\"R8k-MCK-\"\u003e\u003cb\u003e添加噪声\u003c/b\u003e：在训练过程中，向用户的偏好数据中添加噪声，使得模型无法精确地学习用户的偏好，从而保护用户的隐私。\u003c/li\u003e\u003cli data-pid=\"gXbNWFBd\"\u003e\u003cb\u003e根据用户的偏好进行调整\u003c/b\u003e：在推理时，根据用户的偏好，对模型的输出进行调整，使其更符合用户的需求。\u003cbr/\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-82c472044a92c65a1b1facc4e526986f_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1412\" data-rawheight=\"720\" data-original-token=\"v2-82c472044a92c65a1b1facc4e526986f\" class=\"origin_image zh-lightbox-thumb\" width=\"1412\" data-original=\"https://picx.zhimg.com/v2-82c472044a92c65a1b1facc4e526986f_r.jpg\"/\u003e\u003c/figure\u003e\u003ch3\u003e4.2 前沿研究方向\u003c/h3\u003e\u003cp data-pid=\"EfvBfdE-\"\u003e为了解决上述技术瓶颈，研究人员正在探索一些新的研究方向。比如 \u003cb\u003e元认知机制\u003c/b\u003e、\u003cb\u003e物理推理融合\u003c/b\u003e 、 \u003cb\u003e群体智能系统\u003c/b\u003e等。下面我将对这些方向进行更详细的讲解：\u003c/p\u003e\u003cp data-pid=\"bbG_EE1f\"\u003e\u003cb\u003e元认知机制（Meta-Cognition）\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"cjTCH4J6\"\u003e核心思想是\u003cb\u003e让模型学会何时需要深入思考\u003c/b\u003e。元认知是指对认知的认知，即对自己的思考过程的思考。通过赋予模型元认知能力，可以使其能够判断自身是否能够解决当前的问题，并根据需要分配更多的计算资源。\u003c/p\u003e\u003cp data-pid=\"4BHucJPU\"\u003e\u003cb\u003e伪代码示例\u003c/b\u003e：\u003c/p\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003ccode class=\"language-python3\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003emeta_cognition\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003equery\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\t\u003cspan class=\"n\"\u003euncertainty\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecalculate_uncertainty\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003equery\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\t\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003euncertainty\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003ethreshold\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\t\t\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003eallocate_more_compute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003equery\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\t\u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\t\t\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003efast_response\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003equery\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp data-pid=\"WkEuN5qu\"\u003e在这个例子中，\u003ccode\u003ecalculate_uncertainty\u003c/code\u003e 函数用于评估模型对当前问题的\u003cb\u003e不确定性\u003c/b\u003e。如果模型对当前问题的不确定性超过某个阈值，则说明该问题比较复杂，需要分配更多的计算资源（\u003ccode\u003eallocate_more_compute\u003c/code\u003e）；否则，说明该问题比较简单，可以使用快速响应（\u003ccode\u003efast_response\u003c/code\u003e）。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-d7a136e5a6c63228263e9885ee210538_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"952\" data-rawheight=\"924\" data-original-token=\"v2-d7a136e5a6c63228263e9885ee210538\" class=\"origin_image zh-lightbox-thumb\" width=\"952\" data-original=\"https://pic3.zhimg.com/v2-d7a136e5a6c63228263e9885ee210538_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"WdnLWCGi\"\u003e\u003cb\u003e物理推理融合（Physical Reasoning）\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"4hgcg3Aa\"\u003e核心思想是\u003cb\u003e将符号推理与神经网络结合\u003c/b\u003e。物理推理是指模型根据物理定律进行推理的能力。通过将符号推理与神经网络结合，可以使模型既能够利用神经网络的强大表示能力，又能够利用符号推理的精确性和可解释性。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-1ab879a7e71c9fa5154b720d421003a7_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"834\" data-rawheight=\"698\" data-original-token=\"v2-1ab879a7e71c9fa5154b720d421003a7\" class=\"origin_image zh-lightbox-thumb\" width=\"834\" data-original=\"https://picx.zhimg.com/v2-1ab879a7e71c9fa5154b720d421003a7_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"gCU1rrK9\"\u003e\u003cbr/\u003e通过将这些物理规则嵌入到模型中，可以使模型能够进行物理推理，例如，预测物体在自由落体运动中的位置和速度。\u003c/p\u003e\u003cp data-pid=\"N1SEgeSz\"\u003e\u003cb\u003e群体智能系统（Swarm Intelligence）\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"zH35x9xU\"\u003e群体智能是指由多个个体组成的系统，通过个体之间的协作来实现复杂问题的解决。通过构建多模型协作推理框架，可以使不同的模型发挥各自的优势，共同完成复杂的推理任务。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic3.zhimg.com/v2-3367ddcf3386cb827ab567889bbe77ac_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1182\" data-rawheight=\"370\" data-original-token=\"v2-3367ddcf3386cb827ab567889bbe77ac\" class=\"origin_image zh-lightbox-thumb\" width=\"1182\" data-original=\"https://pic3.zhimg.com/v2-3367ddcf3386cb827ab567889bbe77ac_r.jpg\"/\u003e\u003c/figure\u003e\u003cp data-pid=\"06mhOp2S\"\u003e在这个流程图中，「任务分解」Agent 负责将问题分解为多个子问题，并将这些子问题分配给各个子任务Agent。「结果整合」Agent 负责将这些结果整合起来，得到最终的答案。\u003c/p\u003e\u003ch2\u003e五、实践指南：如何选择后训练方案\u003c/h2\u003e\u003ch3\u003e5.1 决策流程图\u003c/h3\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-44b1e97efa5e13d3183a9b45f8542935_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1712\" data-rawheight=\"582\" data-original-token=\"v2-44b1e97efa5e13d3183a9b45f8542935\" class=\"origin_image zh-lightbox-thumb\" width=\"1712\" data-original=\"https://picx.zhimg.com/v2-44b1e97efa5e13d3183a9b45f8542935_r.jpg\"/\u003e\u003c/figure\u003e\u003ch3\u003e5.2 工具链推荐\u003c/h3\u003e\u003ctable data-draft-node=\"block\" data-draft-type=\"table\" data-size=\"normal\" data-row-style=\"normal\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003cth\u003e工具类型\u003c/th\u003e\u003cth\u003e推荐选项\u003c/th\u003e\u003cth\u003e核心功能\u003c/th\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e微调框架\u003c/td\u003e\u003ctd\u003eHuggingFace PEFT\u003c/td\u003e\u003ctd\u003eLoRA/QLoRA实现\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eRLHF平台\u003c/td\u003e\u003ctd\u003eTRL (Transformer RL)\u003c/td\u003e\u003ctd\u003ePPO/DPO实现\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e推理加速\u003c/td\u003e\u003ctd\u003evLLM\u003c/td\u003e\u003ctd\u003e分页注意力机制\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e监控评估\u003c/td\u003e\u003ctd\u003eWeights \u0026amp; Biases\u003c/td\u003e\u003ctd\u003e训练过程可视化\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003cp\u003e\u003c/p\u003e","is_labeled":false,"visited_count":10930,"thumbnails":["https://pic1.zhimg.com/50/v2-67cf28dcafb3c822d9599335428a87dd_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-50bef4bcf97bd4710f5f5814adfdce21_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-2dbf66043653a0f1fb3e05087d6e4d06_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-f58473c340a87bfc46c2b55c97d3491b_720w.jpg?source=b6762063","https://pica.zhimg.com/50/v2-6c1fd8992f04441ab53106bfd7241fed_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-15fc8cdf4f0fc59c3131f8c552319167_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-ed0c1fcaa176691228968c86018fade5_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-c506139d52c6a9a08293f63fc1ede887_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-a4324b8f968d3c0cd664795d6fb936ae_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-1212a51f9fdf572cd5a9ce5da234f478_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-dad9007e8349a55e291c86a5dba65c26_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-46e8c39a75150e3b8ebd68cb40a357cd_720w.jpg?source=b6762063","https://picx.zhimg.com/50/v2-670a81bdd87f9c9c9f8696049361f7c9_720w.jpg?source=b6762063"],"favorite_count":1005,"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 30201040247}","attached_info":"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","action_card":false},{"id":"62_1750898464.947","type":"feed","offset":62,"verb":"TOPIC_ACKNOWLEDGED_ARTICLE","created_time":1750898464,"updated_time":1750898464,"target":{"id":"603582603","type":"article","url":"https://api.zhihu.com/articles/603582603","author":{"id":"e92fdb27894dfa792af21058a5a0b426","url":"https://api.zhihu.com/people/e92fdb27894dfa792af21058a5a0b426","user_type":"people","url_token":"wen36","name":"洗了都要爱","headline":"当不了人民艺术家，那就当个人民的艺术家吧！","avatar_url":"https://picx.zhimg.com/50/v2-c1be5b32d88658609522d3ed728cb821_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":311,"is_following":false,"is_followed":false},"title":"林彪谈读书习惯","comment_permission":"all","created":1675560400,"updated":1675560400,"voteup_count":1032,"voting":0,"comment_count":59,"linkbox":{"category":"","pic":"","title":"","url":""},"excerpt":"林彪的书桌上平时只摆一部书，其它书刊统统不能放。这部书读完，再读另一部。 应该是用啥学啥，需要什么东西，学什么东西。搞什么“完整的”那一套，把那个东西神秘化，费力大，得不到什么好处。费力很大，使用很少。每读一本书，都要有明确的目的，有重点，有针对性。有些章节要精读，有些可以粗读，有些索性不读。读书切忌平均使用力量，有时一目一页，有时一目十行，有时则十目一行，这样就可以大省精力。读书有明确的目的性…","excerpt_new":"林彪的书桌上平时只摆一部书，其它书刊统统不能放。这部书读完，再读另一部。 应该是用啥学啥，需要什么东西，学什么东西。搞什么“完整的”那一套，把那个东西神秘化，费力大，得不到什么好处。费力很大，使用很少。每读一本书，都要有明确的目的，有重点，有针对性。有些章节要精读，有些可以粗读，有些索性不读。读书切忌平均使用力量，有时一目一页，有时一目十行，有时则十目一行，这样就可以大省精力。读书有明确的目的性…","preview_type":"default","preview_text":"","content":"\u003cp data-pid=\"YHjnBlC_\"\u003e林彪的书桌上平时只摆一部书，其它书刊统统不能放。这部书读完，再读另一部。\u003c/p\u003e\u003cul\u003e\u003cli data-pid=\"REu5uHFy\"\u003e应该是用啥学啥，需要什么东西，学什么东西。\u003c/li\u003e\u003cli data-pid=\"bxCKPnfQ\"\u003e搞什么“完整的”那一套，把那个东西神秘化，费力大，得不到什么好处。费力很大，使用很少。\u003c/li\u003e\u003cli data-pid=\"4xeqscWw\"\u003e每读一本书，都要有明确的目的，有重点，有针对性。有些章节要精读，有些可以粗读，有些索性不读。读书切忌平均使用力量，有时一目一页，有时一目十行，有时则十目一行，这样就可以大省精力。\u003c/li\u003e\u003cli data-pid=\"ZxiqenmP\"\u003e读书有明确的目的性，总是围绕当前的问题来读书。\u003c/li\u003e\u003cli data-pid=\"2YcWRvkp\"\u003e学习毛主席著作，要带着问题学，活学活用，学用结合。急用先学，立竿见影，在用字上狠下功夫。\u003c/li\u003e\u003cli data-pid=\"SVeQq6ki\"\u003e什么东西是‘完整’的，‘系统’的，我说这些都是糊涂观念。不同的对象，应该有不同的学习方法。对自然科学的学习，是应该比较系统的。对社会科学，则不一定。\u003c/li\u003e\u003cli data-pid=\"lee6syvS\"\u003e我们要站在书上来读书，不要爬在书下来读书。要批判地读，要吸收地读。书应该为我服务，而不是我为书服务。让书牵着鼻子走，我不干。\u003c/li\u003e\u003cli data-pid=\"qIuDmbPS\"\u003e通过做卡片，把分散的论点按问题集中起来。凡属同一内容，同一含义的都要，字句差不多的也要，不要怕重复。只有一两条就记不住，有几十条就可以加深印象。这样学力量就够，才可能。不然力量不够，也不可能，这也要集中精力打歼灭战。\u003c/li\u003e\u003c/ul\u003e","is_labeled":false,"visited_count":124832,"favorite_count":3669,"reaction_instruction":{"REACTION_COMMENT_NEWEST_LIST":"HIDE"},"article_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"article\", \"id\": 603582603}","attached_info":"CqgGCPq2yZP9xtXXnwEQBxoJMjIyMjYxNTgwINCL/J4GKIgIMDtAPkowChtUU19TT1VSQ0VfQkFTSUNfSU5GT19SRUNBTEwSATAYACAAOgp7InJhdyI6IiJ9YiA1OTAxOTkzODk3YjJiNjcxNTM0YjQxZGZlMTcwMzk0N3IJNjAzNTgyNjAzqgEJcmVjb21tZW5kwgEgZTkyZmRiMjc4OTRkZmE3OTJhZjIxMDU4YTVhMGI0MjbyAQoIDBIGTm9ybWFs8gEoCAoSJDM1MDQ1ZGE1LTYwZTktNGJlZi1hMWYzLTQ0NjgwNjZhN2NiN/IBBggLEgIxMYICAIgCyqy5zfoykgIgZTkyZmRiMjc4OTRkZmE3OTJhZjIxMDU4YTVhMGI0MjaaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIWQWN0aW9uU2hvckludGVyZXN0UnVsZcoCG0ludGVyYWN0aW9uU2hvckludGVyZXN0UnVsZcoCFlJldmlzaXRWYWx1ZVdlaWdodFJ1bGXKAhhQZXJpb2RJbnRlcmVzdFdlaWdodFJ1bGXKAhVVc2VyTGNuRXhpdFdlaWdodFJ1bGXKAhRDb250ZW50QWdlV2VpZ2h0UnVsZcoCF1Rlc3RlZEFuZFdvcmtXZWlnaHRSdWxl2gIbVFNfU09VUkNFX0JBU0lDX0lORk9fUkVDQUxM6AIC+gILTk9STUFMX0ZMT1eKAyBkYTQ5ZjJhOGI0NGI0NWEzYWYyNGU0NThhZDJmNDBiMpoDDQoCdjIQABoFb3RoZXKoA6DPB9gDAOoDEWJhc2ljX2luZm9fcmVjYWxs+gMfEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERYAEAIgEAJIEBk5vcm1hbJoEATKgBACoBACwBAC6BAZtYW51YWzCBAMxNzDIBADSBA/mjqjojZDlt7Lmm7TmlrDYBADwBAD5BAAAAGCNlMg/gQUAAAAAAAAAAIkFWhKVCKSs0j+SBQCaBQNkZnSiBQNkZnSyBQExuQUAAAAAAAAAANAFAOAFAOgFAPAFC5AGAKAGQqgGAJICJAoJMjIyMjYxNTgwEgk2MDM1ODI2MDMYByIKSU1BR0VfVEVYVA==","action_card":false},{"id":"63_1750898464.4","type":"feed","offset":63,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750898464,"updated_time":1750898464,"target":{"id":"1897298439471073252","type":"answer","url":"https://api.zhihu.com/answers/1897298439471073252","author":{"id":"7ea6322f7ea810bd44f5ba58b2524a25","url":"https://api.zhihu.com/people/7ea6322f7ea810bd44f5ba58b2524a25","user_type":"people","url_token":"sonofabitch","name":"哈五高","headline":"逻辑能解释一切","avatar_url":"https://picx.zhimg.com/50/v2-3f578602ba4784fd4659ed74ab4724f5_l.jpg?source=b6762063","is_org":false,"gender":1,"followers_count":5848,"is_following":false,"is_followed":false},"created_time":1745131198,"updated_time":1747664764,"voteup_count":1529,"thanks_count":65,"comment_count":710,"is_copyable":true,"question":{"id":"867751968","type":"question","url":"https://api.zhihu.com/questions/867751968","author":{"id":"407c39a2d035fd6e8de7ad4a9462151e","url":"https://api.zhihu.com/people/407c39a2d035fd6e8de7ad4a9462151e","user_type":"people","url_token":"shanxia-23","name":"鹏翼","headline":"","avatar_url":"https://picx.zhimg.com/50/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":768,"is_following":false,"is_followed":false},"title":"为什么特斯拉坚持用纯视觉智驾？","created":1728863302,"answer_count":0,"follower_count":0,"comment_count":6,"bound_topic_ids":[28480,169215,2091567,2269969,3723218],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"有一片沙滩。 有人愿意花十年时间，投入几百亿研究沙子，然后用整个沙滩上取之不尽沙子来打造芯片，点沙成金。 有人只想快速变现赚钱，他们既没有几百亿也等不了十年，就只能在沙滩上捡贝壳卖钱。 为了让人相信贝壳比芯片值钱，后者就花大钱推广贝壳，然后把芯片贬低成沙子。 久而久之，在后者受众眼里，那些芯片的成本就是一堆沙子。 贝壳当然比沙子值钱。 于是那些花大钱买芯片的人都成了傻子。 直到有一天大家都用上了电脑和…","excerpt_new":"有一片沙滩。 有人愿意花十年时间，投入几百亿研究沙子，然后用整个沙滩上取之不尽沙子来打造芯片，点沙成金。 有人只想快速变现赚钱，他们既没有几百亿也等不了十年，就只能在沙滩上捡贝壳卖钱。 为了让人相信贝壳比芯片值钱，后者就花大钱推广贝壳，然后把芯片贬低成沙子。 久而久之，在后者受众眼里，那些芯片的成本就是一堆沙子。 贝壳当然比沙子值钱。 于是那些花大钱买芯片的人都成了傻子。 直到有一天大家都用上了电脑和…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"86qLcU8x\"\u003e有一片沙滩。\u003c/p\u003e\u003cp data-pid=\"kAKzPMNv\"\u003e有人愿意花十年时间，投入几百亿研究沙子，然后用整个沙滩上取之不尽沙子来打造芯片，点沙成金。\u003c/p\u003e\u003cp data-pid=\"gAB2R5BK\"\u003e有人只想快速变现赚钱，他们既没有几百亿也等不了十年，就只能在沙滩上捡贝壳卖钱。\u003c/p\u003e\u003cp data-pid=\"SsBo2mEW\"\u003e为了让人相信贝壳比芯片值钱，后者就花大钱推广贝壳，然后把芯片贬低成沙子。\u003c/p\u003e\u003cp data-pid=\"H8OCkMhU\"\u003e久而久之，在后者受众眼里，那些芯片的成本就是一堆沙子。\u003c/p\u003e\u003cp data-pid=\"mSnhqQVM\"\u003e贝壳当然比沙子值钱。\u003c/p\u003e\u003cp data-pid=\"2SK-ZjfB\"\u003e于是那些花大钱买芯片的人都成了傻子。\u003c/p\u003e\u003cp data-pid=\"bo7O8LMN\"\u003e直到有一天大家都用上了电脑和手机。\u003c/p\u003e\u003chr/\u003e\u003cp data-pid=\"W6Xuy1Xh\"\u003e两个结论：\u003c/p\u003e\u003cp data-pid=\"DUMIGuqf\"\u003e1.“室外光子密度下限”远高于“雷达点云密度上限”。\u003c/p\u003e\u003cp data-pid=\"iD0GoYP_\"\u003e2.成本不变，“CMOS成像方案的信噪比提升速度”高于“雷达点云密度提升速度”。\u003c/p\u003e\u003cp data-pid=\"WuonU4-K\"\u003e就跟星舰不用碳纤维钛铝合金，而去用不锈钢的逻辑是一样的。前者在这片沙滩上看到的不是贝壳和沙子，而是真空管和晶体管，是雷达点云密度和光子密度。\u003c/p\u003e\u003cp data-pid=\"TriHX-LF\"\u003e根据我的理解，所谓“自动驾驶”大致分为“对外部信息的获取”和“对自身行为的规划”两部分。\u003c/p\u003e\u003cp data-pid=\"TBisZlhX\"\u003e而“纯视觉”和“雷达”两个方案主要涉及“对外部信息的获取”这部分。\u003c/p\u003e\u003cp data-pid=\"62ZmPtYE\"\u003e试着以第一性原理去分析。\u003c/p\u003e\u003cp data-pid=\"wVZpyP_K\"\u003e“广义上的亮度”与“单位面积上的光子密度”成正比。\u003c/p\u003e\u003cp data-pid=\"kuVBqLv2\"\u003e而即便是在漆黑的夜晚，哪怕人的肉眼几乎无法看见任何东西，理论上室外的光子密度依然远高于最先进的激光雷达能够达到的点云密度上限好几个数量级。\u003c/p\u003e\u003cp data-pid=\"DKUt-VxG\"\u003e雷达是把激光或者毫米波投射到物体上再反射回来，\u003cb\u003e检测到物体的“外形”和“距离”两大信息\u003c/b\u003e，从而构建出一个3D点云。\u003c/p\u003e\u003cp data-pid=\"PUOIO1U9\"\u003e而cmos是通过捕获从车灯路灯，天上的太阳和星星发出来的光射到物体上再反射到摄像头，生成一帧帧2d图像，再通过不同角度的摄像头的图像组合，\u003cb\u003e推测出物体的“外形”和“距离”两大信息\u003c/b\u003e，最后生成一个3D场景。\u003c/p\u003e\u003cp data-pid=\"Pr_c37CT\"\u003e虽然成像精度也取决于摄像头的动态范围，曝光长度，光电转换效率，还有光的波长等因素，但可以说\u003cb\u003e“单位面积上的光子密度”决定了cmos成像精度的上限\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"_Zmld0kQ\"\u003e关键就在于cmos感光成像方案在捕获光子信号时会产生噪点，而且对3D空间的感知高度依赖于AI大模型和多目摄像头3D重建算法的支持。\u003c/p\u003e\u003cp data-pid=\"wlK9KYYg\"\u003e而现在主流的雷达对3D空间的感知方案更加成熟稳定，技术门槛更低，相比摄像头，更容易构建出一个粗糙，低帧率但相对可靠的3D空间。\u003c/p\u003e\u003cp data-pid=\"Fh5d1DZT\"\u003e\u003cb\u003e相比这种高识别率却粗糙的3D空间模型，高清彩色图像提供的信息必然远多于前者\u003c/b\u003e，还能能最大限度利用马斯克在AI上的多年积累，让车载电脑不但能“看到”整个环境，\u003cb\u003e不仅仅能让你识别到障碍物，还能更好的去“理解”眼前的一切\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"SqAE5UM0\"\u003e这是个活人还是人形立牌？\u003c/p\u003e\u003cp data-pid=\"l4UQh-uk\"\u003e如果是活人，他现在是打算横穿马路吗？我是否需要减速？\u003c/p\u003e\u003cp data-pid=\"clXYcMle\"\u003e如果他打算横穿马路，那这个人到底是交警还是路人？\u003c/p\u003e\u003cp data-pid=\"o3TV2eDV\"\u003e他的手势到底是让我快走还是让我调头？\u003c/p\u003e\u003cp data-pid=\"32lI9ORY\"\u003e我该不该听他的？\u003c/p\u003e\u003cp data-pid=\"8TTdTzjl\"\u003e\u003cb\u003e越是对自己视觉处理能力没信心，才会越强调雷达方案提供的下限保障\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"C2u7WQzt\"\u003e但是当你有信心确保自己的视觉处理能力下限能够超越雷达方案的上限，你追求的就不再是“如何轻松辨别出障碍物”，而是“如何理解这个场景里的一切，帮助我更好的做出决策”，那你自然就不再需要雷达了。\u003c/p\u003e\u003cp data-pid=\"GUW6Xjwa\"\u003e咱们国内的“高科技”企业，基本都是对欧美那些经过大量试错最终得到市场检验的行业，在国内进行排外式的复刻（大疆和抖音可能是唯二的例外）。\u003c/p\u003e\u003cp data-pid=\"cfysukOn\"\u003e而且由于环境特殊，高科技行业里经常能看到大量打着对标欧美前沿领域旗号的“民族企业”，但凡你稍加了解，很容易发现其实就是靠炒作营销来骗补贴。\u003c/p\u003e\u003cp data-pid=\"SsOAHAJg\"\u003e根据这个逻辑，你会发现咱们的很多“高科技”企业在各种技术路线中，往往不优先考虑未来的发展上限。\u003c/p\u003e\u003cp data-pid=\"6zFjc6ct\"\u003e咱们的创业者想的往往是如何最快速度达到60分及格，先确保一个稳定的下限，然后就开启萨哈夫模式卖货赚钱，营销预算甚至高于研发预算，在前期的优势环节跟对手的劣势进行各种对比，后期利用信息差依然能大赢特赢，直到被上限更高的对手全面超越，然后黯然退场，选择卷款跑路或者换一条赛道继续赢。\u003c/p\u003e\u003cp data-pid=\"D86v9Fgi\"\u003e尤其可以观察马斯克涉及的那几条赛道，电车和FSD就不说了，什么paypal啊，星舰啊，星链啊，筷子夹火箭啊，脑机接口啊，机器人啊，你都能在国内找到一堆正在“弯道超车”的亲戚。\u003c/p\u003e\u003cp data-pid=\"QK4DMdMt\"\u003e咱们一直在用前期英雄错位“碾压”对手的后期英雄，只考虑前期场面好看，方便你吹牛逼骗补贴骗投资，而完全不考虑最后比赛输赢。\u003c/p\u003e\u003cp data-pid=\"zMxuM3Kh\"\u003e什么“弯道超车”啦，“遥遥领先”啦，其实都是这种语境下的宣传口号。\u003c/p\u003e\u003cp data-pid=\"CM0lR7SM\"\u003e别看现在那些“新势力”一个个说自己如何朝着L5智驾努力，万一那一天特斯拉真的率先推出L4，L5智驾，承诺由特斯拉承担全程事故责任，国内这帮车企大概率会180度调头，联合抵制一切超过L3的智驾，开始宣扬“自动驾驶不安全”“辅助驾驶永远只能辅助人类”的口号。\u003c/p\u003e\u003cp data-pid=\"j0zqgrhK\"\u003e得不到这个市场，那就必须毁了它。\u003c/p\u003e\u003cp data-pid=\"vtoFLqwx\"\u003e稍有一些常识，就知道本质上并不是“雷达比摄像头安全”。\u003c/p\u003e\u003cp data-pid=\"dOomf8ah\"\u003e而是“通过雷达点云重建3D空间”比“通过算法分析光子重建3D空间”更简单，相关技术更成熟，前期的研发投入，算力中心等基建投入更少。\u003c/p\u003e\u003cp data-pid=\"FY-k5WM2\"\u003e学自行车肯定比考驾照简单，还不用花钱培训，可能你已经往前骑行3天了，人家才刚刚考上驾照。\u003c/p\u003e\u003cp data-pid=\"E3Nouv3Z\"\u003e但人家开车3小时就能追上你，然后远远把你抛在身后。\u003c/p\u003e\u003cp data-pid=\"sYT5WE3Q\"\u003e回到这个问题，“为什么特斯拉坚持用纯视觉智驾？”\u003c/p\u003e\u003cp data-pid=\"LUCWC0JB\"\u003e我想说如果基于cmos成像方案的摄像头画面清晰程度，取决于将光子转化为电子过程中的信噪比。\u003c/p\u003e\u003cp data-pid=\"-KPlYXgy\"\u003e那么两者的应用前景基本取决于：\u003c/p\u003e\u003cp data-pid=\"25CNmOJI\"\u003e在成本不变的情况下，未来“人类前沿领域在相同光子密度下成像信噪比的提升速度”，与“人类前沿领域对激光雷达和相控阵雷达点云密度的提升速度”哪个更快。\u003c/p\u003e\u003cp data-pid=\"C19-1Lnw\"\u003e至少根据当前的技术发展，以及未来可预见的趋势来看，“CMOS成像方案的信噪比提升速度”显然是要快于“激光雷达和相控阵雷达点云密度提升速度”的。\u003c/p\u003e\u003cp data-pid=\"T8PTFz2i\"\u003e我的判断依据是，前者可以通过“制程工艺”，“材料学”和“AI算法”等方式对\u003cb\u003e收集端进一步迭代提升\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"fpXN2slh\"\u003e而后者已经能看到比如“转速”“散热”“最大帧率”等\u003cb\u003e发射端的根本限制\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"oKbwbzVt\"\u003e在“对外部信息的获取”上，\u003cb\u003e“雷达”等于是主动抛弃了大自然里免费的海量光学信息，抛弃了整片沙滩上取之不尽的沙子，把信息量上限局限到了自身的发射端，也就是那几个贝壳上\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"GydX9WJg\"\u003e那么马斯克更看好纯视觉，而非雷达的态度，也就不难理解了。\u003c/p\u003e\u003cp data-pid=\"v7wFIRBq\"\u003e时间，将是纯视觉方案最好的伙伴。\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":226595,"favorite_count":737,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1897298439471073252}","attached_info":"CrAGCPq2yZP9xtXXnwEQBBoJNzIzNzUwMDgyIL6tksAGKPkLMMYFQD9KMAobVFNfU09VUkNFX0JBU0lDX0lORk9fUkVDQUxMEgEwGAAgADoKeyJyYXciOiIifVoJMTExMTM1OTg1YiA1OTAxOTkzODk3YjJiNjcxNTM0YjQxZGZlMTcwMzk0N3ITMTg5NzI5ODQzOTQ3MTA3MzI1MooBCTg2Nzc1MTk2OKoBCXJlY29tbWVuZMIBIDdlYTYzMjJmN2VhODEwYmQ0NGY1YmE1OGIyNTI0YTI18gEKCAwSBk5vcm1hbPIBKAgKEiQ1MjUzNGNiNi1iNTM3LTQ5NTUtOTY1Ny0zMTlmOGRiMzAwMGTyAQYICxICMTGCAgCIAsqsuc36MpICIDdlYTYzMjJmN2VhODEwYmQ0NGY1YmE1OGIyNTI0YTI1mgIAygIWU2hvckludGVyZXN0V2VpZ2h0UnVsZcoCFkFjdGlvblNob3JJbnRlcmVzdFJ1bGXKAhtJbnRlcmFjdGlvblNob3JJbnRlcmVzdFJ1bGXKAhZSZXZpc2l0VmFsdWVXZWlnaHRSdWxlygIYUGVyaW9kSW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygIUQ29udGVudEFnZVdlaWdodFJ1bGXaAhtUU19TT1VSQ0VfQkFTSUNfSU5GT19SRUNBTEzoAgP6AgtOT1JNQUxfRkxPV4oDIGRhNDlmMmE4YjQ0YjQ1YTNhZjI0ZTQ1OGFkMmY0MGIymgMNCgJ2MhAAGgVvdGhlcqgDo+oN2AMA6gMRYmFzaWNfaW5mb19yZWNhbGz6Ax8SDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFgAQAiAQAkgQGTm9ybWFsmgQBM6AEAKgEALAEALoEBm1hbnVhbMIEAzE2MMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAgKNBwz+BBQAAAAAAAAAAiQVaEpUIpKzSP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AULkAYAoAZDqAYAkgIuCgk3MjM3NTAwODISEzE4OTcyOTg0Mzk0NzEwNzMyNTIYBCIKSU1BR0VfVEVYVA==","action_card":false},{"id":"64_1750898464.83","type":"feed","offset":64,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750898464,"updated_time":1750898464,"target":{"id":"1921220878567449158","type":"answer","url":"https://api.zhihu.com/answers/1921220878567449158","author":{"id":"786abb58bed6418a143d856bd17886a4","url":"https://api.zhihu.com/people/786abb58bed6418a143d856bd17886a4","user_type":"people","url_token":"xiao-tian-shi-91-95-42","name":"意升","headline":"爱看书，爱看电影，爱写感悟！","avatar_url":"https://pic1.zhimg.com/50/v2-3b024ba421bf229a0d2829e5ea619bf2_l.jpg?source=b6762063","is_org":false,"gender":1,"badge":[{"type":"identity_people","description":"英格玛（上海）企业服务外包有限公司 员工"}],"followers_count":1439,"is_following":false,"is_followed":false},"created_time":1750834752,"updated_time":1750834752,"voteup_count":3,"thanks_count":1,"comment_count":0,"is_copyable":false,"question":{"id":"1889620823519766303","type":"question","url":"https://api.zhihu.com/questions/1889620823519766303","author":{"id":"d8114fb4877269a0ec78198b9ce54680","url":"https://api.zhihu.com/people/d8114fb4877269a0ec78198b9ce54680","user_type":"people","url_token":"he-he-72-74-80","name":"呵呵","headline":"","avatar_url":"https://pica.zhimg.com/50/v2-8b4dd85f10e3037b14a550f06b8f8c19_l.jpg?source=b6762063","is_org":false,"gender":0,"followers_count":6,"is_following":false,"is_followed":false},"title":"想买书来打发无聊的时光，有什么好书推荐？","created":1743300711,"answer_count":0,"follower_count":0,"comment_count":0,"bound_topic_ids":[23139,1322883,1324569],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"excerpt":"推荐你看《隐谷路:一个精神分裂症家族的绝望与希望》。 这是一本纪实的书籍，详细全面记录了加尔文一家人的生活轨迹。他们虽然被各种困难缠身，尤其是精神分裂症的严重影响。可谓一路走来，荆棘满布，很多时候几乎把加尔文一家逼入绝境。但实际上，他们却坚强地活了下来，每一个家庭成员，用自己的方式，过着生活。疗愈，沉沦，绝望与希望。 另外值得一提的是，这一家人的存在，对于精神分裂症的攻克有着非同一般的作用。读这本…","excerpt_new":"推荐你看《隐谷路:一个精神分裂症家族的绝望与希望》。 这是一本纪实的书籍，详细全面记录了加尔文一家人的生活轨迹。他们虽然被各种困难缠身，尤其是精神分裂症的严重影响。可谓一路走来，荆棘满布，很多时候几乎把加尔文一家逼入绝境。但实际上，他们却坚强地活了下来，每一个家庭成员，用自己的方式，过着生活。疗愈，沉沦，绝望与希望。 另外值得一提的是，这一家人的存在，对于精神分裂症的攻克有着非同一般的作用。读这本…","preview_type":"default","preview_text":"","reshipment_settings":"disallowed","content":"\u003cp data-pid=\"-rlXRc0x\"\u003e推荐你看《隐谷路:一个精神分裂症家族的绝望与希望》。\u003c/p\u003e\u003cp data-pid=\"qIKfoGkb\"\u003e这是一本纪实的书籍，详细全面记录了加尔文一家人的生活轨迹。他们虽然被各种困难缠身，尤其是精神分裂症的严重影响。可谓一路走来，荆棘满布，很多时候几乎把加尔文一家逼入绝境。但实际上，他们却坚强地活了下来，每一个家庭成员，用自己的方式，过着生活。疗愈，沉沦，绝望与希望。\u003c/p\u003e\u003cp data-pid=\"16GASy9J\"\u003e另外值得一提的是，这一家人的存在，对于精神分裂症的攻克有着非同一般的作用。读这本书，除了看到加尔文一家的生活轨迹，体验他们的希望和绝望。也对比自己的生活，更加自信，更加积极寻找自己的存在的意义。\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":33,"favorite_count":0,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1921220878567449158}","attached_info":"CtsFCPq2yZP9xtXXnwEQBBoJNzMzOTQ1NjkzIMC87sIGKAMwAEBASiQKGVRTX1NPVVJDRV9XQVJNX1VQX05PUk1BTDISATAYACAAOgBKIgoXVFNfU09VUkNFX1dBUk1VUF9SVUNFTkUSATAYACAAOgBaCTExNDI0MjAxM2IgNTkwMTk5Mzg5N2IyYjY3MTUzNGI0MWRmZTE3MDM5NDdyEzE5MjEyMjA4Nzg1Njc0NDkxNTiKARMxODg5NjIwODIzNTE5NzY2MzAzqgEJcmVjb21tZW5kwgEgNzg2YWJiNThiZWQ2NDE4YTE0M2Q4NTZiZDE3ODg2YTTyAQoIDBIGTm9ybWFs8gEoCAoSJDUxMDhhMTE3LTg3N2YtNGJkMC1iYjBmLTBkMWI2MzM0OTg3YfIBBggLEgIxMYICAIgCyqy5zfoykgIgNzg2YWJiNThiZWQ2NDE4YTE0M2Q4NTZiZDE3ODg2YTSaAgDKAhZTaG9ySW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygIYQ29udGVudFdhcm1VcEJyZWFrSW5SdWxl2gIZVFNfU09VUkNFX1dBUk1fVVBfTk9STUFMMugCAvoCC05PUk1BTF9GTE9XigMgZGE0OWYyYThiNDRiNDVhM2FmMjRlNDU4YWQyZjQwYjKaAw0KAnYyEAAaBW90aGVyqAMh2AMA6gMLdGV4dF9ydWNlbmX6Ax8SDFVOS05PV05fTU9ERSAAKg1OT19JTUFHRV9NT0RFgAQAiAQAkgQGTm9ybWFsmgQBMqAEAKgEALAEALoEAmFpwgQDNDAwyAQA0gQP5o6o6I2Q5bey5pu05paw2AQA8AQA+QQAAAAgQF6hP4EFAAAAAAAAAACJBVoSlQikrNI/kgUAmgUDZGZ0ogUDZGZ0sgUBMbkFAAAAAAAAAADQBQDgBQDoBQDwBQuQBgCgBkSoBgGSAi4KCTczMzk0NTY5MxITMTkyMTIyMDg3ODU2NzQ0OTE1OBgEIgpJTUFHRV9URVhU","action_card":false},{"id":"65_1750898464.708","type":"feed","offset":65,"verb":"TOPIC_ACKNOWLEDGED_ANSWER","created_time":1750898464,"updated_time":1750898464,"target":{"id":"1907718327259861976","type":"answer","url":"https://api.zhihu.com/answers/1907718327259861976","author":{"id":"2ddc134b2d6bcde89f883e4c051f1bc2","url":"https://api.zhihu.com/people/2ddc134b2d6bcde89f883e4c051f1bc2","user_type":"people","url_token":"ke-ke-neng-xing","name":"晏北","headline":"公众号——晏北，理解芯片，理解经济","avatar_url":"https://picx.zhimg.com/50/v2-a0874375d3926d8580eec8f4e8de3ce1_l.jpg?source=b6762063","is_org":false,"gender":1,"badge":[{"type":"best_answerer","description":"职场话题下的优秀答主","topic_names":["职场"],"topic_ids":[2566]},{"type":"super_activity","description":"知势榜职场领域成长力榜答主"}],"followers_count":5360,"is_following":false,"is_followed":false},"created_time":1747615492,"updated_time":1747621507,"voteup_count":12,"thanks_count":0,"comment_count":13,"is_copyable":true,"question":{"id":"428730647","type":"question","url":"https://api.zhihu.com/questions/428730647","author":{"id":"578d0e2464faeb326ebc06cd0b6de36b","url":"https://api.zhihu.com/people/578d0e2464faeb326ebc06cd0b6de36b","user_type":"people","url_token":"qing-feng-44-51","name":"清风","headline":"","avatar_url":"https://pica.zhimg.com/50/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=b6762063","is_org":false,"gender":-1,"followers_count":0,"is_following":false,"is_followed":false},"title":"辞职在家搞自媒体现实吗？","created":1604459481,"answer_count":0,"follower_count":0,"comment_count":11,"bound_topic_ids":[307,2566,68370,123355,32797],"is_following":false,"excerpt":"","relationship":{"is_author":false},"detail":"","question_type":"normal"},"thumbnail":"https://pic1.zhimg.com/50/v2-6b9615ee6071b59947b978296a0d6b0a_720w.jpg?source=b6762063","excerpt":"昨天， 在逍遥津，一晤大V @大成职场 ，这段经历，对想从事自媒体的朋友，也许有所启发。 周末，回老家，参加同学婚礼， 见证10年前就认识的两个家伙，走进新生活，很奇妙的感觉。早上八点，动身返宁， 在逍遥津公园，和一位 上市公司前高管，如今的知乎大V，聊了几小时，   大V说：你这家伙，看文章，以为至少三十多岁，没想到这么年轻， 我说：俺的文字比较早熟，一见面，就原形毕露，你啥时候开始搞自媒体？ 大V说：1年前，当时…","excerpt_new":"昨天， 在逍遥津，一晤大V @大成职场 ，这段经历，对想从事自媒体的朋友，也许有所启发。 周末，回老家，参加同学婚礼， 见证10年前就认识的两个家伙，走进新生活，很奇妙的感觉。早上八点，动身返宁， 在逍遥津公园，和一位 上市公司前高管，如今的知乎大V，聊了几小时，   大V说：你这家伙，看文章，以为至少三十多岁，没想到这么年轻， 我说：俺的文字比较早熟，一见面，就原形毕露，你啥时候开始搞自媒体？ 大V说：1年前，当时…","preview_type":"default","preview_text":"","reshipment_settings":"allowed","content":"\u003cp data-pid=\"nXP2Lk2R\"\u003e昨天，\u003cb\u003e在逍遥津，一晤大V\u003c/b\u003e \u003ca class=\"member_mention\" href=\"https://www.zhihu.com/people/dc810723af6326722801a4f8829b589f\" data-hash=\"dc810723af6326722801a4f8829b589f\" data-hovercard=\"p$b$dc810723af6326722801a4f8829b589f\"\u003e@大成职场\u003c/a\u003e ，\u003c/p\u003e\u003cp data-pid=\"TSuMd-PH\"\u003e这段经历，对想从事自媒体的朋友，也许有所启发。\u003c/p\u003e\u003cp data-pid=\"GsO3udZL\"\u003e周末，回老家，参加同学婚礼，\u003c/p\u003e\u003cp data-pid=\"Jxsm4Sy0\"\u003e\u003cb\u003e见证10年前就认识的两个家伙，走进新生活\u003c/b\u003e，很奇妙的感觉。\u003c/p\u003e\u003cp data-pid=\"fSRP6IXb\"\u003e早上八点，动身返宁，\u003c/p\u003e\u003cp data-pid=\"x3juHf7e\"\u003e在逍遥津公园，和一位\u003cb\u003e上市公司前高管，如今的知乎大V，\u003c/b\u003e聊了几小时，\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://picx.zhimg.com/v2-022f872f82a8250d7cd6dd31d77a213d_1440w.jpg\" data-rawwidth=\"402\" data-rawheight=\"306\" data-size=\"normal\" data-original-token=\"v2-e37f5c68e4e87f7b2dc1a58eff5f645a\" data-default-watermark-src=\"https://pic4.zhimg.com/v2-92320e9e3cd2fe1be8b712ed923e48a3_b.jpg\" class=\"content_image\" width=\"402\"/\u003e\u003cfigcaption\u003e图片来源：网络\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"0Jun35ao\"\u003e\u003cb\u003e大V说：\u003c/b\u003e你这家伙，\u003cb\u003e看文章，以为至少三十多岁，没想到这么年轻\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"fii0FOh0\"\u003e\u003cb\u003e我说：俺的文字比较早熟，一见面，就原形毕露\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"zl1qFePP\"\u003e你啥时候开始搞自媒体？\u003c/p\u003e\u003cp data-pid=\"k--MKeUI\"\u003e\u003cb\u003e大V说：\u003c/b\u003e1年前，\u003c/p\u003e\u003cp data-pid=\"L3BA8F0B\"\u003e当时，我从前东家辞职，\u003cb\u003e在朋友公司，挂了个顾问\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"3WRV7iRA\"\u003e不用天天上班，很闲，\u003c/p\u003e\u003cp data-pid=\"3KN7E4bA\"\u003e另一朋友说，\u003cb\u003e你在职场混了这么多年，小有所成，不如将这些经验，写成文章，分享到网上\u003c/b\u003e，还能赚点钱，\u003c/p\u003e\u003cp data-pid=\"GTDsoJK2\"\u003e闲着也是闲着，就开始写知乎。\u003c/p\u003e\u003cp data-pid=\"rGooXu0O\"\u003e没想到，\u003cb\u003e难度超乎想象\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"-nUDkL2s\"\u003e起初半年，基本没挣到钱，搞得我很焦虑，\u003c/p\u003e\u003cp data-pid=\"onlmjjH6\"\u003e\u003cb\u003e在商业世界看来，不能变现的东西，毫无价值\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"q8gQmaJ-\"\u003e难道我引以为傲的职业生涯，如此不值一提？\u003c/p\u003e\u003cp data-pid=\"zYGCOsok\"\u003e所幸，我没有放弃，\u003cb\u003e每天坚持更新，才有了现在的用户数量和收入\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"y5IHEWsV\"\u003e\u003cb\u003e我说：\u003c/b\u003e起步的艰难，感同身受，\u003c/p\u003e\u003cp data-pid=\"O2C6aK21\"\u003e再看这个过程，感触最深的是什么？\u003c/p\u003e\u003cp data-pid=\"09ZIIFau\"\u003e\u003cb\u003e大V说：\u003c/b\u003e最大的感受，是\u003cb\u003e内容质量\u003c/b\u003e的重要性，\u003c/p\u003e\u003cp data-pid=\"GNpD1-Zd\"\u003e一开始，有些误入歧途，\u003c/p\u003e\u003cp data-pid=\"tFuBJIG7\"\u003e\u003cb\u003e和其他创作者，互动过于频繁，\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"ZR7nu1cj\"\u003e坚持半年，才慢慢体会到，质量的重要性，\u003c/p\u003e\u003cp data-pid=\"ZeWWri4Z\"\u003e产生一种意识，\u003cb\u003e每个看我文章的家伙，都是我的客户\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"YjBuBKh5\"\u003e他们需要的，也许是管理经验，也许是对付领导的方法，\u003c/p\u003e\u003cp data-pid=\"8eQyffzT\"\u003e总之，我必须提供些干货，\u003cb\u003e能够真正对客户产生帮助的干货\u003c/b\u003e，这大概就是知乎提倡的“\u003cb\u003e获得感\u003c/b\u003e”。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-5d9e277f87485282992448c4ef6b57bf_1440w.jpg\" data-rawwidth=\"1200\" data-rawheight=\"662\" data-size=\"normal\" data-original-token=\"v2-db97cc8e03ac7751a62f6417e4c21a78\" data-default-watermark-src=\"https://pic2.zhimg.com/v2-934396da73a110befa5074984c0e519b_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1200\" data-original=\"https://pic2.zhimg.com/v2-5d9e277f87485282992448c4ef6b57bf_r.jpg\"/\u003e\u003cfigcaption\u003e图片来源：网络\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"llk8Tb21\"\u003e\u003cb\u003e我说：\u003c/b\u003e非常认同，\u003c/p\u003e\u003cp data-pid=\"4aZ3Jwbt\"\u003e我最大的感受，是要\u003cb\u003e用产品思维，写文章，\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"1WaNmQzg\"\u003e一开始，想到哪写到哪，觉得表达自我最重要，\u003c/p\u003e\u003cp data-pid=\"WQTWCRA8\"\u003e慢慢意识到，自媒体文章，不是这个逻辑，\u003c/p\u003e\u003cp data-pid=\"7BnHt0PH\"\u003e你不能随心所欲，而是应该\u003cb\u003e用制作产品的严谨性，制作文章\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"_tEL8uBq\"\u003e什么是好产品？\u003c/p\u003e\u003cp data-pid=\"9agdBbB3\"\u003e\u003cb\u003e创造性+标准化\u003c/b\u003e，缺一不可，\u003c/p\u003e\u003cp data-pid=\"B19jGNuv\"\u003e以芯片产品为例，\u003c/p\u003e\u003cp data-pid=\"ps18NdWj\"\u003e芯片结构设计，需要\u003cb\u003e创造性\u003c/b\u003e，以实现\u003cb\u003e性能突破\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"onD9NmYr\"\u003e实际制作工艺，需要\u003cb\u003e标准化\u003c/b\u003e，以确保\u003cb\u003e稳定生产\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"GyMU1WEs\"\u003e\u003cb\u003e内容产品\u003c/b\u003e，也是这个逻辑，\u003c/p\u003e\u003cp data-pid=\"SvyLT463\"\u003e\u003cb\u003e具体内容\u003c/b\u003e，可以有天马行空的想象力，这是\u003cb\u003e创造性\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"cjFKBcMs\"\u003e\u003cb\u003e表现形式\u003c/b\u003e，必须符合基本的传播规律，这是\u003cb\u003e标准化\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"RcV59Y3V\"\u003e\u003cb\u003e大V问：\u003c/b\u003e具体解释一下传播规律？\u003c/p\u003e\u003cp data-pid=\"Yx6hvU0Y\"\u003e\u003cb\u003e我说：\u003c/b\u003e比如，提供情绪价值，\u003c/p\u003e\u003cp data-pid=\"AamU5oq6\"\u003e\u003cb\u003e我曾经以为，只要内容质量足够好，不愁没人看\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"6b4GNJ20\"\u003e后来才发现，不是这么回事，\u003c/p\u003e\u003cp data-pid=\"T7vVGg9h\"\u003e\u003cb\u003e学术性与传播性，是此消彼长的两极\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"aCsEpsMb\"\u003e大家工作之余，看个文章，多数只图一乐，\u003c/p\u003e\u003cp data-pid=\"OzksjcPf\"\u003e你要是长篇大论，各种学术名词堆积，没人看得下去，\u003c/p\u003e\u003cp data-pid=\"qcin3tbY\"\u003e最好的文章，\u003cb\u003e是在逗你开心的同时，引人深思\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"1tzE3gS5\"\u003e换言之，\u003cb\u003e兼具功能价值和情绪价值\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"OkvNRpkx\"\u003e六神磊磊，便是此中高手，非常牛逼。\u003c/p\u003e\u003cp data-pid=\"H6uYxkqd\"\u003e\u003cb\u003e幽默的本质，是只需20%的CPU，便能轻松论述问题\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"WrKdhUEU\"\u003e剩下的算力，用来逗汝一笑，\u003c/p\u003e\u003cp data-pid=\"PO5HtxOx\"\u003e\u003cb\u003e这，才是玩弄文字的高手，才是真正高级的能力\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"G7lAQBsF\"\u003e\u003cb\u003e大V说：\u003c/b\u003e难怪你的文章，每篇都有好玩的图，\u003c/p\u003e\u003cp data-pid=\"LKdjUu8o\"\u003e之前就想问你，那些图怎么准备，\u003c/p\u003e\u003cp data-pid=\"atHGyXc6\"\u003e这块，是我的劣势。\u003c/p\u003e\u003cp data-pid=\"zU63atRX\"\u003e\u003cb\u003e我说：\u003c/b\u003e咱俩打法不同，\u003c/p\u003e\u003cp data-pid=\"PozBPgGx\"\u003e你侧重于量，我侧重于质，\u003c/p\u003e\u003cp data-pid=\"xmoJFlbW\"\u003e\u003cb\u003e如果一篇文章花的时间过长，势必要牺牲数量\u003c/b\u003e，这是每个创作者都要面对的取舍问题。\u003c/p\u003e\u003cp data-pid=\"2MjFxS1S\"\u003e你现在，已获自由身，不考虑做视频？\u003c/p\u003e\u003cp data-pid=\"Iz5Bsmrr\"\u003e图文领域的流量，还是太低。\u003c/p\u003e\u003cp data-pid=\"9gx7TIlc\"\u003e\u003cb\u003e大V说：\u003c/b\u003e正在筹划，迟早会做，\u003c/p\u003e\u003cp data-pid=\"WzgmTNxQ\"\u003e你这家伙，\u003cb\u003e眉清目秀，逻辑清晰，知识储备让人惊叹\u003c/b\u003e，不考虑做视频？\u003c/p\u003e\u003cp data-pid=\"Syr-cv7R\"\u003e\u003cb\u003e我哈哈一笑：\u003c/b\u003e等俺脱离苦海，迟早要走出这一步，到时候，还得请您指点迷津。\u003c/p\u003e\u003cfigure data-size=\"normal\"\u003e\u003cimg src=\"https://pic2.zhimg.com/v2-688daaad63b5689cf69a5aa0b4ed3915_1440w.jpg\" data-rawwidth=\"1080\" data-rawheight=\"737\" data-size=\"normal\" data-original-token=\"v2-cf40eddc7afc96b64dce45b33ebb93cf\" data-default-watermark-src=\"https://pic1.zhimg.com/v2-3019740688a42f68885888bcd9866ac2_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-688daaad63b5689cf69a5aa0b4ed3915_r.jpg\"/\u003e\u003cfigcaption\u003e图片来源：网络\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-pid=\"S5Ngzwrb\"\u003e在高铁上，复盘这段经历，\u003c/p\u003e\u003cp data-pid=\"sCoDRw1-\"\u003e\u003cb\u003e再次体会到，强连接与弱连接的区别\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"Z49oaHhe\"\u003e出生在哪个地区、何样家庭，并非我们能决定。\u003c/p\u003e\u003cp data-pid=\"z-yPHgA3\"\u003e\u003cb\u003e血缘和地缘关系，带来的连接，可称之为强连接\u003c/b\u003e。\u003c/p\u003e\u003cp data-pid=\"H_Qj34Cr\"\u003e七大姑八大姨、同学同乡，都是如此，\u003c/p\u003e\u003cp data-pid=\"Q76K01dR\"\u003e强连接的上限，在考上大学的那刻，基本已经锁定。\u003c/p\u003e\u003cp data-pid=\"n4_Z1eAN\"\u003e\u003cb\u003e素不相识的陌生人，是弱连接\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"542h3Y26\"\u003e每天记录些感悟，扔到网上，吸引一批志同道合、却又位于天南海北的人，\u003c/p\u003e\u003cp data-pid=\"pcot7rC8\"\u003e甚至更进一步，\u003cb\u003e面对面交流，分享不同领域的洞见，寻找原先无法想象的合作机会\u003c/b\u003e，\u003c/p\u003e\u003cp data-pid=\"IqbC4zrH\"\u003e这，便是弱连接的魔力。\u003c/p\u003e\u003cp data-pid=\"EATGC7UH\"\u003e也欢迎各位，私信俺，有机会线下交流，\u003c/p\u003e\u003cp data-pid=\"ZpmZCTUK\"\u003e因为，\u003cb\u003e思想的碰撞，是最令人兴奋的生命体验之一。\u003c/b\u003e\u003c/p\u003e\u003cp data-pid=\"6CtREp7h\"\u003e关注 \u003ca class=\"member_mention\" href=\"https://www.zhihu.com/people/2ddc134b2d6bcde89f883e4c051f1bc2\" data-hash=\"2ddc134b2d6bcde89f883e4c051f1bc2\" data-hovercard=\"p$b$2ddc134b2d6bcde89f883e4c051f1bc2\"\u003e@晏北\u003c/a\u003e，理解芯片与经济~\u003c/p\u003e","relationship":{"is_thanked":false,"is_nothelp":false,"voting":0},"is_labeled":false,"visited_count":454,"thumbnails":["https://pic1.zhimg.com/50/v2-6b9615ee6071b59947b978296a0d6b0a_720w.jpg?source=b6762063","https://pic1.zhimg.com/50/v2-ba92fcf5c320e9c9cb04d264d233ee86_720w.jpg?source=b6762063"],"favorite_count":8,"answer_type":"normal","is_navigator":false,"navigator_vote":false,"vote_next_step":"vote"},"brief":"{\"source\": \"TS\", \"type\": \"answer\", \"id\": 1907718327259861976}","attached_info":"CqIHCPq2yZP9xtXXnwEQBBoJNzI4MDAyMDg5IIT+qcEGKAwwDUBBSigKHVRTX1NPVVJDRV9ORUFSTElORV9DT05URU5UX1YyEgEwGAAgADoAWgg1NzU1Mjc5NGIgNTkwMTk5Mzg5N2IyYjY3MTUzNGI0MWRmZTE3MDM5NDdyEzE5MDc3MTgzMjcyNTk4NjE5NzaKAQk0Mjg3MzA2NDeqAQlyZWNvbW1lbmTCASAyZGRjMTM0YjJkNmJjZGU4OWY4ODNlNGMwNTFmMWJjMvIBCggMEgZOb3JtYWzyASgIChIkYTRhNGJiYzYtNDgyYi00MGYzLThlMmQtNzdiYTQ1ZDkwNDFh8gEGCAsSAjExggIAiALKrLnN+jKSAiAyZGRjMTM0YjJkNmJjZGU4OWY4ODNlNGMwNTFmMWJjMpoCAMoCFlNob3JJbnRlcmVzdFdlaWdodFJ1bGXKAhZBY3Rpb25TaG9ySW50ZXJlc3RSdWxlygIbSW50ZXJhY3Rpb25TaG9ySW50ZXJlc3RSdWxlygIYUGVyaW9kSW50ZXJlc3RXZWlnaHRSdWxlygIVVXNlckxjbkV4aXRXZWlnaHRSdWxlygIUQ29udGVudEFnZVdlaWdodFJ1bGXKAhxCYXllc0ZpcnN0TGV2ZWxJc29sYXRpb25SdWxl2gIdVFNfU09VUkNFX05FQVJMSU5FX0NPTlRFTlRfVjLoAgT6AgtOT1JNQUxfRkxPV4oDIGRhNDlmMmE4YjQ0YjQ1YTNhZjI0ZTQ1OGFkMmY0MGIymgMNCgJ2MhAAGgVvdGhlcqgDxgPYAwD6A6wBEgxVTktOT1dOX01PREUgACoNTk9fSU1BR0VfTU9ERTotCAIQkgMYsgIiI3YyLWUzN2Y1YzY4ZTRlODdmN2IyZGMxYTU4ZWZmNWY2NDVhOi0IAhCwCRiWBSIjdjItZGI5N2NjOGUwM2FjNzc1MWE2MmY2NDE3ZTRjMjFhNzg6LQgDELgIGOEFIiN2Mi1jZjQwZWRkYzdhZmM5NmI2NGRjZTQ1YjMzZWJiOTNjZoAEAIgEAJIEBk5vcm1hbJoEATSgBACoBACwBAC6BAJhacIEAzQwMMgEANIED+aOqOiNkOW3suabtOaWsNgEAPAEAPkEAAAAoDDjxj+BBQAAAAAAAAAAiQVaEpUIpKzSP5IFAJoFA2RmdKIFA2RmdLIFATG5BQAAAAAAAAAA0AUA4AUA6AUA8AULkAYAoAZFqAYAkgIuCgk3MjgwMDIwODkSEzE5MDc3MTgzMjcyNTk4NjE5NzYYBCIKSU1BR0VfVEVYVA==","action_card":false}],"paging":{"is_end":false,"is_start":false,"next":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=down\u0026ad_interval=-10\u0026after_id=65\u0026desktop=true\u0026end_offset=69\u0026page_number=12\u0026session_token=5901993897b2b671534b41dfe1703947","previous":"https://www.zhihu.com/api/v3/feed/topstory/recommend?action=pull\u0026ad_interval=-10\u0026before_id=65\u0026desktop=true\u0026end_offset=69\u0026page_number=12\u0026session_token=5901993897b2b671534b41dfe1703947","totals":0},"fresh_text":"推荐已更新"}
